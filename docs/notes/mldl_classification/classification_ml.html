<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>MLDL 머신러닝 분류 - kNN SVM – 세상의 모든 통계 이야기</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-2757cfadcc89ddbfb9e61569f8c3689f.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">세상의 모든 통계 이야기</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../notes/math_stat/index.html"> 
<span class="menu-text">기초수학·수리통계</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../notes/intro_stat/index.html"> 
<span class="menu-text">기초통계·조사방법</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../notes/linear_model/index.html"> 
<span class="menu-text">회귀·다변량</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../notes/mldl_intro/index.html"> 
<span class="menu-text">MLDL개념</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../notes/mldl_prediction/index.html"> 
<span class="menu-text">MLDL예측</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../../notes/mldl_classification/index.html" aria-current="page"> 
<span class="menu-text">MLDL분류</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../cardnews/index.html"> 
<span class="menu-text">카드뉴스</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../consult.html"> 
<span class="menu-text">통계상담</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../notes/mldl_classification/classification_ml.html">📄 머신러닝 kNN SVM</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">【머신·딥러닝 분류문제】</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/classification_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📄 분류문제: 정의</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/lm_logistic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📄 예측분류-로지스틱회귀</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/mda_discriminant.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📄 예측분류-판별분석</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/prediction_treebase.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📄 예측분류-ML 트리기반</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/classification_ml.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">📄 머신러닝 kNN SVM</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/classification_deeplearning01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📄 딥러닝 분류 파트1</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/classification_deeplearning02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📄 딥러닝 분류 파트2</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/classification_evaluation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📄 분류모델 평가</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">목차</h2>
   
  <ul>
  <li><a href="#chapter-1.-머신러닝-분류-k-nn-svm" id="toc-chapter-1.-머신러닝-분류-k-nn-svm" class="nav-link active" data-scroll-target="#chapter-1.-머신러닝-분류-k-nn-svm">Chapter 1. 머신러닝 분류 (k-NN | SVM)</a>
  <ul>
  <li><a href="#전통적-분류방법과-차이" id="toc-전통적-분류방법과-차이" class="nav-link" data-scroll-target="#전통적-분류방법과-차이">1. 전통적 분류방법과 차이</a></li>
  <li><a href="#규칙-기반k-nn" id="toc-규칙-기반k-nn" class="nav-link" data-scroll-target="#규칙-기반k-nn">2. 규칙 기반(k-NN)</a></li>
  <li><a href="#마진-기반svm" id="toc-마진-기반svm" class="nav-link" data-scroll-target="#마진-기반svm">3. 마진 기반(SVM)</a></li>
  <li><a href="#분할-기반tree-분류-상세-내용-예측모형-강의노트-참고" id="toc-분할-기반tree-분류-상세-내용-예측모형-강의노트-참고" class="nav-link" data-scroll-target="#분할-기반tree-분류-상세-내용-예측모형-강의노트-참고">4. 분할 기반(Tree) 분류 — 상세 내용: 예측모형 강의노트 참고</a></li>
  <li><a href="#결합-기반ensemble-분류-상세-내용-예측모형-강의노트-참고" id="toc-결합-기반ensemble-분류-상세-내용-예측모형-강의노트-참고" class="nav-link" data-scroll-target="#결합-기반ensemble-분류-상세-내용-예측모형-강의노트-참고">5. 결합 기반(Ensemble) 분류 — 상세 내용: 예측모형 강의노트 참고</a></li>
  <li><a href="#사례분석이진분류" id="toc-사례분석이진분류" class="nav-link" data-scroll-target="#사례분석이진분류">6. 사례분석(이진분류)</a></li>
  <li><a href="#사례분석이진분류-회소성공-불균형" id="toc-사례분석이진분류-회소성공-불균형" class="nav-link" data-scroll-target="#사례분석이진분류-회소성공-불균형">7. 사례분석(이진분류, 회소성공-불균형)</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">MLDL 머신러닝 분류 - kNN SVM</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="chapter-1.-머신러닝-분류-k-nn-svm" class="level3">
<h3 class="anchored" data-anchor-id="chapter-1.-머신러닝-분류-k-nn-svm">Chapter 1. 머신러닝 분류 (k-NN | SVM)</h3>
<section id="전통적-분류방법과-차이" class="level4">
<h4 class="anchored" data-anchor-id="전통적-분류방법과-차이">1. 전통적 분류방법과 차이</h4>
<p>분류 문제는 본질적으로 조건부 확률 <span class="math inline">\(P(Y = k \mid X = x),k = 1,\ldots,K\)</span>을 추정하거나(확률예측), 최소한 그 확률에 기반한 의사결정 규칙 <span class="math inline">\(\widehat{y}(x) = \arg\max_{k}P(Y = k \mid X = x)\)</span>을 구현하는 일이다. 통계적 분류모형과 머신러닝 분류기는 모두 이 목표를 공유하지만, 접근 방식이 다르다.</p>
<section id="통계적-분류모형" class="level5">
<h5 class="anchored" data-anchor-id="통계적-분류모형">(1) 통계적 분류모형</h5>
<p><span dir="rtl">”</span>확률모형을 먼저 세우고, 그 안에서 추정한다”. 통계적 분류모형(로지스틱 회귀, LDA/QDA)의 출발점은 데이터 생성 메커니즘에 대한 가정이다.</p>
<p><strong>(1) 로지스틱 회귀: <span class="math inline">\(P(Y \mid X)\)</span>를 직접 모형화 (Discriminative)</strong></p>
<p>이진분류에서 <span class="math inline">\(P(Y = 1 \mid X = x) = \sigma(\beta_{0} + \beta^{\top}x) = \frac{1}{1 + e^{- (\beta_{0} + \beta^{\top}x)}}\)</span>처럼 조건부 확률을 직접 모형화한다. 즉, <span dir="rtl">”</span>결정경계가 선형(log-odds 선형)“이라는 구조적 가정을 둔다.</p>
<p><strong>(2) LDA/QDA: <span class="math inline">\(P(X \mid Y)\)</span>와 <span class="math inline">\(P(Y)\)</span>를 모형화 (Generative)</strong></p>
<p>베이즈 정리를 이용해 <span class="math inline">\(P(Y = k \mid X = x) \propto \pi_{k}f_{k}(x)\)</span>를 계산한다. 여기서 <span class="math inline">\(\pi_{k} = P(Y = k),f_{k}(x) = p(X = x \mid Y = k)\)</span>.</p>
<ul>
<li>LDA: <span class="math inline">\(X \mid Y = k \sim N(\mu_{k},\Sigma)\)</span> (공분산 동일) → 결정경계가 선형</li>
<li>QDA: <span class="math inline">\(X \mid Y = k \sim N(\mu_{k},\Sigma_{k})\)</span> (공분산 클래스별) → 결정경계가 이차(곡선)</li>
</ul>
<p><strong>통계적 분류모형의 강점/한계</strong></p>
<ul>
<li>강점: 추정/검정/해석(계수, 신뢰구간 등)이 체계적, 소표본에서도 안정적(가정이 맞으면)</li>
<li>한계: 가정이 틀리면(비선형, 복잡한 상호작용, 비정규 등) 성능이 급격히 저하될 수 있음</li>
</ul>
</section>
<section id="머신러닝-분류기" class="level5">
<h5 class="anchored" data-anchor-id="머신러닝-분류기">(2) 머신러닝 분류기</h5>
<p><span dir="rtl">”</span>가정보다 예측성능·일반화를 먼저 최적화한다”. 머신러닝 분류기는 대체로 명시적 확률가정(정규성, 선형성 등)을 약하게 두거나 거의 두지 않고, 훈련오차만 줄이는 것이 아니라 일반화 성능을 최대화하는 방향으로 설계된다.</p>
<p><strong>(1) 목표함수 관점: 경험위험 + 규제(복잡도 제어)</strong></p>
<p>머신러닝의 공통 형태는 다음과 같이 정리할 수 있다. <span class="math inline">\(\min_{f \in \mathcal{F}}\frac{1}{n}\overset{n}{\sum_{i = 1}}\ell(y_{i},f(x_{i})) + \lambda\Omega(f)\)</span>, 여기서 <span class="math inline">\(\ell( \cdot )\)</span>은 손실함수(예: 0-1 loss, hinge loss, log loss 등), <span class="math inline">\(\Omega(f)\)</span>는 복잡도 페널티(모형이 너무 흔들리지 않게 제어), 그리고 <span class="math inline">\(\lambda\)</span>는 적합 vs 단순성의 균형(튜닝 파라미터)이다.</p>
<p>즉, 머신러닝은 <span dir="rtl">”</span>데이터를 잘 맞추되(적합) 너무 복잡해지지 않게(규제)“라는 Bias–Variance trade-off를 직접 다룬다.</p>
<p><strong>(2) 의사결정규칙을 직접 학습하는 방식이 많다</strong></p>
<p>통계적 모형이 확률모형(혹은 분포가정)으로부터 P(Y\mid X)를 유도하는 경우가 많은 반면, 머신러닝은 종종 결정경계/분류규칙 자체를 직접 최적화한다.</p>
<ul>
<li>k-NN: 주변 이웃의 다수결(지역적 규칙)</li>
<li>SVM: 분류오차 대신 마진 최대화(hinge loss 기반)</li>
<li>Tree: 불순도 감소로 분할 규칙을 누적</li>
<li>Ensemble: 여러 약한 분류기를 결합해 일반화 향상</li>
</ul>
<p><strong>(3) <span dir="rtl">”</span>튜닝 + 검증”이 모형의 일부다</strong></p>
<p>머신러닝에서는 하이퍼파라미터(예: k-NN의 k, SVM의 C, <span class="math inline">\(\gamma\)</span>, 트리 깊이, learning rate 등)가 성능을 좌우한다. 따라서 교차검증(CV), 홀드아웃, 조기중단(early stopping) 같은 평가-선택 절차가 모형 학습의 핵심 구성요소가 된다.</p>
</section>
<section id="전통적-방법과-머신러닝-방법-비교" class="level5">
<h5 class="anchored" data-anchor-id="전통적-방법과-머신러닝-방법-비교">(3) 전통적 방법과 머신러닝 방법 비교</h5>
<p><strong>가정과 유연성: 구조 가정 vs 데이터 주도 유연성</strong></p>
<p>통계적 분류모형(로지스틱 회귀, LDA/QDA)은 먼저 데이터 생성 구조에 대한 비교적 강한 가정(예: 선형성, 정규성, 동분산 등)을 두고 그 틀 안에서 모수를 추정한다. 이 때문에 모형 형태가 명확하고 해석이 쉽지만, 가정이 현실 데이터와 어긋나면(비선형·복잡한 상호작용·비정규 등) 예측 성능이 쉽게 제한될 수 있다. 반면 머신러닝 분류기는 명시적 가정보다는 일반화 성능을 우선하며 더 유연한 결정경계를 허용한다. 그 대신 과적합 위험을 제어하기 위한 하이퍼파라미터 튜닝과 검증(교차검증, 검증셋, 조기중단 등)이 사실상 필수로 포함된다.</p>
<p><strong>확률 예측과 분류 정확도: 확률 모델링 중심 vs 성능 지표 중심</strong></p>
<p>통계모형은 <span class="math inline">\(P(Y \mid X)\)</span>의 확률 추정 자체가 핵심 산출물이다. 예를 들어 로지스틱 회귀는 <span class="math inline">\(P(Y = 1 \mid X = x) = \frac{1}{1 + \exp\{ - (\beta_{0} + \beta^{\top}x)\}}\)</span>처럼 조건부확률을 직접 모형화하여 위험도 해석이나 임계값 기반 의사결정에 자연스럽게 연결된다. 머신러닝 분류는 종종 정확도(Accuracy), F1, AUC 같은 분류 성능 지표를 목표로 최적화되는 경우가 많다. 다만 Random Forest, Gradient Boosting, Neural Network 등은 클래스 확률도 출력할 수 있으며, 이때 출력 확률이 실제 빈도와 잘 맞는지(확률보정, calibration)를 점검·보정해야 하는 상황이 자주 발생한다.</p>
<p><strong>해석가능성: 내재적 해석과 추론 vs 사후적 설명 도구</strong></p>
<p>통계모형은 계수 <span class="math inline">\(\beta\)</span>를 통해 변수 효과를 직접 설명할 수 있고(예: 오즈비 <span class="math inline">\(e^{\beta_{j}}\)</span>), 표준오차·신뢰구간·가설검정 등 불확실성까지 함께 제공한다는 점에서 <span dir="rtl">”</span>설명과 추론”에 강하다. 반면 머신러닝 모형은 구조가 복잡할수록 내부 파라미터만으로 해석하기 어렵기 때문에, permutation importance, PDP/ICE, SHAP 등의 사후적 설명 기법을 활용해 <span dir="rtl">”</span>어떤 변수가 얼마나 기여했는가”를 보완적으로 제시하는 방식이 일반적이다.</p>
<p><strong>데이터 규모와 차원: 소표본 안정성 vs 대규모·고차원 대응(규제 중요)</strong></p>
<p>통계모형은 가정이 적절할 경우 소표본에서도 비교적 안정적으로 추정되며, 모형 복잡도가 제한되어 과적합 위험이 상대적으로 작다. 머신러닝은 데이터가 많을수록(그리고 패턴이 복잡할수록) 강점을 발휘하는 경우가 많지만, 고차원에서는 불필요한 변수로 인해 분산이 커지거나 학습이 불안정해질 수 있다. 따라서 정규화(regularization), 특징선택(feature selection), 차원축소, 적절한 규제 및 튜닝이 성능과 일반화를 좌우한다.</p>
</section>
</section>
<section id="규칙-기반k-nn" class="level4">
<h4 class="anchored" data-anchor-id="규칙-기반k-nn">2. 규칙 기반(k-NN)</h4>
<section id="핵심-아이디어" class="level5">
<h5 class="anchored" data-anchor-id="핵심-아이디어">(1) 핵심 아이디어</h5>
<p>k-NN은 <span dir="rtl">”</span>입력공간에서 서로 가까운 관측치들은 같은 클래스에 속할 가능성이 높다”는 지역적 평활성 가정에 기반한다. 즉, 어떤 점 x 근처에서는 클래스 확률 <span class="math inline">\(P(Y = k \mid X = x)\)</span>가 급격히 변하지 않는다고 보고, x 주변의 훈련 표본들로부터 그 확률을 국소적으로 추정한다.</p>
<p>이 방법은 회귀계수나 명시적 모수(예:<span class="math inline">\(\beta\)</span>)를 학습하는 형태의 <span dir="rtl">”</span>모형 적합”이라기보다, 훈련 데이터 자체가 분류 규칙을 구성한다는 점에서 사례 기반(instance-based) 혹은 기억 기반(memory-based) 방법으로 분류된다. 새로운 관측치가 들어오면, 미리 정해 둔 규칙(거리 및 K)에 따라 <span dir="rtl">”</span>가까운 이웃들을 찾아” 그들의 클래스 정보를 활용해 예측한다.</p>
</section>
<section id="베이즈-분류기와-k-nn의-위치" class="level5">
<h5 class="anchored" data-anchor-id="베이즈-분류기와-k-nn의-위치">(2) 베이즈 분류기와 k-NN의 위치</h5>
<p>분류 문제의 이상적 목표는, 각 x에서의 참 조건부확률 <span class="math inline">\(P(Y = k \mid X = x)\)</span>을 알고 있을 때, 다음 규칙으로 분류하는 베이즈 분류기(Bayes classifier)를 사용하는 것이다. <span class="math inline">\({\widehat{y}}_{\text{Bayes}}(x) = \arg\max_{k}P(Y = k \mid X = x)\)</span>. 이 규칙은 가능한 모든 분류기 중에서 기대 분류오차를 최소화한다는 의미에서 <span dir="rtl">”</span>최적”이다.</p>
<p>그러나 현실 데이터에서는 <span class="math inline">\(P(Y \mid X)\)</span>의 진짜 형태를 알 수 없으므로, 베이즈 분류기를 직접 계산하는 것은 불가능하다. 따라서 베이즈 분류기는 실제로는 도달할 수 없지만, 다른 방법들의 성능을 판단하는 기준점으로서 이상적인 <span dir="rtl">’</span>황금 기준(gold standard)<span dir="rtl">’</span> 역할을 한다.</p>
<p>이러한 맥락에서 많은 분류 방법들은 다음의 공통 전략을 따른다. 데이터로부터 P(Y=k\mid X=x)를 어떤 방식으로든 추정하고 추정 확률이 가장 큰 클래스로 할당한다. <span class="math inline">\(\widehat{y}(x) = \arg\max_{k}\widehat{P}(Y = k \mid X = x)\)</span></p>
<p>k-NN은 이 전략을 가장 직관적으로 구현한 대표적 방법이다. 즉, x 주변의 <span dir="rtl">”</span>가까운 이웃”들이 보여주는 클래스 비율을 이용해 <span class="math inline">\(P(Y \mid X = x)\)</span>를 국소적으로 근사하고, 그 값이 최대가 되는 클래스로 분류한다.</p>
<p>요약하면, 베이즈 분류기가 <span dir="rtl">”</span>알 수 없는 진짜 확률에 기반한 최적 규칙”이라면, k-NN은 그 확률을 <span dir="rtl">”</span>이웃의 경험적 비율”로 대체하여 현실에서 실행 가능하게 만든 비모수적 근사 규칙이다.</p>
</section>
<section id="거리와-이웃-정의" class="level5">
<h5 class="anchored" data-anchor-id="거리와-이웃-정의">(3) 거리와 이웃 정의</h5>
<p><strong>이웃 집합의 정의</strong></p>
<p>훈련표본 <span class="math inline">\(\{(x_{i},y_{i})\}_{i = 1}^{n},x_{i} \in \mathbb{R}^{p}\)</span>을 정의하자. 새 관측치 <span class="math inline">\(x_{0}\)</span>에 대해 거리 <span class="math inline">\(d(x_{0},x_{i})\)</span>가 작은 순서로 k개를 선택하여 이웃 집합을 정의한다:</p>
<p><span class="math inline">\(N_{k}(x_{0}) = \{ i_{1},\ldots,i_{k}\},d(x_{0},x_{i_{1}}) \leq \cdots \leq d(x_{0},x_{i_{k}})\)</span>, 여기서 <span class="math inline">\(N_{k}(x_{0})\)</span>는 <span dir="rtl">”</span>이웃 인덱스 집합”이다(이웃 점 자체가 아니라 인덱스)아다.</p>
<p><strong>대표 거리(연속형 변수)</strong></p>
<p>가장 흔한 선택은 유클리드 거리보다 일반적으로는 Minkowski 거리(<span class="math inline">\(q \geq 1\)</span>)를 사용한다.</p>
<p><span class="math inline">\(d_{q}(x,z) = (\overset{p}{\sum_{j = 1}}|x_{j} - z_{j}|^{q})^{\frac{1}{q}}\)</span>, 여기서 q=1이면 Manhattan, q=2는 Euclidean 거리이다.</p>
<p><strong>변수 스케일 문제와 표준화</strong></p>
<p>변수의 단위/분산이 다르면 거리 계산이 특정 변수에 의해 지배되어 이웃 선택이 왜곡된다. 따라서 보통 표준화 후 거리 계산을 수행한다.</p>
<p><span class="math display">\[x_{ij}^{(std)} = \frac{x_{ij} - {\overline{x}}_{j}}{s_{j}}\]</span></p>
<p><span class="math inline">\({\overline{x}}_{j},s_{j}\)</span>는 반드시 훈련 데이터에서 계산한 값을 사용하고, 테스트 데이터에도 같은 값으로 변환해야 한다. 테스트 데이터의 평균/표준편차로 표준화하면 정보 누수(leakage)가 발생한다.</p>
<p><strong>범주형 변수가 있을 때</strong></p>
<p>거리는 연속형에 자연스럽다. 범주형이 포함되면 다음 중 하나를 고려한다.</p>
<p>원-핫 인코딩 후 거리 계산(차원 증가 주의)</p>
<p>Gower distance 등 혼합형 거리(연속+범주)</p>
<p>도메인 맞춤 거리(예: 매칭 불일치 수)</p>
<p><strong>동률 처리</strong></p>
<p><span class="math inline">\(\widehat{p}(c \mid x_{0})\)</span>가 같은 클래스가 나오거나, 거리 동률로 k번째 이웃이 애매한 경우가 있다. 일반적으로는 (i) 무작위 tie-break, (ii) 더 작은 거리 이웃 우선, (iii) 가중 k-NN 사용 등으로 처리한다.</p>
</section>
<section id="분류-규칙-다중분류-포함" class="level5">
<h5 class="anchored" data-anchor-id="분류-규칙-다중분류-포함">(4) 분류 규칙 (다중분류 포함)</h5>
<p>클래스 집합이 <span class="math inline">\(\{ 1,\ldots,K\}\)</span>일 때, k-NN은 x_0의 이웃들에서 클래스 비율로 조건부확률을 추정한다.</p>
<p><span class="math inline">\(\widehat{p}(c \mid x_{0}) = \frac{1}{k}\sum_{i \in N_{k}(x_{0})}\mathbf{1}(y_{i} = c),c = 1,\ldots,K\)</span>, 여기서 <span class="math inline">\(\mathbf{1}( \cdot )\)</span>는 지시함수(indicator)이다.</p>
<p>예측은 최대 사후확률(MAP) 규칙, 즉 다수결과 동일한 원리로 결정된다:</p>
<p><span class="math display">\[\widehat{y}(x_{0}) = \arg\max_{c \in \{ 1,\ldots,K\}}\widehat{p}(c \mid x_{0})\]</span></p>
<p>이 식은 <span dir="rtl">”</span>다중분류”에서도 그대로 성립한다. 이진분류라면 <span class="math inline">\(\widehat{p}(1 \mid x_{0}) &gt; 0.5\)</span>와 같은 임계값 규칙으로도 표현 가능.</p>
</section>
<section id="가중-k-nn-거리-가중-weighted-k-nn" class="level5">
<h5 class="anchored" data-anchor-id="가중-k-nn-거리-가중-weighted-k-nn">(5) 가중 k-NN (거리 가중, Weighted k-NN)</h5>
<p><strong>왜 가중을 주나?</strong></p>
<p>기본 k-NN은 이웃 k개를 모두 동일 가중치로 취급한다. 하지만 직관적으로는 더 가까운 이웃이 더 큰 정보를 가지므로, 거리 기반 가중치를 부여하면 성능이 개선되는 경우가 많다.</p>
<p><strong>가중치 정의</strong></p>
<p>가까운 이웃에 더 큰 가중치를 준다. <span class="math inline">\(w_{i}(x_{0}) = \frac{1}{d(x_{0},x_{i})^{r} + \varepsilon},r &gt; 0,\varepsilon &gt; 0\)</span>, 여기서 <span class="math inline">\(\varepsilon\)</span>는 d=0일 때 발산을 막기 위한 작은 값(수치 안정화)이며, r가 클수록 <span dir="rtl">”</span>가까운 이웃”을 더 강하게 강조(유연성 증가)한다.</p>
<p><strong>가중 확률 추정과 예측</strong></p>
<p><span class="math display">\[\widehat{p}(c \mid x_{0}) = \frac{\sum_{i \in N_{k}(x_{0})}w_{i}(x_{0})\mathbf{1}(y_{i} = c)}{\sum_{i \in N_{k}(x_{0})}w_{i}(x_{0})}\widehat{y}(x_{0}) = \arg\max_{c}\widehat{p}(c \mid x_{0})\]</span></p>
<p>이 방식은 동률 문제를 완화하고, 경계 근처에서 더 자연스러운 확률 추정을 제공한다.</p>
<p><strong>커널 가중(대안)</strong></p>
<p>거리 가중치를 커널 형태로 두기도 한다. <span class="math inline">\(w_{i}(x_{0}) = \exp( - \gamma d(x_{0},x_{i})^{2})\)</span>, 여기서 <span class="math inline">\(\gamma\)</span>가 클수록 가까운 점에 더 집중(국소성 강화)하게 된다.</p>
</section>
<section id="k와-biasvariance" class="level5">
<h5 class="anchored" data-anchor-id="k와-biasvariance">(6) k와 Bias–Variance</h5>
<p>k-NN에서 k는 모델의 유연성(flexibility)을 직접 결정하는 핵심 튜닝 파라미터이다. k가 작으면 예측에 사용되는 이웃의 범위가 매우 좁아져, 각 점 주변의 국소적 패턴(심지어 노이즈까지)도 그대로 따라가게 된다. 그 결과 결정경계는 매우 구불구불해지고, 훈련 데이터에는 잘 맞지만 새로운 데이터에서는 성능이 떨어질 수 있는 저편향·고분산(과적합) 상태로 가기 쉽다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/classification_ml_knn.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
<p>반대로 k가 커지면 더 넓은 이웃을 평균내어 판단하므로 우연한 변동이 상쇄되어 경계가 매끈해지고 변동성이 줄어든다. 하지만 이 경우 지역적 구조까지 과도하게 평활화되어 실제로 필요한 비선형 경계를 놓칠 수 있어 고편향·저분산(과소적합) 위험이 커진다.</p>
<p>따라서 k는 <span dir="rtl">”</span>훈련 성능”이 아니라 <span dir="rtl">”</span>일반화 성능”을 기준으로 정해야 하며, 실무적으로는 교차검증을 통해 테스트 오차(또는 AUC/F1 등)가 최소가 되는 k를 선택하는 것이 표준적 절차이다.</p>
<p>다음 그림은 k-NN에서 이웃의 수 K를 바꾸면 분류기의 유연성(복잡도)이 어떻게 달라지고, 그에 따라 훈련오차와 테스트오차가 서로 다른 방식으로 변한다는 점을 보여준다. 가로축은 1/K로 표시되어 있는데, 이는 K가 작아질수록 1/K가 커져 오른쪽으로 갈수록 분류기가 더 유연해진다는 뜻이다. 즉, 오른쪽으로 갈수록 결정경계가 더 구불구불해져 훈련 데이터의 국소적 패턴을 더 적극적으로 따라가게 된다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/classification_ml_knn02.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:60.0%"></p>
</figure>
</div>
<p>먼저 훈련오차(파란색)는 K가 작아질수록 꾸준히 감소한다. 이는 더 유연한 모델일수록 훈련 데이터에 맞춰 경계를 세밀하게 조정할 수 있기 때문이다. 극단적으로 K=1에 가까워지면 각 관측치가 사실상 자기 자신과 가장 가까운 이웃이 되어 훈련 데이터는 거의 완벽하게 분류되므로, 훈련오차가 0에 근접할 수도 있다. 따라서 훈련오차만 보면 K를 계속 줄이는 것이 좋아 보이지만, 이 판단은 일반화 성능을 보장하지 않는다.</p>
<p>반면 테스트오차(주황색)는 같은 방식으로 움직이지 않는다. K를 어느 정도 줄여 유연성을 키우면 처음에는 테스트오차가 감소하는데, 이는 너무 단순했던 결정경계가 실제 클래스 구조를 더 잘 반영하기 시작하기 때문이다. 그러나 K가 지나치게 작아지면 모델이 신호뿐 아니라 우연한 변동(노이즈)까지 따라가면서 과적합이 발생하고, 그 결과 테스트오차가 다시 증가한다. 즉 테스트오차는 일반적으로 처음에는 내려가다가 어느 지점 이후 다시 올라가는 U자 형태를 띠며, 이 U자 곡선의 최저점이 <span dir="rtl">”</span>가장 적절한 K”에 해당한다.</p>
<p>그림의 검은 점선은 베이즈 오류율을 나타내며, 이는 주어진 문제에서 어떤 분류기를 쓰더라도 이론적으로 완전히 없앨 수 없는 최소 오류(불가약 오차)의 기준선이다. 적절한 K를 선택하면 테스트오차가 이 기준선에 가까워질 수 있지만, K가 너무 크거나 너무 작으면 각각 과소적합 또는 과적합으로 인해 테스트오차가 커져 베이즈 오류율과의 차이가 벌어진다. 또한 곡선이 매끈하지 않고 들쭉날쭉한 것은 훈련 데이터가 비교적 작아, K가 조금만 바뀌어도 이웃 구성과 결정경계가 민감하게 변하는 표본 변동의 영향이 나타나기 때문이다.</p>
<p>결론적으로 이 그림은 <span dir="rtl">”</span>훈련오차를 최소화하는 방향으로 모델을 복잡하게 만드는 것”이 곧 <span dir="rtl">”</span>좋은 예측모형”을 의미하지 않으며, 실제로는 테스트오차가 최소가 되는 적절한 유연성 수준(즉 적절한 K)이 존재한다는 사실을 강조한다. 따라서 k-NN에서 K는 훈련 성능이 아니라 일반화 성능을 기준으로, 보통 교차검증을 통해 선택해야 한다.</p>
</section>
<section id="knn-장단점" class="level5">
<h5 class="anchored" data-anchor-id="knn-장단점">(7) kNN 장단점</h5>
<p>k-NN의 가장 큰 장점은 방법이 직관적이고 구현이 간단하다는 점이다. 별도의 복잡한 모수 추정 없이도 데이터의 국소 구조를 이용해 분류를 수행하므로, 선형 가정에 묶이지 않고 매우 유연한 비선형 결정경계를 자연스럽게 만들 수 있다. 반면 단점도 분명하다. k-NN은 학습 단계가 가벼운 대신, 새로운 관측치가 들어올 때마다 전체 훈련 데이터와의 거리를 계산해 이웃을 찾아야 하므로 예측 비용이 커지며(대략 O(np)), 데이터가 커질수록 실시간 예측이 부담될 수 있다. 또한 차원이 커질수록 거리의 상대적 차이가 희미해져 <span dir="rtl">”</span>가까움” 자체가 의미를 잃는 차원의 저주 문제가 나타나 성능이 악화되기 쉽다. 마지막으로 거리 기반 방법이기 때문에 변수 스케일에 매우 민감하고(표준화가 필수에 가까움), 이상치가 있으면 거리 계산이 왜곡되어 이웃 선택이 불안정해질 수 있다는 점도 중요한 한계로 고려해야 한다.</p>
</section>
</section>
<section id="마진-기반svm" class="level4">
<h4 class="anchored" data-anchor-id="마진-기반svm">3. 마진 기반(SVM)</h4>
<section id="개념" class="level5">
<h5 class="anchored" data-anchor-id="개념">(1) 개념</h5>
<p>SVM은 1990년대 컴퓨터 과학 분야에서 개발된 분류 방법으로, 이후 그 인기가 꾸준히 증가해 왔다. SVM은 다양한 상황에서 좋은 성능을 보이는 것으로 알려져 있으며, 종종 별다른 특별한 조정 없이도 잘 작동하는(<span dir="rtl">”</span>out of the box”) 분류기 중 하나로 여겨진다.</p>
<p>서포트 벡터 머신은 최대 마진 분류기(maximal margin classifier)라고 불리는 단순하고 직관적인 분류기의 일반화 형태이다. 이 분류기는 우아하고 단순하지만, 클래스들이 선형 경계로 완전히 분리 가능(separable)해야 한다는 조건을 필요로 하므로, 안타깝게도 대부분의 데이터셋에는 적용할 수 없다는 것을 보게 될 것이다.</p>
<p>최대 마진 분류기를 확장하여 더 넓은 범위의 경우에 적용할 수 있는 서포트 벡터 분류기(support vector classifier)를 소개한다. 비선형 클래스 경계를 수용하기 위해 서포트 벡터 분류기를 한 단계 더 확장한 서포트 벡터 머신을 소개한다. 서포트 벡터 머신은 기본적으로 두 개의 클래스가 존재하는 이진 분류 설정을 대상으로 한다.</p>
</section>
<section id="최대-마진-분류기-maximal-margin-classifier" class="level5">
<h5 class="anchored" data-anchor-id="최대-마진-분류기-maximal-margin-classifier">(2) 최대 마진 분류기 (Maximal Margin Classifier)</h5>
<p><strong>초평면이란?</strong></p>
<p>p차원 공간에서 초평면(hyperplane)은 차원이 p-1인 평평한(평탄한) 아핀 부분공간이다. 예를 들어 2차원에서 초평면은 1차원 평평한 부분공간, 즉 직선이다. 3차원에서 초평면은 2차원 평평한 부분공간, 즉 평면이다. p&gt;3인 경우 초평면을 시각화하기는 어렵지만, <span dir="rtl">”</span>차원이 p-1인 평평한 부분공간”이라는 개념은 그대로 적용된다.</p>
<p>초평면의 수학적 정의는 매우 간단하다. p-차원에서 초평면은 다음 방정식으로 정의된다.</p>
<p><span class="math inline">\(\beta_{0} + \beta_{1}X_{1} + \beta_{2}X_{2} + \cdots + \beta_{p}X_{p} = 0\)</span>. p차원 공간(즉 길이가 p인 벡터)에 있는 점 <span class="math inline">\(X = (X_{1},X_{2},\ldots,X_{p})^{\top}\)</span>가 위를 만족하면, 그 점은 초평면 위에 놓인다.</p>
<p>이제 X가 위의 식을 만족하지 않는다고 하자. 대신 <span class="math inline">\(\beta_{0} + \beta_{1}X_{1} + \beta_{2}X_{2} + \cdots + \beta_{p}X_{p} &gt; 0\)</span> 라면, 이는 X가 초평면의 한쪽에 놓여 있음을 뜻한다. 반대인 경우에는 X는 초평면의 다른 쪽에 놓인다. 따라서 초평면은 p차원 공간을 두 개의 부분으로 나누는 경계로 생각할 수 있다. 점이 초평면의 어느 쪽에 있는지는 부호(sign)를 계산하는 것만으로 쉽게 판별할 수 있다.</p>
<p>이 그림은 초평면(hyperplane)이 차원에 따라 어떻게 나타나는지를 보여주는데, 2차원 <span class="math inline">\(\mathbb{R}^{2}\)</span>에서는 초평면이 한 차원 낮은 1차원 경계이므로 직선으로 나타나 평면을 두 영역으로 나누고(왼쪽), 3차원 <span class="math inline">\(\mathbb{R}^{3}\)</span>에서는 한 차원 낮은 2차원 경계이므로 평면으로 나타나 공간을 두 반공간으로 분할한다(오른쪽); 따라서 빨간 점과 초록 점처럼 서로 다른 클래스의 관측치들은 이 직선/평면의 서로 다른 쪽에 위치하게 되며, 어떤 점 x가 <span class="math inline">\(\beta_{0} + \beta_{1}x_{1} + \cdots + \beta_{p}x_{p}\)</span>의 부호에 따라 초평면의 어느 편에 놓이는지가 분류 결과를 결정한다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/classification_ml_hyperplane.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
<p><strong>분리 초평면을 이용한 분류</strong></p>
<p>이제 p차원 공간에 있는 n개의 훈련 관측치로 이루어진 <span class="math inline">\(n \times p\)</span> 데이터 행렬 X, <span class="math inline">\(x_{1} = \left( \begin{array}{r}
x_{11} \\
\vdots \\
x_{1p}
\end{array} \right),\ldots,x_{n} = \left( \begin{array}{r}
x_{n1} \\
\vdots \\
x_{np}
\end{array} \right)\)</span>가 있다고 하자. 또한 이 관측치들이 두 클래스에 속한다고 하자. 즉, <span class="math inline">\(y_{1},\ldots,y_{n} \in \{ - 1,1\}\)</span>이며, -1은 한 클래스를, 1은 다른 클래스를 나타낸다.</p>
<p>아울러 관측될 특성 벡터가 p차원인 테스트 관측치 <span class="math inline">\(x^{*} = (x_{1}^{*},\ldots,x_{p}^{*})^{\top}\)</span>도 하나 존재한다고 하자. 우리의 목표는 훈련 데이터에 기반하여, 테스트 관측치의 특성 측정값을 이용해 이를 올바르게 분류하는 분류기를 개발하는 것이다.</p>
<p>훈련 관측치들이 클래스 라벨에 따라 완벽히 분리되도록 하는 초평면이 존재한다고 하자. 이때 분리 초평면은 모든 훈련표본에 대해 다음 성질을 만족한다:</p>
<p><span class="math inline">\(y_{i}(\beta_{0} + \beta^{\top}x_{i}) &gt; 0,i = 1,\ldots,n\)</span> 만약 분리 초평면이 존재한다면 이를 이용해 매우 자연스러운 분류 규칙을 구성할 수 있다. 즉, 결정함수 <span class="math inline">\(f(x) = \beta_{0} + \beta^{\top}x\)</span>의 부호에 따라 테스트 관측치 <span class="math inline">\(x^{*}\)</span>를 분류하며, <span class="math inline">\(\widehat{y}(x^{*}) = sign(f(x^{*}))\)</span>로 정의된다. 다시 말해 <span class="math inline">\(f(x^{*}) &gt; 0\)</span>이면 클래스 +1, <span class="math inline">\(f(x^{*}) &lt; 0\)</span>이면 클래스 -1로 할당한다.</p>
<p>또한 <span class="math inline">\(y(x^{*})\)</span>의 크기도 활용할 수 있다. <span class="math inline">\(y(x^{*})\)</span>가 0에서 멀면, <span class="math inline">\(x^{*}\)</span>가 초평면에서 멀리 떨어져 있다는 뜻이므로 분류에 대한 확신이 커진다. 반대로 0에 가까우면 <span class="math inline">\(x^{*}\)</span>는 초평면 근처에 위치하므로 분류 확신이 낮아진다. 분리 초평면에 기반한 분류기는 선형 결정경계(linear decision boundary)를 만든다.</p>
<p><strong>최대 마진 분류기 (The Maximal Margin Classifier)</strong></p>
<p>일반적으로 데이터가 초평면으로 완벽히 분리될 수 있다면, 실제로 그런 초평면은 무한히 많이 존재한다. 이는 어떤 분리 초평면이라도 관측치들과 접촉하지 않는 한, 약간 위아래로 평행 이동하거나 회전시킬 수 있기 때문이다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/classification_ml_classifier.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%"></p>
</figure>
</div>
<p>자연스러운 선택은 최대 마진 초평면(maximal margin hyperplane)(또는 최적 분리 초평면(optimal separating hyperplane))이다. 이는 훈련 관측치들로부터 가장 멀리 떨어진 분리 초평면을 말한다.</p>
<p>구체적으로, 각 분리 초평면에 대해 각 훈련 관측치로부터 그 초평면까지의 (수직) 거리를 계산할 수 있으며, 그 거리들 중 가장 작은 값이 <span dir="rtl">”</span>관측치에서 초평면까지의 최소거리”가 된다.</p>
<p>이 최소거리를 마진(margin)이라 부른다. 최대 마진 초평면은 이 마진이 가장 큰 분리 초평면, 즉 훈련 관측치들로부터의 최소거리가 최대가 되는 초평면이다.</p>
<p>몇몇 훈련 관측치가 최대 마진 초평면과 동일한 최소 거리를 가지며 마진 경계(점선) 위에 놓여, 결과적으로 마진의 폭과 초평면의 위치를 결정하고 있음을 볼 수 있는데, 이러한 관측치들을 서포트 벡터(support vectors)라고 한다.</p>
<p>서포트 벡터는 p차원 특성공간의 점으로서, 이 점들이 조금만 이동해도 <span dir="rtl">”</span>가장 가까운 점”이 바뀌기 때문에 최대 마진 초평면 역시 함께 이동하게 된다는 의미에서 초평면을 <span dir="rtl">’</span>지지(support)<span dir="rtl">’</span>한다.</p>
<p>최대 마진 초평면이 전체 데이터에 의해 정해지는 것이 아니라 오직 서포트 벡터들에 의해 직접적으로 결정된다는 사실이며, 다른 관측치들은 마진 경계 안쪽으로 들어오지만 않는 한(즉 마진을 침범하지 않는 한) 위치가 다소 변해도 초평면에 영향을 주지 않는다. 이러한 <span dir="rtl">”</span>경계 근처의 소수 관측치만이 결정경계를 규정한다”는 성질은 이후 서포트 벡터 분류기와 서포트 벡터 머신의 핵심 원리로 다시 등장한다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/classification_ml_margin.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
<p>이제 테스트 관측치가 최대 마진 초평면의 어느 쪽에 위치하는지를 기준으로 분류할 수 있고, 이를 최대 마진 분류기(maximal margin classifier)라 한다.</p>
<p>훈련 데이터에서 마진이 큰 분류기는 테스트 데이터에서도 마진이 클 것이며, 따라서 테스트 관측치도 올바르게 분류할 것이라고 기대한다. 최대 마진 분류기는 종종 성공적이지만, p가 클 때는 과적합을 유발할 수도 있다.</p>
<p>만약 <span class="math inline">\(\beta_{0},\beta_{1},\ldots,\beta_{p}\)</span>가 최대 마진 초평면의 계수라면, 최대 마진 분류기는 <span class="math inline">\(f(x^{*}) = \beta_{0} + \beta_{1}x_{1}^{*} + \beta_{2}x_{2}^{*} + \cdots + \beta_{p}x_{p}^{*}\)</span>의 부호에 따라 테스트 관측치 <span class="math inline">\(x^{*}\)</span>를 분류한다.</p>
<p><strong>최대 마진 분류기의 구성</strong></p>
<p>이제 n개의 훈련 관측치 <span class="math inline">\(x_{1},\ldots,x_{n} \in \mathbb{R}^{p}\)</span>와 클래스 라벨 <span class="math inline">\(y_{1},\ldots,y_{n} \in \{ - 1,1\}\)</span>가 주어졌을 때, 최대 마진 초평면을 구성하는 문제를 생각하자. 간단히 말해, 최대 마진 초평면은 다음 최적화 문제의 해이다.</p>
<p><span class="math display">\[\begin{matrix}
\underset{\beta_{0},\beta_{1},\ldots,\beta_{p},M}{\text{maximize}} &amp; M \\
\text{subject to} &amp; \overset{p}{\sum_{j = 1}}\beta_{j}^{2} = 1, \\
&amp; y_{i}(\beta_{0} + \beta_{1}x_{i1} + \beta_{2}x_{i2} + \cdots + \beta_{p}x_{ip}) \geq M,i = 1,\ldots,n.
\end{matrix}\]</span></p>
<p>M이 양수일 때 각 관측치가 초평면의 올바른 쪽에 놓이도록 보장한다. 사실 각 관측치가 올바른 쪽에 있기 위해서는 <span class="math inline">\(y_{i}(\beta_{0} + \beta_{1}x_{i1} + \cdots + \beta_{p}x_{ip}) &gt; 0\)</span>이면 충분하다. 따라서 위 식의 제약은, M&gt;0인 경우 각 관측치가 <span dir="rtl">”</span>여유(cushion”를 갖고 올바른 쪽에 위치하도록 더 강하게 요구하는 것이다.</p>
<p>둘째로, <span class="math inline">\(\overset{p}{\sum_{j = 1}}\beta_{j}^{2} = 1\)</span> 은 초평면 자체에 대한 제약이라기보다는 스케일을 고정하기 위한 조건이다. 왜냐하면 <span class="math inline">\(\beta_{0} + \beta_{1}x_{i1} + \cdots + \beta_{p}x_{ip} = 0\)</span>이 어떤 초평면을 정의한다면, <span class="math inline">\(k \neq 0\)</span>인 임의의 상수 k에 대해 <span class="math inline">\(k(\beta_{0} + \beta_{1}x_{i1} + \cdots + \beta_{p}x_{ip}) = 0\)</span>도 동일한 초평면을 정의하기 때문이다.</p>
<p>이 제약하에서 i번째 관측치가 초평면까지 갖는 수직거리는 <span class="math inline">\(y_{i}(\beta_{0} + \beta_{1}x_{i1} + \beta_{2}x_{i2} + \cdots + \beta_{p}x_{ip})\)</span>로 주어진다는 것을 보일 수 있다.</p>
<p>따라서 제약식은 각 관측치가 초평면의 올바른 쪽에 놓이면서 동시에 초평면으로부터 최소한 M만큼 떨어져 있도록 보장한다. 그러므로 M은 우리 초평면의 마진을 나타내며, 최적화 문제는 M을 최대화하는 <span class="math inline">\(\beta_{0},\beta_{1},\ldots,\beta_{p}\)</span>를 선택한다.</p>
<p><strong>비분리인 경우: 하드 마진의 실패와 소프트 마진의 필요성</strong></p>
<p>최대 마진 분류기(하드 마진)는 두 클래스가 어떤 초평면에 의해 완벽히 분리(linearly separable)될 수 있다는 가정 하에서 정의된다. 즉, 모든 훈련 표본이 올바른 쪽에 놓이면서 동시에 일정한 여유(마진)를 갖도록 <span class="math inline">\(y_{i}(\beta_{0} + \beta^{\top}x_{i}) \geq M,i = 1,\ldots,n,(M &gt; 0)\)</span>를 만족하는 초평면을 찾고, 그중 M을 최대화하는 해를 선택한다.</p>
<p>그러나 실제 데이터에서는 두 클래스가 서로 섞여 있어 어떤 직선(2차원) 또는 초평면(고차원)으로도 모든 관측치를 완전히 분리할 수 없는 비분리(non-separable) 상황이 빈번하다. 이 경우에는 모든 i에 대해 <span class="math inline">\(y_{i}(\beta_{0} + \beta^{\top}x_{i}) &gt; 0\)</span>을 동시에 만족하는 분리 초평면 자체가 존재하지 않으므로, 하드 마진 최적화 문제는 M&gt;0 인 해를 갖지 못하고, 결과적으로 최대 마진 분류기 또한 정의될 수 없다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/classification_ml_margin02.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
<p>이를 그림으로 이해하면 더 명확하다. 그림(비분리 + 마진)에서 실선은 후보 초평면 <span class="math inline">\(f(x) = \beta_{0} + \beta^{\top}x = 0\)</span>이고, 점선 두 개는 마진 경계 <span class="math inline">\(f(x) = \pm 1\)</span>을 나타낸다(이때 기하학적 마진 폭은 <span class="math inline">\(1/ \parallel \beta \parallel\)</span>) 이상적인 하드 마진 분류기라면 모든 파란 점(+1)은 <span class="math inline">\(f(x) \geq + 1\)</span> 쪽에, 모든 주황 점(-1)은 <span class="math inline">\(f(x) \leq - 1\)</span> 쪽에 위치해야 한다. 하지만 실제로는 일부 점들이 마진 내부로 들어오거나(마진 침범), 심지어 반대편으로 넘어가기도(오분류) 하며, 그림에서는 이러한 점들을 테두리로 강조해 표시했다. 즉, 어떤 초평면을 선택하더라도 <span dir="rtl">”</span>모든 점을 마진 밖으로 밀어내는” 하드 마진 조건을 만족시키기 어렵기 때문에, 하드 마진은 현실 데이터에 그대로 적용될 수 없다.</p>
<p>따라서 비분리 상황에서는 <span dir="rtl">”</span>정확히(exactly) 분리”를 포기하고, 일부 위반을 허용하는 방식으로 문제를 확장해야 한다. 이것이 소프트 마진(soft margin)이며, 각 관측치가 마진 조건을 얼마나 위반했는지를 나타내는 슬랙 변수 <span class="math inline">\(\xi_{i} \geq 0\)</span>를 도입하여 <span class="math inline">\(y_{i}(\beta_{0} + \beta^{\top}x_{i}) \geq 1 - \xi_{i},i = 1,\ldots,n\)</span>처럼 제약을 완화한다. 그리고 <span dir="rtl">”</span>마진을 크게(단순한 경계)” 유지하려는 목표와 <span dir="rtl">”</span>위반을 작게(오분류/침범 최소화)” 하려는 목표를 동시에 고려하여<span class="math inline">\(\min_{\beta_{0},\beta,\xi}\frac{1}{2} \parallel \beta \parallel^{2} + C\overset{n}{\sum_{i = 1}}\xi_{i}\text{s.t.}y_{i}(\beta_{0} + \beta^{\top}x_{i}) \geq 1 - \xi_{i},\xi_{i} \geq 0\)</span>를 푼다.</p>
<p>이때 C는 위반을 얼마나 강하게 벌점할지(즉, 오분류 허용 vs 마진 확보의 균형)를 조절하는 튜닝 파라미터이며, 이러한 소프트 마진 최대 마진 방법을 서포트 벡터 분류기(support vector classifier)라고 부른다. 이후 커널을 도입해 비선형 경계까지 확장한 것이 서포트 벡터 머신(SVM)이다.</p>
</section>
<section id="서포트-벡터-분류기" class="level5">
<h5 class="anchored" data-anchor-id="서포트-벡터-분류기">(3) 서포트 벡터 분류기</h5>
<p><strong>개념</strong></p>
<p>두 클래스의 관측치가 특성공간에서 서로 섞여 있는 경우에는, 어떤 초평면을 그어도 모든 점을 완벽하게 양쪽으로 나누는 것이 불가능하다.</p>
<p>따라서 최대 마진 분류기가 요구하는 것처럼 <span dir="rtl">”</span>모든 훈련점이 올바른 쪽에 있으면서 동시에 마진 바깥에 위치”하도록 만드는 조건을 만족시킬 수 없고, 그 결과 최대 마진 분류기 자체가 성립하지 않거나 적용될 수 없다.</p>
<p>현실의 데이터는 잡음, 측정오차, 클래스 중첩 등으로 인해 이러한 비분리 상황이 흔하므로, 완벽한 분리를 전제로 하는 접근은 근본적으로 적용 범위에 한계를 갖는다.</p>
<p>더 나아가, 데이터가 우연히 선형적으로 분리 가능한 경우라 하더라도 <span dir="rtl">”</span>완벽 분리”가 항상 바람직한 목표는 아니다. 아래 그림이 보여주듯, 단 하나의 관측치가 추가되거나 위치가 조금만 바뀌어도 최대 마진 초평면이 크게 이동할 수 있는데, 이는 최대 마진 해가 특정 관측치(특히 경계 근처의 점이나 이상치)에 매우 민감하다는 뜻이다.</p>
<p>이런 민감성은 결과적으로 마진을 지나치게 작게 만들어 분류 경계 주변에서의 판단을 불안정하게 하고(즉, 예측 확신을 떨어뜨리고), 데이터의 작은 변동에 따라 결정경계가 크게 요동치게 하여 일반화 성능을 해치는 과적합 위험을 증가시킨다.</p>
<p>따라서 <span dir="rtl">”</span>훈련 데이터를 완벽히 맞추는 분리 초평면”이 존재한다는 사실만으로 그 분류기가 좋은 모델이라고 결론내릴 수는 없으며, 오히려 일정 수준의 위반을 허용하는 더 강건한 접근이 필요해진다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/classification_ml_margin03.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:60.0%"></p>
</figure>
</div>
<p><strong>소프트 마진의 직관</strong></p>
<p>소프트 마진의 핵심 직관은 <span dir="rtl">”</span>훈련 데이터를 한 점도 틀리지 않게 맞추는 것”을 절대 목표로 삼기보다, 약간의 오류를 허용하더라도 전체적으로 더 안정적이고 일반화가 잘 되는 분류기를 만들자는 데 있다.</p>
<p>현실 데이터에서는 경계 근처의 애매한 점이나 이상치 하나가 결정경계를 크게 흔들 수 있는데, 완벽 분리를 강제하면 이러한 개별 관측치에 과도하게 끌려가면서 모델이 불안정해지기 쉽다.</p>
<p>따라서 소프트 마진은 일부 관측치가 마진을 침범하거나 심지어 오분류되는 것을 제한적으로 허용함으로써, 특정 몇 점에 대한 민감도를 낮추고 분류기를 더 강건하게 만든다.</p>
<p>그 결과 모든 훈련 표본을 완벽히 맞추는 대신, 훈련 데이터의 <span dir="rtl">”</span>대부분”을 더 잘 설명하고 새로운 데이터에서도 성능이 유지되는 방향으로 균형을 잡게 된다. 이런 철학을 수학적으로 구현한 방법이 바로 서포트 벡터 분류기이며, 마진 위반을 허용한다는 의미에서 소프트 마진 분류기라고도 부른다.</p>
<p><strong>서포트 벡터 분류기의 수식</strong></p>
<p><strong>목표</strong>: 마진 M을 크게 하되, 위반을 허용한다. <span class="math inline">\(\begin{matrix}
\text{maximize} &amp; M \\
\text{subject to} &amp; \parallel \beta \parallel^{2} = 1 \\
&amp; y_{i}(\beta_{0} + \beta^{\top}x_{i}) \geq M(1 - \varepsilon_{i}),i = 1,\ldots,n \\
&amp; \varepsilon_{i} \geq 0,\overset{n}{\sum_{i = 1}}\varepsilon_{i} \leq C
\end{matrix}\)</span>, 여기서 핵심은 슬랙 변수 <span class="math inline">\(\varepsilon_{i}\)</span>와 튜닝 파라미터 C이다.</p>
<p><strong>슬랙변수</strong>: 슬랙 변수 <span class="math inline">\(\varepsilon_{i}\)</span>는 각 관측치 i가 다음 제약을 얼마나 위반하는지를 나타낸다. <span class="math inline">\(y_{i}f(x_{i}) \geq M(1 - \varepsilon_{i})\)</span> 또는 표준화 하면</p>
<p><span class="math inline">\(y_{i}f(x_{i}) \geq 1 - \varepsilon_{i}\text{)}\)</span>이다. 즉, <span class="math inline">\(\varepsilon_{i}\)</span>는 <span dir="rtl">”</span>그 점이 얼마나 문제를 일으키는지(마진 침범/오분류)“를 정량화한다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/classification_ml_svm.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
<p>이 그림은 실선으로 표시된 초평면(결정경계)과 점선으로 표시된 마진 경계를 기준으로, 슬랙 변수 <span class="math inline">\(\varepsilon_{i}\)</span>가 각 관측치의 <span dir="rtl">”</span>마진/경계 위반 정도”를 어떻게 의미하는지를 기하학적으로 설명한다.</p>
<p>어떤 관측치가 자신의 클래스에 해당하는 마진 바깥쪽(점선 밖)에 위치하면 충분한 여유를 두고 올바르게 분류된 것이므로 <span class="math inline">\(\varepsilon_{i} = 0\)</span>으로 해석된다.</p>
<p>반대로 관측치가 초평면의 올바른 쪽에 있기는 하지만 점선과 실선 사이의 마진 내부로 들어오면 분류는 맞지만 여유가 부족한 상태이므로 <span class="math inline">\(0 &lt; \varepsilon_{i} &lt; 1\)</span>로, 즉 마진을 침범한 것으로 해석된다.</p>
<p>더 나아가 관측치가 실선을 넘어 초평면의 반대쪽에 놓이면 이는 오분류에 해당하며, 마진 위반을 넘어 경계 자체를 위반한 상황이므로 <span class="math inline">\(\varepsilon_{i} &gt; 1\)</span>로 해석된다.</p>
<p>이러한 관점에서 왼쪽 패널은 대부분의 점들이 <span class="math inline">\(\varepsilon_{i} = 0\)</span>인 상태로 마진 바깥에 있으나 일부 점이 <span class="math inline">\(0 &lt; \varepsilon_{i} &lt; 1\)</span>처럼 마진을 위반할 수 있음을 보여주고, 오른쪽 패널은 점이 추가되면 일부가 초평면의 반대편으로 넘어가 <span class="math inline">\(\varepsilon_{i} &gt; 1\)</span>인 오분류까지 제한적으로 허용해야 할 수도 있음을 보여준다.</p>
<p>따라서 이 그림은 소프트 마진 분류기에서 슬랙 변수의 값이 0, 양수, 그리고 1을 초과할 때 각각이 어떤 기하학적 상황을 뜻하는지를 대표적으로 시각화한 예시라고 정리할 수 있다.</p>
<p><strong>튜닝 파라미터 C</strong></p>
<p>C는 서포트 벡터 분류기(소프트 마진 SVM)에서 사용자가 정하는 튜닝 파라미터(hyperparameter)이다. C는 슬랙 변수 <span class="math inline">\(\varepsilon_{i}\)</span>를 통해 마진 위반(및 오분류)을 얼마나 허용할지를 조절하며, 그 결과 결정경계의 위치와 마진 폭이 달라져 일반화 성능에 큰 영향을 준다.</p>
<p>따라서 C는 보통 교차검증으로 여러 후보값을 비교해 검증(테스트) 성능이 가장 좋은 값으로 선택한다.</p>
<p>이 그림은 동일한 데이터에 대해 서포트 벡터 분류기(소프트 마진)를 적합할 때, 튜닝 파라미터 C 값을 달리하면 결정경계(실선)와 마진(점선)이 어떻게 달라지는지를 4개의 패널로 비교한 것이다. 각 패널에서 굵은 실선은 분류 초평면 <span class="math inline">\(f(x) = 0\)</span>이고, 양쪽의 점선은 마진 경계(예: <span class="math inline">\(f(x) = \pm M\)</span> 또는 표준화된 <span class="math inline">\(\pm 1\)</span>)를 나타낸다.</p>
<p>제약식 <span class="math inline">\(\sum_{i}\varepsilon_{i} \leq C\)</span>에서 C는 마진 위반을 허용하는 총량(예산)이므로, C가 클수록 마진 위반(마진 안쪽 진입, 심지어 오분류까지)에 대해 더 관대해진다.</p>
<p>그 결과, 모델은 <span dir="rtl">”</span>모든 점을 마진 밖에 두려고 애쓰는” 대신 더 넓은 마진을 확보하는 방향으로 초평면을 선택할 수 있으며, 실제로 그림에서도 C가 큰 패널일수록 점선(마진)이 더 넓게 벌어지는 경향이 나타난다.</p>
<p>반대로 C가 작아지면 위반 예산이 줄어들어, 마진을 크게 잡으면 곧바로 많은 점들이 마진을 침범해 <span class="math inline">\(\sum\varepsilon_{i}\)</span>가 커지기 때문에, 모델은 마진을 좁히는 쪽(점선 간격 축소)으로 조정하게 된다. 즉, <span class="math inline">\(C \downarrow\)</span>일수록 마진이 점점 좁아지고, 결정경계는 <span dir="rtl">”</span>마진 위반을 최소화”하는 쪽으로 재배치된다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/classification_ml_svm02.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
<p>결론적으로 이 그림은 C가 <span dir="rtl">”</span>위반 허용 정도”를 조절하며, C의 변화가 마진 폭(복잡도)과 경계 위치를 바꾸어 일반화 성능에 영향을 준다는 점을 시각적으로 보여준다.</p>
</section>
<section id="svm-support-vector-machine" class="level5">
<h5 class="anchored" data-anchor-id="svm-support-vector-machine">(4) SVM support vector machine</h5>
<p>서포트 벡터 분류기(소프트 마진)는 본질적으로 선형 결정경계를 만든다. 그러나 실제 데이터에서는 클래스 경계가 선형이 아닌 경우가 많으며, 이때 선형 분류기는 구조적으로 성능 한계를 가진다. 여기서는 <span dir="rtl">”</span>선형 분류기 → 비선형 결정경계”로 확장하는 일반 메커니즘을 먼저 설명한 뒤, 이를 커널을 통해 계산적으로 효율적으로 구현하는 서포트 벡터 머신(SVM)을 소개한다.</p>
<p><strong>비선형 결정경계가 필요한 이유와 특성공간 확장 아이디어</strong></p>
<p>서포트 벡터 분류기는 두 클래스의 경계가 선형이면 매우 자연스럽고 강력하다. 하지만 실제로는 경계가 비선형인 경우가 있으며, 이때는 어떤 선형 분류기(서포트 벡터 분류기 포함)도 적절한 분류를 수행하기 어렵다.</p>
<p>아래 그림은 두 클래스의 경계가 곡선 형태(비선형)임을 보여주므로(왼쪽) 서포트 벡터 분류기는 선형 경계만 찾으므로, 최선의 직선을 그어도 경계를 제대로 따라가지 못해 성능이 매우 나빠진다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/classification_ml_svm03.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
<p><strong>회귀에서의 비선형성 처리와의 유사성</strong></p>
<p>회귀분류에서도 X–Y 관계가 비선형이면 선형회귀가 성능이 떨어지고, 이를 해결하기 위해 <span class="math inline">\(X^{2},X^{3}\)</span> 같은 비선형 변환(기저함수)을 추가해 특성공간을 확장한다.</p>
<p>분류에서도 동일한 전략이 가능하다. 즉, 원래 입력변수 <span class="math inline">\(X_{1},\ldots,X_{p}\)</span>만 쓰지 말고, 제곱항/세제곱항/상호작용항 등을 추가한 새로운 특성들로 분류기를 학습하면, 원래 공간에서는 비선형 경계를 만들 수 있다.</p>
<p>원래 p개 특성 <span class="math inline">\(X_{1},X_{2},\ldots,X_{p}\)</span> 대신, 제곱항을 포함한 2p개 특성 <span class="math inline">\(X_{1},X_{1}^{2},X_{2},X_{2}^{2},\ldots,X_{p},X_{p}^{2}\)</span>로 서포트 벡터 분류기를 적합할 수 있다.</p>
<p><strong>왜 비선형 경계가 생기는가?</strong></p>
<p>확장된 특성공간에서는 결정경계가 여전히 선형이다. 하지만 원래 입력공간으로 되돌아오면 그 경계는 x에 대한 2차식(또는 더 높은 차수)이 되어 일반적으로 비선형 곡선이 된다. 원문 표현을 따르면, 원래 공간에서 결정경계는 <span class="math inline">\(q(x) = 0\)</span>꼴(여기서 q는 2차 다항식)이며, 해집합은 보통 비선형이다.</p>
<p><strong>문제점: 특성 수 폭발</strong></p>
<p>이 접근은 이론적으로 간단하지만, 다항차수를 올리거나 상호작용항 <span class="math inline">\(X_{j}X_{j'}(j \neq j')\)</span>까지 추가하면 특성 수가 매우 커진다. 그러면 계산이 급격히 어려워져 <span dir="rtl">”</span>특성을 확장하는 방식”만으로는 실용성이 떨어질 수 있다. 이를 효율적으로 구현하는 장치가 커널이며, 이것이 SVM의 핵심이다.</p>
<p><strong><span dir="rtl">”</span>내적만 쓰는 해”와 커널 트릭</strong></p>
<p>해는 관측치의 <span dir="rtl">”</span>내적(inner product)“만으로 표현된다 서포트 벡터 분류기 해를 직접 푸는 계산은 기술적으로 복잡해 생략하지만, 놀랍게도 그 해는 관측치 자체가 아니라 내적만으로 구성된다는 점을 강조한다.</p>
<p>두 벡터 <span class="math inline">\(a,b \in \mathbb{R}^{p}\)</span>의 내적은 <span class="math inline">\(\langle a,b\rangle = \overset{p}{\sum_{j = 1}}a_{j}b_{j}\)</span>이다. 두 관측치 <span class="math inline">\(x_{i},x_{i'}\)</span>의 내적은 <span class="math inline">\(\langle x_{i},x_{i'}\rangle = \overset{p}{\sum_{j = 1}}x_{ij}x_{i'j}\)</span>이다.</p>
<p>그리고 선형 서포트 벡터 분류기의 결정함수는 다음과 같은 형태로 쓸 수 있다. <span class="math inline">\(f(x) = \beta_{0} + \overset{n}{\sum_{i = 1}}\alpha_{i}\langle x,x_{i}\rangle\)</span>. 즉, 새로운 점 x를 분류하려면 훈련점들과의 내적 \langle x, x_i\rangle만 계산하면 된다.</p>
<p><strong>서포트 벡터만 남는다(희소성)</strong></p>
<p>또 하나의 핵심 성질은 <span class="math inline">\(\alpha_{i}\)</span>가 서포트 벡터에 대해서만 0이 아니다라는 점이다. 서포트 벡터 인덱스 집합을 S라 두면, <span class="math inline">\(f(x) = \beta_{0} + \sum_{i \in S}\alpha_{i}\langle x,x_{i}\rangle\)</span>이다. 즉, 실제 예측에는 소수의 점(서포트 벡터)만 관여하므로 계산이 효율적이고, 경계 근처의 핵심 표본만이 결정경계를 규정한다.</p>
<p><strong>커널의 도입: 내적을 <span class="math inline">\(K( \cdot , \cdot )\)</span>로 바꿔치기</strong></p>
<p>내적이 등장하는 모든 곳에서 <span class="math inline">\(\langle x_{i},x_{i'}\rangle \rightarrow K(x_{i},x_{i'})\)</span>로 바꾸면, 마치 <span dir="rtl">”</span>확장된 특성공간에서 선형분류”를 한 것과 같은 효과를 얻으면서도, 실제로는 그 공간으로 명시적으로 가지 않아도 된다.</p>
<p>이때 K를 커널이라 부르며, <span dir="rtl">”</span>두 관측치의 유사도”를 수치로 제공하는 함수다.</p>
<p>선형 커널: <span class="math inline">\(K(x_{i},x_{i'}) = \overset{p}{\sum_{j = 1}}x_{ij}x_{i'j}\)</span> → 이 경우는 결국 선형 서포트 벡터 분류기로 돌아간다.</p>
<p>다항 커널: <span class="math inline">\(K(x,x') = (1 + x^{\top}x')^{d}\)</span>, 여기서 d는 다항 차수. d&gt;1이면 훨씬 유연한(비선형) 결정경계를 만들 수 있다. 이는 <span dir="rtl">”</span>고차원 다항 특성공간에서 선형분류를 한 것”과 같은 효과다.</p>
<p>방사형(Radial, RBF) 커널: , <span class="math inline">\(K(x_{i},x_{i'}) = \exp\left( - \gamma\overset{p}{\sum_{j = 1}}(x_{ij} - x_{i'j})^{2} \right)\)</span>, 여기서 <span class="math inline">\(\gamma &gt; 0\)</span>. 두 점이 가까우면 K가 1에 가깝고, 멀면 0에 가까워진다. 즉, <span dir="rtl">”</span>가까운 점만 영향력이 있다”는 지역적 특성을 갖는다.</p>
<p>커널을 쓰는 SVM의 결정함수는 다음과 같이 쓴다:</p>
<p><span class="math inline">\(f(x) = \beta_{0} + \sum_{i \in S}\alpha_{i}K(x,x_{i})\)</span>. 이 식은 <span dir="rtl">”</span>비선형 SVM의 예측이 결국 서포트 벡터들과의 커널 유사도 합”으로 이루어진다는 의미다.</p>
<p><strong>RBF 커널의 직관</strong></p>
<p>RBF 커널에서 어떤 테스트 점 <span class="math inline">\(x^{*}\)</span>가 훈련점 <span class="math inline">\(x_{i}\)</span>와 매우 멀면 <span class="math inline">\(\parallel x^{*} - x_{i} \parallel^{2}\)</span>가 커져 <span class="math inline">\(K(x^{*},x_{i}) \approx 0\)</span>이 된다. 그러면 해당 <span class="math inline">\(x_{i}\)</span>의 기여는 거의 사라진다. 즉, 멀리 있는 훈련점은 예측에 거의 영향을 주지 않고, 가까운 점들만 영향력을 갖는다. 이것이 RBF 커널이 매우 유연한 비선형 경계를 만들 수 있는 이유 중 하나다.</p>
<p>아래 그림은 선형 결정경계로는 잘 분리되지 않는 비선형 데이터에 대해, 커널 SVM이 어떻게 비선형 결정경계를 학습하는지를 두 가지 커널로 비교해 보여준다.</p>
<p>왼쪽 패널은 3차 다항 커널을 사용한 SVM 결과로, 원래 입력공간에서는 곡선 형태로 나타나는 결정경계를 만들어 중심부의 보라색 군집과 주변의 파란 점들을 비교적 자연스럽게 구분한다.</p>
<p>즉, 다항 커널이 고차 다항 특성공간에서의 선형 분리를 암묵적으로 수행한 결과, 원래 공간에서는 <span dir="rtl">’</span>휘어진<span dir="rtl">’</span> 경계가 형성된 것이다. 오른쪽 패널은 방사형(RBF, radial) 커널을 사용한 SVM 결과로, 보라색 군집을 둘러싸는 폐곡선 형태의 경계가 나타나며, 이는 RBF 커널이 거리 기반의 국소적 유사도를 이용해 매우 유연한 비선형 경계를 만들 수 있음을 보여준다.</p>
<p>두 패널 모두 배경의 색/격자는 해당 위치의 점이 어느 클래스로 분류되는지를 나타내며, 결과적으로 이 예시에서는 다항 커널과 RBF 커널 모두 비선형 경계를 성공적으로 포착하여 선형 분류기에서 발생했던 성능 저하를 크게 개선할 수 있음을 시각적으로 확인할 수 있다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/classification_ml_svm04.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</section>
<section id="gamma와-c-결정경계-복잡도와-biasvariance" class="level5">
<h5 class="anchored" data-anchor-id="gamma와-c-결정경계-복잡도와-biasvariance">(5) <span class="math inline">\(\gamma\)</span>와 C: 결정경계 복잡도와 Bias–Variance</h5>
<p><strong>C: 마진 위반(오분류/침범) 허용 정도</strong></p>
<p>소프트 마진 SVM은 <span dir="rtl">”</span>마진을 크게 유지하려는 목표”와 <span dir="rtl">”</span>훈련 데이터의 위반(슬랙)을 줄이려는 목표”를 균형 있게 조절한다. 일반적인 표준 형태(hinge loss 관점)로는 <span class="math inline">\(\min_{\beta_{0},\beta}\frac{1}{2} \parallel \beta \parallel^{2} + C\overset{n}{\sum_{i = 1}}\max\{ 0,1 - y_{i}f(x_{i})\}\)</span>로 쓸 수 있으며, 여기서 C가 클수록 위반을 더 강하게 벌점하여 훈련오차를 줄이려는 압력이 커진다.</p>
<p>그 결과 경계는 데이터에 더 민감해져 유연성이 증가(분산 증가)할 수 있고, C가 작을수록 마진을 넓게 두고 위반을 더 허용하는 방향으로 경계가 매끈해져 과적합을 완화(분산 감소)하는 경향이 있다. (교재에서 C를 \sum \varepsilon_i\le C 형태의 <span dir="rtl">”</span>예산”으로 소개하는 경우는 표기상 방향이 달라 보일 수 있으나, 핵심은 <span dir="rtl">”</span>C가 마진-오분류의 절충을 조절한다”는 점이다.)</p>
<p><strong><span class="math inline">\(\gamma\)</span>: RBF 커널의 국소성(곡률) 조절</strong></p>
<p><span class="math inline">\(\gamma\)</span>는 RBF 커널에서 거리 <span class="math inline">\(\parallel x - x' \parallel^{2}\)</span>에 대한 민감도를 정한다.</p>
<p><span class="math inline">\(\gamma\)</span>가 작으면, 커널이 완만하게 감소하여 넓은 범위의 점들이 서로 영향을 주고, 결정경계가 비교적 매끈해진다(고편향·저분산 방향).</p>
<p><span class="math inline">\(\gamma\)</span>가 크면, 아주 가까운 점만 영향을 주어 경계가 국소적으로 급격히 휘어질 수 있다(저편향·고분산 방향).</p>
<p><span class="math inline">\(\gamma\)</span>를 크게 하면 훈련 ROC는 거의 완벽해질 수 있지만, 테스트에서는 오히려 성능이 악화될 수 있다. 즉, <span class="math inline">\(\gamma\)</span>는 <span dir="rtl">”</span>훈련 성능을 극대화”하기보다 <span dir="rtl">”</span>일반화 성능을 최적화”하는 관점에서 선택되어야 한다.</p>
<p><strong>결합 효과: C–<span class="math inline">\(\gamma\)</span>의 상호작용</strong></p>
<p>RBF SVM에서 유연성은 C와 <span class="math inline">\(\gamma\)</span>의 조합으로 결정된다.</p>
<p>C가 크고 <span class="math inline">\(\gamma\)</span>도 크면: 훈련 데이터를 매우 강하게 맞추는 방향(복잡한 경계) → 과적합 위험 최고.</p>
<p>C가 작고 <span class="math inline">\(\gamma\)</span>도 작으면: 경계가 매우 매끈(단순) → 과소적합 위험.</p>
<p>따라서 두 파라미터는 함께 튜닝해야 하며, 어느 하나만 조절하면 <span dir="rtl">”</span>복잡도 통제가 불완전”할 수 있다.</p>
<p><strong>C와 <span class="math inline">\(\gamma\)</span>를 어떻게 선택하는가?</strong></p>
<p>(1) 스케일링(표준화)은 사실상 필수</p>
<p>특히 RBF 커널은 <span class="math inline">\(\parallel x - x' \parallel^{2}\)</span>에 직접 의존하므로, 변수 스케일이 다르면 특정 변수에 의해 거리가 지배되어 <span class="math inline">\(\gamma\)</span> 해석과 최적화가 왜곡된다. 따라서 SVM을 적용할 때는 보통 <span class="math inline">\(x_{ij}^{(std)} = \frac{x_{ij} - {\overline{x}}_{j}}{s_{j}}\)</span>로 표준화한 뒤 모델을 학습한다(훈련 기준으로 변환).</p>
<p>(2) 그리드 탐색 + 교차검증이 기본</p>
<p>가장 널리 쓰이는 방법은 로그 스케일의 후보 집합을 두고 교차검증으로 최적 조합을 찾는 것이다.</p>
<p><span class="math inline">\(C \in \{ 2^{- 5}{,2}^{- 3},\ldots{,2}^{15}\},\gamma \in \{ 2^{- 15}{,2}^{- 13},\ldots{,2}^{3}\}\)</span>처럼 잡고, 각 조합에 대해 교차검증 성능(Accuracy/F1/AUC 등)을 평가하여 최고 성능 조합을 선택한다. 성능이 비슷한 조합이 여러 개면, 일반적으로 더 단순한(더 매끈한) 경계 쪽을 택해 과적합 위험을 줄인다.</p>
<p>(3) 평가 지표 선택</p>
<p>불균형 데이터에서는 Accuracy가 오해를 만들 수 있으므로 AUC, F1, PR-AUC, 민감도/특이도 균형 등 과제에 맞는 지표로 튜닝해야 한다. 특히 ROC 곡선은 임계값 변화에 따른 성능을 한눈에 보여주지만, 그림 9.10–9.11처럼 훈련 ROC만으로는 과적합을 판별할 수 없으므로 반드시 검증/테스트 ROC를 함께 확인해야 한다.</p>
<p>(4) 요약: <span dir="rtl">”</span>훈련 성능 ↑“가 목표가 아니라 <span dir="rtl">”</span>일반화 성능 최적화”</p>
<p>SVM은 커널과 튜닝 파라미터에 따라 매우 유연해져 훈련 성능을 거의 완벽하게 만들 수 있다. 그러나 이는 곧 과적합 가능성을 의미한다. 따라서 C와 <span class="math inline">\(\gamma\)</span>는 훈련 성능이 아니라 교차검증 기반 일반화 성능으로 선택해야 하며, 최종적으로는 독립된 테스트 셋에서 성능을 확인하는 절차가 필요하다.</p>
</section>
<section id="두-개보다-많은-클래스에서의-svm" class="level5">
<h5 class="anchored" data-anchor-id="두-개보다-많은-클래스에서의-svm">(6) 두 개보다 많은 클래스에서의 SVM</h5>
<p>지금까지의 논의는 이진 분류, 즉 두 클래스 상황에서의 분류에 한정되어 있었다. 그렇다면 클래스 수가 임의의 개수인 더 일반적인 경우(다중 분류)로 SVM을 어떻게 확장할 수 있을까?</p>
<p>SVM의 기반이 되는 분리 초평면이라는 개념은 두 개를 초과하는 클래스에 대해 자연스럽게 확장되지는 않는다. SVM을 K개 클래스의 경우로 확장하기 위한 여러 제안이 존재하지만, 그중 가장 널리 사용되는 두 가지 방법은 일대일 방식과 일대다 방식이다.</p>
<p><strong>일대일 분류</strong></p>
<p>SVM을 사용해 분류를 수행하려고 하는데 클래스가 K&gt;2개라고 하자. 일대일 또는 모든 쌍(all-pairs) 접근법은 각 클래스 쌍을 비교하는 SVM을 <span class="math inline">\(\binom{K}{2}\)</span>개 구축한다. 예를 들어, 어떤 SVM은 k번째 클래스를 +1로, k'번째 클래스를 -1로 코딩하여 두 클래스를 비교할 수 있다. 테스트 관측치 하나에 대해 <span class="math inline">\(\binom{K}{2}\)</span>개의 분류기를 모두 적용한 뒤, 그 테스트 관측치가 각 K개 클래스에 할당된 횟수를 집계한다. 최종 분류는 이러한 <span class="math inline">\(\binom{K}{2}\)</span>개의 쌍대 분류 결과에서 가장 자주 할당된 클래스로 테스트 관측치를 배정하는 방식으로 수행된다.</p>
<p><strong>일대다 분류</strong></p>
<p>일대다 접근법은 <span class="math inline">\(K &gt; 2\)</span>개 클래스 상황에서 SVM을 적용하는 또 다른 절차이다. 이 방법에서는 K개의 SVM을 적합시키는데, 매번 한 클래스를 나머지 <span class="math inline">\(K - 1\)</span>개 클래스와 비교한다. k번째 클래스를 +1로, 나머지 모든 클래스를 -1로 코딩하여 학습한 SVM에서 얻어지는 모수를 <span class="math inline">\(\beta_{0k},\beta_{1k},\ldots,\beta_{pk}\)</span>로 나타내자. 테스트 관측치를 <span class="math inline">\(x^{*}\)</span>라 하면, 우리는</p>
<p><span class="math inline">\(\beta_{0k} + \beta_{1k}x_{1}^{*} + \beta_{2k}x_{2}^{*} + \cdots + \beta_{pk}x_{p}^{*}\)</span> 값이 가장 큰 클래스로 그 관측치를 할당한다. 이는 해당 값이 클수록 테스트 관측치가 다른 어떤 클래스보다 k번째 클래스에 속한다는 확신이 높다는 것을 의미하기 때문이다.</p>
</section>
<section id="로지스틱-회귀와의-관계" class="level5">
<h5 class="anchored" data-anchor-id="로지스틱-회귀와의-관계">(7) 로지스틱 회귀와의 관계</h5>
<p>SVM이 1990년대 중반 처음 소개되었을 때, 통계학 및 머신러닝 커뮤니티에서 상당한 반향을 일으켰다. 이는 부분적으로 SVM의 좋은 성능과 효과적인 마케팅 덕분이기도 했고, 또한 그 기반 접근법이 새롭고도 신비롭게 보였기 때문이기도 하다.</p>
<p>즉, 어느 정도의 분리 위반을 허용하면서도 데이터를 가능한 한 잘 분리하는 초평면을 찾는다는 발상은 로지스틱 회귀나 선형판별분석 같은 고전적 분류 접근법과는 확연히 다른 것처럼 보였다. 더 나아가 비선형 클래스 경계를 수용하기 위해 커널을 사용하여 특성공간을 확장하는 아이디어는 독특하고 가치 있는 특징으로 여겨졌다.</p>
<p>그러나 그 이후로 SVM과 보다 고전적인 통계적 방법들 사이에 깊은 연결고리가 존재함이 드러났다. 실제로 서포트 벡터 분류기 <span class="math inline">\(f(X) = \beta_{0} + \beta_{1}X_{1} + \cdots + \beta_{p}X_{p}\)</span>를 적합하기 위한 기준식은 다음과 같이 다시 쓸 수 있다:</p>
<p><span class="math inline">\(\min_{\beta_{0},\beta_{1},\ldots,\beta_{p}}\left\{ \overset{n}{\sum_{i = 1}}\max\lbrack 0,1 - y_{i}f(x_{i})\rbrack + \lambda\overset{p}{\sum_{j = 1}}\beta_{j}^{2} \right\}\)</span>, 여기서 <span class="math inline">\(\lambda\)</span>는 0 이상의 튜닝 파라미터이다. <span class="math inline">\(\lambda\)</span>가 크면 <span class="math inline">\(\beta_{1},\ldots,\beta_{p}\)</span>는 작아지고, 마진에 대한 위반이 더 많이 허용되며, 그 결과 분산은 낮고 편향은 높은 분류기가 된다.</p>
<p>반대로 <span class="math inline">\(\lambda\)</span>가 작으면 마진 위반이 거의 발생하지 않게 되며, 이는 분산은 높고 편향은 낮은 분류기에 해당한다. 따라서 <span class="math inline">\(\lambda\)</span>가 작다는 것은 C가 작다는 것과 대응한다. 또한 <span class="math inline">\(\lambda\overset{p}{\sum_{j = 1}}\beta_{j}^{2}\)</span>항은 규제회귀의 릿지(ridge) 페널티 항이며, 서포트 벡터 분류기에서 편향–분산 절충을 조절하는 역할도 유사하게 수행한다.</p>
<p><span class="math inline">\(\min_{\beta_{0},\beta_{1},\ldots,\beta_{p}}\{ L(X,y,\beta) + \lambda P(\beta)\}\)</span>, 여기서 <span class="math inline">\(L(X,y,\beta)\)</span>는 모수 <span class="math inline">\(\beta\)</span>로 매개화된 모형이 데이터 (X,y)에 얼마나 잘 맞는지를 정량화하는 손실 함수이며, <span class="math inline">\(P(\beta)\)</span>는 모수 벡터 <span class="math inline">\(\beta\)</span>에 대한 페널티 함수로서 그 효과는 0 이상의 튜닝 파라미터 <span class="math inline">\(\lambda\)</span>에 의해 조절된다. 예를 들어 릿지 회귀와 라쏘는 각각 다음 형태를 취한다:</p>
<p><span class="math inline">\(L(X,y,\beta) = \overset{n}{\sum_{i = 1}}\left( y_{i} - \beta_{0} - \overset{p}{\sum_{j = 1}}x_{ij}\beta_{j} \right)^{2}\)</span>. 그리고 릿지 회귀에서는 <span class="math inline">\(P(\beta) = \overset{p}{\sum_{j = 1}}\beta_{j}^{2}\)</span>, 라쏘에서는 <span class="math inline">\(P(\beta) = \overset{p}{\sum_{j = 1}}|\beta_{j}|\)</span>이다.</p>
<p>손실 함수는 다음 형태를 갖는다:</p>
<p><span class="math display">\[L(X,y,\beta) = \overset{n}{\sum_{i = 1}}\max\lbrack 0,1 - y_{i}(\beta_{0} + \beta_{1}x_{i1} + \cdots + \beta_{p}x_{ip})\rbrack\]</span></p>
<p>이는 힌지 손실(hinge loss)이라 불리며, 힌지 손실은 로지스틱 회귀에서 사용되는 손실 함수와 밀접하게 관련되어 있음이 알려져 있다.</p>
<p>서포트 벡터 분류기의 흥미로운 특징은 서포트 벡터만이 최종 분류기에 영향을 준다는 점이다. 마진의 올바른 쪽에 있는 관측치들은 분류기에 영향을 주지 않는데, 이는 손실 함수가 <span class="math inline">\(y_{i}(\beta_{0} + \beta_{1}x_{i1} + \cdots + \beta_{p}x_{ip}) \geq 1\)</span>인 관측치에 대해 정확히 0이 되기 때문이다.</p>
<p>로지스틱 회귀 손실 함수는 어느 지점에서도 정확히 0이 되지는 않는다. 다만 결정경계에서 멀리 떨어진 관측치들에 대해서는 그 값이 매우 작아진다.</p>
<p>이러한 두 손실 함수의 유사성 때문에, 로지스틱 회귀와 서포트 벡터 분류기는 종종 매우 비슷한 결과를 낸다. 클래스들이 잘 분리되어 있을 때는 SVM이 로지스틱 회귀보다 더 잘 작동하는 경향이 있고, 클래스가 많이 겹치는 영역에서는 로지스틱 회귀가 종종 더 선호된다.</p>
<p>서포트 벡터 분류기와 SVM이 처음 소개되었을 때는 튜닝 파라미터 C가 중요하지 않은 <span dir="rtl">’</span>사소한(nuisance)<span dir="rtl">’</span> 파라미터로 여겨져, 어떤 기본값(예: 1)으로 설정해도 된다고 생각되곤 했다.</p>
<p>그러나 서포트 벡터 분류기의 <span dir="rtl">”</span>손실 + 페널티” 표현은 이것이 사실이 아님을 보여준다. 튜닝 파라미터의 선택은 매우 중요하며, 모형이 데이터에 과소적합 또는 과적합하는 정도를 결정한다.</p>
<p>우리는 서포트 벡터 분류기가 로지스틱 회귀 및 다른 기존 통계적 방법들과 밀접하게 관련되어 있음을 확인했다. 그렇다면 비선형 클래스 경계를 수용하기 위해 특성공간을 커널로 확장하는 측면에서 SVM은 독특한가? 이 질문에 대한 답은 <span dir="rtl">”</span>아니다”이다.</p>
<p>로지스틱 회귀나 이 책에서 다룬 다른 분류 방법들에도 비선형 커널을 적용해 특성공간을 확장하는 것을 충분히 할 수 있으며, 이는 비선형 방법들과 밀접한 관련이 있다. 다만 역사적 이유로, 비선형 커널은 로지스틱 회귀나 다른 방법들보다 SVM 맥락에서 훨씬 더 널리 사용되어 왔다.</p>
</section>
</section>
<section id="분할-기반tree-분류-상세-내용-예측모형-강의노트-참고" class="level4">
<h4 class="anchored" data-anchor-id="분할-기반tree-분류-상세-내용-예측모형-강의노트-참고">4. 분할 기반(Tree) 분류 — <a href="../../notes/mldl_prediction/prediction_treebase.html">상세 내용: 예측모형 강의노트 참고</a></h4>
<p>분할 기반 분류모형(분류나무, Classification Tree)은 입력공간을 여러 개의 영역으로 나누고, 각 영역에서 가장 우세한 클래스를 예측하는 방식이다. 핵심 아이디어는 <span dir="rtl">”</span>어떤 변수의 임계값(또는 범주)으로 데이터를 반복적으로 쪼개면, 클래스가 비교적 균질한 구간을 만들 수 있다”는 것이다. 즉, 트리는 선형 결합으로 하나의 경계를 만드는 대신, 규칙의 조합으로 비선형·상호작용 구조를 자연스럽게 포착한다.</p>
<p>방법론적으로는 예측(회귀)나무와 동일한 절차를 따르되, 분할 기준만 <span dir="rtl">”</span>연속형 오차(MSE)“가 아니라 <span dir="rtl">”</span>분류 순도”를 개선하는 방향으로 바뀐다. 대표적으로 노드 t에서 클래스 비율을 <span class="math inline">\(p_{k}(t)\)</span>라 할 때,</p>
<p><strong>지니 불순도(Gini)</strong>: <span class="math inline">\(G(t) = \overset{K}{\sum_{k = 1}}p_{k}(t)(1 - p_{k}(t)) = 1 - \overset{K}{\sum_{k = 1}}p_{k}(t)^{2}\)</span></p>
<p><strong>엔트로피(Entropy)</strong>: <span class="math inline">\(H(t) = - \overset{K}{\sum_{k = 1}}p_{k}(t)\log p_{k}(t)\)</span></p>
<p>같은 기준을 사용하여 분할 전후의 불순도 감소가 최대가 되도록 분할을 선택한다.</p>
<p>최종 예측은 새 관측치 x가 도달한 말단노드(leaf)에서의 다수결(또는 클래스 확률 <span class="math inline">\({\widehat{p}}_{k}\)</span>)로 결정된다. 과적합을 막기 위해 최대 깊이 제한, 최소 노드 크기, 비용-복잡도 가지치기(pruning) 등의 규제는 회귀나무와 동일한 논리로 적용된다.</p>
<p>정리하면, 분할 기반(Tree) 분류는 예측모형(트리 기반 예측)에서 다룬 트리 방법론과 구조·학습 절차는 동일하며, 손실/분할 기준만 분류용 불순도 척도로 바뀐다는 점만 강조하면 된다.</p>
</section>
<section id="결합-기반ensemble-분류-상세-내용-예측모형-강의노트-참고" class="level4">
<h4 class="anchored" data-anchor-id="결합-기반ensemble-분류-상세-내용-예측모형-강의노트-참고">5. 결합 기반(Ensemble) 분류 — <a href="../../notes/mldl_prediction/prediction_treebase.html">상세 내용: 예측모형 강의노트 참고</a></h4>
<p>결합 기반 분류모형(앙상블, Ensemble)은 단일 분류나무(또는 약한 학습기)의 불안정성(분산 큼)과 한계를 보완하기 위해, 여러 개의 모형을 학습한 뒤 결합하여 예측 성능과 안정성을 높이는 방법이다. 기본 철학은 <span dir="rtl">”</span>여러 개의 다소 불완전한 분류기를 적절히 합치면, 단일 모델보다 일반화 성능이 좋아진다”는 것이다.</p>
<p>예측(회귀)에서의 앙상블과 동일하게, 분류에서도 대표적으로 다음 두 흐름이 핵심이다.</p>
<section id="배깅랜덤포레스트baggingrandom-forest" class="level5">
<h5 class="anchored" data-anchor-id="배깅랜덤포레스트baggingrandom-forest">1. 배깅/랜덤포레스트(Bagging/Random Forest)</h5>
<p>부트스트랩 표본으로 여러 트리를 학습하고, 분류에서는 각 트리의 예측을 다수결(voting)로 결합한다. <span class="math inline">\(\widehat{y}(x) = \arg\max_{k}\overset{B}{\sum_{b = 1}}\mathbf{1}({\widehat{y}}_{b}(x) = k)\)</span></p>
<p>랜덤포레스트는 여기에 분할 시 후보 변수의 무작위 선택을 추가하여 트리 간 상관을 줄이고 분산 감소 효과를 강화한다. (확률이 필요하면 트리들의 클래스확률 평균을 사용하고, 필요시 calibration을 고려한다.)</p>
</section>
<section id="부스팅boosting-adaboostgbmxgboost-등" class="level5">
<h5 class="anchored" data-anchor-id="부스팅boosting-adaboostgbmxgboost-등">2. 부스팅(Boosting: AdaBoost/GBM/XGBoost 등)</h5>
<p>이전 모델이 틀린 관측치(오분류/손실이 큰 표본)에 더 집중하도록 순차적으로 모델을 추가하여, 편향을 줄이면서 성능을 끌어올린다. 분류에서는 로지스틱 손실, 지수손실 등 분류용 손실함수를 최소화하는 형태로 전개되며, 최종 예측은 여러 약한 학습기의 가중 결합으로 얻는다.</p>
<p>정리하면, 결합 기반(Ensemble) 분류는 예측모형(앙상블)에서 다룬 배깅·랜덤포레스트·부스팅의 방법론적 틀과 동일하며, 결합 규칙이 평균(회귀) 대신 다수결/확률 평균(분류)로 바뀐다는 점과, 성능평가 지표가 분류용(Accuracy/F1/AUC 등)으로 바뀐다는 정도만 덧붙이면 충분하다.</p>
</section>
</section>
<section id="사례분석이진분류" class="level4">
<h4 class="anchored" data-anchor-id="사례분석이진분류">6. 사례분석(이진분류)</h4>
<section id="데이터" class="level5">
<h5 class="anchored" data-anchor-id="데이터">(1) 데이터</h5>
<p>본 실습에서는 이진분류 예제로 널리 사용되는 Breast Cancer Wisconsin (Diagnostic) 데이터를 사용한다. 이 데이터는 유방 종양의 세포핵(nucleus) 형태 특성으로부터 종양이 악성(malignant 0) 인지 양성(benign 1) 인지를 분류하는 문제를 다룬다. 표본 수는 𝑛 = 569, 변수(특징) 수는 p=30이다.</p>
<p>30개의 입력 변수는 모두 연속형 수치 변수로, 종양의 형태를 요약한 통계적 특성들이다. 예를 들어 평균 반지름(mean radius), 둘레(mean perimeter), 면적(mean area) 등 “mean / error / worst” 유형의 파생 특징들이 포함된다.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1) 데이터 불러오기: Breast Cancer Wisconsin (Diagnostic)</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_breast_cancer</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> load_breast_cancer()</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> data.data</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data.target</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>feature_names <span class="op">=</span> data.feature_names</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>target_names <span class="op">=</span> data.target_names</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"X shape:"</span>, X.shape)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"y shape:"</span>, y.shape)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Classes:"</span>, <span class="bu">dict</span>(<span class="bu">enumerate</span>(target_names)))</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Class counts:"</span>, <span class="bu">dict</span>(<span class="bu">zip</span>(<span class="op">*</span>np.unique(y, return_counts<span class="op">=</span><span class="va">True</span>))))</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># DataFrame으로 보기 좋게(선택)</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(X, columns<span class="op">=</span>feature_names)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"target"</span>] <span class="op">=</span> y</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>df.info()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="전처리" class="level5">
<h5 class="anchored" data-anchor-id="전처리">(2) 전처리</h5>
<p><strong>왜 train/test 분할을 먼저 하는가?</strong></p>
<p>모형 성능 평가는 “새로운 데이터에서 얼마나 잘 맞추는가”를 보는 것이므로, 전체 데이터를 학습용(train) 과 평가용(test) 으로 나눈다. 이때 핵심 원칙은 테스트 데이터는 학습 과정에 절대 사용되지 않아야 한다는 점이다. (데이터 누수 방지)</p>
<p>코드에서는 다음처럼 75%는 학습, 25%는 테스트로 분할했다.</p>
<p>학습 데이터: 426개 / 테스트 데이터: 143개</p>
<p><strong>“층화(stratify)”는 왜 필요한가?</strong></p>
<p>이 데이터는 이진분류이며 클래스(악성/양성)의 비율이 212:357로 약간 불균형이다. 무작위 분할만 하면 우연히 한쪽 클래스가 테스트에 과소/과다 포함될 수 있어 평가가 흔들릴 수 있다.</p>
<p>train_test_split(…, stratify=y)는 훈련/테스트 각각에서 클래스 비율이 원 데이터와 유사하게 유지되도록 분할한다.</p>
<p>그래서 출력에서 train: (0) 159, (1) 267 / test : (0) 53, (1) 90처럼 비율이 큰 폭으로 깨지지 않는다.</p>
<p><strong>StandardScaler(표준화)를 왜 하는가?</strong></p>
<p>SVM(특히 RBF 커널)과 k-NN은 거리/내적 기반이라 변수 스케일에 매우 민감하다.</p>
<p>예를 들어, mean area 같은 변수는 값의 스케일이 크고, mean smoothness 같은 변수는 스케일이 작다. 표준화 없이 거리 계산을 하면 스케일이 큰 변수가 거리를 지배해, 모델이 “큰 단위 변수”만 보고 판단하는 부작용이 생긴다.</p>
<p><strong>파이프라인(Pipeline)을 쓰는 이유: 누수 방지 + 재사용성</strong></p>
<p>표준화는 반드시 학습 데이터에서만 평균/표준편차를 추정(fit)해야 한다. 만약 테스트 데이터까지 포함해 스케일을 맞추면, 테스트 정보가 학습 단계에 섞이는 데이터 누수가 발생한다. 즉, 테스트 데이터는 “변환(transform)”만 한다.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 2단계: train/test 분할(층화) + 표준화(Standardization) 파이프라인 준비</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_breast_cancer</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co"># (1) 데이터 로드</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> load_breast_cancer()</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> data.data</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data.target</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co"># (2) train/test 분할 (층화: stratify=y)</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    X, y,</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    test_size<span class="op">=</span><span class="fl">0.25</span>,</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    stratify<span class="op">=</span>y</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[Split]"</span>)</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"X_train:"</span>, X_train.shape, <span class="st">"X_test:"</span>, X_test.shape)</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"y_train counts:"</span>, <span class="bu">dict</span>(<span class="bu">zip</span>(<span class="op">*</span>np.unique(y_train, return_counts<span class="op">=</span><span class="va">True</span>))))</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"y_test  counts:"</span>, <span class="bu">dict</span>(<span class="bu">zip</span>(<span class="op">*</span>np.unique(y_test, return_counts<span class="op">=</span><span class="va">True</span>))))</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a><span class="co"># (3) 표준화 파이프라인(학습 데이터로 fit, 테스트에는 transform만 적용)</span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>scaler_pipe <span class="op">=</span> Pipeline([</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"scaler"</span>, StandardScaler())</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a><span class="co"># 표준화 적용(이후 k-NN, SVM 파이프라인에 그대로 끼워 넣을 예정)</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>X_train_scaled <span class="op">=</span> scaler_pipe.fit_transform(X_train)</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>X_test_scaled  <span class="op">=</span> scaler_pipe.transform(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>[Split] X_train: (426, 30) X_test: (143, 30) <br> y_train counts: {np.int64(0): np.int64(159), np.int64(1): np.int64(267)} <br> y_test counts: {np.int64(0): np.int64(53), np.int64(1): np.int64(90)}</p>
</section>
<section id="knn" class="level5">
<h5 class="anchored" data-anchor-id="knn">(3) KNN</h5>
<p><strong>kNN 분석 및 성능 출력</strong></p>
<p>이 코드는 Breast Cancer Wisconsin 데이터에 대해 k-NN 분류기를 학습하고, 테스트셋에서 기본 성능(정확도/혼동행렬/분류리포트)을 확인하는 절차를 구현한다. 특히 k-NN은 거리 기반 방법이므로 표준화(Standardization) 를 반드시 포함해야 하며, 이를 누수 없이 수행하기 위해 Pipeline을 사용한다.</p>
<p>먼저 Pipeline([(“scaler”, StandardScaler()), (“knn”, KNeighborsClassifier(…))]) 형태로 전처리와 모델을 하나의 흐름으로 묶는다. 여기서 StandardScaler()는 각 변수를 훈련 데이터 기준 평균, 표준편차로 정규화 변환한다.</p>
<p>이 변환은 거리 계산에서 특정 변수(스케일이 큰 변수)가 과도하게 영향을 주는 문제를 막기 위해 필수적이다. Pipeline을 쓰면 표준화의 fit이 훈련 데이터에서만 수행되고, 테스트 데이터에는 동일한 변환이 transform으로만 적용되어 데이터 누수(leakage) 를 방지한다.</p>
<p>KNeighborsClassifier의 주요 설정은 다음 의미를 갖는다. n_neighbors=15: 예측 시 가장 가까운 이웃 k=15개를 사용한다. k가 작으면 잡음에 민감(분산↑), 너무 크면 경계가 과도하게 매끄러워짐(편향↑)이므로 적절한 균형이 필요하다.</p>
<p>p=2: 유클리드 거리(Euclidean)를 계산된다. (p=1이면 맨해튼 거리)</p>
<p>weights=“distance”: 단순 다수결이 아니라 가까운 이웃에 더 큰 가중치를 두어 투표한다. 경계 근처에서 더 안정적인 예측을 기대할 수 있다.</p>
<p>학습은 knn_model.fit(X_train, y_train)로 수행된다. k-NN은 손실함수 최적화로 파라미터를 학습하기보다는 “훈련 데이터를 저장해두고”, 예측 시 매번 이웃을 검색하는 형태이므로(게으른 학습), 실질적 계산 부담은 예측 단계에 더 크게 발생한다.</p>
<p>이후 predict(X_test)로 클래스 라벨을 예측하고, accuracy_score, confusion_matrix, classification_report를 통해 성능을 요약한다.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, confusion_matrix, classification_report</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># k-NN 모델 (표준화 + kNN)</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>knn_model <span class="op">=</span> Pipeline([</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"scaler"</span>, StandardScaler()),</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"knn"</span>, KNeighborsClassifier(</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>        n_neighbors<span class="op">=</span><span class="dv">15</span>,      <span class="co"># k</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>        weights<span class="op">=</span><span class="st">"distance"</span>,  <span class="co"># 가까운 이웃 가중↑</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>        p<span class="op">=</span><span class="dv">2</span>                  <span class="co"># p=2: Euclidean, p=1: Manhattan</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    ))</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 학습</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>knn_model.fit(X_train, y_train)</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="co"># 예측(클래스)</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>y_pred_knn <span class="op">=</span> knn_model.predict(X_test)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="co"># 평가(기본)</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[k-NN] Accuracy:"</span>, accuracy_score(y_test, y_pred_knn))</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[k-NN] Confusion matrix:</span><span class="ch">\n</span><span class="st">"</span>, confusion_matrix(y_test, y_pred_knn))</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[k-NN] Classification report:</span><span class="ch">\n</span><span class="st">"</span>, classification_report(y_test, y_pred_knn, target_names<span class="op">=</span>data.target_names))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>[k-NN] Accuracy: 0.965034965034965 <br> [k-NN] Confusion matrix: <br> [[48 5] <br> [ 0 90]]</p>
<p>[k-NN] Classification report:</p>
<pre class="text"><code>               precision    recall  f1-score   support

   malignant       1.00      0.91      0.95        53
      benign       0.95      1.00      0.97        90

    accuracy                           0.97       143
   macro avg       0.97      0.95      0.96       143 
weighted avg       0.97      0.97      0.96       143</code></pre>
<p><strong>k-NN: ROC/PR 곡선과 임계값(Threshold) 선택</strong></p>
<p>이 코드는 k-NN 분류기가 출력하는 확률(score) 을 이용해, (1) ROC 곡선과 PR 곡선을 계산하고 (2) 임계값 t를 바꿀 때 혼동행렬과 성능지표가 어떻게 변하는지 확인하며 (3) 운영 목적에 맞는 임계값을 선택하는 절차를 구현한다.</p>
<p>핵심 아이디어는 “확률을 0/1로 바꾸는 기준이 임계값이며, 임계값을 어디에 두느냐에 따라 FP/FN이 달라진다”는 점이다.</p>
<p>ROC/PR 및 임계값 선택은 항상 “어떤 클래스를 positive(관심 이벤트)로 볼 것인가”를 먼저 정해야 한다. Breast Cancer 데이터는 라벨이 0=malignant(악성), 1=benign(양성) 이므로, 코드의 기본 설정(A)은 positive=1(benign) 로 둔다. 따라서 y_pos = y_test 그대로 사용하고, 확률도 P(y=1|x)를 사용한다.</p>
<p>다만 의료 진단에서는 보통 “악성(놓치면 치명적)”을 positive로 두는 해석이 자연스럽다. 이를 위해 코드에는 옵션(B)이 포함되어 있으며, 이 경우 y_pos = (y_test==0)처럼 악성을 1로 재코딩하고, score도 P(malignant|x)가 되도록 1 - P(benign|x)로 뒤집어 사용한다. 즉, 같은 모델이라도 positive 정의에 따라 ROC/PR의 의미가 달라진다.</p>
<p>k-NN은 predict_proba를 제공하므로, 테스트 데이터에 대해 “positive 클래스의 확률”을 다음처럼 만든다. p_pos1 = knn_model.predict_proba(X_test)[:,1] 이 확률 벡터가 이후 ROC/PR 곡선과 임계값 분석의 유일한 핵심 입력(score) 이 된다.</p>
<p><strong>ROC 곡선과 AUC 계산</strong></p>
<p>ROC는 임계값 t를 0에서 1까지 움직이며, 각 임계값에서 다음 두 값을 계산해 그린 곡선이다.</p>
<ul>
<li>TPR(재현율, 민감도) = TP / (TP + FN)</li>
<li>FPR(위양성률) = FP / (FP + TN)</li>
</ul>
<p>코드의 roc_curve(y_pos, score)는 (FPR 배열, TPR 배열, 그리고 그때의 임계값 배열)을 반환한다. 이어서 auc(fpr, tpr)는 ROC 곡선 아래 면적(AUC)을 계산한다. AUC는 “positive 샘플이 negative보다 더 높은 점수(score)를 받도록 정렬되는 능력(순위 분리 성능)”을 요약한 값이다.</p>
<p><strong>PR 곡선과 AP 계산</strong></p>
<p>PR 곡선은 임계값 변화에 따라 다음 두 값의 trade-off를 본다.</p>
<ul>
<li>Precision(정밀도) = TP / (TP + FP)</li>
<li>Recall(재현율) = TP / (TP + FN)</li>
</ul>
<p>특히 양성 클래스가 희귀한 상황에서는 ROC보다 PR이 운영 품질을 더 직접적으로 보여주는 경우가 많다. average_precision_score로 계산한 AP는 PR 곡선을 하나의 수치로 요약한 값이다.</p>
<p><strong>“임계값 t 하나”에서 혼동행렬과 지표를 계산하는 함수</strong></p>
<p>metrics_at_threshold()는 특정 임계값 t를 주면 다음을 수행한다.</p>
<p>확률을 이진 예측으로 변환: y_hat = (score &gt;= t). 즉, score가 임계값 이상이면 positive로 판정한다.</p>
<p>혼동행렬(TN, FP, FN, TP) 계산하고 그 혼동행렬로부터 지표 recall(TPR), fpr, precision, accuracy을 계산한다. 이 함수는 ROC/PR 같은 “곡선”을 실제 운영 관점의 “한 점(임계값 하나)”으로 풀어주는 역할을 한다.</p>
<p>여러 임계값(grid)을 찍어보며 FP/FN trade-off를 확인: 코드는 t=0.1,0.2,…,0.9에 대해 metrics_at_threshold 결과를 출력한다. 일반적으로 임계값을 올리면 positive 판정이 보수적으로 변하면서: FP는 감소(정밀도는 증가하는 경향), FN은 증가(재현율은 감소하는 경향). 즉, 임계값은 “오경보(FP)를 줄이느냐, 놓침(FN)을 줄이느냐”의 균형을 조절하는 손잡이다.</p>
<p><strong>임계값 선택 규칙 (A): Youden’s J 최대화</strong></p>
<p>Youden’s J는 ROC 관점에서 균형점을 잡는 단순한 기준이다.</p>
<p>J(t) = TPR(t) − FPR(t)</p>
<p>코드는 모든 ROC 점에서 J를 계산하고, J가 최대인 지점의 임계값을 선택한다. 이 방식은 “재현율을 높이되 위양성률도 너무 크지 않게” 만드는 균형형 기준으로 이해하면 된다.</p>
<p><strong>임계값 선택 규칙 (B): FPR 제약 조건 하에서 최적화</strong></p>
<p>운영에서 “오경보는 최대 α까지만 허용” 같은 정책이 있을 때, 먼저 FPR ≤ α를 만족하는 임계값 후보들만 남긴 뒤, 그중에서 TPR(재현율)이 가장 큰 임계값을 선택한다. 즉, 제약 조건을 먼저 만족시키고 그 안에서 성능을 최대로 만드는 방식이다. 예컨대 α=0.02는 매우 보수적인 오경보 제한에 해당하므로 임계값이 상대적으로 높아지고, 그 결과 recall이 일부 감소할 수 있다.</p>
<p><strong>임계값 선택 규칙 (C): 비용 기반 최소화</strong></p>
<p>현실에서는 FN과 FP의 비용이 다르므로, 비용함수를 두고 임계값을 고를 수 있다.</p>
<p>Cost(t) = c_fn * FN(t) + c_fp * FP(t)</p>
<p>코드는 가능한 임계값 후보들을 순회하면서 비용을 계산하고, 비용이 최소인 임계값을 선택한다. 예를 들어 c_fn을 크게 두면(놓침 비용이 큼), 모델은 FN을 줄이기 위해 임계값을 낮추는 방향으로 선택되는 경향이 강해진다. 반대로 c_fp가 크면 오경보를 줄이기 위해 임계값을 올리는 방향이 된다.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># k-NN: ROC / PR + 임계값(Threshold) 선택 코드</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co"># (전제) knn_model이 이미 fit 되어 있고, X_test, y_test가 준비되어 있어야 함.</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> (</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    roc_curve, auc,</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    precision_recall_curve, average_precision_score,</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    confusion_matrix</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co"># =========================================================</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 0) Positive(관심 클래스) 정의</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co">#    - 기본: positive = 1 (benign)  [데이터 라벨 그대로]</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co">#    - 의료진단 관점: positive = 0 (malignant) 로 바꾸려면 옵션 B 사용</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="co"># =========================================================</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="co"># 1) score(확률): P(y=1 | x)</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>p_pos1 <span class="op">=</span> knn_model.predict_proba(X_test)[:, <span class="dv">1</span>]</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a><span class="co"># A) positive = 1(benign)</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>y_pos <span class="op">=</span> y_test</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> p_pos1</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a><span class="co"># B) (옵션) positive = malignant(0)로 변경 시</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a><span class="co"># y_pos = (y_test == 0).astype(int)</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a><span class="co"># score = 1.0 - p_pos1   # = P(malignant | x)</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a><span class="co"># =========================================================</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a><span class="co"># 1) ROC curve + AUC</span></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a><span class="co"># =========================================================</span></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>fpr, tpr, thr_roc <span class="op">=</span> roc_curve(y_pos, score)</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>roc_auc <span class="op">=</span> auc(fpr, tpr)</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a><span class="co"># =========================================================</span></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a><span class="co"># 2) PR curve + AP</span></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a><span class="co"># =========================================================</span></span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>precision, recall, thr_pr <span class="op">=</span> precision_recall_curve(y_pos, score)</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>ap <span class="op">=</span> average_precision_score(y_pos, score)</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[k-NN] ROC AUC ="</span>, roc_auc)</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[k-NN] PR  AP  ="</span>, ap)</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"ROC thresholds:"</span>, thr_roc.shape, <span class="st">"| PR thresholds:"</span>, thr_pr.shape)</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a><span class="co"># =========================================================</span></span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a><span class="co"># 3) 임계값 t에서 혼동행렬/지표 계산</span></span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a><span class="co"># =========================================================</span></span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> metrics_at_threshold(y_true01, score, t):</span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a><span class="co">    y_true01: {0,1} (1이 positive)</span></span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a><span class="co">    score   : positive 점수(확률)</span></span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a><span class="co">    t       : threshold</span></span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>    y_hat <span class="op">=</span> (score <span class="op">&gt;=</span> t).astype(<span class="bu">int</span>)</span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>    tn, fp, fn, tp <span class="op">=</span> confusion_matrix(y_true01, y_hat).ravel()</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>    recall_ <span class="op">=</span> tp <span class="op">/</span> (tp <span class="op">+</span> fn) <span class="cf">if</span> (tp <span class="op">+</span> fn) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="fl">0.0</span>  <span class="co"># TPR</span></span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>    fpr_    <span class="op">=</span> fp <span class="op">/</span> (fp <span class="op">+</span> tn) <span class="cf">if</span> (fp <span class="op">+</span> tn) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>    prec_   <span class="op">=</span> tp <span class="op">/</span> (tp <span class="op">+</span> fp) <span class="cf">if</span> (tp <span class="op">+</span> fp) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>    acc_    <span class="op">=</span> (tp <span class="op">+</span> tn) <span class="op">/</span> (tp <span class="op">+</span> tn <span class="op">+</span> fp <span class="op">+</span> fn)</span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>        <span class="st">"t"</span>: <span class="bu">float</span>(t),</span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>        <span class="st">"tn"</span>: <span class="bu">int</span>(tn), <span class="st">"fp"</span>: <span class="bu">int</span>(fp), <span class="st">"fn"</span>: <span class="bu">int</span>(fn), <span class="st">"tp"</span>: <span class="bu">int</span>(tp),</span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a>        <span class="st">"recall(tpr)"</span>: <span class="bu">float</span>(recall_),</span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a>        <span class="st">"fpr"</span>: <span class="bu">float</span>(fpr_),</span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a>        <span class="st">"precision"</span>: <span class="bu">float</span>(prec_),</span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a>        <span class="st">"accuracy"</span>: <span class="bu">float</span>(acc_)</span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a><span class="co"># =========================================================</span></span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a><span class="co"># 4) 임계값 grid로 변화 확인(0.1~0.9)</span></span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a><span class="co"># =========================================================</span></span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a>grid <span class="op">=</span> np.arange(<span class="fl">0.1</span>, <span class="fl">1.0</span>, <span class="fl">0.1</span>)</span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> grid:</span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(metrics_at_threshold(y_pos, score, t))</span>
<span id="cb5-76"><a href="#cb5-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-77"><a href="#cb5-77" aria-hidden="true" tabindex="-1"></a><span class="co"># =========================================================</span></span>
<span id="cb5-78"><a href="#cb5-78" aria-hidden="true" tabindex="-1"></a><span class="co"># 5) 임계값 선택 규칙 (A) Youden J = TPR - FPR 최대</span></span>
<span id="cb5-79"><a href="#cb5-79" aria-hidden="true" tabindex="-1"></a><span class="co"># =========================================================</span></span>
<span id="cb5-80"><a href="#cb5-80" aria-hidden="true" tabindex="-1"></a>J <span class="op">=</span> tpr <span class="op">-</span> fpr</span>
<span id="cb5-81"><a href="#cb5-81" aria-hidden="true" tabindex="-1"></a>best_idx <span class="op">=</span> np.argmax(J)</span>
<span id="cb5-82"><a href="#cb5-82" aria-hidden="true" tabindex="-1"></a>best_t_youden <span class="op">=</span> thr_roc[best_idx]</span>
<span id="cb5-83"><a href="#cb5-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-84"><a href="#cb5-84" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">[Youden J]"</span>)</span>
<span id="cb5-85"><a href="#cb5-85" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"best t ="</span>, best_t_youden)</span>
<span id="cb5-86"><a href="#cb5-86" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(metrics_at_threshold(y_pos, score, best_t_youden))</span>
<span id="cb5-87"><a href="#cb5-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-88"><a href="#cb5-88" aria-hidden="true" tabindex="-1"></a><span class="co"># =========================================================</span></span>
<span id="cb5-89"><a href="#cb5-89" aria-hidden="true" tabindex="-1"></a><span class="co"># 6) 임계값 선택 규칙 (B) FPR &lt;= alpha 조건에서 TPR 최대</span></span>
<span id="cb5-90"><a href="#cb5-90" aria-hidden="true" tabindex="-1"></a><span class="co"># =========================================================</span></span>
<span id="cb5-91"><a href="#cb5-91" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> best_threshold_fpr_constraint(y_true01, score, alpha<span class="op">=</span><span class="fl">0.02</span>):</span>
<span id="cb5-92"><a href="#cb5-92" aria-hidden="true" tabindex="-1"></a>    fpr, tpr, thr <span class="op">=</span> roc_curve(y_true01, score)</span>
<span id="cb5-93"><a href="#cb5-93" aria-hidden="true" tabindex="-1"></a>    candidates <span class="op">=</span> np.where(fpr <span class="op">&lt;=</span> alpha)[<span class="dv">0</span>]</span>
<span id="cb5-94"><a href="#cb5-94" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(candidates) <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb5-95"><a href="#cb5-95" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb5-96"><a href="#cb5-96" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> candidates[np.argmax(tpr[candidates])]</span>
<span id="cb5-97"><a href="#cb5-97" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> thr[i]</span>
<span id="cb5-98"><a href="#cb5-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-99"><a href="#cb5-99" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.02</span></span>
<span id="cb5-100"><a href="#cb5-100" aria-hidden="true" tabindex="-1"></a>best_t_fpr <span class="op">=</span> best_threshold_fpr_constraint(y_pos, score, alpha<span class="op">=</span>alpha)</span>
<span id="cb5-101"><a href="#cb5-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-102"><a href="#cb5-102" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">[FPR constraint]"</span>)</span>
<span id="cb5-103"><a href="#cb5-103" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"alpha ="</span>, alpha, <span class="st">"best t ="</span>, best_t_fpr)</span>
<span id="cb5-104"><a href="#cb5-104" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> best_t_fpr <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb5-105"><a href="#cb5-105" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(metrics_at_threshold(y_pos, score, best_t_fpr))</span>
<span id="cb5-106"><a href="#cb5-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-107"><a href="#cb5-107" aria-hidden="true" tabindex="-1"></a><span class="co"># =========================================================</span></span>
<span id="cb5-108"><a href="#cb5-108" aria-hidden="true" tabindex="-1"></a><span class="co"># 7) 임계값 선택 규칙 (C) 비용 기반: c_fn*FN + c_fp*FP 최소</span></span>
<span id="cb5-109"><a href="#cb5-109" aria-hidden="true" tabindex="-1"></a><span class="co"># =========================================================</span></span>
<span id="cb5-110"><a href="#cb5-110" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> best_threshold_cost(y_true01, score, c_fn<span class="op">=</span><span class="fl">10.0</span>, c_fp<span class="op">=</span><span class="fl">1.0</span>):</span>
<span id="cb5-111"><a href="#cb5-111" aria-hidden="true" tabindex="-1"></a>    thresholds <span class="op">=</span> np.unique(np.r_[<span class="fl">0.0</span>, score, <span class="fl">1.0</span>])</span>
<span id="cb5-112"><a href="#cb5-112" aria-hidden="true" tabindex="-1"></a>    best_t, best_m, best_cost <span class="op">=</span> <span class="va">None</span>, <span class="va">None</span>, np.inf</span>
<span id="cb5-113"><a href="#cb5-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-114"><a href="#cb5-114" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> thresholds:</span>
<span id="cb5-115"><a href="#cb5-115" aria-hidden="true" tabindex="-1"></a>        m <span class="op">=</span> metrics_at_threshold(y_true01, score, t)</span>
<span id="cb5-116"><a href="#cb5-116" aria-hidden="true" tabindex="-1"></a>        cost <span class="op">=</span> c_fn <span class="op">*</span> m[<span class="st">"fn"</span>] <span class="op">+</span> c_fp <span class="op">*</span> m[<span class="st">"fp"</span>]</span>
<span id="cb5-117"><a href="#cb5-117" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> cost <span class="op">&lt;</span> best_cost:</span>
<span id="cb5-118"><a href="#cb5-118" aria-hidden="true" tabindex="-1"></a>            best_t, best_m, best_cost <span class="op">=</span> <span class="bu">float</span>(t), m, <span class="bu">float</span>(cost)</span>
<span id="cb5-119"><a href="#cb5-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-120"><a href="#cb5-120" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_t, best_m, best_cost</span>
<span id="cb5-121"><a href="#cb5-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-122"><a href="#cb5-122" aria-hidden="true" tabindex="-1"></a>best_t_cost, best_m_cost, best_cost_val <span class="op">=</span> best_threshold_cost(y_pos, score, c_fn<span class="op">=</span><span class="dv">10</span>, c_fp<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-123"><a href="#cb5-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-124"><a href="#cb5-124" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">[Cost-based]"</span>)</span>
<span id="cb5-125"><a href="#cb5-125" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"best t ="</span>, best_t_cost, <span class="st">"cost ="</span>, best_cost_val)</span>
<span id="cb5-126"><a href="#cb5-126" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(best_m_cost)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>(A) Youden J 최대:</strong> t≈0.5953 / tn=51, fp=2, fn=2, tp=88</p>
<p>FPR = 0.0377, TPR(recall)=0.9778</p>
<p>ROC 관점에서 TPR을 높이면서 FPR도 낮추는 “균형점”이다. t=0.5보다 FP(악성 놓침)가 5→2로 감소하지만, FN이 0→2로 소폭 증가한다.</p>
<p><strong>(B) FPR 제약:</strong> α=0.02 → t≈0.7527</p>
<p>tn=53, fp=0, fn=11, tp=79</p>
<p>FPR=0 (악성을 benign으로 놓치는 일이 0) 대신 FN=11 (benign을 악성으로 오경보 증가) → “악성(malignant)을 benign으로 놓치면 안 된다” 같은 정책이라면(오경보 비용보다 놓침 비용이 큰 경우) 이 방식이 자연스럽다.</p>
<p><strong>(C) 비용 기반:</strong> $C_{FN}=10, C_{FP}=1 $ → t≈0.7527</p>
<p>tn=49, fp=4, fn=0, tp=90, cost=4</p>
<p>FN(benign을 악성으로 오경보)을 10배로 벌점 주었기 때문에, FN=0을 유지하려고 t가 상대적으로 낮게 선택된다. 그 대가로 FP=4를 허용한다. → 이 결과는 “양성(benign)을 악성으로 오경보 내는 게 매우 비싸다”는 운영 가정에 맞춘 임계값입니다.</p>
<p>[k-NN] ROC AUC = 0.9947589098532496 <br> [k-NN] PR AP = 0.9968371869230795 <br> ROC thresholds: (11,) | PR thresholds: (52,) {‘t’: 0.1, ‘tn’: 43, ‘fp’: 10, ‘fn’: 0, ‘tp’: 90, ‘recall(tpr)’: 1.0, ‘fpr’: 0.18867924528301888, ‘precision’: 0.9, ‘accuracy’: 0.9300699300699301} <br> (중간생략) <br> {‘t’: 0.9, ‘tn’: 53, ‘fp’: 0, ‘fn’: 18, ‘tp’: 72, ‘recall(tpr)’: 0.8, ‘fpr’: 0.0, ‘precision’: 1.0, ‘accuracy’: 0.8741258741258742}</p>
<p>[Youden J] <br> best t = 0.5952751094038484 <br> {‘t’: 0.5952751094038484, ‘tn’: 51, ‘fp’: 2, ‘fn’: 2, ‘tp’: 88, ‘recall(tpr)’: 0.9777777777777777, ‘fpr’: 0.03773584905660377, ‘precision’: 0.9777777777777777, ‘accuracy’: 0.972027972027972}</p>
<p>[FPR constraint] <br> alpha = 0.02 best t = 0.7527356507381722 <br> {‘t’: 0.7527356507381722, ‘tn’: 53, ‘fp’: 0, ‘fn’: 11, ‘tp’: 79, ‘recall(tpr)’: 0.8777777777777778, ‘fpr’: 0.0, ‘precision’: 1.0, ‘accuracy’: 0.9230769230769231}</p>
<p>[Cost-based] <br> best t = 0.5563197878398277 cost = 4.0 <br> {‘t’: 0.5563197878398277, ‘tn’: 49, ‘fp’: 4, ‘fn’: 0, ‘tp’: 90, ‘recall(tpr)’: 1.0, ‘fpr’: 0.07547169811320754, ‘precision’: 0.9574468085106383, ‘accuracy’: 0.972027972027972}</p>
</section>
<section id="svm" class="level5">
<h5 class="anchored" data-anchor-id="svm">(4) SVM</h5>
<p>이 코드는 Breast Cancer Wisconsin 데이터에 대해 SVM(서포트 벡터 머신) 분류기를 학습하고, 테스트 데이터에서 기본 분류 성능(정확도·혼동행렬·분류리포트) 을 확인하는 절차를 구현한다.</p>
<p>특히 SVM은 입력 변수의 스케일에 민감하므로, 표준화(Standardization) 와 모델을 Pipeline으로 묶어 전처리와 학습·예측 과정을 한 번에 처리하도록 구성하였다.</p>
<p>먼저 Pipeline([(“scaler”, StandardScaler()), (“svm”, SVC(…))]) 형태로 파이프라인을 정의한다. 여기서 StandardScaler()는 훈련 데이터에서 각 변수의 평균과 표준편차를 추정한 뒤, 모든 변수를 정규 변환하여 평균 0, 분산 1 수준으로 맞춘다.</p>
<p>SVM은 거리·내적 기반(특히 RBF 커널은 거리 기반)의 분류기이므로 변수 스케일이 다르면 특정 변수의 영향이 과도해질 수 있는데, 표준화는 이를 방지하여 학습을 안정화한다. 또한 Pipeline을 사용하면 표준화의 fit은 훈련 데이터에만 적용되고 테스트 데이터에는 같은 변환이 transform으로만 적용되어, 테스트 정보가 학습에 섞이는 데이터 누수(leakage) 를 막는다.</p>
<p>두 번째 단계인 SVC(…)는 SVM 분류기를 의미한다. 여기서 kernel=“rbf”는 비선형 분류를 가능하게 하는 가우시안(RBF) 커널을 사용한다는 뜻이며, 입력공간에서 선형 분리가 어렵더라도 고차원 특징공간에서의 분리 초평면을 통해 복잡한 결정경계를 학습할 수 있다.</p>
<p>C=1.0은 마진을 넓게 유지하려는 성향과 학습 데이터 오분류를 줄이려는 성향 사이의 균형을 조절하는 규제(regularization) 파라미터로, C가 커지면 오분류를 더 강하게 벌점 주어 훈련 데이터에 더 맞추려 하고, 작아지면 마진을 넓게 두며 일반화를 더 중시하는 경향이 있다.</p>
<p>gamma=“scale”은 RBF 커널의 폭(영향 범위)을 자동으로 설정하는 옵션으로, 값이 커지면 결정경계가 더 구불구불해져 과적합 위험이 커지고, 작아지면 더 매끈한 경계가 된다. probability=True는 SVM이 기본적으로는 “확률”이 아니라 결정함수 값(decision score) 을 출력하는 모델이기 때문에, ROC/PR 곡선 및 임계값 조정을 위해 확률 형태의 출력(predict_proba) 을 사용할 수 있도록 내부적으로 확률 보정(calibration)을 수행하겠다는 설정이다.</p>
<p>random_state=42는 확률 보정 과정 등에서 재현성을 확보하기 위한 난수 시드로 이해하면 된다.</p>
<p>모델 학습은 svm_model.fit(X_train, y_train)에서 이루어진다. 이때 파이프라인이 먼저 훈련 데이터를 표준화한 뒤, 표준화된 입력으로 SVM을 학습한다. 학습이 끝나면 svm_model.predict(X_test)로 테스트 데이터의 클래스 라벨(0/1)을 예측한다.</p>
<p>마지막으로 accuracy_score는 전체 정확도를 계산하고, confusion_matrix는 실제 라벨과 예측 라벨을 교차 집계하여 TN, FP, FN, TP의 구조를 제공한다. classification_report는 클래스별로 precision, recall, F1-score를 요약해주므로, 단순 정확도뿐 아니라 “악성을 얼마나 놓치는지(FN)” 또는 “양성을 얼마나 악성으로 오경보하는지(FP)”와 같은 오류 유형을 더 세밀하게 해석할 수 있게 한다.</p>
<p>요약하면, 이 코드는 (표준화 → RBF SVM 학습 → 테스트 예측 → 기본 성능 평가) 의 전형적인 이진분류 실습 흐름을 파이프라인 형태로 깔끔하게 구현한 예제이며, 이후 ROC/PR 분석 및 임계값 선택으로 자연스럽게 확장할 수 있는 기본 골격을 제공한다.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, confusion_matrix, classification_report</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co"># SVM 모델 (표준화 + SVM)</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>svm_model <span class="op">=</span> Pipeline([</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"scaler"</span>, StandardScaler()),</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"svm"</span>, SVC(</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>        kernel<span class="op">=</span><span class="st">"rbf"</span>,        <span class="co"># 'linear', 'rbf' 등</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>        C<span class="op">=</span><span class="fl">1.0</span>,</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>        gamma<span class="op">=</span><span class="st">"scale"</span>,</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>        probability<span class="op">=</span><span class="va">True</span>,    <span class="co"># ROC/PR용 확률 필요</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    ))</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="co"># 학습</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>svm_model.fit(X_train, y_train)</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a><span class="co"># 예측(클래스)</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>y_pred_svm <span class="op">=</span> svm_model.predict(X_test)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a><span class="co"># 평가(기본)</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[SVM] Accuracy:"</span>, accuracy_score(y_test, y_pred_svm))</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[SVM] Confusion matrix:</span><span class="ch">\n</span><span class="st">"</span>, confusion_matrix(y_test, y_pred_svm))</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[SVM] Classification report:</span><span class="ch">\n</span><span class="st">"</span>, classification_report(y_test, y_pred_svm, target_names<span class="op">=</span>data.target_names))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>[SVM] Accuracy: 0.9790209790209791
[SVM] Confusion matrix:
 [[52  1]
 [ 2 88]]
[SVM] Classification report:
               precision    recall  f1-score   support

   malignant       0.96      0.98      0.97        53
      benign       0.99      0.98      0.98        90

    accuracy                           0.98       143
   macro avg       0.98      0.98      0.98       143
weighted avg       0.98      0.98      0.98       143</code></pre>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># =========================================================</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co"># SVM 임계값(Threshold) 결정 파트</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co">#   - 지표 함수(metrics_at_threshold)</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co">#   - Youden J 최적</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co">#   - FPR &lt;= alpha 제약 최적</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co">#   - 비용 기반(c_fn*FN + c_fp*FP) 최적</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co"># (전제) svm_model.fit(...) 완료, X_test, y_test 존재</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co"># =========================================================</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, roc_curve</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 0) Positive(관심 클래스) 정의</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="co">#   - 기본: positive = 1 (benign)  [원 라벨 그대로]</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="co">#   - 의료진단 관점: positive = malignant(0)로 바꾸려면 옵션 B 사용</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a><span class="co"># SVM 확률(score): P(y=1 | x)</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>p_pos1_svm <span class="op">=</span> svm_model.predict_proba(X_test)[:, <span class="dv">1</span>]</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a><span class="co"># A) positive = 1(benign)</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>y_pos <span class="op">=</span> y_test</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> p_pos1_svm</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a><span class="co"># B) (옵션) positive = malignant(0)로 변경 시 (악성을 1로 재코딩)</span></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a><span class="co"># y_pos = (y_test == 0).astype(int)</span></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a><span class="co"># score = 1.0 - p_pos1_svm   # = P(malignant | x)</span></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a><span class="co"># 1) 임계값 t에서 혼동행렬/지표 계산</span></span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> metrics_at_threshold(y_true01, score, t):</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a><span class="co">    y_true01: {0,1} (1이 positive)</span></span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a><span class="co">    score   : positive 점수(확률)</span></span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a><span class="co">    t       : threshold</span></span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a>    y_hat <span class="op">=</span> (score <span class="op">&gt;=</span> t).astype(<span class="bu">int</span>)</span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a>    tn, fp, fn, tp <span class="op">=</span> confusion_matrix(y_true01, y_hat).ravel()</span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a>    recall_ <span class="op">=</span> tp <span class="op">/</span> (tp <span class="op">+</span> fn) <span class="cf">if</span> (tp <span class="op">+</span> fn) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="fl">0.0</span>  <span class="co"># TPR</span></span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a>    fpr_    <span class="op">=</span> fp <span class="op">/</span> (fp <span class="op">+</span> tn) <span class="cf">if</span> (fp <span class="op">+</span> tn) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a>    prec_   <span class="op">=</span> tp <span class="op">/</span> (tp <span class="op">+</span> fp) <span class="cf">if</span> (tp <span class="op">+</span> fp) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a>    acc_    <span class="op">=</span> (tp <span class="op">+</span> tn) <span class="op">/</span> (tp <span class="op">+</span> tn <span class="op">+</span> fp <span class="op">+</span> fn)</span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a>        <span class="st">"t"</span>: <span class="bu">float</span>(t),</span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a>        <span class="st">"tn"</span>: <span class="bu">int</span>(tn), <span class="st">"fp"</span>: <span class="bu">int</span>(fp), <span class="st">"fn"</span>: <span class="bu">int</span>(fn), <span class="st">"tp"</span>: <span class="bu">int</span>(tp),</span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a>        <span class="st">"recall(tpr)"</span>: <span class="bu">float</span>(recall_),</span>
<span id="cb8-51"><a href="#cb8-51" aria-hidden="true" tabindex="-1"></a>        <span class="st">"fpr"</span>: <span class="bu">float</span>(fpr_),</span>
<span id="cb8-52"><a href="#cb8-52" aria-hidden="true" tabindex="-1"></a>        <span class="st">"precision"</span>: <span class="bu">float</span>(prec_),</span>
<span id="cb8-53"><a href="#cb8-53" aria-hidden="true" tabindex="-1"></a>        <span class="st">"accuracy"</span>: <span class="bu">float</span>(acc_)</span>
<span id="cb8-54"><a href="#cb8-54" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb8-55"><a href="#cb8-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-56"><a href="#cb8-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[Default t=0.5]"</span>)</span>
<span id="cb8-57"><a href="#cb8-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(metrics_at_threshold(y_pos, score, <span class="fl">0.5</span>))</span>
<span id="cb8-58"><a href="#cb8-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-59"><a href="#cb8-59" aria-hidden="true" tabindex="-1"></a><span class="co"># (선택) 임계값 변화 감 확인</span></span>
<span id="cb8-60"><a href="#cb8-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">[Grid check]"</span>)</span>
<span id="cb8-61"><a href="#cb8-61" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> np.arange(<span class="fl">0.1</span>, <span class="fl">1.0</span>, <span class="fl">0.1</span>):</span>
<span id="cb8-62"><a href="#cb8-62" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(metrics_at_threshold(y_pos, score, t))</span>
<span id="cb8-63"><a href="#cb8-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-64"><a href="#cb8-64" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb8-65"><a href="#cb8-65" aria-hidden="true" tabindex="-1"></a><span class="co"># 2) (A) Youden's J = TPR - FPR 최대화</span></span>
<span id="cb8-66"><a href="#cb8-66" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb8-67"><a href="#cb8-67" aria-hidden="true" tabindex="-1"></a>fpr, tpr, thr_roc <span class="op">=</span> roc_curve(y_pos, score)</span>
<span id="cb8-68"><a href="#cb8-68" aria-hidden="true" tabindex="-1"></a>J <span class="op">=</span> tpr <span class="op">-</span> fpr</span>
<span id="cb8-69"><a href="#cb8-69" aria-hidden="true" tabindex="-1"></a>best_t_youden <span class="op">=</span> <span class="bu">float</span>(thr_roc[np.argmax(J)])</span>
<span id="cb8-70"><a href="#cb8-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-71"><a href="#cb8-71" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">[Youden J]"</span>)</span>
<span id="cb8-72"><a href="#cb8-72" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"best t ="</span>, best_t_youden)</span>
<span id="cb8-73"><a href="#cb8-73" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(metrics_at_threshold(y_pos, score, best_t_youden))</span>
<span id="cb8-74"><a href="#cb8-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-75"><a href="#cb8-75" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb8-76"><a href="#cb8-76" aria-hidden="true" tabindex="-1"></a><span class="co"># 3) (B) FPR &lt;= alpha 제약에서 TPR 최대화</span></span>
<span id="cb8-77"><a href="#cb8-77" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb8-78"><a href="#cb8-78" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> best_threshold_fpr_constraint(y_true01, score, alpha<span class="op">=</span><span class="fl">0.02</span>):</span>
<span id="cb8-79"><a href="#cb8-79" aria-hidden="true" tabindex="-1"></a>    fpr, tpr, thr <span class="op">=</span> roc_curve(y_true01, score)</span>
<span id="cb8-80"><a href="#cb8-80" aria-hidden="true" tabindex="-1"></a>    candidates <span class="op">=</span> np.where(fpr <span class="op">&lt;=</span> alpha)[<span class="dv">0</span>]</span>
<span id="cb8-81"><a href="#cb8-81" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(candidates) <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb8-82"><a href="#cb8-82" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb8-83"><a href="#cb8-83" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> candidates[np.argmax(tpr[candidates])]</span>
<span id="cb8-84"><a href="#cb8-84" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">float</span>(thr[i])</span>
<span id="cb8-85"><a href="#cb8-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-86"><a href="#cb8-86" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.02</span></span>
<span id="cb8-87"><a href="#cb8-87" aria-hidden="true" tabindex="-1"></a>best_t_fpr <span class="op">=</span> best_threshold_fpr_constraint(y_pos, score, alpha<span class="op">=</span>alpha)</span>
<span id="cb8-88"><a href="#cb8-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-89"><a href="#cb8-89" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">[FPR constraint]"</span>)</span>
<span id="cb8-90"><a href="#cb8-90" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"alpha ="</span>, alpha, <span class="st">"best t ="</span>, best_t_fpr)</span>
<span id="cb8-91"><a href="#cb8-91" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> best_t_fpr <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb8-92"><a href="#cb8-92" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(metrics_at_threshold(y_pos, score, best_t_fpr))</span>
<span id="cb8-93"><a href="#cb8-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-94"><a href="#cb8-94" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb8-95"><a href="#cb8-95" aria-hidden="true" tabindex="-1"></a><span class="co"># 4) (C) 비용 기반: cost = c_fn*FN + c_fp*FP 최소화</span></span>
<span id="cb8-96"><a href="#cb8-96" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb8-97"><a href="#cb8-97" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> best_threshold_cost(y_true01, score, c_fn<span class="op">=</span><span class="fl">10.0</span>, c_fp<span class="op">=</span><span class="fl">1.0</span>):</span>
<span id="cb8-98"><a href="#cb8-98" aria-hidden="true" tabindex="-1"></a>    thresholds <span class="op">=</span> np.unique(np.r_[<span class="fl">0.0</span>, score, <span class="fl">1.0</span>])</span>
<span id="cb8-99"><a href="#cb8-99" aria-hidden="true" tabindex="-1"></a>    best_t, best_m, best_cost <span class="op">=</span> <span class="va">None</span>, <span class="va">None</span>, np.inf</span>
<span id="cb8-100"><a href="#cb8-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-101"><a href="#cb8-101" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> thresholds:</span>
<span id="cb8-102"><a href="#cb8-102" aria-hidden="true" tabindex="-1"></a>        m <span class="op">=</span> metrics_at_threshold(y_true01, score, t)</span>
<span id="cb8-103"><a href="#cb8-103" aria-hidden="true" tabindex="-1"></a>        cost <span class="op">=</span> c_fn <span class="op">*</span> m[<span class="st">"fn"</span>] <span class="op">+</span> c_fp <span class="op">*</span> m[<span class="st">"fp"</span>]</span>
<span id="cb8-104"><a href="#cb8-104" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> cost <span class="op">&lt;</span> best_cost:</span>
<span id="cb8-105"><a href="#cb8-105" aria-hidden="true" tabindex="-1"></a>            best_t, best_m, best_cost <span class="op">=</span> <span class="bu">float</span>(t), m, <span class="bu">float</span>(cost)</span>
<span id="cb8-106"><a href="#cb8-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-107"><a href="#cb8-107" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_t, best_m, best_cost</span>
<span id="cb8-108"><a href="#cb8-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-109"><a href="#cb8-109" aria-hidden="true" tabindex="-1"></a>best_t_cost, best_m_cost, best_cost_val <span class="op">=</span> best_threshold_cost(</span>
<span id="cb8-110"><a href="#cb8-110" aria-hidden="true" tabindex="-1"></a>    y_pos, score, c_fn<span class="op">=</span><span class="dv">10</span>, c_fp<span class="op">=</span><span class="dv">1</span></span>
<span id="cb8-111"><a href="#cb8-111" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-112"><a href="#cb8-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-113"><a href="#cb8-113" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">[Cost-based]"</span>)</span>
<span id="cb8-114"><a href="#cb8-114" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"best t ="</span>, best_t_cost, <span class="st">"cost ="</span>, best_cost_val)</span>
<span id="cb8-115"><a href="#cb8-115" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(best_m_cost)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>[Default t=0.5] {‘t’: 0.5, ‘tn’: 52, ‘fp’: 1, ‘fn’: 2, ‘tp’: 88, ‘recall(tpr)’: 0.9777777777777777, ‘fpr’: 0.018867924528301886, ‘precision’: 0.9887640449438202, ‘accuracy’: 0.9790209790209791}</p>
<p>[Grid check] {‘t’: 0.1, ‘tn’: 44, ‘fp’: 9, ‘fn’: 0, ‘tp’: 90, ‘recall(tpr)’: 1.0, ‘fpr’: 0.16981132075471697, ‘precision’: 0.9090909090909091, ‘accuracy’: 0.9370629370629371}</p>
<p>(이하 생략)</p>
<p>[Youden J] best t = 0.4325023552646032</p>
<p>{‘t’: 0.4325023552646032, ‘tn’: 52, ‘fp’: 1, ‘fn’: 1, ‘tp’: 89, ‘recall(tpr)’: 0.9888888888888889, ‘fpr’: 0.018867924528301886, ‘precision’: 0.9888888888888889, ‘accuracy’: 0.986013986013986}</p>
<p>[FPR constraint] alpha = 0.02 best t = 0.4325023552646032</p>
<p>{‘t’: 0.4325023552646032, ‘tn’: 52, ‘fp’: 1, ‘fn’: 1, ‘tp’: 89, ‘recall(tpr)’: 0.9888888888888889, ‘fpr’: 0.018867924528301886, ‘precision’: 0.9888888888888889, ‘accuracy’: 0.986013986013986}</p>
<p>[Cost-based] best t = 0.2980459103264749 cost = 3.0</p>
<p>{‘t’: 0.2980459103264749, ‘tn’: 50, ‘fp’: 3, ‘fn’: 0, ‘tp’: 90, ‘recall(tpr)’: 1.0, ‘fpr’: 0.05660377358490566, ‘precision’: 0.967741935483871, ‘accuracy’: 0.9790209790209791}</p>
</section>
<section id="knn-vs.svm-비교" class="level5">
<h5 class="anchored" data-anchor-id="knn-vs.svm-비교">(5) knn vs.SVM 비교</h5>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_curve, confusion_matrix</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co"># =========================================================</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 1) 악성=positive(1)로 재코딩 + 모델 score(악성 확률) 추출</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># =========================================================</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_score_for_class(model, X, class_label):</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""predict_proba 기반으로 특정 class_label의 확률을 반환 (Pipeline 포함)."""</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">hasattr</span>(model, <span class="st">"predict_proba"</span>):</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"This model has no predict_proba. (SVC는 probability=True 필요)"</span>)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    proba <span class="op">=</span> model.predict_proba(X)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Pipeline인 경우 classes_ 접근을 안전하게 처리</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    classes <span class="op">=</span> <span class="bu">getattr</span>(model, <span class="st">"classes_"</span>, <span class="va">None</span>)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> classes <span class="kw">is</span> <span class="va">None</span> <span class="kw">and</span> <span class="bu">hasattr</span>(model, <span class="st">"named_steps"</span>):</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>        classes <span class="op">=</span> <span class="bu">list</span>(model.named_steps.values())[<span class="op">-</span><span class="dv">1</span>].classes_</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>    classes <span class="op">=</span> np.array(classes)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>    idx <span class="op">=</span> np.where(classes <span class="op">==</span> class_label)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> proba[:, idx]</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a><span class="co"># 악성(malignant=0)을 positive=1로 두기</span></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>y_pos <span class="op">=</span> (y_test <span class="op">==</span> <span class="dv">0</span>).astype(<span class="bu">int</span>)  <span class="co"># 1이면 malignant</span></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a><span class="co"># 각 모델의 "악성 확률" score</span></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>score_knn <span class="op">=</span> get_score_for_class(knn_model, X_test, class_label<span class="op">=</span><span class="dv">0</span>)  <span class="co"># P(malignant|x)</span></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>score_svm <span class="op">=</span> get_score_for_class(svm_model, X_test, class_label<span class="op">=</span><span class="dv">0</span>)  <span class="co"># P(malignant|x)</span></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a><span class="co"># =========================================================</span></span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a><span class="co"># 2) 임계값 t에서 지표 계산</span></span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a><span class="co"># =========================================================</span></span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> metrics_at_threshold(y_true01, score, t):</span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>    y_hat <span class="op">=</span> (score <span class="op">&gt;=</span> t).astype(<span class="bu">int</span>)</span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>    tn, fp, fn, tp <span class="op">=</span> confusion_matrix(y_true01, y_hat).ravel()</span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a>    recall_ <span class="op">=</span> tp <span class="op">/</span> (tp <span class="op">+</span> fn) <span class="cf">if</span> (tp <span class="op">+</span> fn) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="fl">0.0</span>  <span class="co"># TPR</span></span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>    fpr_    <span class="op">=</span> fp <span class="op">/</span> (fp <span class="op">+</span> tn) <span class="cf">if</span> (fp <span class="op">+</span> tn) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a>    prec_   <span class="op">=</span> tp <span class="op">/</span> (tp <span class="op">+</span> fp) <span class="cf">if</span> (tp <span class="op">+</span> fp) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a>    acc_    <span class="op">=</span> (tp <span class="op">+</span> tn) <span class="op">/</span> (tp <span class="op">+</span> tn <span class="op">+</span> fp <span class="op">+</span> fn)</span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a>        <span class="st">"t"</span>: <span class="bu">float</span>(t),</span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a>        <span class="st">"tn"</span>: <span class="bu">int</span>(tn), <span class="st">"fp"</span>: <span class="bu">int</span>(fp), <span class="st">"fn"</span>: <span class="bu">int</span>(fn), <span class="st">"tp"</span>: <span class="bu">int</span>(tp),</span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a>        <span class="st">"recall(tpr)"</span>: <span class="bu">float</span>(recall_),</span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a>        <span class="st">"fpr"</span>: <span class="bu">float</span>(fpr_),</span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a>        <span class="st">"precision"</span>: <span class="bu">float</span>(prec_),</span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a>        <span class="st">"accuracy"</span>: <span class="bu">float</span>(acc_)</span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a><span class="co"># =========================================================</span></span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a><span class="co"># 3) 임계값 선택 규칙 3종</span></span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a><span class="co"># =========================================================</span></span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> threshold_youden(y_true01, score):</span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a>    fpr, tpr, thr <span class="op">=</span> roc_curve(y_true01, score)</span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a>    J <span class="op">=</span> tpr <span class="op">-</span> fpr</span>
<span id="cb9-57"><a href="#cb9-57" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">float</span>(thr[np.argmax(J)])</span>
<span id="cb9-58"><a href="#cb9-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-59"><a href="#cb9-59" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> threshold_fpr_constraint(y_true01, score, alpha<span class="op">=</span><span class="fl">0.02</span>):</span>
<span id="cb9-60"><a href="#cb9-60" aria-hidden="true" tabindex="-1"></a>    fpr, tpr, thr <span class="op">=</span> roc_curve(y_true01, score)</span>
<span id="cb9-61"><a href="#cb9-61" aria-hidden="true" tabindex="-1"></a>    cand <span class="op">=</span> np.where(fpr <span class="op">&lt;=</span> alpha)[<span class="dv">0</span>]</span>
<span id="cb9-62"><a href="#cb9-62" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(cand) <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb9-63"><a href="#cb9-63" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb9-64"><a href="#cb9-64" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> cand[np.argmax(tpr[cand])]</span>
<span id="cb9-65"><a href="#cb9-65" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">float</span>(thr[i])</span>
<span id="cb9-66"><a href="#cb9-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-67"><a href="#cb9-67" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> threshold_cost(y_true01, score, c_fn<span class="op">=</span><span class="fl">10.0</span>, c_fp<span class="op">=</span><span class="fl">1.0</span>):</span>
<span id="cb9-68"><a href="#cb9-68" aria-hidden="true" tabindex="-1"></a>    thresholds <span class="op">=</span> np.unique(np.r_[<span class="fl">0.0</span>, score, <span class="fl">1.0</span>])</span>
<span id="cb9-69"><a href="#cb9-69" aria-hidden="true" tabindex="-1"></a>    best_t, best_cost <span class="op">=</span> <span class="va">None</span>, np.inf</span>
<span id="cb9-70"><a href="#cb9-70" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> thresholds:</span>
<span id="cb9-71"><a href="#cb9-71" aria-hidden="true" tabindex="-1"></a>        m <span class="op">=</span> metrics_at_threshold(y_true01, score, t)</span>
<span id="cb9-72"><a href="#cb9-72" aria-hidden="true" tabindex="-1"></a>        cost <span class="op">=</span> c_fn <span class="op">*</span> m[<span class="st">"fn"</span>] <span class="op">+</span> c_fp <span class="op">*</span> m[<span class="st">"fp"</span>]</span>
<span id="cb9-73"><a href="#cb9-73" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> cost <span class="op">&lt;</span> best_cost:</span>
<span id="cb9-74"><a href="#cb9-74" aria-hidden="true" tabindex="-1"></a>            best_cost <span class="op">=</span> cost</span>
<span id="cb9-75"><a href="#cb9-75" aria-hidden="true" tabindex="-1"></a>            best_t <span class="op">=</span> <span class="bu">float</span>(t)</span>
<span id="cb9-76"><a href="#cb9-76" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_t, <span class="bu">float</span>(best_cost)</span>
<span id="cb9-77"><a href="#cb9-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-78"><a href="#cb9-78" aria-hidden="true" tabindex="-1"></a><span class="co"># =========================================================</span></span>
<span id="cb9-79"><a href="#cb9-79" aria-hidden="true" tabindex="-1"></a><span class="co"># 4) k-NN vs SVM 비교표 생성</span></span>
<span id="cb9-80"><a href="#cb9-80" aria-hidden="true" tabindex="-1"></a><span class="co"># =========================================================</span></span>
<span id="cb9-81"><a href="#cb9-81" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_rows(model_name, y_true01, score, alpha<span class="op">=</span><span class="fl">0.02</span>, c_fn<span class="op">=</span><span class="fl">10.0</span>, c_fp<span class="op">=</span><span class="fl">1.0</span>):</span>
<span id="cb9-82"><a href="#cb9-82" aria-hidden="true" tabindex="-1"></a>    rows <span class="op">=</span> []</span>
<span id="cb9-83"><a href="#cb9-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-84"><a href="#cb9-84" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Youden</span></span>
<span id="cb9-85"><a href="#cb9-85" aria-hidden="true" tabindex="-1"></a>    t_y <span class="op">=</span> threshold_youden(y_true01, score)</span>
<span id="cb9-86"><a href="#cb9-86" aria-hidden="true" tabindex="-1"></a>    m_y <span class="op">=</span> metrics_at_threshold(y_true01, score, t_y)</span>
<span id="cb9-87"><a href="#cb9-87" aria-hidden="true" tabindex="-1"></a>    m_y.update({<span class="st">"model"</span>: model_name, <span class="st">"rule"</span>: <span class="st">"Youden (TPR-FPR)"</span>, <span class="st">"cost"</span>: c_fn<span class="op">*</span>m_y[<span class="st">"fn"</span>] <span class="op">+</span> c_fp<span class="op">*</span>m_y[<span class="st">"fp"</span>]})</span>
<span id="cb9-88"><a href="#cb9-88" aria-hidden="true" tabindex="-1"></a>    rows.append(m_y)</span>
<span id="cb9-89"><a href="#cb9-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-90"><a href="#cb9-90" aria-hidden="true" tabindex="-1"></a>    <span class="co"># FPR constraint</span></span>
<span id="cb9-91"><a href="#cb9-91" aria-hidden="true" tabindex="-1"></a>    t_f <span class="op">=</span> threshold_fpr_constraint(y_true01, score, alpha<span class="op">=</span>alpha)</span>
<span id="cb9-92"><a href="#cb9-92" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> t_f <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb9-93"><a href="#cb9-93" aria-hidden="true" tabindex="-1"></a>        m_f <span class="op">=</span> metrics_at_threshold(y_true01, score, t_f)</span>
<span id="cb9-94"><a href="#cb9-94" aria-hidden="true" tabindex="-1"></a>        m_f.update({<span class="st">"model"</span>: model_name, <span class="st">"rule"</span>: <span class="ss">f"FPR &lt;= </span><span class="sc">{</span>alpha<span class="sc">}</span><span class="ss">"</span>, <span class="st">"cost"</span>: c_fn<span class="op">*</span>m_f[<span class="st">"fn"</span>] <span class="op">+</span> c_fp<span class="op">*</span>m_f[<span class="st">"fp"</span>]})</span>
<span id="cb9-95"><a href="#cb9-95" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb9-96"><a href="#cb9-96" aria-hidden="true" tabindex="-1"></a>        m_f <span class="op">=</span> {<span class="st">"model"</span>: model_name, <span class="st">"rule"</span>: <span class="ss">f"FPR &lt;= </span><span class="sc">{</span>alpha<span class="sc">}</span><span class="ss">"</span>, <span class="st">"t"</span>: <span class="va">None</span>,</span>
<span id="cb9-97"><a href="#cb9-97" aria-hidden="true" tabindex="-1"></a>               <span class="st">"tn"</span>: <span class="va">None</span>, <span class="st">"fp"</span>: <span class="va">None</span>, <span class="st">"fn"</span>: <span class="va">None</span>, <span class="st">"tp"</span>: <span class="va">None</span>,</span>
<span id="cb9-98"><a href="#cb9-98" aria-hidden="true" tabindex="-1"></a>               <span class="st">"recall(tpr)"</span>: <span class="va">None</span>, <span class="st">"fpr"</span>: <span class="va">None</span>, <span class="st">"precision"</span>: <span class="va">None</span>, <span class="st">"accuracy"</span>: <span class="va">None</span>,</span>
<span id="cb9-99"><a href="#cb9-99" aria-hidden="true" tabindex="-1"></a>               <span class="st">"cost"</span>: <span class="va">None</span>}</span>
<span id="cb9-100"><a href="#cb9-100" aria-hidden="true" tabindex="-1"></a>    rows.append(m_f)</span>
<span id="cb9-101"><a href="#cb9-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-102"><a href="#cb9-102" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Cost-based</span></span>
<span id="cb9-103"><a href="#cb9-103" aria-hidden="true" tabindex="-1"></a>    t_c, best_cost <span class="op">=</span> threshold_cost(y_true01, score, c_fn<span class="op">=</span>c_fn, c_fp<span class="op">=</span>c_fp)</span>
<span id="cb9-104"><a href="#cb9-104" aria-hidden="true" tabindex="-1"></a>    m_c <span class="op">=</span> metrics_at_threshold(y_true01, score, t_c)</span>
<span id="cb9-105"><a href="#cb9-105" aria-hidden="true" tabindex="-1"></a>    m_c.update({<span class="st">"model"</span>: model_name, <span class="st">"rule"</span>: <span class="ss">f"Cost (c_fn=</span><span class="sc">{</span>c_fn<span class="sc">}</span><span class="ss">, c_fp=</span><span class="sc">{</span>c_fp<span class="sc">}</span><span class="ss">)"</span>, <span class="st">"cost"</span>: best_cost})</span>
<span id="cb9-106"><a href="#cb9-106" aria-hidden="true" tabindex="-1"></a>    rows.append(m_c)</span>
<span id="cb9-107"><a href="#cb9-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-108"><a href="#cb9-108" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> rows</span>
<span id="cb9-109"><a href="#cb9-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-110"><a href="#cb9-110" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.02</span></span>
<span id="cb9-111"><a href="#cb9-111" aria-hidden="true" tabindex="-1"></a>c_fn, c_fp <span class="op">=</span> <span class="fl">10.0</span>, <span class="fl">1.0</span></span>
<span id="cb9-112"><a href="#cb9-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-113"><a href="#cb9-113" aria-hidden="true" tabindex="-1"></a>rows <span class="op">=</span> []</span>
<span id="cb9-114"><a href="#cb9-114" aria-hidden="true" tabindex="-1"></a>rows <span class="op">+=</span> build_rows(<span class="st">"k-NN"</span>, y_pos, score_knn, alpha<span class="op">=</span>alpha, c_fn<span class="op">=</span>c_fn, c_fp<span class="op">=</span>c_fp)</span>
<span id="cb9-115"><a href="#cb9-115" aria-hidden="true" tabindex="-1"></a>rows <span class="op">+=</span> build_rows(<span class="st">"SVM"</span>,  y_pos, score_svm, alpha<span class="op">=</span>alpha, c_fn<span class="op">=</span>c_fn, c_fp<span class="op">=</span>c_fp)</span>
<span id="cb9-116"><a href="#cb9-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-117"><a href="#cb9-117" aria-hidden="true" tabindex="-1"></a>df_cmp <span class="op">=</span> pd.DataFrame(rows)[</span>
<span id="cb9-118"><a href="#cb9-118" aria-hidden="true" tabindex="-1"></a>    [<span class="st">"model"</span>,<span class="st">"rule"</span>,<span class="st">"t"</span>,<span class="st">"tn"</span>,<span class="st">"fp"</span>,<span class="st">"fn"</span>,<span class="st">"tp"</span>,<span class="st">"recall(tpr)"</span>,<span class="st">"fpr"</span>,<span class="st">"precision"</span>,<span class="st">"accuracy"</span>,<span class="st">"cost"</span>]</span>
<span id="cb9-119"><a href="#cb9-119" aria-hidden="true" tabindex="-1"></a>].sort_values([<span class="st">"rule"</span>,<span class="st">"model"</span>]).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-120"><a href="#cb9-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-121"><a href="#cb9-121" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"== 악성(malignant=0)을 positive(=1)로 통일한 임계값 비교표 =="</span>)</span>
<span id="cb9-122"><a href="#cb9-122" aria-hidden="true" tabindex="-1"></a>display(df_cmp)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>SVM은 t≈0.593에서 TN=89, FP=1, FN=1, TP=52로 나타나며, 이는 악성 53건 중 52건을 찾아 재현율(Recall)=0.981을 달성하면서도, 양성 90건 중 오경보는 1건뿐이라 FPR=0.011로 매우 낮다는 뜻이다. 정확도도 0.986으로 높다.</p>
<p>즉 SVM은 놓침(FN)과 오경보(FP)를 동시에 작게 유지하는 균형형 운영점을 제공한다. 또한 이 데이터에서는 Youden 기준과 FPR≤0.02 제약 기준이 같은 임계값(동일한 ROC 구간의 최적점)으로 수렴하여, “오경보를 2% 이내로 제한”하더라도 성능 저하 없이 같은 운영점이 선택되었다고 해석할 수 있다. (표본이 유한하면 ROC가 계단형이어서 여러 규칙이 같은 점을 선택하는 일이 흔하다.)</p>
<p>반면 k-NN은 비용기반(c_FN=10, c_FP=1)에서 t≈0.254로 임계값이 낮게 선택되며, 이때 FN=0이 되어 악성 놓침이 발생하지 않는다(Recall=1.0). 하지만 그 대가로 FP=11이 발생해 FPR이 0.122로 커지고, 정확도도 0.923으로 떨어진다. 즉 k-NN의 비용기반 선택은 “악성을 절대 놓치지 않는 것”을 우선하는 대신, 양성에 대한 오경보를 많이 감수하는 운영점이다.</p>
<p>k-NN에서 FPR≤0.02 제약을 강하게 적용하면 t≈0.423에서 FP=1로 오경보를 거의 SVM 수준까지 줄일 수 있지만, 그때 FN=3으로 악성 놓침이 증가하여(Recall≈0.943) 비용(여기서는 c_FN이 크므로)이 커진다. Youden 기준은 t≈0.406에서 FP=2, FN=2로 균형을 잡지만, 여전히 SVM의 운영점(FP=1, FN=1)보다 전체적으로 불리하다.</p>
<p>따라서 이 표가 시사하는 결론은 다음과 같다. 일반적인 균형 성능(낮은 FN과 낮은 FP를 동시에)과 높은 정확도를 원하면 SVM이 우세하며, 특히 현재 설정에서는 SVM의 Youden(=FPR 제약) 임계값이 가장 안정적인 선택이다.</p>
<p>반대로 “악성 놓침(FN)=0”이 정책적으로 절대조건이라면, 현재 표에서는 k-NN의 비용기반 임계값이 그 조건을 만족하지만, 오경보(FP)가 크게 늘어나는 점을 함께 감수해야 한다. (실무적으로는 같은 목적을 위해 SVM도 임계값을 더 낮춰 FN=0을 만족하는 지점을 찾는 방식으로 조정할 수도 있다.)</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/classification_ml_tvalue.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%"></p>
</figure>
</div>
</section>
<section id="회귀기반-분류" class="level5">
<h5 class="anchored" data-anchor-id="회귀기반-분류">(6) 회귀기반 분류</h5>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, confusion_matrix, classification_report</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 로지스틱 회귀 모델 (표준화 + Logistic Regression)</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>logit_model <span class="op">=</span> Pipeline([</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"scaler"</span>, StandardScaler()),</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"logit"</span>, LogisticRegression(</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>        penalty<span class="op">=</span><span class="st">"l2"</span>,</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>        C<span class="op">=</span><span class="fl">1.0</span>,</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>        solver<span class="op">=</span><span class="st">"lbfgs"</span>,      <span class="co"># 이진/다중 모두 안정적</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>        max_iter<span class="op">=</span><span class="dv">5000</span>,</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    ))</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a><span class="co"># 학습</span></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>logit_model.fit(X_train, y_train)</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a><span class="co"># 예측(클래스)</span></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>y_pred_logit <span class="op">=</span> logit_model.predict(X_test)</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a><span class="co"># 평가(기본)</span></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[Logistic] Accuracy:"</span>, accuracy_score(y_test, y_pred_logit))</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[Logistic] Confusion matrix:</span><span class="ch">\n</span><span class="st">"</span>, confusion_matrix(y_test, y_pred_logit))</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[Logistic] Classification report:</span><span class="ch">\n</span><span class="st">"</span>,</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>      classification_report(y_test, y_pred_logit, target_names<span class="op">=</span>data.target_names))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>[Logistic] Accuracy: 0.986013986013986
[Logistic] Confusion matrix:
 [[52  1]
 [ 1 89]]
[Logistic] Classification report:
               precision    recall  f1-score   support

   malignant       0.98      0.98      0.98        53
      benign       0.99      0.99      0.99        90

    accuracy                           0.99       143
   macro avg       0.99      0.99      0.99       143
weighted avg       0.99      0.99      0.99       143</code></pre>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> (</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    roc_curve, auc,</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    precision_recall_curve, average_precision_score,</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    confusion_matrix</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="co"># (A) 악성(malignant=0)을 positive(=1)로 통일</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>y_pos <span class="op">=</span> (y_test <span class="op">==</span> <span class="dv">0</span>).astype(<span class="bu">int</span>)  <span class="co"># 1이면 malignant</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="co"># 로지스틱 회귀 확률: P(y=1|x)에서 클래스 0(malignant) 확률을 score로 사용</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>proba <span class="op">=</span> logit_model.predict_proba(X_test)  <span class="co"># shape: (n, 2)</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>classes <span class="op">=</span> logit_model.named_steps[<span class="st">"logit"</span>].classes_</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>idx_malignant <span class="op">=</span> np.where(classes <span class="op">==</span> <span class="dv">0</span>)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> proba[:, idx_malignant]            <span class="co"># score = P(malignant | x)</span></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a><span class="co"># (B) ROC / PR</span></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>fpr, tpr, thr_roc <span class="op">=</span> roc_curve(y_pos, score)</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>roc_auc <span class="op">=</span> auc(fpr, tpr)</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>precision, recall, thr_pr <span class="op">=</span> precision_recall_curve(y_pos, score)</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>ap <span class="op">=</span> average_precision_score(y_pos, score)</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[Logistic] ROC AUC ="</span>, roc_auc)</span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[Logistic] PR  AP  ="</span>, ap)</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a><span class="co"># (C) 임계값 t에서 혼동행렬/지표 계산</span></span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> metrics_at_threshold(y_true01, score, t):</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>    y_hat <span class="op">=</span> (score <span class="op">&gt;=</span> t).astype(<span class="bu">int</span>)</span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>    tn, fp, fn, tp <span class="op">=</span> confusion_matrix(y_true01, y_hat).ravel()</span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>    recall_ <span class="op">=</span> tp <span class="op">/</span> (tp <span class="op">+</span> fn) <span class="cf">if</span> (tp <span class="op">+</span> fn) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="fl">0.0</span>  <span class="co"># TPR</span></span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>    fpr_    <span class="op">=</span> fp <span class="op">/</span> (fp <span class="op">+</span> tn) <span class="cf">if</span> (fp <span class="op">+</span> tn) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>    prec_   <span class="op">=</span> tp <span class="op">/</span> (tp <span class="op">+</span> fp) <span class="cf">if</span> (tp <span class="op">+</span> fp) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a>    acc_    <span class="op">=</span> (tp <span class="op">+</span> tn) <span class="op">/</span> (tp <span class="op">+</span> tn <span class="op">+</span> fp <span class="op">+</span> fn)</span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a>        <span class="st">"t"</span>: <span class="bu">float</span>(t),</span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a>        <span class="st">"tn"</span>: <span class="bu">int</span>(tn), <span class="st">"fp"</span>: <span class="bu">int</span>(fp), <span class="st">"fn"</span>: <span class="bu">int</span>(fn), <span class="st">"tp"</span>: <span class="bu">int</span>(tp),</span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a>        <span class="st">"recall(tpr)"</span>: <span class="bu">float</span>(recall_),</span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a>        <span class="st">"fpr"</span>: <span class="bu">float</span>(fpr_),</span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a>        <span class="st">"precision"</span>: <span class="bu">float</span>(prec_),</span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a>        <span class="st">"accuracy"</span>: <span class="bu">float</span>(acc_)</span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">[Default t=0.5]"</span>)</span>
<span id="cb12-53"><a href="#cb12-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(metrics_at_threshold(y_pos, score, <span class="fl">0.5</span>))</span>
<span id="cb12-54"><a href="#cb12-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-55"><a href="#cb12-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">[Grid check]"</span>)</span>
<span id="cb12-56"><a href="#cb12-56" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> np.arange(<span class="fl">0.1</span>, <span class="fl">1.0</span>, <span class="fl">0.1</span>):</span>
<span id="cb12-57"><a href="#cb12-57" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(metrics_at_threshold(y_pos, score, t))</span>
<span id="cb12-58"><a href="#cb12-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-59"><a href="#cb12-59" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb12-60"><a href="#cb12-60" aria-hidden="true" tabindex="-1"></a><span class="co"># (D) 임계값 선택 1: Youden J = TPR - FPR 최대</span></span>
<span id="cb12-61"><a href="#cb12-61" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb12-62"><a href="#cb12-62" aria-hidden="true" tabindex="-1"></a>J <span class="op">=</span> tpr <span class="op">-</span> fpr</span>
<span id="cb12-63"><a href="#cb12-63" aria-hidden="true" tabindex="-1"></a>best_t_youden <span class="op">=</span> <span class="bu">float</span>(thr_roc[np.argmax(J)])</span>
<span id="cb12-64"><a href="#cb12-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-65"><a href="#cb12-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">[Youden J]"</span>)</span>
<span id="cb12-66"><a href="#cb12-66" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"best t ="</span>, best_t_youden)</span>
<span id="cb12-67"><a href="#cb12-67" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(metrics_at_threshold(y_pos, score, best_t_youden))</span>
<span id="cb12-68"><a href="#cb12-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-69"><a href="#cb12-69" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb12-70"><a href="#cb12-70" aria-hidden="true" tabindex="-1"></a><span class="co"># (E) 임계값 선택 2: FPR &lt;= alpha 제약에서 TPR 최대</span></span>
<span id="cb12-71"><a href="#cb12-71" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb12-72"><a href="#cb12-72" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> best_threshold_fpr_constraint(y_true01, score, alpha<span class="op">=</span><span class="fl">0.02</span>):</span>
<span id="cb12-73"><a href="#cb12-73" aria-hidden="true" tabindex="-1"></a>    fpr, tpr, thr <span class="op">=</span> roc_curve(y_true01, score)</span>
<span id="cb12-74"><a href="#cb12-74" aria-hidden="true" tabindex="-1"></a>    cand <span class="op">=</span> np.where(fpr <span class="op">&lt;=</span> alpha)[<span class="dv">0</span>]</span>
<span id="cb12-75"><a href="#cb12-75" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(cand) <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb12-76"><a href="#cb12-76" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb12-77"><a href="#cb12-77" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> cand[np.argmax(tpr[cand])]</span>
<span id="cb12-78"><a href="#cb12-78" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">float</span>(thr[i])</span>
<span id="cb12-79"><a href="#cb12-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-80"><a href="#cb12-80" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.02</span></span>
<span id="cb12-81"><a href="#cb12-81" aria-hidden="true" tabindex="-1"></a>best_t_fpr <span class="op">=</span> best_threshold_fpr_constraint(y_pos, score, alpha<span class="op">=</span>alpha)</span>
<span id="cb12-82"><a href="#cb12-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-83"><a href="#cb12-83" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">[FPR constraint]"</span>)</span>
<span id="cb12-84"><a href="#cb12-84" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"alpha ="</span>, alpha, <span class="st">"best t ="</span>, best_t_fpr)</span>
<span id="cb12-85"><a href="#cb12-85" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> best_t_fpr <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb12-86"><a href="#cb12-86" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(metrics_at_threshold(y_pos, score, best_t_fpr))</span>
<span id="cb12-87"><a href="#cb12-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-88"><a href="#cb12-88" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb12-89"><a href="#cb12-89" aria-hidden="true" tabindex="-1"></a><span class="co"># (F) 임계값 선택 3: 비용 기반 (c_fn*FN + c_fp*FP) 최소</span></span>
<span id="cb12-90"><a href="#cb12-90" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb12-91"><a href="#cb12-91" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> best_threshold_cost(y_true01, score, c_fn<span class="op">=</span><span class="fl">10.0</span>, c_fp<span class="op">=</span><span class="fl">1.0</span>):</span>
<span id="cb12-92"><a href="#cb12-92" aria-hidden="true" tabindex="-1"></a>    thresholds <span class="op">=</span> np.unique(np.r_[<span class="fl">0.0</span>, score, <span class="fl">1.0</span>])</span>
<span id="cb12-93"><a href="#cb12-93" aria-hidden="true" tabindex="-1"></a>    best_t, best_m, best_cost <span class="op">=</span> <span class="va">None</span>, <span class="va">None</span>, np.inf</span>
<span id="cb12-94"><a href="#cb12-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-95"><a href="#cb12-95" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> thresholds:</span>
<span id="cb12-96"><a href="#cb12-96" aria-hidden="true" tabindex="-1"></a>        m <span class="op">=</span> metrics_at_threshold(y_true01, score, t)</span>
<span id="cb12-97"><a href="#cb12-97" aria-hidden="true" tabindex="-1"></a>        cost <span class="op">=</span> c_fn <span class="op">*</span> m[<span class="st">"fn"</span>] <span class="op">+</span> c_fp <span class="op">*</span> m[<span class="st">"fp"</span>]</span>
<span id="cb12-98"><a href="#cb12-98" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> cost <span class="op">&lt;</span> best_cost:</span>
<span id="cb12-99"><a href="#cb12-99" aria-hidden="true" tabindex="-1"></a>            best_t, best_m, best_cost <span class="op">=</span> <span class="bu">float</span>(t), m, <span class="bu">float</span>(cost)</span>
<span id="cb12-100"><a href="#cb12-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-101"><a href="#cb12-101" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_t, best_m, best_cost</span>
<span id="cb12-102"><a href="#cb12-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-103"><a href="#cb12-103" aria-hidden="true" tabindex="-1"></a>best_t_cost, best_m_cost, best_cost_val <span class="op">=</span> best_threshold_cost(y_pos, score, c_fn<span class="op">=</span><span class="dv">10</span>, c_fp<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb12-104"><a href="#cb12-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-105"><a href="#cb12-105" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">[Cost-based]"</span>)</span>
<span id="cb12-106"><a href="#cb12-106" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"best t ="</span>, best_t_cost, <span class="st">"cost ="</span>, best_cost_val)</span>
<span id="cb12-107"><a href="#cb12-107" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(best_m_cost)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>[Logistic] ROC AUC = 0.9976939203354298 [Logistic] PR AP = 0.9967570754716981</p>
<p>[Youden J] best t = 0.636819048492104</p>
<p>{‘t’: 0.636819048492104, ‘tn’: 90, ‘fp’: 0, ‘fn’: 1, ‘tp’: 52, ‘recall(tpr)’: 0.9811320754716981, ‘fpr’: 0.0, ‘precision’: 1.0, ‘accuracy’: 0.993006993006993}</p>
<p>[FPR constraint] alpha = 0.02 best t = 0.636819048492104</p>
<p>{‘t’: 0.636819048492104, ‘tn’: 90, ‘fp’: 0, ‘fn’: 1, ‘tp’: 52, ‘recall(tpr)’: 0.9811320754716981, ‘fpr’: 0.0, ‘precision’: 1.0, ‘accuracy’: 0.993006993006993}</p>
<p>[Cost-based] best t = 0.636819048492104 cost = 10.0</p>
<p>{‘t’: 0.636819048492104, ‘tn’: 90, ‘fp’: 0, ‘fn’: 1, ‘tp’: 52, ‘recall(tpr)’: 0.9811320754716981, ‘fpr’: 0.0, ‘precision’: 1.0, ‘accuracy’: 0.993006993006993}</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># (전제) logit_model = Pipeline([("scaler", StandardScaler()), ("logit", LogisticRegression(...))])</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co">#       logit_model.fit(X_train, y_train) 가 이미 수행되었다고 가정</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 1) 학습된 로지스틱 회귀 계수 꺼내기</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>logit <span class="op">=</span> logit_model.named_steps[<span class="st">"logit"</span>]</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>coef <span class="op">=</span> logit.coef_.ravel()          <span class="co"># shape: (p,)</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>intercept <span class="op">=</span> <span class="bu">float</span>(logit.intercept_[<span class="dv">0</span>])</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 2) 변수명 준비 (앞에서 feature_names를 만들었다면 그대로 사용)</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="co">#    feature_names = data.feature_names</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>feature_names <span class="op">=</span> <span class="bu">list</span>(feature_names)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 3) 오즈비(OR) 계산</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>odds_ratio <span class="op">=</span> np.exp(coef)</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a><span class="co"># 4) 결과 테이블 생성</span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>coef_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>    <span class="st">"feature"</span>: feature_names,</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>    <span class="st">"beta(coef)"</span>: coef,</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">"odds_ratio(exp(beta))"</span>: odds_ratio</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>}).sort_values(<span class="st">"beta(coef)"</span>, ascending<span class="op">=</span><span class="va">False</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a><span class="co">#print("Intercept (beta0) =", intercept)</span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a><span class="co">#display(coef_df.head(10))</span></span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a><span class="co"># 5) 상위 양(+) / 음(-) 계수 변수 출력</span></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>top_k <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>top_pos <span class="op">=</span> coef_df.head(top_k)                  <span class="co"># benign(=1) 확률을 높이는 방향</span></span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>top_neg <span class="op">=</span> coef_df.tail(top_k).iloc[::<span class="op">-</span><span class="dv">1</span>]       <span class="co"># malignant(=0) 쪽으로 기여(benign 확률 낮춤)</span></span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">[상위 +계수 </span><span class="sc">{</span>top_k<span class="sc">}</span><span class="ss">개]  (benign=1 오즈를 증가시키는 변수)"</span>)</span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>display(top_pos)</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">[상위 -계수 </span><span class="sc">{</span>top_k<span class="sc">}</span><span class="ss">개]  (benign=1 오즈를 감소 → malignant 쪽으로 기여하는 변수)"</span>)</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>display(top_neg)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>본 로지스틱 회귀모형에서 종속변수는 benign = 1로 정의되었으며, 회귀계수는 각 설명변수가 양성 종양일 오즈(odds)에 미치는 영향을 나타낸다. 양(+)의 회귀계수는 해당 변수가 증가할수록 양성일 오즈가 증가함을, 음(–)의 회귀계수는 반대로 악성일 가능성이 상대적으로 높아짐을 의미한다.</p>
<p>먼저, 양성(benign) 오즈를 증가시키는 변수로는 mean compactness가 가장 큰 영향을 보였다. 이 변수의 회귀계수는 0.694로, 다른 조건이 동일할 때 평균 compactness가 1단위 증가하면 양성일 오즈는 약 2.00배 증가하는 것으로 나타났다. 이는 종양의 형태적 압축도가 높을수록 상대적으로 양성으로 분류될 가능성이 커짐을 시사한다.</p>
<p>이외에도 compactness error, symmetry error, fractal dimension error 등 형태의 불규칙성과 관련된 오차 변수들이 양성 오즈를 유의하게 증가시키는 방향으로 작용하였다. 전반적으로 보면, 평균 수준의 형태 지표보다는 측정 오차(error) 계열 변수들이 양성 분류에 상대적으로 긍정적인 기여를 하고 있다는 점이 특징적이다.</p>
<p>반면, 양성 오즈를 감소시키는(즉, 악성 방향으로 기여하는) 변수들은 주로 worst 접두어가 붙은 변수들로 구성되어 있다. 특히 worst texture는 회귀계수 –1.25로 가장 큰 음의 효과를 보였으며, 이는 해당 변수가 1단위 증가할 때 양성일 오즈가 약 0.29배로 감소함을 의미한다. 다시 말해, 종양의 최악(worst) 상태에서 관측된 질감이나 크기, 둘레, 면적 관련 지표들은 악성 종양을 강하게 시사하는 특징으로 작용한다.</p>
<p>worst radius, worst area, worst perimeter, mean concave points 등도 모두 일관되게 음의 계수를 보여, 종양의 크기 및 경계의 침습성이 악성 여부 판단에 핵심적인 역할을 함을 확인할 수 있다.</p>
<p>종합하면, 본 분석 결과는 악성 종양의 판별에는 ‘worst-case’ 형태 지표들이 결정적이며, 반대로 양성 종양의 경우 평균적 형태 특성이나 변동성(오차) 관련 지표들이 상대적으로 중요한 역할을 한다는 점을 시사한다. 이는 임상적으로도 종양의 최대 크기나 가장 불리한 형태적 특징이 악성 여부 판단에 우선적으로 고려된다는 기존 의학적 해석과도 정합적인 결과이다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/classification_ml_regresult.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</section>
<section id="트리기반단일-분류" class="level5">
<h5 class="anchored" data-anchor-id="트리기반단일-분류">(7) 트리기반(단일) 분류</h5>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, confusion_matrix, classification_report</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Decision Tree (분할 기반)</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>tree_model <span class="op">=</span> DecisionTreeClassifier(</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    criterion<span class="op">=</span><span class="st">"gini"</span>,        <span class="co"># or "entropy"</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="dv">4</span>,             <span class="co"># 과적합 방지용(예시). None이면 끝까지 분할</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    min_samples_leaf<span class="op">=</span><span class="dv">5</span>,      <span class="co"># 잎노드 최소 표본수</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 학습</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>tree_model.fit(X_train, y_train)</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a><span class="co"># 예측(클래스)</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>y_pred_tree <span class="op">=</span> tree_model.predict(X_test)</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a><span class="co"># 평가(기본)</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[Tree] Accuracy:"</span>, accuracy_score(y_test, y_pred_tree))</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[Tree] Confusion matrix:</span><span class="ch">\n</span><span class="st">"</span>, confusion_matrix(y_test, y_pred_tree))</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[Tree] Classification report:</span><span class="ch">\n</span><span class="st">"</span>,</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>      classification_report(y_test, y_pred_tree, target_names<span class="op">=</span>data.target_names))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>[Tree] Accuracy: 0.9300699300699301
[Tree] Confusion matrix:
 [[48  5]
 [ 5 85]]
[Tree] Classification report:
               precision    recall  f1-score   support

   malignant       0.91      0.91      0.91        53
      benign       0.94      0.94      0.94        90

    accuracy                           0.93       143
   macro avg       0.93      0.93      0.93       143
weighted avg       0.93      0.93      0.93       143</code></pre>
<div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> (</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    roc_curve, auc,</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    precision_recall_curve, average_precision_score,</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    confusion_matrix</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 0) 악성(malignant=0)을 positive(=1)로 통일</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>y_pos <span class="op">=</span> (y_test <span class="op">==</span> <span class="dv">0</span>).astype(<span class="bu">int</span>)  <span class="co"># 1이면 malignant</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="co"># DecisionTree의 "악성 확률" score = P(malignant | x)</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>proba_tree <span class="op">=</span> tree_model.predict_proba(X_test)</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>idx_malignant <span class="op">=</span> np.where(tree_model.classes_ <span class="op">==</span> <span class="dv">0</span>)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> proba_tree[:, idx_malignant]</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a><span class="co"># 1) ROC / PR</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>fpr, tpr, thr_roc <span class="op">=</span> roc_curve(y_pos, score)</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>roc_auc <span class="op">=</span> auc(fpr, tpr)</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>prec, rec, thr_pr <span class="op">=</span> precision_recall_curve(y_pos, score)</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>ap <span class="op">=</span> average_precision_score(y_pos, score)</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[Tree] ROC AUC ="</span>, roc_auc)</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[Tree] PR  AP  ="</span>, ap)</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a><span class="co"># 2) 임계값 t에서 혼동행렬/지표 계산</span></span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> metrics_at_threshold(y_true01, score, t):</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>    y_hat <span class="op">=</span> (score <span class="op">&gt;=</span> t).astype(<span class="bu">int</span>)</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>    tn, fp, fn, tp <span class="op">=</span> confusion_matrix(y_true01, y_hat).ravel()</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>    recall_ <span class="op">=</span> tp <span class="op">/</span> (tp <span class="op">+</span> fn) <span class="cf">if</span> (tp <span class="op">+</span> fn) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="fl">0.0</span>  <span class="co"># TPR</span></span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>    fpr_    <span class="op">=</span> fp <span class="op">/</span> (fp <span class="op">+</span> tn) <span class="cf">if</span> (fp <span class="op">+</span> tn) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>    prec_   <span class="op">=</span> tp <span class="op">/</span> (tp <span class="op">+</span> fp) <span class="cf">if</span> (tp <span class="op">+</span> fp) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>    acc_    <span class="op">=</span> (tp <span class="op">+</span> tn) <span class="op">/</span> (tp <span class="op">+</span> tn <span class="op">+</span> fp <span class="op">+</span> fn)</span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a>        <span class="st">"t"</span>: <span class="bu">float</span>(t),</span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a>        <span class="st">"tn"</span>: <span class="bu">int</span>(tn), <span class="st">"fp"</span>: <span class="bu">int</span>(fp), <span class="st">"fn"</span>: <span class="bu">int</span>(fn), <span class="st">"tp"</span>: <span class="bu">int</span>(tp),</span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>        <span class="st">"recall(tpr)"</span>: <span class="bu">float</span>(recall_),</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a>        <span class="st">"fpr"</span>: <span class="bu">float</span>(fpr_),</span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a>        <span class="st">"precision"</span>: <span class="bu">float</span>(prec_),</span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a>        <span class="st">"accuracy"</span>: <span class="bu">float</span>(acc_)</span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">[Default t=0.5]"</span>)</span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(metrics_at_threshold(y_pos, score, <span class="fl">0.5</span>))</span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb16-55"><a href="#cb16-55" aria-hidden="true" tabindex="-1"></a><span class="co"># 3) Youden J = TPR - FPR 최대</span></span>
<span id="cb16-56"><a href="#cb16-56" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb16-57"><a href="#cb16-57" aria-hidden="true" tabindex="-1"></a>J <span class="op">=</span> tpr <span class="op">-</span> fpr</span>
<span id="cb16-58"><a href="#cb16-58" aria-hidden="true" tabindex="-1"></a>best_t_youden <span class="op">=</span> <span class="bu">float</span>(thr_roc[np.argmax(J)])</span>
<span id="cb16-59"><a href="#cb16-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-60"><a href="#cb16-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">[Youden J]"</span>)</span>
<span id="cb16-61"><a href="#cb16-61" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"best t ="</span>, best_t_youden)</span>
<span id="cb16-62"><a href="#cb16-62" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(metrics_at_threshold(y_pos, score, best_t_youden))</span>
<span id="cb16-63"><a href="#cb16-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-64"><a href="#cb16-64" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb16-65"><a href="#cb16-65" aria-hidden="true" tabindex="-1"></a><span class="co"># 4) FPR &lt;= alpha 제약에서 TPR 최대</span></span>
<span id="cb16-66"><a href="#cb16-66" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb16-67"><a href="#cb16-67" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> best_threshold_fpr_constraint(y_true01, score, alpha<span class="op">=</span><span class="fl">0.02</span>):</span>
<span id="cb16-68"><a href="#cb16-68" aria-hidden="true" tabindex="-1"></a>    fpr, tpr, thr <span class="op">=</span> roc_curve(y_true01, score)</span>
<span id="cb16-69"><a href="#cb16-69" aria-hidden="true" tabindex="-1"></a>    cand <span class="op">=</span> np.where(fpr <span class="op">&lt;=</span> alpha)[<span class="dv">0</span>]</span>
<span id="cb16-70"><a href="#cb16-70" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(cand) <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb16-71"><a href="#cb16-71" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb16-72"><a href="#cb16-72" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> cand[np.argmax(tpr[cand])]</span>
<span id="cb16-73"><a href="#cb16-73" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">float</span>(thr[i])</span>
<span id="cb16-74"><a href="#cb16-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-75"><a href="#cb16-75" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.02</span></span>
<span id="cb16-76"><a href="#cb16-76" aria-hidden="true" tabindex="-1"></a>best_t_fpr <span class="op">=</span> best_threshold_fpr_constraint(y_pos, score, alpha<span class="op">=</span>alpha)</span>
<span id="cb16-77"><a href="#cb16-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-78"><a href="#cb16-78" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">[FPR constraint]"</span>)</span>
<span id="cb16-79"><a href="#cb16-79" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"alpha ="</span>, alpha, <span class="st">"best t ="</span>, best_t_fpr)</span>
<span id="cb16-80"><a href="#cb16-80" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> best_t_fpr <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb16-81"><a href="#cb16-81" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(metrics_at_threshold(y_pos, score, best_t_fpr))</span>
<span id="cb16-82"><a href="#cb16-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-83"><a href="#cb16-83" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb16-84"><a href="#cb16-84" aria-hidden="true" tabindex="-1"></a><span class="co"># 5) 비용 기반: c_fn*FN + c_fp*FP 최소</span></span>
<span id="cb16-85"><a href="#cb16-85" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------------------------------------------</span></span>
<span id="cb16-86"><a href="#cb16-86" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> best_threshold_cost(y_true01, score, c_fn<span class="op">=</span><span class="fl">10.0</span>, c_fp<span class="op">=</span><span class="fl">1.0</span>):</span>
<span id="cb16-87"><a href="#cb16-87" aria-hidden="true" tabindex="-1"></a>    thresholds <span class="op">=</span> np.unique(np.r_[<span class="fl">0.0</span>, score, <span class="fl">1.0</span>])</span>
<span id="cb16-88"><a href="#cb16-88" aria-hidden="true" tabindex="-1"></a>    best_t, best_m, best_cost <span class="op">=</span> <span class="va">None</span>, <span class="va">None</span>, np.inf</span>
<span id="cb16-89"><a href="#cb16-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-90"><a href="#cb16-90" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> thresholds:</span>
<span id="cb16-91"><a href="#cb16-91" aria-hidden="true" tabindex="-1"></a>        m <span class="op">=</span> metrics_at_threshold(y_true01, score, t)</span>
<span id="cb16-92"><a href="#cb16-92" aria-hidden="true" tabindex="-1"></a>        cost <span class="op">=</span> c_fn <span class="op">*</span> m[<span class="st">"fn"</span>] <span class="op">+</span> c_fp <span class="op">*</span> m[<span class="st">"fp"</span>]</span>
<span id="cb16-93"><a href="#cb16-93" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> cost <span class="op">&lt;</span> best_cost:</span>
<span id="cb16-94"><a href="#cb16-94" aria-hidden="true" tabindex="-1"></a>            best_t, best_m, best_cost <span class="op">=</span> <span class="bu">float</span>(t), m, <span class="bu">float</span>(cost)</span>
<span id="cb16-95"><a href="#cb16-95" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_t, best_m, best_cost</span>
<span id="cb16-96"><a href="#cb16-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-97"><a href="#cb16-97" aria-hidden="true" tabindex="-1"></a>best_t_cost, best_m_cost, best_cost_val <span class="op">=</span> best_threshold_cost(y_pos, score, c_fn<span class="op">=</span><span class="dv">10</span>, c_fp<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb16-98"><a href="#cb16-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-99"><a href="#cb16-99" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">[Cost-based]"</span>)</span>
<span id="cb16-100"><a href="#cb16-100" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"best t ="</span>, best_t_cost, <span class="st">"cost ="</span>, best_cost_val)</span>
<span id="cb16-101"><a href="#cb16-101" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(best_m_cost)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>[Tree] ROC AUC = 0.931446540880503 [Tree] PR AP = 0.9139770620510188</p>
<p>[Default t=0.5]</p>
<p>{‘t’: 0.5, ‘tn’: 85, ‘fp’: 5, ‘fn’: 5, ‘tp’: 48, ‘recall(tpr)’: 0.9056603773584906, ‘fpr’: 0.05555555555555555, ‘precision’: 0.9056603773584906, ‘accuracy’: 0.9300699300699301}</p>
<p>[Youden J] best t = 1.0</p>
<p>{‘t’: 1.0, ‘tn’: 88, ‘fp’: 2, ‘fn’: 5, ‘tp’: 48, ‘recall(tpr)’: 0.9056603773584906, ‘fpr’: 0.022222222222222223, ‘precision’: 0.96, ‘accuracy’: 0.951048951048951}</p>
<p>[FPR constraint] alpha = 0.02 best t = inf</p>
<p>{‘t’: inf, ‘tn’: 90, ‘fp’: 0, ‘fn’: 53, ‘tp’: 0, ‘recall(tpr)’: 0.0, ‘fpr’: 0.0, ‘precision’: 0.0, ‘accuracy’: 0.6293706293706294}</p>
<p>[Cost-based] best t = 0.4 cost = 47.0</p>
<p>{‘t’: 0.4, ‘tn’: 83, ‘fp’: 7, ‘fn’: 4, ‘tp’: 49, ‘recall(tpr)’: 0.9245283018867925, ‘fpr’: 0.07777777777777778, ‘precision’: 0.875, ‘accuracy’: 0.9230769230769231}</p>
</section>
<section id="앙상블-기법" class="level5">
<h5 class="anchored" data-anchor-id="앙상블-기법">(8) 앙상블 기법</h5>
<p><strong>RandomForest 학습</strong></p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, confusion_matrix, classification_report</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>rf_model <span class="op">=</span> RandomForestClassifier(</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">500</span>,</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    min_samples_leaf<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>rf_model.fit(X_train, y_train)</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>y_pred_rf <span class="op">=</span> rf_model.predict(X_test)</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[RF] Accuracy:"</span>, accuracy_score(y_test, y_pred_rf))</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[RF] Confusion matrix:</span><span class="ch">\n</span><span class="st">"</span>, confusion_matrix(y_test, y_pred_rf))</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[RF] Classification report:</span><span class="ch">\n</span><span class="st">"</span>,</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>      classification_report(y_test, y_pred_rf, target_names<span class="op">=</span>data.target_names))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>[RF] Accuracy: 0.958041958041958
[RF] Confusion matrix:
 [[49  4]
 [ 2 88]]
[RF] Classification report:
               precision    recall  f1-score   support

   malignant       0.96      0.92      0.94        53
      benign       0.96      0.98      0.97        90

    accuracy                           0.96       143
   macro avg       0.96      0.95      0.95       143
weighted avg       0.96      0.96      0.96       143</code></pre>
<p><strong>GradientBoosting 학습</strong></p>
<div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> GradientBoostingClassifier</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, confusion_matrix, classification_report</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>gb_model <span class="op">=</span> GradientBoostingClassifier(</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">300</span>,</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="fl">0.05</span>,</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="dv">2</span>,        <span class="co"># 약한 트리(깊이 낮게) 권장</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>gb_model.fit(X_train, y_train)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>y_pred_gb <span class="op">=</span> gb_model.predict(X_test)</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[GB] Accuracy:"</span>, accuracy_score(y_test, y_pred_gb))</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[GB] Confusion matrix:</span><span class="ch">\n</span><span class="st">"</span>, confusion_matrix(y_test, y_pred_gb))</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[GB] Classification report:</span><span class="ch">\n</span><span class="st">"</span>,</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>      classification_report(y_test, y_pred_gb, target_names<span class="op">=</span>data.target_names))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>[GB] Accuracy: 0.951048951048951
[GB] Confusion matrix:
 [[48  5]
 [ 2 88]]
[GB] Classification report:
               precision    recall  f1-score   support

   malignant       0.96      0.91      0.93        53
      benign       0.95      0.98      0.96        90

    accuracy                           0.95       143
   macro avg       0.95      0.94      0.95       143
weighted avg       0.95      0.95      0.95       143</code></pre>
<p><strong>RF / GB 공통: ROC/PR + 임계값(Youden / FPR제약 / 비용기반)</strong></p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> (</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    roc_curve, auc,</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    precision_recall_curve, average_precision_score,</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    confusion_matrix</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="co"># --------------------------------------------</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 0) 악성=positive(1)로 통일</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="co"># --------------------------------------------</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>y_pos <span class="op">=</span> (y_test <span class="op">==</span> <span class="dv">0</span>).astype(<span class="bu">int</span>)  <span class="co"># 1이면 malignant</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_score_for_class(model, X, class_label<span class="op">=</span><span class="dv">0</span>):</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""특정 클래스(class_label)의 확률 score = P(class_label|x)"""</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>    proba <span class="op">=</span> model.predict_proba(X)</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>    classes <span class="op">=</span> np.array(model.classes_)</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>    idx <span class="op">=</span> np.where(classes <span class="op">==</span> class_label)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> proba[:, idx]</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> metrics_at_threshold(y_true01, score, t):</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>    y_hat <span class="op">=</span> (score <span class="op">&gt;=</span> t).astype(<span class="bu">int</span>)</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>    tn, fp, fn, tp <span class="op">=</span> confusion_matrix(y_true01, y_hat).ravel()</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>    recall_ <span class="op">=</span> tp <span class="op">/</span> (tp <span class="op">+</span> fn) <span class="cf">if</span> (tp <span class="op">+</span> fn) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>    fpr_    <span class="op">=</span> fp <span class="op">/</span> (fp <span class="op">+</span> tn) <span class="cf">if</span> (fp <span class="op">+</span> tn) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>    prec_   <span class="op">=</span> tp <span class="op">/</span> (tp <span class="op">+</span> fp) <span class="cf">if</span> (tp <span class="op">+</span> fp) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>    acc_    <span class="op">=</span> (tp <span class="op">+</span> tn) <span class="op">/</span> (tp <span class="op">+</span> tn <span class="op">+</span> fp <span class="op">+</span> fn)</span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>        <span class="st">"t"</span>: <span class="bu">float</span>(t),</span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>        <span class="st">"tn"</span>: <span class="bu">int</span>(tn), <span class="st">"fp"</span>: <span class="bu">int</span>(fp), <span class="st">"fn"</span>: <span class="bu">int</span>(fn), <span class="st">"tp"</span>: <span class="bu">int</span>(tp),</span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a>        <span class="st">"recall(tpr)"</span>: <span class="bu">float</span>(recall_),</span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>        <span class="st">"fpr"</span>: <span class="bu">float</span>(fpr_),</span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>        <span class="st">"precision"</span>: <span class="bu">float</span>(prec_),</span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a>        <span class="st">"accuracy"</span>: <span class="bu">float</span>(acc_)</span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> threshold_youden(y_true01, score):</span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a>    fpr, tpr, thr <span class="op">=</span> roc_curve(y_true01, score)</span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a>    J <span class="op">=</span> tpr <span class="op">-</span> fpr</span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">float</span>(thr[np.argmax(J)])</span>
<span id="cb21-43"><a href="#cb21-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-44"><a href="#cb21-44" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> threshold_fpr_constraint(y_true01, score, alpha<span class="op">=</span><span class="fl">0.02</span>):</span>
<span id="cb21-45"><a href="#cb21-45" aria-hidden="true" tabindex="-1"></a>    fpr, tpr, thr <span class="op">=</span> roc_curve(y_true01, score)</span>
<span id="cb21-46"><a href="#cb21-46" aria-hidden="true" tabindex="-1"></a>    cand <span class="op">=</span> np.where(fpr <span class="op">&lt;=</span> alpha)[<span class="dv">0</span>]</span>
<span id="cb21-47"><a href="#cb21-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(cand) <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb21-48"><a href="#cb21-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb21-49"><a href="#cb21-49" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> cand[np.argmax(tpr[cand])]</span>
<span id="cb21-50"><a href="#cb21-50" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">float</span>(thr[i])</span>
<span id="cb21-51"><a href="#cb21-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-52"><a href="#cb21-52" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> threshold_cost(y_true01, score, c_fn<span class="op">=</span><span class="fl">10.0</span>, c_fp<span class="op">=</span><span class="fl">1.0</span>):</span>
<span id="cb21-53"><a href="#cb21-53" aria-hidden="true" tabindex="-1"></a>    thresholds <span class="op">=</span> np.unique(np.r_[<span class="fl">0.0</span>, score, <span class="fl">1.0</span>])</span>
<span id="cb21-54"><a href="#cb21-54" aria-hidden="true" tabindex="-1"></a>    best_t, best_cost <span class="op">=</span> <span class="va">None</span>, np.inf</span>
<span id="cb21-55"><a href="#cb21-55" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> thresholds:</span>
<span id="cb21-56"><a href="#cb21-56" aria-hidden="true" tabindex="-1"></a>        m <span class="op">=</span> metrics_at_threshold(y_true01, score, t)</span>
<span id="cb21-57"><a href="#cb21-57" aria-hidden="true" tabindex="-1"></a>        cost <span class="op">=</span> c_fn<span class="op">*</span>m[<span class="st">"fn"</span>] <span class="op">+</span> c_fp<span class="op">*</span>m[<span class="st">"fp"</span>]</span>
<span id="cb21-58"><a href="#cb21-58" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> cost <span class="op">&lt;</span> best_cost:</span>
<span id="cb21-59"><a href="#cb21-59" aria-hidden="true" tabindex="-1"></a>            best_cost <span class="op">=</span> cost</span>
<span id="cb21-60"><a href="#cb21-60" aria-hidden="true" tabindex="-1"></a>            best_t <span class="op">=</span> <span class="bu">float</span>(t)</span>
<span id="cb21-61"><a href="#cb21-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_t, <span class="bu">float</span>(best_cost)</span>
<span id="cb21-62"><a href="#cb21-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-63"><a href="#cb21-63" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_rows(model_name, y_true01, score, alpha<span class="op">=</span><span class="fl">0.02</span>, c_fn<span class="op">=</span><span class="fl">10.0</span>, c_fp<span class="op">=</span><span class="fl">1.0</span>):</span>
<span id="cb21-64"><a href="#cb21-64" aria-hidden="true" tabindex="-1"></a>    rows <span class="op">=</span> []</span>
<span id="cb21-65"><a href="#cb21-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-66"><a href="#cb21-66" aria-hidden="true" tabindex="-1"></a>    <span class="co"># AUC/AP (요약용)</span></span>
<span id="cb21-67"><a href="#cb21-67" aria-hidden="true" tabindex="-1"></a>    fpr, tpr, _ <span class="op">=</span> roc_curve(y_true01, score)</span>
<span id="cb21-68"><a href="#cb21-68" aria-hidden="true" tabindex="-1"></a>    roc_auc <span class="op">=</span> auc(fpr, tpr)</span>
<span id="cb21-69"><a href="#cb21-69" aria-hidden="true" tabindex="-1"></a>    ap <span class="op">=</span> average_precision_score(y_true01, score)</span>
<span id="cb21-70"><a href="#cb21-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-71"><a href="#cb21-71" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Youden</span></span>
<span id="cb21-72"><a href="#cb21-72" aria-hidden="true" tabindex="-1"></a>    t_y <span class="op">=</span> threshold_youden(y_true01, score)</span>
<span id="cb21-73"><a href="#cb21-73" aria-hidden="true" tabindex="-1"></a>    m_y <span class="op">=</span> metrics_at_threshold(y_true01, score, t_y)</span>
<span id="cb21-74"><a href="#cb21-74" aria-hidden="true" tabindex="-1"></a>    m_y.update({<span class="st">"model"</span>: model_name, <span class="st">"rule"</span>: <span class="st">"Youden (TPR-FPR)"</span>, <span class="st">"roc_auc"</span>: roc_auc, <span class="st">"ap"</span>: ap,</span>
<span id="cb21-75"><a href="#cb21-75" aria-hidden="true" tabindex="-1"></a>                <span class="st">"cost"</span>: c_fn<span class="op">*</span>m_y[<span class="st">"fn"</span>] <span class="op">+</span> c_fp<span class="op">*</span>m_y[<span class="st">"fp"</span>]})</span>
<span id="cb21-76"><a href="#cb21-76" aria-hidden="true" tabindex="-1"></a>    rows.append(m_y)</span>
<span id="cb21-77"><a href="#cb21-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-78"><a href="#cb21-78" aria-hidden="true" tabindex="-1"></a>    <span class="co"># FPR constraint</span></span>
<span id="cb21-79"><a href="#cb21-79" aria-hidden="true" tabindex="-1"></a>    t_f <span class="op">=</span> threshold_fpr_constraint(y_true01, score, alpha<span class="op">=</span>alpha)</span>
<span id="cb21-80"><a href="#cb21-80" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> t_f <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb21-81"><a href="#cb21-81" aria-hidden="true" tabindex="-1"></a>        m_f <span class="op">=</span> metrics_at_threshold(y_true01, score, t_f)</span>
<span id="cb21-82"><a href="#cb21-82" aria-hidden="true" tabindex="-1"></a>        m_f.update({<span class="st">"model"</span>: model_name, <span class="st">"rule"</span>: <span class="ss">f"FPR &lt;= </span><span class="sc">{</span>alpha<span class="sc">}</span><span class="ss">"</span>, <span class="st">"roc_auc"</span>: roc_auc, <span class="st">"ap"</span>: ap,</span>
<span id="cb21-83"><a href="#cb21-83" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"cost"</span>: c_fn<span class="op">*</span>m_f[<span class="st">"fn"</span>] <span class="op">+</span> c_fp<span class="op">*</span>m_f[<span class="st">"fp"</span>]})</span>
<span id="cb21-84"><a href="#cb21-84" aria-hidden="true" tabindex="-1"></a>        rows.append(m_f)</span>
<span id="cb21-85"><a href="#cb21-85" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb21-86"><a href="#cb21-86" aria-hidden="true" tabindex="-1"></a>        rows.append({<span class="st">"model"</span>: model_name, <span class="st">"rule"</span>: <span class="ss">f"FPR &lt;= </span><span class="sc">{</span>alpha<span class="sc">}</span><span class="ss">"</span>, <span class="st">"t"</span>: <span class="va">None</span>,</span>
<span id="cb21-87"><a href="#cb21-87" aria-hidden="true" tabindex="-1"></a>                     <span class="st">"tn"</span>: <span class="va">None</span>, <span class="st">"fp"</span>: <span class="va">None</span>, <span class="st">"fn"</span>: <span class="va">None</span>, <span class="st">"tp"</span>: <span class="va">None</span>,</span>
<span id="cb21-88"><a href="#cb21-88" aria-hidden="true" tabindex="-1"></a>                     <span class="st">"recall(tpr)"</span>: <span class="va">None</span>, <span class="st">"fpr"</span>: <span class="va">None</span>, <span class="st">"precision"</span>: <span class="va">None</span>, <span class="st">"accuracy"</span>: <span class="va">None</span>,</span>
<span id="cb21-89"><a href="#cb21-89" aria-hidden="true" tabindex="-1"></a>                     <span class="st">"roc_auc"</span>: roc_auc, <span class="st">"ap"</span>: ap, <span class="st">"cost"</span>: <span class="va">None</span>})</span>
<span id="cb21-90"><a href="#cb21-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-91"><a href="#cb21-91" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Cost-based</span></span>
<span id="cb21-92"><a href="#cb21-92" aria-hidden="true" tabindex="-1"></a>    t_c, best_cost <span class="op">=</span> threshold_cost(y_true01, score, c_fn<span class="op">=</span>c_fn, c_fp<span class="op">=</span>c_fp)</span>
<span id="cb21-93"><a href="#cb21-93" aria-hidden="true" tabindex="-1"></a>    m_c <span class="op">=</span> metrics_at_threshold(y_true01, score, t_c)</span>
<span id="cb21-94"><a href="#cb21-94" aria-hidden="true" tabindex="-1"></a>    m_c.update({<span class="st">"model"</span>: model_name, <span class="st">"rule"</span>: <span class="ss">f"Cost (c_fn=</span><span class="sc">{</span>c_fn<span class="sc">}</span><span class="ss">, c_fp=</span><span class="sc">{</span>c_fp<span class="sc">}</span><span class="ss">)"</span>,</span>
<span id="cb21-95"><a href="#cb21-95" aria-hidden="true" tabindex="-1"></a>                <span class="st">"roc_auc"</span>: roc_auc, <span class="st">"ap"</span>: ap, <span class="st">"cost"</span>: best_cost})</span>
<span id="cb21-96"><a href="#cb21-96" aria-hidden="true" tabindex="-1"></a>    rows.append(m_c)</span>
<span id="cb21-97"><a href="#cb21-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-98"><a href="#cb21-98" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> rows</span>
<span id="cb21-99"><a href="#cb21-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-100"><a href="#cb21-100" aria-hidden="true" tabindex="-1"></a><span class="co"># --------------------------------------------</span></span>
<span id="cb21-101"><a href="#cb21-101" aria-hidden="true" tabindex="-1"></a><span class="co"># 1) RF / GB score 추출 (악성 확률)</span></span>
<span id="cb21-102"><a href="#cb21-102" aria-hidden="true" tabindex="-1"></a><span class="co"># --------------------------------------------</span></span>
<span id="cb21-103"><a href="#cb21-103" aria-hidden="true" tabindex="-1"></a>score_rf <span class="op">=</span> get_score_for_class(rf_model, X_test, class_label<span class="op">=</span><span class="dv">0</span>)  <span class="co"># P(malignant|x)</span></span>
<span id="cb21-104"><a href="#cb21-104" aria-hidden="true" tabindex="-1"></a>score_gb <span class="op">=</span> get_score_for_class(gb_model, X_test, class_label<span class="op">=</span><span class="dv">0</span>)  <span class="co"># P(malignant|x)</span></span>
<span id="cb21-105"><a href="#cb21-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-106"><a href="#cb21-106" aria-hidden="true" tabindex="-1"></a><span class="co"># --------------------------------------------</span></span>
<span id="cb21-107"><a href="#cb21-107" aria-hidden="true" tabindex="-1"></a><span class="co"># 2) 비교표 생성</span></span>
<span id="cb21-108"><a href="#cb21-108" aria-hidden="true" tabindex="-1"></a><span class="co"># --------------------------------------------</span></span>
<span id="cb21-109"><a href="#cb21-109" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.02</span></span>
<span id="cb21-110"><a href="#cb21-110" aria-hidden="true" tabindex="-1"></a>c_fn, c_fp <span class="op">=</span> <span class="fl">10.0</span>, <span class="fl">1.0</span></span>
<span id="cb21-111"><a href="#cb21-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-112"><a href="#cb21-112" aria-hidden="true" tabindex="-1"></a>rows <span class="op">=</span> []</span>
<span id="cb21-113"><a href="#cb21-113" aria-hidden="true" tabindex="-1"></a>rows <span class="op">+=</span> build_rows(<span class="st">"RandomForest"</span>, y_pos, score_rf, alpha<span class="op">=</span>alpha, c_fn<span class="op">=</span>c_fn, c_fp<span class="op">=</span>c_fp)</span>
<span id="cb21-114"><a href="#cb21-114" aria-hidden="true" tabindex="-1"></a>rows <span class="op">+=</span> build_rows(<span class="st">"GradientBoosting"</span>, y_pos, score_gb, alpha<span class="op">=</span>alpha, c_fn<span class="op">=</span>c_fn, c_fp<span class="op">=</span>c_fp)</span>
<span id="cb21-115"><a href="#cb21-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-116"><a href="#cb21-116" aria-hidden="true" tabindex="-1"></a>df_cmp_ens <span class="op">=</span> pd.DataFrame(rows)[</span>
<span id="cb21-117"><a href="#cb21-117" aria-hidden="true" tabindex="-1"></a>    [<span class="st">"model"</span>,<span class="st">"rule"</span>,<span class="st">"t"</span>,<span class="st">"tn"</span>,<span class="st">"fp"</span>,<span class="st">"fn"</span>,<span class="st">"tp"</span>,<span class="st">"recall(tpr)"</span>,<span class="st">"fpr"</span>,<span class="st">"precision"</span>,<span class="st">"accuracy"</span>,<span class="st">"roc_auc"</span>,<span class="st">"ap"</span>,<span class="st">"cost"</span>]</span>
<span id="cb21-118"><a href="#cb21-118" aria-hidden="true" tabindex="-1"></a>].sort_values([<span class="st">"rule"</span>,<span class="st">"model"</span>]).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-119"><a href="#cb21-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-120"><a href="#cb21-120" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"== 앙상블(RF/GB): 악성=positive 기준 임계값 비교표 =="</span>)</span>
<span id="cb21-121"><a href="#cb21-121" aria-hidden="true" tabindex="-1"></a>display(df_cmp_ens)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/classification_ml_treeresult.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%"></p>
</figure>
</div>
</section>
</section>
<section id="사례분석이진분류-회소성공-불균형" class="level4">
<h4 class="anchored" data-anchor-id="사례분석이진분류-회소성공-불균형">7. 사례분석(이진분류, 회소성공-불균형)</h4>
<p>데이터는 표본이 매우 커서 RBF SVM / kNN은 그대로 돌리면 느릴 수 있어 실무적으로는 (1) Linear SVM + calibration 또는 (2) kNN/SVM은 학습 샘플을 일부만 사용을 권장합니다(코드에 반영).</p>
<section id="데이터-1" class="level5">
<h5 class="anchored" data-anchor-id="데이터-1">(1) 데이터</h5>
<p><strong>데이터 불러오기</strong></p>
<p>Credit Card Fraud(creditcard.csv) 데이터는 대표적인 이진 분류(surveillance / fraud detection) 벤치마크로, 한 건의 거래가 사기(Fraud) 인지 정상(Normal) 인지를 판정하는 문제를 다룬다.</p>
<p>반응변수는 Class 하나이며 보통 Class=0을 정상(negative), Class=1을 사기(positive)로 정의한다. 즉 목표는 각 거래 <span class="math inline">\(P(Y=1∣X=x)\)</span> 을 추정하고, 운영 목적(오탐/미탐 비용, 검토량 등)에 맞는 임계값 t를 정해 <span class="math inline">\(\hat y =1{p(x)≥t}\)</span> 형태로 의사결정을 내리는 것이다.</p>
<p>데이터 규모는 284,807건의 거래로 구성되며, 총 31개 변수를 가진다. 이 중 Class가 타깃(y)이고 나머지 30개가 입력 변수(X) 다. 입력 변수는 Time, V1~V28, Amount로 이루어진다. 자료형 관점에서 입력 변수들은 대부분 연속형이며(실수형), Class만 정수형 라벨이다.</p>
<p>특히 V1~V28은 원래 거래 속성들을 그대로 제공한 것이 아니라, 개인정보 보호 및 비식별화를 위해 PCA(주성분 분석) 로 변환된 특징들이다. 따라서 각 <span class="math inline">\(V_k\)</span> 는 원변수들의 선형결합으로 얻어진 주성분 점수이며, 원래 변수의 해석 가능성은 제한된다.</p>
<p>반면 Time과 Amount는 비교적 직관적인 의미를 유지한다. Time은 기준 시점 이후의 경과 시간으로 시간대에 따른 패턴을 반영할 수 있고, Amount는 거래 금액으로서 사기 여부와 연관된 중요한 신호가 될 수 있다.</p>
<p>이 데이터의 가장 결정적인 특성은 극심한 클래스 불균형(extreme class imbalance) 이다. 정상 거래(Class=0)는 284,315건으로 전체의 약 99.827%를 차지하는 반면, 사기 거래(Class=1)는 492건으로 약 0.173%에 불과하다.</p>
<p>이런 환경에서는 단순 정확도(Accuracy)가 쉽게 과대평가된다. 예를 들어 모든 거래를 정상으로만 예측해도 정확도는 약 99.8%에 달할 수 있으나, 이는 사기 탐지라는 목적을 전혀 달성하지 못한다. 따라서 실무적으로는 양성(사기) 탐지 성능을 직접 반영하는 지표, 예컨대 Precision–Recall(PR) 관점의 평가(AP 포함)나, 오탐을 일정 수준 이하로 제한하는 FPR 제약 기반 임계값 선택, 혹은 미탐(FN)과 오탐(FP)의 비용을 반영한 비용기반 임계값 설계가 핵심이 된다.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip <span class="op">-</span>q install kagglehub</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> kagglehub</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 데이터 다운로드 (캐시 경로 반환)</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> kagglehub.dataset_download(<span class="st">"mlg-ulb/creditcardfraud"</span>)</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"downloaded to:"</span>, path)</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(os.listdir(path)[:<span class="dv">10</span>])</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a><span class="co"># CSV 로드</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(os.path.join(path, <span class="st">"creditcard.csv"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>데이터 메타정보 (불균형 확인)</strong></p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"shape:"</span>, df.shape)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 타깃</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">"Class"</span>].astype(<span class="bu">int</span>)        <span class="co"># 1=Fraud(positive), 0=Normal</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.drop(columns<span class="op">=</span>[<span class="st">"Class"</span>])</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 불균형 정도</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>cnt <span class="op">=</span> y.value_counts().sort_index()</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>ratio <span class="op">=</span> cnt <span class="op">/</span> cnt.<span class="bu">sum</span>()</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Class counts:"</span>)</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cnt)</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Class ratio:"</span>)</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ratio)</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Fraud rate ="</span>, ratio.loc[<span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>shape: (284807, 31)

Class counts:
Class
0    284315
1       492
Name: count, dtype: int64

Class ratio:
Class
0    0.998273
1    0.001727
Name: count, dtype: float64

Fraud rate = 0.001727485630620034</code></pre>
<p><strong>Train/Test 분할(층화) + 표준화 파이프라인</strong></p>
<p>이 코드는 (1) 데이터를 훈련/테스트로 나누고, (2) 불균형 상황에서도 라벨 비율이 유지되도록 층화(stratify) 하며, 이후 모델링에서 반복적으로 쓸 표준화(Standardization) 도구를 준비하는 단계다.</p>
<p>먼저 train_test_split은 전체 데이터 (X,y)를 훈련용(train) 과 평가용(test) 으로 분리한다. 여기서 test_size=0.2는 전체의 20%를 테스트 세트로 떼어두겠다는 뜻이며, 결과적으로 학습은 80%, 평가는 20% 데이터로 수행된다.</p>
<p>random_state=42는 분할 과정에서 난수 시드를 고정해, 코드를 다시 실행해도 동일한 분할 결과가 나오도록 한다. 즉 재현성(reproducibility)을 확보한다.</p>
<p>특히 중요한 옵션이 stratify=y다. Credit Card Fraud처럼 양성(사기) 비율이 극단적으로 작은 데이터에서는, 무작위 분할만 하면 테스트 세트에 양성이 거의 없거나(혹은 우연히 몰리거나) 하는 일이 발생할 수 있다.</p>
<p>그러면 평가 지표(ROC/PR 등)가 불안정해지고, 모델 비교도 왜곡된다. stratify=y는 분할할 때 훈련/테스트 각각에서 클래스 비율이 원자료와 거의 같도록 강제한다. 즉 <span class="math inline">\(P(Y=1) in train≈P(Y=1) in test≈P(Y=1) in full data\)</span> 가 되게 만드는 장치다. 불균형 탐지 문제에서는 사실상 필수 옵션에 가깝다.</p>
<p>마지막의 scaler = StandardScaler()는 입력 변수 X를 표준화하기 위한 객체를 만든다. 표준화는 각 변수를 평균 0, 분산 1이 되도록 변환하는 것이다. 이는 k-NN처럼 거리(distance) 에 민감한 모델이나 SVM처럼 결정경계가 스케일에 영향을 받는 모델에서 특히 중요하다.</p>
<p>여기서는 scaler만 “따로” 만들어 두었고, 실제로는 이후 Pipeline([(“scaler”, StandardScaler()), (“model”, …)]) 형태로 모델과 함께 묶어 훈련 데이터로만 표준화 파라미터(평균/표준편차)를 추정하고, 그 변환을 테스트 데이터에 동일하게 적용하는 방식으로 사용한다. 이렇게 해야 데이터 누수(data leakage)가 생기지 않는다.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    X, y,</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    test_size<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>    stratify<span class="op">=</span>y,          <span class="co"># 극심 불균형이므로 필수</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 표준화 파이프라인(모델마다 붙여 쓰기 위해 scaler만 따로 정의)</span></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="모델-학습-k-nn-svm" class="level5">
<h5 class="anchored" data-anchor-id="모델-학습-k-nn-svm">(2) 모델 학습 (k-NN / SVM)</h5>
<p><strong>k-NN (대용량이라 학습 샘플 일부만 사용 권장)</strong></p>
<div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="co"># kNN은 대용량에서 느리므로 학습 데이터 일부만 사용</span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>n_sub <span class="op">=</span> <span class="bu">min</span>(<span class="dv">50000</span>, <span class="bu">len</span>(X_train))</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>sub_idx <span class="op">=</span> np.random.RandomState(<span class="dv">42</span>).choice(<span class="bu">len</span>(X_train), size<span class="op">=</span>n_sub, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a><span class="co"># ✅ DataFrame/Series는 .iloc로 '행' 선택</span></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>X_train_knn <span class="op">=</span> X_train.iloc[sub_idx]</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>y_train_knn <span class="op">=</span> y_train.iloc[sub_idx]</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>knn_model <span class="op">=</span> Pipeline([</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"scaler"</span>, StandardScaler()),</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"knn"</span>, KNeighborsClassifier(</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>        n_neighbors<span class="op">=</span><span class="dv">15</span>,</span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>        weights<span class="op">=</span><span class="st">"distance"</span>,</span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>        p<span class="op">=</span><span class="dv">2</span></span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a>    ))</span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>knn_model.fit(X_train_knn, y_train_knn)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/classification_ml_knnfit.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%"></p>
</figure>
</div>
<p><strong>SVM (실무 권장: Linear SVM + 확률 보정(calibration))</strong></p>
<div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> LinearSVC</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.calibration <span class="im">import</span> CalibratedClassifierCV</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear SVM (결정함수) + 확률 보정(sigmoid)</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>svm_base <span class="op">=</span> Pipeline([</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"scaler"</span>, StandardScaler()),</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"svm"</span>, LinearSVC(</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>        C<span class="op">=</span><span class="fl">1.0</span>,</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>        class_weight<span class="op">=</span><span class="st">"balanced"</span>,   <span class="co"># 불균형 대응(기본 옵션)</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>    ))</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a><span class="co"># CalibratedClassifierCV는 estimator가 이미 pipeline이어도 동작</span></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>svm_model <span class="op">=</span> CalibratedClassifierCV(</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>    estimator<span class="op">=</span>svm_base,</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>    method<span class="op">=</span><span class="st">"sigmoid"</span>,</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>    cv<span class="op">=</span><span class="dv">3</span></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>svm_model.fit(X_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/classification_ml_svmfit.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%"></p>
</figure>
</div>
<p><strong>ROC/PR + 임계값(Youden / FPR제약 / 비용기반) + 비교표</strong></p>
<div class="sourceCode" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> (</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    roc_curve, auc,</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    precision_recall_curve, average_precision_score,</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>    confusion_matrix</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a><span class="co"># (안전) y를 numpy 1차원으로 통일</span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> np.asarray(y_train).ravel()</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>y_test  <span class="op">=</span> np.asarray(y_test).ravel()</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>y_pos   <span class="op">=</span> y_test  <span class="co"># 1=Fraud(positive)</span></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_pos_score(model, X):</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>    proba <span class="op">=</span> model.predict_proba(X)</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>    classes <span class="op">=</span> np.array(model.classes_)</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>    idx <span class="op">=</span> np.where(classes <span class="op">==</span> <span class="dv">1</span>)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> proba[:, idx]</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> metrics_at_threshold(y_true01, score, t):</span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>    y_hat <span class="op">=</span> (score <span class="op">&gt;=</span> t).astype(<span class="bu">int</span>)</span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a>    tn, fp, fn, tp <span class="op">=</span> confusion_matrix(y_true01, y_hat).ravel()</span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a>    tpr <span class="op">=</span> tp <span class="op">/</span> (tp <span class="op">+</span> fn) <span class="cf">if</span> (tp <span class="op">+</span> fn) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a>    fpr <span class="op">=</span> fp <span class="op">/</span> (fp <span class="op">+</span> tn) <span class="cf">if</span> (fp <span class="op">+</span> tn) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a>    prec <span class="op">=</span> tp <span class="op">/</span> (tp <span class="op">+</span> fp) <span class="cf">if</span> (tp <span class="op">+</span> fp) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a>    acc <span class="op">=</span> (tp <span class="op">+</span> tn) <span class="op">/</span> (tp <span class="op">+</span> tn <span class="op">+</span> fp <span class="op">+</span> fn)</span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">"t"</span>: <span class="bu">float</span>(t), <span class="st">"tn"</span>: <span class="bu">int</span>(tn), <span class="st">"fp"</span>: <span class="bu">int</span>(fp), <span class="st">"fn"</span>: <span class="bu">int</span>(fn), <span class="st">"tp"</span>: <span class="bu">int</span>(tp),</span>
<span id="cb28-30"><a href="#cb28-30" aria-hidden="true" tabindex="-1"></a>            <span class="st">"recall(tpr)"</span>: <span class="bu">float</span>(tpr), <span class="st">"fpr"</span>: <span class="bu">float</span>(fpr), <span class="st">"precision"</span>: <span class="bu">float</span>(prec), <span class="st">"accuracy"</span>: <span class="bu">float</span>(acc)}</span>
<span id="cb28-31"><a href="#cb28-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-32"><a href="#cb28-32" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> threshold_youden(y_true01, score):</span>
<span id="cb28-33"><a href="#cb28-33" aria-hidden="true" tabindex="-1"></a>    fpr, tpr, thr <span class="op">=</span> roc_curve(y_true01, score)</span>
<span id="cb28-34"><a href="#cb28-34" aria-hidden="true" tabindex="-1"></a>    J <span class="op">=</span> tpr <span class="op">-</span> fpr</span>
<span id="cb28-35"><a href="#cb28-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">float</span>(thr[np.argmax(J)])</span>
<span id="cb28-36"><a href="#cb28-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-37"><a href="#cb28-37" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> threshold_fpr_constraint(y_true01, score, alpha<span class="op">=</span><span class="fl">0.001</span>):</span>
<span id="cb28-38"><a href="#cb28-38" aria-hidden="true" tabindex="-1"></a>    fpr, tpr, thr <span class="op">=</span> roc_curve(y_true01, score)</span>
<span id="cb28-39"><a href="#cb28-39" aria-hidden="true" tabindex="-1"></a>    cand <span class="op">=</span> np.where(fpr <span class="op">&lt;=</span> alpha)[<span class="dv">0</span>]</span>
<span id="cb28-40"><a href="#cb28-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(cand) <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb28-41"><a href="#cb28-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb28-42"><a href="#cb28-42" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> cand[np.argmax(tpr[cand])]</span>
<span id="cb28-43"><a href="#cb28-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">float</span>(thr[i])</span>
<span id="cb28-44"><a href="#cb28-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-45"><a href="#cb28-45" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> threshold_cost(y_true01, score, c_fn<span class="op">=</span><span class="fl">100.0</span>, c_fp<span class="op">=</span><span class="fl">1.0</span>):</span>
<span id="cb28-46"><a href="#cb28-46" aria-hidden="true" tabindex="-1"></a>    thresholds <span class="op">=</span> np.unique(np.r_[<span class="fl">0.0</span>, score, <span class="fl">1.0</span>])</span>
<span id="cb28-47"><a href="#cb28-47" aria-hidden="true" tabindex="-1"></a>    best_t, best_cost <span class="op">=</span> <span class="va">None</span>, np.inf</span>
<span id="cb28-48"><a href="#cb28-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> thresholds:</span>
<span id="cb28-49"><a href="#cb28-49" aria-hidden="true" tabindex="-1"></a>        m <span class="op">=</span> metrics_at_threshold(y_true01, score, t)</span>
<span id="cb28-50"><a href="#cb28-50" aria-hidden="true" tabindex="-1"></a>        cost <span class="op">=</span> c_fn<span class="op">*</span>m[<span class="st">"fn"</span>] <span class="op">+</span> c_fp<span class="op">*</span>m[<span class="st">"fp"</span>]</span>
<span id="cb28-51"><a href="#cb28-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> cost <span class="op">&lt;</span> best_cost:</span>
<span id="cb28-52"><a href="#cb28-52" aria-hidden="true" tabindex="-1"></a>            best_cost <span class="op">=</span> cost</span>
<span id="cb28-53"><a href="#cb28-53" aria-hidden="true" tabindex="-1"></a>            best_t <span class="op">=</span> <span class="bu">float</span>(t)</span>
<span id="cb28-54"><a href="#cb28-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_t, <span class="bu">float</span>(best_cost)</span>
<span id="cb28-55"><a href="#cb28-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-56"><a href="#cb28-56" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_rows(model_name, y_true01, score, alpha<span class="op">=</span><span class="fl">0.001</span>, c_fn<span class="op">=</span><span class="fl">100.0</span>, c_fp<span class="op">=</span><span class="fl">1.0</span>):</span>
<span id="cb28-57"><a href="#cb28-57" aria-hidden="true" tabindex="-1"></a>    rows <span class="op">=</span> []</span>
<span id="cb28-58"><a href="#cb28-58" aria-hidden="true" tabindex="-1"></a>    fpr, tpr, _ <span class="op">=</span> roc_curve(y_true01, score)</span>
<span id="cb28-59"><a href="#cb28-59" aria-hidden="true" tabindex="-1"></a>    roc_auc <span class="op">=</span> auc(fpr, tpr)</span>
<span id="cb28-60"><a href="#cb28-60" aria-hidden="true" tabindex="-1"></a>    ap <span class="op">=</span> average_precision_score(y_true01, score)</span>
<span id="cb28-61"><a href="#cb28-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-62"><a href="#cb28-62" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Youden</span></span>
<span id="cb28-63"><a href="#cb28-63" aria-hidden="true" tabindex="-1"></a>    t_y <span class="op">=</span> threshold_youden(y_true01, score)</span>
<span id="cb28-64"><a href="#cb28-64" aria-hidden="true" tabindex="-1"></a>    m_y <span class="op">=</span> metrics_at_threshold(y_true01, score, t_y)</span>
<span id="cb28-65"><a href="#cb28-65" aria-hidden="true" tabindex="-1"></a>    m_y.update({<span class="st">"model"</span>: model_name, <span class="st">"rule"</span>: <span class="st">"Youden (TPR-FPR)"</span>, <span class="st">"roc_auc"</span>: roc_auc, <span class="st">"ap"</span>: ap,</span>
<span id="cb28-66"><a href="#cb28-66" aria-hidden="true" tabindex="-1"></a>                <span class="st">"cost"</span>: c_fn<span class="op">*</span>m_y[<span class="st">"fn"</span>] <span class="op">+</span> c_fp<span class="op">*</span>m_y[<span class="st">"fp"</span>]})</span>
<span id="cb28-67"><a href="#cb28-67" aria-hidden="true" tabindex="-1"></a>    rows.append(m_y)</span>
<span id="cb28-68"><a href="#cb28-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-69"><a href="#cb28-69" aria-hidden="true" tabindex="-1"></a>    <span class="co"># FPR constraint</span></span>
<span id="cb28-70"><a href="#cb28-70" aria-hidden="true" tabindex="-1"></a>    t_f <span class="op">=</span> threshold_fpr_constraint(y_true01, score, alpha<span class="op">=</span>alpha)</span>
<span id="cb28-71"><a href="#cb28-71" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> t_f <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb28-72"><a href="#cb28-72" aria-hidden="true" tabindex="-1"></a>        m_f <span class="op">=</span> metrics_at_threshold(y_true01, score, t_f)</span>
<span id="cb28-73"><a href="#cb28-73" aria-hidden="true" tabindex="-1"></a>        m_f.update({<span class="st">"model"</span>: model_name, <span class="st">"rule"</span>: <span class="ss">f"FPR &lt;= </span><span class="sc">{</span>alpha<span class="sc">}</span><span class="ss">"</span>, <span class="st">"roc_auc"</span>: roc_auc, <span class="st">"ap"</span>: ap,</span>
<span id="cb28-74"><a href="#cb28-74" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"cost"</span>: c_fn<span class="op">*</span>m_f[<span class="st">"fn"</span>] <span class="op">+</span> c_fp<span class="op">*</span>m_f[<span class="st">"fp"</span>]})</span>
<span id="cb28-75"><a href="#cb28-75" aria-hidden="true" tabindex="-1"></a>        rows.append(m_f)</span>
<span id="cb28-76"><a href="#cb28-76" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb28-77"><a href="#cb28-77" aria-hidden="true" tabindex="-1"></a>        rows.append({<span class="st">"model"</span>: model_name, <span class="st">"rule"</span>: <span class="ss">f"FPR &lt;= </span><span class="sc">{</span>alpha<span class="sc">}</span><span class="ss">"</span>, <span class="st">"t"</span>: <span class="va">None</span>,</span>
<span id="cb28-78"><a href="#cb28-78" aria-hidden="true" tabindex="-1"></a>                     <span class="st">"tn"</span>: <span class="va">None</span>, <span class="st">"fp"</span>: <span class="va">None</span>, <span class="st">"fn"</span>: <span class="va">None</span>, <span class="st">"tp"</span>: <span class="va">None</span>,</span>
<span id="cb28-79"><a href="#cb28-79" aria-hidden="true" tabindex="-1"></a>                     <span class="st">"recall(tpr)"</span>: <span class="va">None</span>, <span class="st">"fpr"</span>: <span class="va">None</span>, <span class="st">"precision"</span>: <span class="va">None</span>, <span class="st">"accuracy"</span>: <span class="va">None</span>,</span>
<span id="cb28-80"><a href="#cb28-80" aria-hidden="true" tabindex="-1"></a>                     <span class="st">"roc_auc"</span>: roc_auc, <span class="st">"ap"</span>: ap, <span class="st">"cost"</span>: <span class="va">None</span>})</span>
<span id="cb28-81"><a href="#cb28-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-82"><a href="#cb28-82" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Cost-based</span></span>
<span id="cb28-83"><a href="#cb28-83" aria-hidden="true" tabindex="-1"></a>    t_c, best_cost <span class="op">=</span> threshold_cost(y_true01, score, c_fn<span class="op">=</span>c_fn, c_fp<span class="op">=</span>c_fp)</span>
<span id="cb28-84"><a href="#cb28-84" aria-hidden="true" tabindex="-1"></a>    m_c <span class="op">=</span> metrics_at_threshold(y_true01, score, t_c)</span>
<span id="cb28-85"><a href="#cb28-85" aria-hidden="true" tabindex="-1"></a>    m_c.update({<span class="st">"model"</span>: model_name, <span class="st">"rule"</span>: <span class="ss">f"Cost (c_fn=</span><span class="sc">{</span>c_fn<span class="sc">}</span><span class="ss">, c_fp=</span><span class="sc">{</span>c_fp<span class="sc">}</span><span class="ss">)"</span>,</span>
<span id="cb28-86"><a href="#cb28-86" aria-hidden="true" tabindex="-1"></a>                <span class="st">"roc_auc"</span>: roc_auc, <span class="st">"ap"</span>: ap, <span class="st">"cost"</span>: best_cost})</span>
<span id="cb28-87"><a href="#cb28-87" aria-hidden="true" tabindex="-1"></a>    rows.append(m_c)</span>
<span id="cb28-88"><a href="#cb28-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-89"><a href="#cb28-89" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> rows</span>
<span id="cb28-90"><a href="#cb28-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-91"><a href="#cb28-91" aria-hidden="true" tabindex="-1"></a><span class="co"># score</span></span>
<span id="cb28-92"><a href="#cb28-92" aria-hidden="true" tabindex="-1"></a>score_knn <span class="op">=</span> get_pos_score(knn_model, X_test)</span>
<span id="cb28-93"><a href="#cb28-93" aria-hidden="true" tabindex="-1"></a>score_svm <span class="op">=</span> get_pos_score(svm_model, X_test)</span>
<span id="cb28-94"><a href="#cb28-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-95"><a href="#cb28-95" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.001</span></span>
<span id="cb28-96"><a href="#cb28-96" aria-hidden="true" tabindex="-1"></a>c_fn, c_fp <span class="op">=</span> <span class="fl">100.0</span>, <span class="fl">1.0</span></span>
<span id="cb28-97"><a href="#cb28-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-98"><a href="#cb28-98" aria-hidden="true" tabindex="-1"></a>rows <span class="op">=</span> []</span>
<span id="cb28-99"><a href="#cb28-99" aria-hidden="true" tabindex="-1"></a>rows <span class="op">+=</span> build_rows(<span class="st">"k-NN"</span>, y_pos, score_knn, alpha<span class="op">=</span>alpha, c_fn<span class="op">=</span>c_fn, c_fp<span class="op">=</span>c_fp)</span>
<span id="cb28-100"><a href="#cb28-100" aria-hidden="true" tabindex="-1"></a>rows <span class="op">+=</span> build_rows(<span class="st">"SVM(Linear+Calib)"</span>, y_pos, score_svm, alpha<span class="op">=</span>alpha, c_fn<span class="op">=</span>c_fn, c_fp<span class="op">=</span>c_fp)</span>
<span id="cb28-101"><a href="#cb28-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-102"><a href="#cb28-102" aria-hidden="true" tabindex="-1"></a>df_cmp <span class="op">=</span> pd.DataFrame(rows)[</span>
<span id="cb28-103"><a href="#cb28-103" aria-hidden="true" tabindex="-1"></a>    [<span class="st">"model"</span>,<span class="st">"rule"</span>,<span class="st">"t"</span>,<span class="st">"tn"</span>,<span class="st">"fp"</span>,<span class="st">"fn"</span>,<span class="st">"tp"</span>,<span class="st">"recall(tpr)"</span>,<span class="st">"fpr"</span>,<span class="st">"precision"</span>,<span class="st">"accuracy"</span>,<span class="st">"roc_auc"</span>,<span class="st">"ap"</span>,<span class="st">"cost"</span>]</span>
<span id="cb28-104"><a href="#cb28-104" aria-hidden="true" tabindex="-1"></a>].sort_values([<span class="st">"rule"</span>,<span class="st">"model"</span>]).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-105"><a href="#cb28-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-106"><a href="#cb28-106" aria-hidden="true" tabindex="-1"></a>display(df_cmp)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/classification_ml_knnsvmresult.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%"></p>
</figure>
</div>
</section>
<section id="모델-학습-회귀기반-트리기반-앙상블" class="level5">
<h5 class="anchored" data-anchor-id="모델-학습-회귀기반-트리기반-앙상블">(3) 모델 학습 (회귀기반 트리기반 앙상블)</h5>
<p><strong>회귀기반</strong></p>
<div class="sourceCode" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, classification_report</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>logit_model <span class="op">=</span> Pipeline([</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"scaler"</span>, StandardScaler()),</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"logit"</span>, LogisticRegression(</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>        C<span class="op">=</span><span class="fl">1.0</span>,</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>        solver<span class="op">=</span><span class="st">"lbfgs"</span>,</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>        max_iter<span class="op">=</span><span class="dv">5000</span>,</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>        class_weight<span class="op">=</span><span class="st">"balanced"</span>,   <span class="co"># 극심 불균형 대응(기본 옵션)</span></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>    ))</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>logit_model.fit(X_train, y_train)</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>y_pred_logit <span class="op">=</span> logit_model.predict(X_test)</span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[Logit] Confusion matrix:</span><span class="ch">\n</span><span class="st">"</span>, confusion_matrix(y_test, y_pred_logit))</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[Logit] Classification report:</span><span class="ch">\n</span><span class="st">"</span>, classification_report(y_test, y_pred_logit, digits<span class="op">=</span><span class="dv">4</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>[Logit] Confusion matrix:
 [[55478  1386]
 [    8    90]]
[Logit] Classification report:
               precision    recall  f1-score   support

           0     0.9999    0.9756    0.9876     56864
           1     0.0610    0.9184    0.1144        98

    accuracy                         0.9755     56962
   macro avg     0.5304    0.9470    0.5510     56962
weighted avg     0.9982    0.9755    0.9861     56962</code></pre>
<div class="sourceCode" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 1) 계수 꺼내기 (표준화된 스케일 기준)</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>logit  <span class="op">=</span> logit_model.named_steps[<span class="st">"logit"</span>]</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>coef   <span class="op">=</span> logit.coef_.ravel()</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>intercept <span class="op">=</span> <span class="bu">float</span>(logit.intercept_[<span class="dv">0</span>])</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>feature_names <span class="op">=</span> X.columns</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>df_coef <span class="op">=</span> pd.DataFrame({</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">"feature"</span>: feature_names,</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">"coef"</span>: coef,</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">"odds_ratio"</span>: np.exp(coef),        <span class="co"># OR = exp(beta)</span></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">"abs_coef"</span>: np.<span class="bu">abs</span>(coef),</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">"abs_logOR"</span>: np.<span class="bu">abs</span>(coef)          <span class="co"># log(OR)=coef 이므로 절댓값은 동일</span></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>}).sort_values(<span class="st">"abs_coef"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Intercept:"</span>, intercept)</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a><span class="co"># 2) (+) 계수 큰 것 Top10  -&gt; OR &gt; 1</span></span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>top_pos10 <span class="op">=</span> df_coef[df_coef[<span class="st">"coef"</span>] <span class="op">&gt;</span> <span class="dv">0</span>].sort_values(<span class="st">"coef"</span>, ascending<span class="op">=</span><span class="va">False</span>).head(<span class="dv">10</span>)</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a><span class="co"># 3) (-) 계수 '큰 것' Top10  -&gt; 가장 음수(절댓값 큰 음수), OR &lt; 1</span></span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>top_neg10 <span class="op">=</span> df_coef[df_coef[<span class="st">"coef"</span>] <span class="op">&lt;</span> <span class="dv">0</span>].sort_values(<span class="st">"coef"</span>, ascending<span class="op">=</span><span class="va">True</span>).head(<span class="dv">10</span>)</span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">[Top 10 POSITIVE coefs] (Fraud=1 odds ↑, OR&gt;1)"</span>)</span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>display(top_pos10[[<span class="st">"feature"</span>,<span class="st">"coef"</span>,<span class="st">"odds_ratio"</span>]])</span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">[Top 10 NEGATIVE coefs] (Fraud=1 odds ↓, OR&lt;1)"</span>)</span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a>display(top_neg10[[<span class="st">"feature"</span>,<span class="st">"coef"</span>,<span class="st">"odds_ratio"</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/classification_ml_rareregodds.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:60.0%"></p>
</figure>
</div>
<p><strong>트리기반</strong></p>
<div class="sourceCode" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, classification_report</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>tree_model <span class="op">=</span> DecisionTreeClassifier(</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>    criterion<span class="op">=</span><span class="st">"gini"</span>,</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="dv">6</span>,</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>    min_samples_leaf<span class="op">=</span><span class="dv">50</span>,     <span class="co"># fraud에서는 leaf를 너무 작게 두면 과적합 쉬움</span></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>    class_weight<span class="op">=</span><span class="st">"balanced"</span>,</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>tree_model.fit(X_train, y_train)</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>y_pred_tree <span class="op">=</span> tree_model.predict(X_test)</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[Tree] Confusion matrix:</span><span class="ch">\n</span><span class="st">"</span>, confusion_matrix(y_test, y_pred_tree))</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[Tree] Classification report:</span><span class="ch">\n</span><span class="st">"</span>, classification_report(y_test, y_pred_tree, digits<span class="op">=</span><span class="dv">4</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>[Tree] Confusion matrix:
 [[55491  1373]
 [   13    85]]
[Tree] Classification report:
               precision    recall  f1-score   support

           0     0.9998    0.9759    0.9877     56864
           1     0.0583    0.8673    0.1093        98

    accuracy                         0.9757     56962
   macro avg     0.5290    0.9216    0.5485     56962
weighted avg     0.9981    0.9757    0.9862     56962</code></pre>
<p><strong>앙상블</strong></p>
<div class="sourceCode" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier, GradientBoostingClassifier</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.utils.class_weight <span class="im">import</span> compute_sample_weight</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, classification_report</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="co"># (1) RandomForest</span></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>rf_model <span class="op">=</span> RandomForestClassifier(</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">300</span>,</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>    min_samples_leaf<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>    max_features<span class="op">=</span><span class="st">"sqrt"</span>,</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>    class_weight<span class="op">=</span><span class="st">"balanced_subsample"</span>,</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>rf_model.fit(X_train, y_train)</span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>y_pred_rf <span class="op">=</span> rf_model.predict(X_test)</span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[RF] Confusion matrix:</span><span class="ch">\n</span><span class="st">"</span>, confusion_matrix(y_test, y_pred_rf))</span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[RF] Classification report:</span><span class="ch">\n</span><span class="st">"</span>, classification_report(y_test, y_pred_rf, digits<span class="op">=</span><span class="dv">4</span>))</span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a><span class="co"># (2) GradientBoosting (+ sample_weight)</span></span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a>GradientBoostingClassifier(</span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a>    n_estimators<span class="op">=</span><span class="dv">150</span>,     <span class="co"># 300 → 150</span></span>
<span id="cb34-24"><a href="#cb34-24" aria-hidden="true" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="fl">0.1</span>,    <span class="co"># 0.05 → 0.1</span></span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true" tabindex="-1"></a>    max_depth<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb34-26"><a href="#cb34-26" aria-hidden="true" tabindex="-1"></a>    subsample<span class="op">=</span><span class="fl">0.7</span>,        <span class="co"># 추가</span></span>
<span id="cb34-27"><a href="#cb34-27" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb34-28"><a href="#cb34-28" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb34-29"><a href="#cb34-29" aria-hidden="true" tabindex="-1"></a>sw <span class="op">=</span> compute_sample_weight(class_weight<span class="op">=</span><span class="st">"balanced"</span>, y<span class="op">=</span>y_train)  <span class="co"># 불균형 가중치</span></span>
<span id="cb34-30"><a href="#cb34-30" aria-hidden="true" tabindex="-1"></a>gb_model.fit(X_train, y_train, sample_weight<span class="op">=</span>sw)</span>
<span id="cb34-31"><a href="#cb34-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-32"><a href="#cb34-32" aria-hidden="true" tabindex="-1"></a>y_pred_gb <span class="op">=</span> gb_model.predict(X_test)</span>
<span id="cb34-33"><a href="#cb34-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[GB] Confusion matrix:</span><span class="ch">\n</span><span class="st">"</span>, confusion_matrix(y_test, y_pred_gb))</span>
<span id="cb34-34"><a href="#cb34-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"[GB] Classification report:</span><span class="ch">\n</span><span class="st">"</span>, classification_report(y_test, y_pred_gb, digits<span class="op">=</span><span class="dv">4</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre class="text"><code>[RF] Confusion matrix:
 [[56860     4]
 [   22    76]]
[RF] Classification report:
               precision    recall  f1-score   support

           0     0.9996    0.9999    0.9998     56864
           1     0.9500    0.7755    0.8539        98

    accuracy                         0.9995     56962
   macro avg     0.9748    0.8877    0.9269     56962
weighted avg     0.9995    0.9995    0.9995     56962

[GB] Confusion matrix:
 [[55591  1273]
 [    9    89]]
[GB] Classification report:
               precision    recall  f1-score   support

           0     0.9998    0.9776    0.9886     56864
           1     0.0653    0.9082    0.1219        98

    accuracy                         0.9775     56962
   macro avg     0.5326    0.9429    0.5553     56962
weighted avg     0.9982    0.9775    0.9871     56962</code></pre>
<p><strong>모델 비교</strong></p>
<div class="sourceCode" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_curve, auc, average_precision_score, confusion_matrix</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a><span class="co"># y는 0/1로, 1이 Fraud(positive)</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>y_test_np <span class="op">=</span> np.asarray(y_test).ravel()</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_pos_score(model, X):</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>    proba <span class="op">=</span> model.predict_proba(X)</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>    classes <span class="op">=</span> np.array(model.classes_)</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>    pos_idx <span class="op">=</span> np.where(classes <span class="op">==</span> <span class="dv">1</span>)[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> proba[:, pos_idx]</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> metrics_at_threshold(y_true01, score, t):</span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a>    y_hat <span class="op">=</span> (score <span class="op">&gt;=</span> t).astype(<span class="bu">int</span>)</span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a>    tn, fp, fn, tp <span class="op">=</span> confusion_matrix(y_true01, y_hat).ravel()</span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a>    tpr <span class="op">=</span> tp <span class="op">/</span> (tp <span class="op">+</span> fn) <span class="cf">if</span> (tp <span class="op">+</span> fn) <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a>    fpr <span class="op">=</span> fp <span class="op">/</span> (fp <span class="op">+</span> tn) <span class="cf">if</span> (fp <span class="op">+</span> tn) <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a>    prec <span class="op">=</span> tp <span class="op">/</span> (tp <span class="op">+</span> fp) <span class="cf">if</span> (tp <span class="op">+</span> fp) <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a>    acc <span class="op">=</span> (tp <span class="op">+</span> tn) <span class="op">/</span> (tp <span class="op">+</span> tn <span class="op">+</span> fp <span class="op">+</span> fn)</span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">"t"</span>: <span class="bu">float</span>(t), <span class="st">"tn"</span>: <span class="bu">int</span>(tn), <span class="st">"fp"</span>: <span class="bu">int</span>(fp), <span class="st">"fn"</span>: <span class="bu">int</span>(fn), <span class="st">"tp"</span>: <span class="bu">int</span>(tp),</span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a>            <span class="st">"recall(tpr)"</span>: <span class="bu">float</span>(tpr), <span class="st">"fpr"</span>: <span class="bu">float</span>(fpr), <span class="st">"precision"</span>: <span class="bu">float</span>(prec), <span class="st">"accuracy"</span>: <span class="bu">float</span>(acc)}</span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> threshold_youden(y_true01, score):</span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true" tabindex="-1"></a>    fpr, tpr, thr <span class="op">=</span> roc_curve(y_true01, score)</span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># inf(아무도 양성 예측 안 함) 제외</span></span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> np.isfinite(thr)</span>
<span id="cb36-28"><a href="#cb36-28" aria-hidden="true" tabindex="-1"></a>    J <span class="op">=</span> (tpr <span class="op">-</span> fpr)</span>
<span id="cb36-29"><a href="#cb36-29" aria-hidden="true" tabindex="-1"></a>    J[<span class="op">~</span>mask] <span class="op">=</span> <span class="op">-</span>np.inf</span>
<span id="cb36-30"><a href="#cb36-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">float</span>(thr[np.argmax(J)])</span>
<span id="cb36-31"><a href="#cb36-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-32"><a href="#cb36-32" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> threshold_fpr_constraint(y_true01, score, alpha<span class="op">=</span><span class="fl">0.001</span>):</span>
<span id="cb36-33"><a href="#cb36-33" aria-hidden="true" tabindex="-1"></a>    fpr, tpr, thr <span class="op">=</span> roc_curve(y_true01, score)</span>
<span id="cb36-34"><a href="#cb36-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># inf 제외 + (TPR&gt;0) 조건으로 trivial 해 방지</span></span>
<span id="cb36-35"><a href="#cb36-35" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> np.isfinite(thr) <span class="op">&amp;</span> (tpr <span class="op">&gt;</span> <span class="dv">0</span>)</span>
<span id="cb36-36"><a href="#cb36-36" aria-hidden="true" tabindex="-1"></a>    cand <span class="op">=</span> np.where(mask <span class="op">&amp;</span> (fpr <span class="op">&lt;=</span> alpha))[<span class="dv">0</span>]</span>
<span id="cb36-37"><a href="#cb36-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(cand) <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb36-38"><a href="#cb36-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb36-39"><a href="#cb36-39" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> cand[np.argmax(tpr[cand])]</span>
<span id="cb36-40"><a href="#cb36-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">float</span>(thr[i])</span>
<span id="cb36-41"><a href="#cb36-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-42"><a href="#cb36-42" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> threshold_cost(y_true01, score, c_fn<span class="op">=</span><span class="fl">100.0</span>, c_fp<span class="op">=</span><span class="fl">1.0</span>):</span>
<span id="cb36-43"><a href="#cb36-43" aria-hidden="true" tabindex="-1"></a>    thresholds <span class="op">=</span> np.unique(score)</span>
<span id="cb36-44"><a href="#cb36-44" aria-hidden="true" tabindex="-1"></a>    thresholds <span class="op">=</span> np.r_[<span class="fl">0.0</span>, thresholds, <span class="fl">1.0</span>]  <span class="co"># 범위 포함</span></span>
<span id="cb36-45"><a href="#cb36-45" aria-hidden="true" tabindex="-1"></a>    best_t, best_cost <span class="op">=</span> <span class="va">None</span>, np.inf</span>
<span id="cb36-46"><a href="#cb36-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> thresholds:</span>
<span id="cb36-47"><a href="#cb36-47" aria-hidden="true" tabindex="-1"></a>        m <span class="op">=</span> metrics_at_threshold(y_true01, score, t)</span>
<span id="cb36-48"><a href="#cb36-48" aria-hidden="true" tabindex="-1"></a>        cost <span class="op">=</span> c_fn<span class="op">*</span>m[<span class="st">"fn"</span>] <span class="op">+</span> c_fp<span class="op">*</span>m[<span class="st">"fp"</span>]</span>
<span id="cb36-49"><a href="#cb36-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> cost <span class="op">&lt;</span> best_cost:</span>
<span id="cb36-50"><a href="#cb36-50" aria-hidden="true" tabindex="-1"></a>            best_cost, best_t <span class="op">=</span> cost, <span class="bu">float</span>(t)</span>
<span id="cb36-51"><a href="#cb36-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_t, <span class="bu">float</span>(best_cost)</span>
<span id="cb36-52"><a href="#cb36-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-53"><a href="#cb36-53" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> summarize_model(model_name, y_true01, score, alpha<span class="op">=</span><span class="fl">0.001</span>, c_fn<span class="op">=</span><span class="fl">100.0</span>, c_fp<span class="op">=</span><span class="fl">1.0</span>):</span>
<span id="cb36-54"><a href="#cb36-54" aria-hidden="true" tabindex="-1"></a>    fpr, tpr, _ <span class="op">=</span> roc_curve(y_true01, score)</span>
<span id="cb36-55"><a href="#cb36-55" aria-hidden="true" tabindex="-1"></a>    roc_auc <span class="op">=</span> auc(fpr, tpr)</span>
<span id="cb36-56"><a href="#cb36-56" aria-hidden="true" tabindex="-1"></a>    ap <span class="op">=</span> average_precision_score(y_true01, score)</span>
<span id="cb36-57"><a href="#cb36-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-58"><a href="#cb36-58" aria-hidden="true" tabindex="-1"></a>    rows <span class="op">=</span> []</span>
<span id="cb36-59"><a href="#cb36-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-60"><a href="#cb36-60" aria-hidden="true" tabindex="-1"></a>    t_y <span class="op">=</span> threshold_youden(y_true01, score)</span>
<span id="cb36-61"><a href="#cb36-61" aria-hidden="true" tabindex="-1"></a>    m_y <span class="op">=</span> metrics_at_threshold(y_true01, score, t_y)</span>
<span id="cb36-62"><a href="#cb36-62" aria-hidden="true" tabindex="-1"></a>    m_y.update({<span class="st">"model"</span>: model_name, <span class="st">"rule"</span>: <span class="st">"Youden (TPR-FPR)"</span>, <span class="st">"roc_auc"</span>: roc_auc, <span class="st">"ap"</span>: ap,</span>
<span id="cb36-63"><a href="#cb36-63" aria-hidden="true" tabindex="-1"></a>                <span class="st">"cost"</span>: c_fn<span class="op">*</span>m_y[<span class="st">"fn"</span>] <span class="op">+</span> c_fp<span class="op">*</span>m_y[<span class="st">"fp"</span>]})</span>
<span id="cb36-64"><a href="#cb36-64" aria-hidden="true" tabindex="-1"></a>    rows.append(m_y)</span>
<span id="cb36-65"><a href="#cb36-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-66"><a href="#cb36-66" aria-hidden="true" tabindex="-1"></a>    t_f <span class="op">=</span> threshold_fpr_constraint(y_true01, score, alpha<span class="op">=</span>alpha)</span>
<span id="cb36-67"><a href="#cb36-67" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> t_f <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb36-68"><a href="#cb36-68" aria-hidden="true" tabindex="-1"></a>        m_f <span class="op">=</span> metrics_at_threshold(y_true01, score, t_f)</span>
<span id="cb36-69"><a href="#cb36-69" aria-hidden="true" tabindex="-1"></a>        m_f.update({<span class="st">"model"</span>: model_name, <span class="st">"rule"</span>: <span class="ss">f"FPR &lt;= </span><span class="sc">{</span>alpha<span class="sc">}</span><span class="ss">"</span>, <span class="st">"roc_auc"</span>: roc_auc, <span class="st">"ap"</span>: ap,</span>
<span id="cb36-70"><a href="#cb36-70" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"cost"</span>: c_fn<span class="op">*</span>m_f[<span class="st">"fn"</span>] <span class="op">+</span> c_fp<span class="op">*</span>m_f[<span class="st">"fp"</span>]})</span>
<span id="cb36-71"><a href="#cb36-71" aria-hidden="true" tabindex="-1"></a>        rows.append(m_f)</span>
<span id="cb36-72"><a href="#cb36-72" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb36-73"><a href="#cb36-73" aria-hidden="true" tabindex="-1"></a>        rows.append({<span class="st">"model"</span>: model_name, <span class="st">"rule"</span>: <span class="ss">f"FPR &lt;= </span><span class="sc">{</span>alpha<span class="sc">}</span><span class="ss">"</span>, <span class="st">"t"</span>: <span class="va">None</span>,</span>
<span id="cb36-74"><a href="#cb36-74" aria-hidden="true" tabindex="-1"></a>                     <span class="st">"tn"</span>: <span class="va">None</span>, <span class="st">"fp"</span>: <span class="va">None</span>, <span class="st">"fn"</span>: <span class="va">None</span>, <span class="st">"tp"</span>: <span class="va">None</span>,</span>
<span id="cb36-75"><a href="#cb36-75" aria-hidden="true" tabindex="-1"></a>                     <span class="st">"recall(tpr)"</span>: <span class="va">None</span>, <span class="st">"fpr"</span>: <span class="va">None</span>, <span class="st">"precision"</span>: <span class="va">None</span>, <span class="st">"accuracy"</span>: <span class="va">None</span>,</span>
<span id="cb36-76"><a href="#cb36-76" aria-hidden="true" tabindex="-1"></a>                     <span class="st">"roc_auc"</span>: roc_auc, <span class="st">"ap"</span>: ap, <span class="st">"cost"</span>: <span class="va">None</span>})</span>
<span id="cb36-77"><a href="#cb36-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-78"><a href="#cb36-78" aria-hidden="true" tabindex="-1"></a>    t_c, best_cost <span class="op">=</span> threshold_cost(y_true01, score, c_fn<span class="op">=</span>c_fn, c_fp<span class="op">=</span>c_fp)</span>
<span id="cb36-79"><a href="#cb36-79" aria-hidden="true" tabindex="-1"></a>    m_c <span class="op">=</span> metrics_at_threshold(y_true01, score, t_c)</span>
<span id="cb36-80"><a href="#cb36-80" aria-hidden="true" tabindex="-1"></a>    m_c.update({<span class="st">"model"</span>: model_name, <span class="st">"rule"</span>: <span class="ss">f"Cost (c_fn=</span><span class="sc">{</span>c_fn<span class="sc">}</span><span class="ss">, c_fp=</span><span class="sc">{</span>c_fp<span class="sc">}</span><span class="ss">)"</span>,</span>
<span id="cb36-81"><a href="#cb36-81" aria-hidden="true" tabindex="-1"></a>                <span class="st">"roc_auc"</span>: roc_auc, <span class="st">"ap"</span>: ap, <span class="st">"cost"</span>: best_cost})</span>
<span id="cb36-82"><a href="#cb36-82" aria-hidden="true" tabindex="-1"></a>    rows.append(m_c)</span>
<span id="cb36-83"><a href="#cb36-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-84"><a href="#cb36-84" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> rows</span>
<span id="cb36-85"><a href="#cb36-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-86"><a href="#cb36-86" aria-hidden="true" tabindex="-1"></a><span class="co"># ===== 모델 score 모으기(이미 앞에서 학습된 것으로 가정) =====</span></span>
<span id="cb36-87"><a href="#cb36-87" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> {</span>
<span id="cb36-88"><a href="#cb36-88" aria-hidden="true" tabindex="-1"></a>    <span class="st">"k-NN"</span>: knn_model,</span>
<span id="cb36-89"><a href="#cb36-89" aria-hidden="true" tabindex="-1"></a>    <span class="st">"SVM(Linear+Calib)"</span>: svm_model,</span>
<span id="cb36-90"><a href="#cb36-90" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Logit"</span>: logit_model,</span>
<span id="cb36-91"><a href="#cb36-91" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Tree"</span>: tree_model,</span>
<span id="cb36-92"><a href="#cb36-92" aria-hidden="true" tabindex="-1"></a>    <span class="st">"RandomForest"</span>: rf_model,</span>
<span id="cb36-93"><a href="#cb36-93" aria-hidden="true" tabindex="-1"></a>    <span class="st">"GradientBoosting"</span>: gb_model</span>
<span id="cb36-94"><a href="#cb36-94" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb36-95"><a href="#cb36-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-96"><a href="#cb36-96" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.001</span>          <span class="co"># 사기탐지에서 흔한 FPR 제약(0.1%)</span></span>
<span id="cb36-97"><a href="#cb36-97" aria-hidden="true" tabindex="-1"></a>c_fn, c_fp <span class="op">=</span> <span class="fl">100.0</span>, <span class="fl">1.0</span>  <span class="co"># FN(사기 놓침) 비용을 크게</span></span>
<span id="cb36-98"><a href="#cb36-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-99"><a href="#cb36-99" aria-hidden="true" tabindex="-1"></a>rows <span class="op">=</span> []</span>
<span id="cb36-100"><a href="#cb36-100" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, m <span class="kw">in</span> models.items():</span>
<span id="cb36-101"><a href="#cb36-101" aria-hidden="true" tabindex="-1"></a>    score <span class="op">=</span> get_pos_score(m, X_test)</span>
<span id="cb36-102"><a href="#cb36-102" aria-hidden="true" tabindex="-1"></a>    rows <span class="op">+=</span> summarize_model(name, y_test_np, score, alpha<span class="op">=</span>alpha, c_fn<span class="op">=</span>c_fn, c_fp<span class="op">=</span>c_fp)</span>
<span id="cb36-103"><a href="#cb36-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-104"><a href="#cb36-104" aria-hidden="true" tabindex="-1"></a>df_all <span class="op">=</span> pd.DataFrame(rows)[</span>
<span id="cb36-105"><a href="#cb36-105" aria-hidden="true" tabindex="-1"></a>    [<span class="st">"model"</span>,<span class="st">"rule"</span>,<span class="st">"t"</span>,<span class="st">"tn"</span>,<span class="st">"fp"</span>,<span class="st">"fn"</span>,<span class="st">"tp"</span>,<span class="st">"recall(tpr)"</span>,<span class="st">"fpr"</span>,<span class="st">"precision"</span>,<span class="st">"accuracy"</span>,<span class="st">"roc_auc"</span>,<span class="st">"ap"</span>,<span class="st">"cost"</span>]</span>
<span id="cb36-106"><a href="#cb36-106" aria-hidden="true" tabindex="-1"></a>].sort_values([<span class="st">"rule"</span>,<span class="st">"model"</span>]).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb36-107"><a href="#cb36-107" aria-hidden="true" tabindex="-1"></a>display(df_all)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/classification_ml_rareall.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%"></p>
</figure>
</div>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>