<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>MLDL 딥러닝 분류 - 파트2 – 세상의 모든 통계 이야기</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-2757cfadcc89ddbfb9e61569f8c3689f.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">세상의 모든 통계 이야기</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../notes/math_stat/index.html"> 
<span class="menu-text">기초수학·수리통계</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../notes/intro_stat/index.html"> 
<span class="menu-text">기초통계·조사방법</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../notes/linear_model/index.html"> 
<span class="menu-text">회귀·다변량</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../notes/mldl_intro/index.html"> 
<span class="menu-text">MLDL개념</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../notes/mldl_prediction/index.html"> 
<span class="menu-text">MLDL예측</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../../notes/mldl_classification/index.html" aria-current="page"> 
<span class="menu-text">MLDL분류</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../cardnews/index.html"> 
<span class="menu-text">카드뉴스</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../consult.html"> 
<span class="menu-text">통계상담</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../notes/mldl_classification/classification_deeplearning02.html">📄 딥러닝 분류 파트2</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">【머신·딥러닝 분류문제】</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/classification_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📄 분류문제: 정의</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/lm_logistic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📄 예측분류-로지스틱회귀</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/mda_discriminant.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📄 예측분류-판별분석</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/prediction_treebase.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📄 예측분류-ML 트리기반</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/classification_ml_methods.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📄 머신러닝kNN_SVM강의</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/classification_ml_case_binary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📄 머신러닝 이진형사례</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/classification_deeplearning01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📄 딥러닝 분류 파트1</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/classification_deeplearning02.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">📄 딥러닝 분류 파트2</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/classification_evaluation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📄 분류모델 평가</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">목차</h2>
   
  <ul>
  <li><a href="#chapter-2.-딥러닝-분류-파트2" id="toc-chapter-2.-딥러닝-분류-파트2" class="nav-link active" data-scroll-target="#chapter-2.-딥러닝-분류-파트2">Chapter 2. 딥러닝 분류 (파트2)</a>
  <ul>
  <li><a href="#과신overconfidence과-일반화-개선" id="toc-과신overconfidence과-일반화-개선" class="nav-link" data-scroll-target="#과신overconfidence과-일반화-개선">1. 과신(Overconfidence)과 일반화 개선</a></li>
  <li><a href="#대규모-클래스-분류large-k의-계산-이슈" id="toc-대규모-클래스-분류large-k의-계산-이슈" class="nav-link" data-scroll-target="#대규모-클래스-분류large-k의-계산-이슈">2. 대규모 클래스 분류(Large K)의 계산 이슈</a></li>
  <li><a href="#거리학습-기반-분류-metric-learning" id="toc-거리학습-기반-분류-metric-learning" class="nav-link" data-scroll-target="#거리학습-기반-분류-metric-learning">3. 거리학습 기반 분류: Metric Learning</a></li>
  <li><a href="#자기지도대조학습-후-분류기현대적-파이프라인" id="toc-자기지도대조학습-후-분류기현대적-파이프라인" class="nav-link" data-scroll-target="#자기지도대조학습-후-분류기현대적-파이프라인">4. 자기지도/대조학습 후 분류기(현대적 파이프라인)</a></li>
  <li><a href="#불확실성uncertainty과-안정적-의사결정" id="toc-불확실성uncertainty과-안정적-의사결정" class="nav-link" data-scroll-target="#불확실성uncertainty과-안정적-의사결정">5. 불확실성(uncertainty)과 안정적 의사결정</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">MLDL 딥러닝 분류 - 파트2</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="chapter-2.-딥러닝-분류-파트2" class="level3">
<h3 class="anchored" data-anchor-id="chapter-2.-딥러닝-분류-파트2">Chapter 2. 딥러닝 분류 (파트2)</h3>
<section id="과신overconfidence과-일반화-개선" class="level4">
<h4 class="anchored" data-anchor-id="과신overconfidence과-일반화-개선">1. 과신(Overconfidence)과 일반화 개선</h4>
<p>딥러닝 분류 모델은 종종 <span dir="rtl">”</span>정확도는 괜찮은데 확률이 지나치게 확신적”인 출력을 만든다. 예를 들어 틀린 예측인데도 p=0.99처럼 매우 높은 확률을 내놓는 경우가 있다.</p>
<p>이를 과신이라 부르며, 운영에서는 임계값 정책·리스크 관리·사후 검토량을 크게 왜곡시킨다. 따라서 분류 모델의 품질은 정답률뿐 아니라 확률의 신뢰도까지 함께 점검해야 한다.</p>
<section id="딥러닝-확률의-과신-원인softmax-데이터-편향-ood-등" class="level5">
<h5 class="anchored" data-anchor-id="딥러닝-확률의-과신-원인softmax-데이터-편향-ood-등">(1) 딥러닝 확률의 과신 원인(softmax, 데이터 편향, OOD 등)</h5>
<p>과신은 단일 원인이라기보다 <span dir="rtl">”</span>확률 출력이 만들어지는 구조 + 데이터/학습 환경”이 결합된 결과로 보는 것이 정확하다.</p>
<p><strong>Softmax 구조 자체가 만드는 경쟁과 <span dir="rtl">”</span>확신”</strong></p>
<p>다중분류에서 <span class="math inline">\(p_{k} = \frac{e^{z_{k}}}{\sum_{j = 1}^{K}e^{z_{j}}}\)</span>이므로, 로짓 차이 <span class="math inline">\(z_{(1)} - z_{(2)}\)</span>가 조금만 커져도 최대 확률은 급격히 1에 가까워진다. 즉 softmax는 <span dir="rtl">”</span>최대 클래스가 승자독식”을 만드는 경향이 있어, 결정경계에서 조금 멀어지면 매우 큰 확신을 출력하기 쉽다.</p>
<p>또한 cross-entropy는 정답 클래스 확률 p_y를 크게 만들도록 압력을 주며, <span class="math inline">\(\mathcal{L} = - \log p_{y}\)</span>이다. 이 손실은 <span class="math inline">\(p_{y} \rightarrow 1\)</span>로 밀어붙이는 성격이 있어(특히 데이터가 쉽게 분리되거나 모델이 과대용량일 때) 과신이 강화될 수 있다.</p>
<p><strong>데이터 편향과 라벨 노이즈</strong></p>
<p>훈련 데이터가 현실 운영 분포를 충분히 대표하지 못하면(표본 편향), 모델은 <span dir="rtl">”</span>보지 못한 경우”를 만나도 여전히 높은 확률을 낼 수 있다. 라벨 노이즈가 존재해도 cross-entropy는 틀린 라벨을 맞추려는 방향으로 강하게 학습되므로, 일부 영역에서 불필요한 확신이 쌓일 수 있다.</p>
<p><strong>OOD(Out-of-Distribution) 입력</strong></p>
<p>훈련 분포 밖 입력 <span class="math inline">\(x \sim P_{\text{OOD}}\)</span>에 대해서도 softmax는 어떤 클래스로든 확률을 <span dir="rtl">”</span>합이 1이 되게” 배분해야 한다. 이 때문에 <span dir="rtl">”</span>모르는 입력”인데도 <span class="math inline">\(\max_{k}p_{k}(x)\)</span>가 크게 나오는 현상이 흔하다. 즉 OOD에서의 과신은 softmax 기반 분류기의 구조적 취약점으로 자주 지적된다.</p>
</section>
<section id="calibration-curve-ece-brier-score" class="level5">
<h5 class="anchored" data-anchor-id="calibration-curve-ece-brier-score">(2) Calibration curve / ECE / Brier score</h5>
<p>확률의 신뢰도를 평가하는 핵심은 다음 질문이다. <span dir="rtl">”</span>모델이 0.8이라고 말한 사례들은 실제로 약 80%가 맞는가?”</p>
<p><strong>Calibration curve (Reliability diagram)</strong></p>
<p>확률 예측 <span class="math inline">\({\widehat{p}}_{i}\)</span>를 구간(bin)으로 나눈 뒤, 각 구간에서 평균 예측 확률은 <span class="math inline">\(conf(b)\)</span>. 실제 정확도(양성 비율 또는 정답률) <span class="math inline">\(acc(b)\)</span>를 비교한다.</p>
<p>이진분류 예시(양성 확률): <span class="math inline">\(acc(b) = \frac{1}{|B_{b}|}\sum_{i \in B_{b}}y_{i},conf(b) = \frac{1}{|B_{b}|}\sum_{i \in B_{b}}{\widehat{p}}_{i}\)</span></p>
<p>완전 보정이면 <span class="math inline">\(acc(b) \approx conf(b)\)</span>가 되어 대각선에 놓인다.</p>
<p><strong>ECE (Expected Calibration Error)</strong></p>
<p>ECE는 구간별 차이의 가중 평균이다. <span class="math inline">\(ECE = \overset{B}{\sum_{b = 1}}\frac{|B_{b}|}{n}|acc(b) - conf(b)|\)</span></p>
<p>작을수록 보정이 잘 되고 구간 개수 B 및 binning 방식에 민감할 수 있다(평가 세팅 명시 필요).</p>
<p><strong>Brier score</strong></p>
<p>Brier score는 <span dir="rtl">”</span>확률 예측의 제곱오차”로, calibration과 sharpness(확률의 분별력)를 함께 반영한다.</p>
<p>이진분류: <span class="math inline">\(BS = \frac{1}{n}\overset{n}{\sum_{i = 1}}({\widehat{p}}_{i} - y_{i})^{2}\)</span>, 다중분류(원-핫 <span class="math inline">\(\mathbf{y}_{i}\)</span>, 확률 <span class="math inline">\(\mathbf{p}_{i}\)</span>): <span class="math inline">\(BS = \frac{1}{n}\overset{n}{\sum_{i = 1}}\overset{K}{\sum_{k = 1}}(p_{ik} - y_{ik})^{2}\)</span> 작을수록 좋다.</p>
</section>
<section id="보정-방법-temperature-scaling-platt-isotonic" class="level5">
<h5 class="anchored" data-anchor-id="보정-방법-temperature-scaling-platt-isotonic">(3) 보정 방법: Temperature scaling / Platt / Isotonic</h5>
<p>보정(calibration)은 보통 <span dir="rtl">”</span>모델을 다시 학습”하기보다, 학습된 모델의 출력 점수(logit 또는 score)를 사후 변환하는 방식이 실무적으로 안정적이다. 핵심은 <span dir="rtl">”</span>검증셋(또는 별도 calibration set)“을 사용해 변환 파라미터를 추정하는 것이다.</p>
<p><strong>Temperature scaling (softmax logits 보정)</strong></p>
<p>다중분류에서 로짓 <span class="math inline">\(\mathbf{z}\)</span>에 대해 <span class="math inline">\(\mathbf{p}^{(T)} = softmax\left( \frac{\mathbf{z}}{T} \right),T &gt; 0\)</span></p>
<ul>
<li>T&gt;1: 로짓을 나눠 softmax를 <span dir="rtl">”</span>평평하게” 만들어 과신을 완화</li>
<li>T&lt;1: 더 뾰족하게(과소신 보정일 때)</li>
</ul>
<p>T는 보통 calibration set에서 NLL을 최소화하도록 하나의 스칼라로 추정한다. 장점은 순위(Top-1 클래스)는 거의 유지되며, 확률만 부드럽게 조정되어 운영 임계값 설계가 쉬워진다는 점이다.</p>
<p><strong>Platt scaling (주로 이진분류, score → sigmoid)</strong></p>
<p>SVM 등에서 유래했으며, 어떤 점수 s(x)에 대해 <span class="math inline">\(\widehat{p}(x) = \sigma(as(x) + b)\)</span> 형태로 a, b를 calibration set에서 추정한다. 딥러닝에서도 로짓 z에 적용 가능하다.</p>
<p><strong>Isotonic regression (비모수 단조 보정)</strong></p>
<p>확률을 단조 함수 <span class="math inline">\(g( \cdot )\)</span>로 보정한다. <span class="math inline">\(\widehat{p}(x) = g(s(x))\)</span>. 장점은 형태 가정이 약해 유연하다는 것이고 단점은 데이터가 적으면 과적합 위험이 커진다(특히 희귀 양성일 때).</p>
<p>실무적으로는 데이터가 충분하면 isotonic, 그렇지 않으 temperature/Platt처럼 파라미터 수가 적은 방법이 안전한 편이다.</p>
</section>
<section id="일반화-개선-연결-증강전이학습정규화가-과신에-미치는-영향" class="level5">
<h5 class="anchored" data-anchor-id="일반화-개선-연결-증강전이학습정규화가-과신에-미치는-영향">(4) 일반화 개선 연결: 증강·전이학습·정규화가 과신에 미치는 영향</h5>
<p>과신은 <span dir="rtl">”</span>확률 출력부” 문제처럼 보이지만, 실제로는 일반화와 깊게 연결된다. 일반화가 좋아지면 보통 과신도 함께 완화되지만, 항상 자동으로 해결되지는 않기 때문에 <span dir="rtl">”</span>학습 개선 + 사후 보정”을 함께 고려한다.</p>
<p><strong>데이터 증강(augmentation)</strong></p>
<p>증강은 입력 변형을 통해 모델이 더 넓은 데이터 다양성을 보게 만들어, 특정 패턴에 대한 과도한 확신을 줄이는 경향이 있다. 특히 강한 증강은 결정경계를 부드럽게 만들어 calibration이 개선되는 경우가 많다(다만 과도하면 정확도 자체가 손해 볼 수 있어 균형이 필요).</p>
<p><strong>전이학습(transfer learning)</strong></p>
<p>사전학습된 표현을 사용하면 적은 데이터에서도 과적합이 줄고, 결과적으로 과신이 완화될 수 있다. 반대로 도메인 차이가 큰데 억지로 가져오면 OOD에서 과신이 더 심해질 수도 있으므로, 도메인 적합성이 중요하다.</p>
<p><strong>정규화(regularization): weight decay, dropout, label smoothing</strong></p>
<p>정규화는 과도한 결정경계 <span dir="rtl">”</span>날카로움”을 완화하는 역할을 한다.</p>
<ul>
<li>weight decay: <span class="math inline">\(\lambda \parallel \theta \parallel_{2}^{2}\)</span>로 복잡도 억제</li>
<li>dropout: 표현의 공적응을 줄여 과적합 완화</li>
<li>label smoothing: <span class="math inline">\({\overset{˜}{y}}_{k} = (1 - \varepsilon)y_{k} + \frac{\varepsilon}{K}\)</span></li>
</ul>
<p>정답을 약간 부드럽게 만들어 <span dir="rtl">”</span>확률 1에 대한 강박”을 줄여 과신 완화에 직접적으로 도움이 되는 경우가 많다.</p>
</section>
<section id="calibration-운영-체크리스트4단계" class="level5">
<h5 class="anchored" data-anchor-id="calibration-운영-체크리스트4단계">(5) Calibration 운영 체크리스트(4단계)</h5>
<p><strong>Calibration curve(신뢰도 다이어그램)로 <span dir="rtl">”</span>과신/과소신”을 먼저 확인</strong></p>
<p>모델이 출력한 확률 \hat p를 구간(bin)으로 나누고, 각 구간에서 평균 예측 확률(신뢰도) <span class="math inline">\(conf(b)\)</span>, 실제 정답 비율(정확도) <span class="math inline">\(acc(b)\)</span>을 비교한다.</p>
<p>완전 보정이면 <span class="math inline">\(acc(b) \approx conf(b)\)</span>가 되어 대각선 근처에 놓인다.</p>
<ul>
<li>과신(overconfident): <span class="math inline">\(conf(b) &gt; acc(b)\)</span> (모델이 말한 확률이 실제보다 큼)</li>
<li>과소신(underconfident): <span class="math inline">\(conf(b) &lt; acc(b)\)</span></li>
</ul>
<p>이 단계는 <span dir="rtl">”</span>지표 숫자”보다도, 어느 확률 구간에서 문제가 큰지(0.6~0.8? 0.9 이상?)를 보는 데 의미가 있다.</p>
<p><strong>ECE / Brier score로 수치화해서 비교·추적한다.</strong></p>
<p>ECE (Expected Calibration Error) 구간별 불일치의 가중평균 <span class="math inline">\(ECE = \overset{B}{\sum_{b = 1}}\frac{|B_{b}|}{n}|acc(b) - conf(b)|\)</span>이다. 값이 작을수록 calibration이 좋거 모델/학습법/버전 비교, <span dir="rtl">”</span>보정 전후 개선” 확인에 유용하다.</p>
<p>Brier score 이진분류 기준 확률 제곱오차은 <span class="math inline">\(BS = \frac{1}{n}\overset{n}{\sum_{i = 1}}({\widehat{p}}_{i} - y_{i})^{2}\)</span>이다. 값이 작을수록 좋고 calibration과 함께 확률의 품질을 포괄적으로 반영한다.</p>
<p>ECE + Brier를 함께 기록해 <span dir="rtl">”</span>확률 품질이 시간에 따라 악화되는지”까지 모니터링한다.</p>
<p><strong>Temperature scaling으로 확률을 보정한다(모델은 고정)</strong></p>
<p>다중분류에서 로짓 <span class="math inline">\(\mathbf{z}\)</span>가 있을 때, softmax 앞에 온도 T&gt;0를 둔다. <span class="math inline">\(\mathbf{p}^{(T)} = softmax\left( \frac{\mathbf{z}}{T} \right)\)</span></p>
<ul>
<li>보통 과신이면 T&gt;1로 확률을 평평하게 만들어 과신을 완화한다.</li>
<li>T는 검증용 calibration set에서 NLL(=CE)을 최소화하도록 추정한다. <span class="math inline">\(T^{*} = \arg\min_{T}\overset{n}{\sum_{i = 1}}( - \log p_{i,y_{i}}^{(T)})\)</span></li>
</ul>
<p>장점은 모델 재학습 없이 <span dir="rtl">”</span>출력 확률만” 수정하고 분류 순위(Top-1)는 거의 유지되면서 확률만 현실적으로 조정된다.</p>
<p>보정 후에 다시 위의 작업을 반복해 calibration curve가 개선되고 ECE/Brier가 내려가는지 확인한다.</p>
<p><strong>보정된 확률로 임계값(Threshold)을 재튜닝한다.</strong></p>
<p>보정 전에는 <span class="math inline">\(\widehat{p}\)</span>였고, 보정 후에는 \hat p^{(T)}이므로 운영 결정도 이를 기준으로 다시 설정해야 한다.</p>
<p>이진분류 기준은 <span class="math inline">\(\widehat{y} = 1\{{\widehat{p}}^{(T)} \geq t\}\)</span>이다. 임계값 t는 검증셋에서 아래 중 운영 목적에 맞는 규칙으로 선택한다.</p>
<ul>
<li>F1 최적화: <span class="math inline">\(t = \arg\max_{t}F1(t)\)</span></li>
<li>제약 기반: <span class="math inline">\(FPR(t) \leq \alpha\)</span> 또는 검토량 \le K를 만족하는 t</li>
<li>비용 기반(가능하면): <span class="math inline">\(t^{*} = \frac{c_{FP}}{c_{FP} + c_{FN}}\)</span> (확률이 잘 보정되어 있을수록 의미가 커짐)</li>
</ul>
</section>
</section>
<section id="대규모-클래스-분류large-k의-계산-이슈" class="level4">
<h4 class="anchored" data-anchor-id="대규모-클래스-분류large-k의-계산-이슈">2. 대규모 클래스 분류(Large K)의 계산 이슈</h4>
<p>클래스 수 K가 수만~수백만으로 커지는 문제(예: 상품/문서/광고 ID 예측, 추천, 검색 쿼리-문서 매칭)에서는 <span dir="rtl">”</span>모델이 무엇을 학습하느냐”보다 softmax를 어떻게 계산하느냐가 학습·추론의 병목이 된다.</p>
<p>핵심은 한 번의 학습 스텝에서 필요한 계산이 기본적으로 O(K)로 커지기 때문이다. 따라서 Large-K 분류는 (i) softmax 근사, (ii) 샘플링 기반 학습, (iii) 검색(retrieval) 기반 2-stage 구조로 실무 해법이 갈린다.</p>
<section id="softmax-계산-병목과-메모리-이슈" class="level5">
<h5 class="anchored" data-anchor-id="softmax-계산-병목과-메모리-이슈">(1) softmax 계산 병목과 메모리 이슈</h5>
<p>다중분류에서 로짓 <span class="math inline">\(\mathbf{z} \in \mathbb{R}^{K}\)</span>에 대해 <span class="math inline">\(p_{k} = \frac{e^{z_{k}}}{\sum_{j = 1}^{K}e^{z_{j}}}\)</span>를 계산하려면 분모 <span class="math inline">\(\sum_{j = 1}^{K}e^{z_{j}}\)</span>가 필요하므로, 모든 클래스 로짓을 한 번은 계산해야 한다. 여기서 병목이 두 가지로 나타난다.</p>
<p><strong>시간 복잡도: O(K) softmax + loss</strong></p>
<p>정답이 y일 때 cross-entropy는 <span class="math inline">\(\mathcal{L} = - \log p_{y} = - z_{y} + \log\overset{K}{\sum_{j = 1}}e^{z_{j}}\)</span> 이므로 <span class="math inline">\(\log\overset{K}{\sum_{j = 1}}e^{z_{j}}\)</span> 계산이 곧 비용이다. K가 크면 한 배치에서 이 항을 계산하는 비용이 압도적이 된다.</p>
<p><strong>출력층 파라미터의 메모리: O(Kd)</strong></p>
<p>마지막 선형층이 보통 <span class="math inline">\(z_{k} = \mathbf{w}_{k}^{\top}\mathbf{h} + b_{k}\)</span> (<span class="math inline">\(\mathbf{h} \in \mathbb{R}^{d}\)</span>: 마지막 은닉표현) 형태이므로, 출력층 가중치 <span class="math inline">\(W \in \mathbb{R}^{K \times d}\)</span>를 저장해야 한다. 즉 파라미터 수가 <span class="math inline">\(Kd(\text{+}K\text{bias})\)</span>로 증가한다. K가 수백만이면 이 층만으로도 GPU 메모리가 한계에 부딪히며, 분산 학습/샤딩이 필요해진다.</p>
</section>
<section id="sampled-softmax-negative-sampling-개념" class="level5">
<h5 class="anchored" data-anchor-id="sampled-softmax-negative-sampling-개념">(2) sampled softmax / negative sampling 개념</h5>
<p>Large-K에서 대표적 아이디어는 <span dir="rtl">”</span>정답 클래스 1개 + 일부 음성 클래스만”을 사용해 학습 신호를 만들고, 전체 K에 대한 softmax 계산을 피하는 것이다.</p>
<p><strong>Sampled Softmax (근사된 분모)</strong></p>
<p>기본 CE는 분모가 전체 K를 요구한다. Sampled softmax는 각 샘플마다 정답 클래스 y, 음성 샘플 집합 <span class="math inline">\(S \subset \{ 1,\ldots,K\} \smallsetminus \{ y\},|S| = m \ll K\)</span>만 뽑아서 <span dir="rtl">”</span>부분 softmax”로 근사한다.</p>
<p>개념적으로는 <span class="math inline">\(\log\overset{K}{\sum_{j = 1}}e^{z_{j}} \approx \log(e^{z_{y}} + \sum_{j \in S}e^{z_{j}})\)</span>를 사용한다. 실제로는 샘플링 분포에 따른 보정항을 넣어 편향을 줄이는 변형들이 많다.</p>
<p>학습 시 클래스 연산이 K에서 m으로 감소 → 비용이 O(m). 단, 근사이므로 샘플링 전략과 보정 방식이 품질에 영향을 준다.</p>
<p><strong>Negative Sampling (대조 학습/랭킹 관점)</strong></p>
<p>negative sampling은 <span dir="rtl">”</span>정답 vs 음성”을 이진 분류(또는 랭킹) 문제로 바꾸는 관점이 강하다. 예를 들어 점수 <span class="math inline">\(s(x,k) = z_{k}\)</span>에 대해, 정답 쌍 (x,y)는 양성, <span class="math inline">\((x,j)\)</span>는 음성으로 두고 <span class="math inline">\(\mathcal{L} = - \log\sigma(s(x,y)) - \sum_{j \in S}\log\sigma( - s(x,j))\)</span> 같은 형태의 손실을 쓴다. 이는 <span dir="rtl">”</span>정답의 점수는 크게, 샘플된 음성들의 점수는 작게” 만들도록 학습한다.</p>
<p>negative sampling은 softmax 분모를 직접 근사하기보다, 순위(ranking) 품질을 직접 최적화 하는 느낌이 강하며, 추천/검색에서 특히 자주 쓰인다.</p>
<p><strong>샘플링의 핵심: 음성을 어떻게 뽑을 것인가?</strong></p>
<p>무작위 음성은 너무 쉽고 학습 신호가 약할 수 있다. 그래서 자주 쓰는 전략은 빈도 기반(자주 나오는 클래스에 더 많이), 모델 기반 hard negative(현재 모델이 헷갈리는 클래스), in-batch negative(같은 배치의 다른 정답들을 음성으로 활용)등이다. Large-K에서 성능 차이는 종종 <span dir="rtl">”</span>모델 구조”보다 <span dir="rtl">”</span>negative 구성”에서 크게 난다.</p>
</section>
<section id="retrieval-rerank근사2-stage-관점" class="level5">
<h5 class="anchored" data-anchor-id="retrieval-rerank근사2-stage-관점">(3) retrieval + rerank(근사/2-stage) 관점</h5>
<p>Large-K 문제를 <span dir="rtl">”</span>분류”로만 보면 softmax가 병목이지만, 관점을 바꾸면 본질은 종종 Top-N 후보를 잘 찾는 문제다. 즉 전체 클래스 중 <span dir="rtl">”</span>상위 몇 개”만 정확하면 되는 경우가 많다. 이때 표준 해법이 2-stage 구조다.</p>
<p><strong>Stage 1: Retrieval (후보 생성)</strong></p>
<p>입력 x를 임베딩 <span class="math inline">\(\mathbf{h}(x) \in \mathbb{R}^{d}\)</span>로 만들고, 클래스(또는 아이템)도 임베딩 <span class="math inline">\(\mathbf{e}_{k} \in \mathbb{R}^{d}\)</span>로 두어 유사도로 후보를 찾는다. <span class="math inline">\(\text{score}(x,k) = \mathbf{h}(x)^{\top}\mathbf{e}_{k}\)</span></p>
<p>그 다음 ANN(Approximate Nearest Neighbor) 같은 근사 최근접 탐색으로 Top-N 후보를 빠르게 가져온다. 이 단계는 <span dir="rtl">”</span>정확도”보다 <span dir="rtl">”</span>빠르게 후보를 넓게 회수(recall)“하는 것이 목적이다.</p>
<p><strong>Stage 2: Rerank (정밀 재정렬)</strong></p>
<p>1단계 후보 N개(예: 100~1000개)만 놓고, 더 무거운 모델(딥 네트워크, cross-attention 등)로 정교하게 점수화하여 최종 Top-k를 결정한다. <span class="math inline">\(\widehat{y} \in \text{Top-}k\text{of}\{\text{rerank\_score}(x,c):c \in \mathcal{C}_{N}\}\)</span></p>
<p><strong>왜 2-stage가 강력한가?</strong></p>
<p>전체 K에 대해 매번 계산하지 않아도 됨 → 추론 비용 대폭 감소하고, 모델링이 <span dir="rtl">”</span>정규화된 확률”이 아니라 <span dir="rtl">”</span>랭킹” 중심으로 최적화되기 수빈다. 검색/추천 시스템의 운영 요구(Top-k 응답, 지연시간 제한)에 자연스럽게 맞다.</p>
<p>Large-K에서는 <span dir="rtl">”</span>확률의 정확한 정규화”보다 <span dir="rtl">”</span>상위 후보를 얼마나 잘/빠르게 찾는가”가 더 중요해져, 분류가 검색(retrieval) 문제로 재정식화되는 경우가 많다.</p>
</section>
<section id="무엇을-언제-쓰나" class="level5">
<h5 class="anchored" data-anchor-id="무엇을-언제-쓰나">(4) 무엇을 언제 쓰나?</h5>
<p>Large-K 분류에서 핵심 선택지는 <span dir="rtl">”</span>끝까지 분류(softmax 계열)로 갈 것인가” vs <span dir="rtl">”</span>문제를 검색로 재정식화할 것인가”이다</p>
<p><strong>Sampled softmax / negative sampling을 우선 고려하는 경우</strong></p>
<p>(A) 목표가 <span dir="rtl">’</span>정규화된 확률<span dir="rtl">’</span>에 가깝다</p>
<p>다음 토큰 확률(언어모델류), 확률 자체가 다운스트림에 들어가는 경우 softmax는 <span class="math inline">\(\sum_{k}p_{k} = 1\)</span>인 확률분포를 제공한다.</p>
<p>샘플링은 학습에서만 근사를 쓰되, 추론에서는 필요에 따라 Top-k만 계산하는 방식으로 절충할 수 있다.</p>
<p>(B) 학습은 대규모지만 서빙은 상대적으로 단순/오프라인이다</p>
<p>배치로 추천 후보를 미리 생성하거나, 하루/시간 단위로 점수 산출하는 경우 학습을 샘플링으로 가볍게 만들고, 추론은 충분한 자원으로 처리 가능하다.</p>
<p>(C) <span dir="rtl">”</span>라벨이 명확한 1-of-K” 구조가 강하다</p>
<p>카테고리/클래스가 고정되어 있고 정답이 하나인 폐집합(closed-set) 분류의 경우 sampled softmax는 기본 CE 학습 프레임을 유지하므로 기존 분류 파이프라인과 잘 맞는다.</p>
<p>(D) 평가/목표가 Top-1 정확도 중심</p>
<p>CE 기반 학습은 top-1 분류 성격과 결이 잘 맞는다.</p>
<p>확률모형을 유지하고 싶은 경우 또는 분류 파이프라인을 크게 바꾸기 어려운 경우에 sampled softmax/negative sampling이 현실적이다.</p>
<p><strong>Retrieval + Rerank(2-stage)를 우선 고려하는 경우</strong></p>
<p>(A) 목표가 Top-k 추천/검색이며, 전체 확률이 필요 없다</p>
<p>검색 결과 상위 10개, 추천 상위 50개의 경우 운영 목적이 <span dir="rtl">”</span>확률의 정규화”가 아니라 <span dir="rtl">”</span>상위 후보를 잘 맞추기”라면 2-stage가 자연스럽다.</p>
<p>(B) 초저지연/대규모 서빙이 필수다</p>
<p>온라인 추천/검색에서 ms 단위 지연 제한의 경우 전체 K 스코어링은 불가능에 가깝고, ANN 기반 retrieval로 후보를 줄이는 게 정답에 가깝다.</p>
<p>(C) 클래스(아이템)가 자주 추가/삭제되는 동적 카탈로그</p>
<p>신규 상품/콘텐츠가 계속 들어오는 서비스의 경우 <span dir="rtl">”</span>분류의 출력층 테이블(K\times d)“을 계속 재학습/동기화하기 어렵다. 임베딩 인덱스 기반 retrieval은 추가/갱신이 비교적 수월하다.</p>
<p>(D) hard negative를 잘 만들고 싶다 / 랭킹 지표가 중요하다</p>
<p>NDCG, MAP, Recall@k 중심의 경우 2-stage는 1단계가 <span dir="rtl">”</span>회수(recall)“, 2단계가 <span dir="rtl">”</span>정밀도(precision)”를 담당해 랭킹 지표 최적화에 유리하다.</p>
<p>문제의 본질이 <span dir="rtl">’</span>찾기<span dir="rtl">’</span>(search/recommend)라면, 분류로 억지로 풀기보다 retrieval+rerank가 운영/성능/지연 모두에서 이점이 크다.</p>
<p><strong>Negative sampling은 <span dir="rtl">”</span>분류”라기보다 <span dir="rtl">”</span>랭킹”에 가깝게 쓰는 경우가 많다.</strong></p>
<p>sampled softmax: CE를 유지하되 분모 계산을 샘플로 근사(분류 프레임 유지)</p>
<p>negative sampling: (x,y)를 양성, (x,j)를 음성으로 두고 <span dir="rtl">”</span>정답 점수↑, 음성 점수↓“를 학습 <span class="math inline">\(- \log\sigma(s(x,y)) - \sum_{j \in S}\log\sigma( - s(x,j))\)</span> → 운영 목표가 Top-k이면 특히 잘 맞는다.</p>
<p>즉, <span dir="rtl">”</span>확률이 필요한가?“가 갈림길이다. 확률이 꼭 필요하면 sampled softmax 쪽, Top-k 품질이 핵심이면 negative sampling/2-stage 쪽으로 기운다.</p>
<p><strong>최종 의사결정 체크리스트</strong></p>
<p>1. 출력이 확률분포(<span class="math inline">\(\sum p_{k} = 1\)</span>)로 꼭 필요? Yes → sampled softmax(또는 계층 softmax 등) 우선, No → retrieval+rerank 우선</p>
<p>2. 서빙 지연 제한이 빡빡하고 K가 매우 큼? Yes → 2-stage(ANN retrieval 필수)</p>
<p>3. 아이템/클래스가 자주 변하는 카탈로그? Yes → 2-stage가 유지보수에 유리</p>
<p>4. 목표 지표가 accuracy보다 Recall@k / NDCG / MAP? Yes → 랭킹 관점(negative sampling + 2-stage)로 설계</p>
</section>
</section>
<section id="거리학습-기반-분류-metric-learning" class="level4">
<h4 class="anchored" data-anchor-id="거리학습-기반-분류-metric-learning">3. 거리학습 기반 분류: Metric Learning</h4>
<p>Large-K나 오픈셋(open-set) 환경에서는 <span dir="rtl">”</span>클래스마다 하나의 고정 출력 뉴런”을 두는 방식이 비효율적이거나 불가능해진다. 이때 분류를 임베딩 공간의 거리(유사도) 문제로 바꾸는 접근이 유용하며, 이를 거리학습(metric learning)이라 한다.</p>
<p>핵심 아이디어는 입력 x를 임베딩 <span class="math inline">\(f_{\theta}(x) \in \mathbb{R}^{d}\)</span>로 보내고, 같은 클래스는 가깝게, 다른 클래스는 멀게 배치하여 <span dir="rtl">”</span>가까운 것이 정답”이 되도록 학습하는 것이다.</p>
<section id="임베딩과-유사도-기반-분류최근접프로토타입" class="level5">
<h5 class="anchored" data-anchor-id="임베딩과-유사도-기반-분류최근접프로토타입">(1) 임베딩과 유사도 기반 분류(최근접/프로토타입)</h5>
<p><strong>임베딩 표현</strong></p>
<p>신경망은 입력을 d차원 임베딩으로 변환한다. <span class="math inline">\(\mathbf{h} = f_{\theta}(x) \in \mathbb{R}^{d}\)</span></p>
<p>거리학습에서는 분류기의 마지막 softmax 대신, 임베딩 간 거리 또는 유사도로 판단한다. 자주 쓰는 선택은 유클리드 거리 <span class="math inline">\(\parallel \mathbf{h} - \mathbf{c} \parallel_{2}\)</span>, 코사인 유사도 <span class="math inline">\(\cos(\mathbf{h},\mathbf{c}) = \frac{\mathbf{h}^{\top}\mathbf{c}}{\parallel \mathbf{h} \parallel \parallel \mathbf{c} \parallel}\)</span>이다.</p>
<p><strong>최근접(Nearest Neighbor) 분류</strong></p>
<p>각 클래스의 대표(또는 학습 샘플) 임베딩 <span class="math inline">\(\{\mathbf{c}_{k}\}\)</span>가 있을 때 <span class="math inline">\(\widehat{y} = \arg\min_{k}d(\mathbf{h},\mathbf{c}_{k})\)</span> 또는 <span class="math inline">\(\arg\max_{k}s(\mathbf{h},\mathbf{c}_{k}))\)</span>로 예측한다. 여기서 d는 거리, s는 유사도다.</p>
<p>이 방식은 <span dir="rtl">”</span>출력층이 K개”일 필요가 없어, 클래스가 커지거나 새 클래스를 추가할 때도 유연하다(임베딩만 추가하면 됨).</p>
<p><strong>프로토타입(Prototype) 기반 분류</strong></p>
<p>각 클래스 k에 대해 support set(대표 샘플) 임베딩의 평균을 프로토타입으로 둔다. <span class="math inline">\(\mathbf{c}_{k} = \frac{1}{|S_{k}|}\sum_{x_{i} \in S_{k}}f_{\theta}(x_{i})\)</span> 그리고 <span class="math inline">\(\widehat{y} = \arg\min_{k} \parallel \mathbf{h} - \mathbf{c}_{k} \parallel_{2}\)</span>처럼 분류한다. few-shot에서 특히 자연스럽고, <span dir="rtl">”</span>클래스 내 변동을 평균으로 흡수”하는 장점이 있다.</p>
<p>metric learning 분류는 <span dir="rtl">”</span>확률 분포를 직접 출력”하기보다 <span dir="rtl">”</span>임베딩 공간에서 가까운 클래스가 정답”이라는 규칙을 학습한다.</p>
</section>
<section id="contrastive-triplet-loss" class="level5">
<h5 class="anchored" data-anchor-id="contrastive-triplet-loss">(2) contrastive / triplet loss</h5>
<p>임베딩 공간을 원하는 모양으로 만들려면, <span dir="rtl">”</span>어떤 쌍/삼쌍은 가깝게, 어떤 것은 멀게”라는 학습 신호가 필요하다. 대표 손실이 contrastive loss와 triplet loss다.</p>
<p><strong>Contrastive loss (쌍(pair) 기반)</strong></p>
<p>두 샘플 <span class="math inline">\((x_{i},x_{j})\)</span>에 대해 같은 클래스면 <span class="math inline">\(y_{ij} = 1\)</span>, 다르면 <span class="math inline">\(y_{ij} = 0\)</span>이라 두고, <span class="math inline">\(D_{ij} = \parallel f_{\theta}(x_{i}) - f_{\theta}(x_{j}) \parallel_{2}\)</span>라고 하자. 전형적 형태는 <span class="math inline">\(\mathcal{L} = y_{ij}D_{ij}^{2} + (1 - y_{ij})\lbrack\max(0,m - D_{ij})\rbrack^{2}\)</span>이다.</p>
<p>같은 클래스 <span class="math inline">\((y_{ij} = 1)\)</span>의 경우 거리를 0에 가깝게 줄이도록 학습하고 다른 클래스 <span class="math inline">\((y_{ij} = 0)\)</span>는 거리 <span class="math inline">\(D_{ij}\)</span>가 margin m보다 작으면 벌점 → 최소 m 이상 벌어지게 된다.</p>
<p>핵심은 <span dir="rtl">”</span>음성 쌍은 일정 거리 이상이면 더 밀 필요가 없다”는 margin 개념이다.</p>
<p><strong>Triplet loss (삼쌍(triplet) 기반)</strong></p>
<p>anchor a, positive p(같은 클래스), negative n(다른 클래스)을 구성한다. <span class="math inline">\(D(a,p) = \parallel f(a) - f(p) \parallel_{2},D(a,n) = \parallel f(a) - f(n) \parallel_{2}\)</span></p>
<p>목표는 <span class="math inline">\(D(a,p) + \alpha \leq D(a,n)\)</span>가 되게 만드는 것이며, 손실은 <span class="math inline">\(\mathcal{L} = \max(0,D(a,p) - D(a,n) + \alpha)\)</span>로 쓴다(<span class="math inline">\(\alpha\)</span>: margin).</p>
<p>triplet loss의 성패는 negative를 어떻게 고르느냐(hard / semi-hard negative mining)에 크게 달려 있다. 너무 쉬운 negative는 학습 신호가 약하고, 너무 어려운 negative(노이즈/오표기 포함)는 불안정해질 수 있다.</p>
<p>contrastive는 <span dir="rtl">”</span>쌍을 맞추는 문제”, triplet은 <span dir="rtl">”</span>순위(가까움의 상대 비교)를 맞추는 문제”에 가깝다.</p>
</section>
<section id="few-shot-오픈셋과-연결" class="level5">
<h5 class="anchored" data-anchor-id="few-shot-오픈셋과-연결">(3) few-shot, 오픈셋과 연결</h5>
<p><strong>Few-shot 학습과의 연결</strong></p>
<p>few-shot은 클래스당 샘플이 매우 적은 상황이다. 일반 softmax 분류는 클래스별 파라미터를 충분히 학습하기 어렵지만, metric learning은 <span dir="rtl">”</span>임베딩 공간의 일반화”가 핵심이므로 적은 샘플로도 분류 규칙을 만들 수 있다.</p>
<p>프로토타입 방식은 특히 few-shot에서 강력하다. support set으로 <span class="math inline">\(\mathbf{c}_{k}\)</span>를 만든 뒤 최근접 분류로 끝나기 때문이다. 새로운 클래스가 와도 <span dir="rtl">”</span>프로토타입만 계산”하면 바로 동작한다.</p>
<p><strong>오픈셋(open-set)과 OOD 탐지</strong></p>
<p>오픈셋에서는 <span dir="rtl">”</span>학습에 없던 클래스”가 들어올 수 있다. softmax는 항상 <span class="math inline">\(\sum_{k}p_{k} = 1\)</span>이므로 무엇이든 기존 클래스 중 하나로 강제 분류하는 경향이 있어 과신 문제가 생긴다.</p>
<p>반면 metric learning은 <span dir="rtl">”</span>가까운 클래스가 없으면 거리가 멀다”는 신호를 이용해 거절(reject) 규칙을 만들기 쉽다.</p>
<p>예를 들면, 최소 거리 기반 거절 <span class="math inline">\(\min_{k}d(\mathbf{h},\mathbf{c}_{k}) &gt; \tau \Rightarrow \text{unknown}\)</span>또는 유사도가 일정 이하이면 unknown 처리한다.</p>
<p><strong>2-stage(retrieval+rerank)와의 연결</strong></p>
<p>metric learning은 retrieval 단계와 궁합이 좋다. 임베딩을 만들고 ANN으로 후보를 회수한 뒤, rerank 모델로 정밀 점수화를 하는 구조는 8장에서 본 2-stage와 자연스럽게 연결된다. 즉 Large-K 문제에서 metric learning은 <span dir="rtl">”</span>분류를 검색으로 바꾸는” 핵심 도구로도 쓰인다.</p>
</section>
<section id="무엇을-언제-쓰나-softmax-분류-vs-metric-learning-선택-기준" class="level5">
<h5 class="anchored" data-anchor-id="무엇을-언제-쓰나-softmax-분류-vs-metric-learning-선택-기준">(4) 무엇을 언제 쓰나? (Softmax 분류 vs Metric Learning 선택 기준)</h5>
<p>둘 다 <span dir="rtl">”</span>분류”지만 전제가 다릅니다. softmax 분류는 폐집합(closed-set), metric learning은 확장/검색/오픈셋에 강합니다. 아래 체크리스트로 고르면 됩니다.</p>
<p><strong>Softmax(+CE)를 우선 선택하는 경우</strong></p>
<p>클래스가 고정되고(폐집합), 학습/운영에서 동일한 클래스 집합을 쓴다. <span class="math inline">\(\Rightarrow\)</span> <span dir="rtl">”</span>정답은 K 중 하나”가 확실한 전형적 분류이다.</p>
<p>확률 <span class="math inline">\(P(Y = k \mid x)\)</span> 자체가 필요하다(리스크 스코어링, 비용기반 의사결정, calibration 운영 등). <span class="math inline">\(\Rightarrow \sum_{k}p_{k} = 1\)</span>인 확률분포가 자연스럽다.</p>
<p>클래스당 데이터가 충분하고, 클래스 내 변동을 모델이 직접 학습할 수 있다. <span class="math inline">\(\Rightarrow\)</span> 출력층 파라미터가 안정적으로 추정된다.</p>
<p>목표가 Top-1 정확도 중심이며, <span dir="rtl">”</span>거절(unknown)“이 운영 요구가 아니다.</p>
<p><strong>Metric Learning을 우선 선택하는 경우</strong></p>
<p>새 클래스가 자주 추가/변경되거나, 학습 시점에 모든 클래스를 다 보지 못한다. <span class="math inline">\(\Rightarrow\)</span> softmax 출력층(<span class="math inline">\(K \times d\)</span>)을 계속 재학습하기 어렵다.</p>
<p>few-shot(클래스당 샘플이 매우 적음)에서 <span dir="rtl">”</span>빠르게 적응”해야 한다. <span class="math inline">\(\Rightarrow\)</span> 프로토타입 <span class="math inline">\(\mathbf{c}_k= \frac{1}{\|S_k\|}\\sum
f(x)\)</span> + 최근접 분류가 강력하다.</p>
<p>오픈셋/unknown 거절이 중요하다. <span class="math inline">\(\Rightarrow\)</span> <span class="math inline">\(\min_{k}d(\mathbf{h},\mathbf{c}_{k}) &gt; \tau\)</span> 같은 규칙으로 자연스럽게 거절 가능하다.</p>
<p>검색/추천/유사도 질의(retrieval)가 문제의 본질이다(Top-k, 랭킹 지표 중심). <span class="math inline">\(\Rightarrow\)</span> 임베딩 + ANN + rerank(2-stage)로 확장성이 좋다.</p>
<p><strong>실무 결론</strong></p>
<p>폐집합 분류 + 확률 필요: softmax(+CE)로 가고, calibration/threshold 정책까지 함께 설계</p>
<p>대규모/동적/검색형 문제: metric learning으로 임베딩을 만들고 retrieval+rerank로 운영</p>
<p>하이브리드도 흔함: 임베딩 기반 retrieval로 후보를 줄이고 후보에 대해 softmax(또는 pairwise scoring)로 rerank/확률화</p>
</section>
</section>
<section id="자기지도대조학습-후-분류기현대적-파이프라인" class="level4">
<h4 class="anchored" data-anchor-id="자기지도대조학습-후-분류기현대적-파이프라인">4. 자기지도/대조학습 후 분류기(현대적 파이프라인)</h4>
<p>현대 딥러닝 분류는 <span dir="rtl">”</span>처음부터 끝까지 supervised 학습”만으로 설명되기 어렵다. 특히 이미지·텍스트 모두에서 (i) 강한 데이터 증강, (ii) 사전학습(pretraining), (iii) 전이학습(transfer learning)이 표준 파이프라인이 되었고, 분류기는 종종 <span dir="rtl">”</span>잘 학습된 표현(representation) 위에 얹는 얕은(head)” 형태로 구현된다.</p>
<p>여기에서는 CNN 기반 이미지 분류의 기본 구조를 정리하고, 증강과 전이학습이 왜 일반화와 calibration에까지 영향을 주는지, 그리고 문서 분류에서의 전형적 파이프라인을 함께 연결한다.</p>
<section id="cnn합성곱-기반-딥러닝-분류" class="level5">
<h5 class="anchored" data-anchor-id="cnn합성곱-기반-딥러닝-분류">(1) CNN(합성곱) 기반 딥러닝 분류</h5>
<p>신경망은 2010년 무렵 이미지 분류에서 큰 성공을 거두면서 다시 주목받기 시작했다. 그 당시에는 라벨이 붙은 이미지로 이루어진 대규모 데이터베이스가 빠르게 축적되고 있었고, 클래스 수도 계속 증가하고 있었다.</p>
<p>다음 그림은 CIFAR100 데이터베이스에서 뽑은 75장의 이미지를 보여준다. 이 데이터베이스는 20개의 상위 범주(예: 수생 포유류)로 구분된 60,000장의 이미지로 구성되며, 각 상위 범주마다 5개의 클래스(예: 비버, 돌고래, 수달, 물개, 고래)가 있다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/classification_deep_cnn.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%"></p>
</figure>
</div>
<p>각 이미지는 32×32 픽셀의 해상도를 가지며, 각 픽셀은 빨강(red), 초록(green), 파랑(blue)을 나타내는 8비트 숫자 3개로 표현된다. 각 이미지의 숫자들은 특징맵(feature map)이라 불리는 3차원 배열로 정리된다. 앞의 두 축은 공간 축(둘 다 길이 32)이고, 세 번째 축은 세 가지 색을 나타내는 채널(channel) 축이다. 학습용(training) 세트는 50,000장, 테스트(test) 세트는 10,000장으로 지정되어 있다.</p>
<p>이러한 이미지들을 분류하기 위해 합성곱 신경망(CNN)이라는 특수한 신경망 계열이 발전해 왔으며, 매우 다양한 문제에서 뛰어난 성과를 보여 왔다. CNN은 이미지 속 어디에서든 특정 특징이나 패턴을 인식함으로써, 어느 정도는 인간이 이미지를 분류하는 방식과 유사하게 작동한다.</p>
<p>이미지 분류에서 CNN은 <span dir="rtl">”</span>공간적 구조를 활용해 특징을 계층적으로 추출”하는 대표 모델이다. 입력 <span class="math inline">\(X \in \mathbb{R}^{H \times W \times C}\)</span>에 대해, CNN은 국소 영역을 공유 가중치로 스캔하며(feature sharing) 특징맵(feature map)을 만든다. 이는 완전연결(FC)보다 파라미터 효율이 높고, 위치 변화에 더 강건한 표현을 학습하게 한다.</p>
<p><strong>Convolutional Layers (합성곱 층)</strong></p>
<p>합성곱 층은 많은 수의 합성곱 필터로 구성된다. 각 필터는 이미지 안에 특정한 국소 특징이 존재하는지를 판별하는 템플릿 역할을 한다. 합성곱 필터는 합성곱이라 불리는 매우 단순한 연산에 기반하며, 이는 기본적으로 행렬 원소들을 반복적으로 곱한 뒤 그 결과를 더하는 작업으로 이루어진다.</p>
<p>합성곱 필터가 어떻게 작동하는지 이해하기 위해, 아주 단순한 <span class="math inline">\(2 \times 3\)</span>이미지 예를 생각해보자.</p>
<p><span class="math inline">\(\text{Original Image} = \begin{bmatrix}
a &amp; b &amp; c \\
d &amp; e &amp; f \\
g &amp; h &amp; i \\
j &amp; k &amp; l
\end{bmatrix}\)</span>. 다음의 <span class="math inline">\(2 \times 2\)</span> 필터 <span class="math inline">\(\text{Convolution Filter} = \begin{bmatrix}
\alpha &amp; \beta \\
\gamma &amp; \delta
\end{bmatrix}\)</span>로 이미지를 합성곱하면 다음 결과를 얻는다. 예를 들어, 왼쪽 위 원소는 <span class="math inline">\(2 \times 2\)</span> 필터의 각 원소를 이미지의 왼쪽 위 <span class="math inline">\(2 \times 2\)</span> 부분과 대응시키며 곱한 뒤 그 결과를 합하여 얻는다. 다른 원소들도 동일한 방식으로 얻어진다.</p>
<p><span class="math display">\[\text{Convolved Image} = \begin{bmatrix}
a\alpha + b\beta + d\gamma + e\delta &amp; b\alpha + c\beta + e\gamma + f\delta \\
d\alpha + e\beta + g\gamma + h\delta &amp; e\alpha + f\beta + h\gamma + i\delta \\
g\alpha + h\beta + j\gamma + k\delta &amp; h\alpha + i\beta + k\gamma + l\delta
\end{bmatrix}\]</span></p>
<p>즉, 합성곱 필터를 원본 이미지의 모든 <span class="math inline">\(2 \times 2\)</span> 부분행렬에 적용함으로써 합성곱된 이미지를 만든다. 원본 이미지의 어떤 <span class="math inline">\(2 \times 2\)</span> 부분행렬이 합성곱 필터와 비슷하다면, 합성곱된 이미지에서 해당 위치의 값은 크게 나타나고, 그렇지 않다면 작게 나타난다.</p>
<p>따라서 합성곱된 이미지는 원본 이미지에서 합성곱 필터와 유사한 영역을 강조(highlight)한다. 여기서는 <span class="math inline">\(2 \times 2\)</span>를 예로 들었지만, 일반적으로 합성곱 필터는 <span class="math inline">\(\ell_{1} \times \ell_{2}\)</span> 크기의 작은 배열이며, <span class="math inline">\(\ell_{1},\ell_{2}\)</span> 는 (반드시 같을 필요는 없는) 작은 양의 정수이다.</p>
<p>다음 그림은 왼쪽에 있는 <span class="math inline">\(192 \times 179\)</span> 크기의 호랑이 이미지에 두 개의 합성곱 필터를 적용하는 예를 보여준다. 각 합성곱 필터는 <span class="math inline">\(15 \times 15\)</span> 크기의 이미지로, 대부분은 0(검정)이며 이미지 안에서 세로 또는 가로 방향으로 놓인 1(흰색)의 좁은 띠를 포함한다. 각 필터를 호랑이 이미지에 합성곱하면, 필터와 유사한(즉 세로/가로 줄무늬나 에지를 가진) 영역에는 큰 값이 부여되고, 해당 특징과 닮지 않은 영역에는 작은 값이 부여된다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/classification_deep_cnn02.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%"></p>
</figure>
</div>
<p>합성곱 필터는 에지(edge)나 작은 모양처럼 이미지의 국소 특징을 찾아낸다. 왼쪽의 호랑이 이미지에 가운데의 두 개 작은 합성곱 필터를 적용한다. 합성곱된 이미지는 원본 이미지에서 필터와 비슷한 세부 구조가 발견되는 영역을 강조한다.</p>
<p>구체적으로 위쪽 합성곱 결과는 호랑이의 세로 줄무늬를 강조하고, 아래쪽 합성곱 결과는 가로 줄무늬를 강조한다. 원본 이미지를 합성곱 신경망의 입력층으로, 합성곱된 이미지들을 첫 번째 은닉층의 유닛들로 생각할 수 있다.</p>
<p>합성곱 층에서는 서로 다른 방향의 에지와 형태를 다양하게 골라내기 위해 필터들의 전체 집합(bank)을 사용한다. 이러한 방식으로 미리 정의된 필터를 쓰는 것은 전통적인 이미지 처리에서 표준적 관행이다.</p>
<p>반면 CNN에서는 필터가 특정 분류 과제를 위해 학습된다. 필터의 가중치는 입력층에서 은닉층으로 가는 모수로 생각할 수 있는데, 합성곱된 이미지의 각 픽셀마다 하나의 은닉 유닛이 대응된다고 보면 된다.</p>
<p>실제로도 그렇지만, 이 모수들은 매우 구조화되고 제약된 형태를 가진다. 즉 입력 이미지의 국소 패치에만 작동하므로 구조적으로 0인 부분이 많고, 하나의 필터 안에서 같은 가중치가 이미지의 모든 가능한 위치에 재사용되므로(가중치가 공유되므로) 가중치가 제약된다.</p>
<p>입력 이미지가 컬러이므로, 3차원 특징맵(배열)로 표현되는 세 개의 채널을 가진다. 각 채널은 <span class="math inline">\(32 \times 32\)</span>의 2차원 특징맵이며, 각각 빨강(red), 초록(green), 파랑(blue)에 해당한다.</p>
<p>하나의 합성곱 필터도 마찬가지로 색상별로 하나씩, 총 세 개의 채널을 가지며, 각 채널은 <span class="math inline">\(3 \times 3\)</span> 크기이고 채널마다 필터 가중치가 달라질 수 있다.</p>
<p>이 세 번의 합성곱 결과를 합산하여 하나의 2차원 출력 특징맵을 만든다. 이 시점에서는 색상 정보가 이미 사용되었고, 이후 층으로는(합성곱에서의 역할을 제외하면) 별도로 전달되지 않는다.</p>
<p>첫 번째 은닉층에서 서로 다른 합성곱 필터를 K개 사용하면, K개의 2차원 출력 특징맵을 얻게 된다. 이들은 함께 하나의 3차원 특징맵으로 취급된다.</p>
<p>우리는 K개의 출력 특징맵 각각을 서로 다른 정보 채널로 보며, 따라서 원래 입력 특징맵의 3개 색상 채널과 대비되어 이제는 K개의 채널을 갖게 된다. 이 3차원 특징맵은 단순 신경망 은닉층의 활성값(activations)과 유사하지만, 공간적으로 구조화된 방식으로 정리되고 생성된다는 점이 다르다.</p>
<p>보통 합성곱된 이미지에 ReLU 활성함수를 적용한다. 이 단계는 때로 CNN의 별도 층으로 간주되며, 그런 경우 detector layer(검출기 층)라고 부르기도 한다.</p>
<p><strong>Pooling Layers</strong></p>
<p>풀링 층(pooling layer)은 큰 이미지를 더 작은 요약 이미지로 압축(condense)하는 방법을 제공한다. 풀링에는 여러 방식이 가능하지만, 맥스 풀링(max pooling)은 이미지의 겹치지 않는 각 <span class="math inline">\(2 \times 2\)</span> 블록을 그 블록 안의 최댓값으로 요약한다.</p>
<p>이 연산은 이미지의 크기를 각 방향에서 2배씩 줄이며(즉 가로/세로 모두 절반), 동시에 어느 정도의 위치 불변성(location invariance)을 제공한다. 즉 블록 안의 4개 픽셀 중 하나라도 큰 값이 있으면, 축소된 이미지에서는 그 블록 전체가 큰 값으로 기록된다.</p>
<p>맥스 풀링의 간단한 예는 다음과 같다.</p>
<p><span class="math display">\[\text{Max pool}\begin{bmatrix}
1 &amp; 2 &amp; 5 &amp; 3 \\
3 &amp; 0 &amp; 1 &amp; 2 \\
2 &amp; 1 &amp; 3 &amp; 4 \\
1 &amp; 1 &amp; 2 &amp; 0
\end{bmatrix} \rightarrow \begin{bmatrix}
3 &amp; 5 \\
2 &amp; 4
\end{bmatrix}\]</span></p>
<p><strong>CNN Architecture</strong></p>
<p>지금까지 우리는 하나의 합성곱 층을 정의했다. 각 필터는 새로운 2차원 특징맵 하나를 만든다. 합성곱 층에서 필터의 개수는, 완전연결 신경망에서 특정 은닉층의 유닛 수와 유사한 역할을 한다.</p>
<p>이 수는 또한 결과로 생성되는 3차원 특징맵의 채널 수를 결정한다. 또한 풀링 층은 각 3차원 특징맵의 앞 두 차원(공간 차원)을 줄인다는 것을 설명했다. 깊은 CNN은 이러한 층을 많이 쌓는다.</p>
<p>다음 그림은 CIFAR100 이미지 분류 과제를 위한 CNN의 전형적인 구조를 보여준다. CIFAR100 분류 과제를 위한 깊은 CNN의 아키텍처. 합성곱 층들 사이에 <span class="math inline">\(2 \times 2\)</span> 맥스풀 층이 끼워져 있으며, 맥스풀은 두 공간 차원 모두에서 크기를 2배씩 줄인다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/classification_deep_cnn03.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
<p>입력층에서는 컬러 이미지의 3차원 특징맵을 보게 되는데, 여기서 채널 축은 각 색을 <span class="math inline">\(32 \times 32\)</span>의 2차원 픽셀 특징맵으로 나타낸다.</p>
<p>첫 번째 은닉층에서 각 합성곱 필터는 새로운 채널을 하나씩 만들어내며, 각각은(가장자리에 패딩을 약간 준 뒤) <span class="math inline">\(32 \times 32\)</span> 특징맵이 된다.</p>
<p>첫 번째 합성곱을 마치면 우리는 새로운 <span dir="rtl">”</span>이미지”, 즉 입력의 3개 색상 채널보다 훨씬 많은 채널을 가진 특징맵을 얻게 된다(그림에서는 합성곱 필터를 6개 사용했기 때문에 채널이 6개).</p>
<p>그 다음에는 맥스풀 층이 이어지며, 이는 각 채널의 특징맵 크기를 4분의 1로 줄인다(각 방향에서 2배씩 줄어드는 것과 같다). 이런 <span dir="rtl">”</span>합성곱→풀링” 순서는 다음 두 층에서도 반복된다.</p>
<p>세부 사항은 다음과 같다. 이후의 각 합성곱 층은 첫 번째 층과 유사하다. 이전 층의 3차원 특징맵을 입력으로 받아 이를 하나의 다채널 이미지처럼 취급한다. 학습되는 각 합성곱 필터는 이 특징맵과 동일한 수의 채널을 가진다.</p>
<p>풀링 층을 거치면 채널 특징맵의 공간 크기가 줄어드므로, 보통 이를 보상하기 위해 다음 합성곱 층에서 필터 수를 늘린다.</p>
<p>때로는 풀링 층을 넣기 전에 합성곱 층을 여러 번 반복한다. 이는 사실상 필터의 차원을(표현력을) 증가시키는 효과가 있다.</p>
<p>이 연산들은 풀링을 통해 각 채널 특징맵이 각 차원에서 몇 픽셀만 남을 때까지 반복된다. 이 시점에서 3차원 특징맵은 flatten되어(픽셀을 개별 유닛으로 취급) 하나 이상의 완전연결 층으로 들어가며, 최종적으로 출력층에 도달한다. 출력층은 100개 클래스에 대한 softmax 활성함수를 사용한다.</p>
<p>이런 네트워크를 구성할 때는 각 층의 개수·종류·크기 외에도 선택해야 할 튜닝 파라미터가 많다. 드롭아웃(dropout)은 각 층에서 사용할 수 있고, 라쏘(lasso)나 릿지(ridge) 정규화도 사용할 수 있다. 합성곱 신경망을 구성하는 세부 사항은 부담스럽게 느껴질 수 있다.</p>
<p>다음 그림은 데이터 증강(data augmentation)으로 원본 이미지(가장 왼쪽)를 자연스러운 방식으로 왜곡하여 같은 클래스 레이블을 갖는 서로 다른 이미지를 만든다. 이러한 왜곡은 사람을 속이지 않으며, CNN을 적합할 때 정규화(regularization)의 한 형태로 작동한다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/classification_deep_cnn04.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</section>
<section id="data-augmentation" class="level5">
<h5 class="anchored" data-anchor-id="data-augmentation">(2) Data Augmentation</h5>
<p>데이터 증강은 <span dir="rtl">”</span>라벨을 유지하는 변환으로 학습 데이터를 확장”하여 일반화 성능을 높이는 핵심 기법이다. 증강은 단순히 데이터 수를 늘리는 것 이상으로, 모델에게 불변성(invariance) 또는 평활한 결정경계를 학습시키는 역할을 한다.</p>
<p><strong>기본 증강(flip/crop/rotate/color jitter)</strong></p>
<ul>
<li>flip: 좌우 반전 (대칭성이 있는 문제에서 유효)</li>
<li>random crop / resize: 위치/스케일 변화에 강건</li>
<li>rotate: 회전 불변성이 있는 경우 유효(과도한 회전은 라벨 의미를 바꿀 수 있음)</li>
<li>color jitter: 밝기/대비/채도 변형으로 조명 변화에 강건</li>
</ul>
<p>증강의 본질은 <span dir="rtl">”</span>입력 공간에서 같은 라벨을 갖는 영역을 넓혀” 과적합을 줄이는 것이다.</p>
<p><strong>강한 증강/혼합(mixup/cutmix 등, 선택)</strong></p>
<p>강한 증강은 일반화를 크게 올릴 수 있지만, 과하면 학습이 어려워지거나 과소적합을 유발할 수 있어 데이터/도메인에 맞춰 조절한다.</p>
<ul>
<li>mixup: 두 샘플과 라벨을 선형 결합 <span class="math inline">\(\overset{˜}{x} = \lambda x_{i} + (1 - \lambda)x_{j},\overset{˜}{y} = \lambda y_{i} + (1 - \lambda)y_{j}\)</span> 이는 결정경계를 더 선형/평활하게 만들어 과신을 줄이고(calibration 개선 사례 많음), 노이즈에 강해질 수 있다.</li>
<li>cutmix: 한 이미지의 일부 패치를 다른 이미지로 교체하고, 면적 비율로 라벨을 혼합</li>
</ul>
<p>라벨 혼합이 <span dir="rtl">”</span>공간적 부분”과 대응하므로 이미지 분류에서 효과가 좋은 경우가 많다.</p>
</section>
<section id="pretrained-model-transfer-learning전이학습" class="level5">
<h5 class="anchored" data-anchor-id="pretrained-model-transfer-learning전이학습">(3) Pretrained Model &amp; Transfer Learning(전이학습)</h5>
<p>사전학습 모델은 대규모 데이터로 학습된 표현을 제공하며, 작은 데이터에서도 강력한 출발점을 만든다. 특히 CNN/Transformer 모두에서 <span dir="rtl">”</span>표현 학습은 대규모로, 과제별 분류기는 소규모로”가 표준이 되었다.</p>
<p><strong>feature extraction vs fine-tuning</strong></p>
<p>Feature extraction(특징 추출): backbone g_\theta는 고정하고, head만 학습 <span class="math inline">\(\mathbf{h} = g_{\theta_{0}}(x),\min_{W}\sum_{i}\mathcal{L}(y_{i},softmax(W\mathbf{h}_{i}))\)</span></p>
<p>장점으로는 빠르고 과적합 위험이 낮다(특히 데이터가 작을 때).</p>
<p>Fine-tuning(미세조정): backbone까지 함께 업데이트 <span class="math inline">\(\min_{\theta,W}\sum_{i}\mathcal{L}(y_{i},softmax(Wg_{\theta}(x_{i})))\)</span></p>
<p>장점은 도메인 적응력이 커서 최종 성능이 더 좋아지기 쉽고 단점으로는 데이터가 작으면 과적합/과신이 커질 수 있어 정규화/증강이 중요하다.</p>
<p><strong>작은 데이터에서의 실무 절차(동결→점진적 unfreeze)</strong></p>
<p>작은 데이터에서 흔히 쓰는 안정적 절차는 다음이다.</p>
<p>1. head만 학습(backbone 동결) → 빠르게 베이스라인 확보</p>
<p>2. 성능이 정체되면 상위 블록부터 점진적 unfreeze</p>
<p>3. backbone 학습률은 head보다 작게(예: <span class="math inline">\(\eta_{\text{backbone}} \ll \eta_{\text{head}}\)</span>)</p>
<p>4. 증강/weight decay/early stopping으로 과적합 제어</p>
<p>5. 필요 시 calibration(temperature scaling)과 임계값 재튜닝까지 묶어서 운영 성능 정리</p>
</section>
<section id="document-classification문서-분류" class="level5">
<h5 class="anchored" data-anchor-id="document-classification문서-분류">(4) Document Classification(문서 분류)</h5>
<p>문서 분류는 <span dir="rtl">”</span>텍스트를 어떤 표현으로 바꾸고, 그 위에 분류기를 얹는다”는 점에서 이미지와 동일한 구조를 가진다. 다만 표현 방식이 BoW/TF-IDF 같은 고전적 희소 벡터에서, Transformer 기반 문맥 임베딩으로 이동했다.</p>
<p><strong>TF-IDF/BoW + 선형분류(개념 요약)</strong></p>
<ul>
<li>BoW/TF-IDF로 문서를 벡터화: \mathbf{x}\in\mathbb{R}^p (희소)</li>
<li>선형 분류기(로지스틱 회귀, 선형 SVM 등): <span class="math inline">\(z = \mathbf{w}^{\top}\mathbf{x} + b,p = \sigma(z)\)</span>(이진) 또는 다중분류 softmax를 사용한다.</li>
</ul>
<p>장점은 빠르고 강력한 베이스라인, 데이터가 적어도 안정적인 반면, 한계로는 단어 순서/문맥 정보 손실(동음이의, 긴 의존관계 처리 약함)이다.</p>
</section>
<section id="transformer-기반-문서-분류-파이프라인" class="level5">
<h5 class="anchored" data-anchor-id="transformer-기반-문서-분류-파이프라인">(5) Transformer 기반 문서 분류 파이프라인</h5>
<p>Transformer(예: BERT류)는 토큰 시퀀스 (w_1,\dots,w_T)를 문맥 임베딩으로 바꾼다. <span class="math inline">\(\mathbf{H} = Transformer(w_{1:T})\)</span></p>
<p>대표적으로 [CLS] 토큰 표현 \mathbf{h}_{\text{CLS}} 또는 평균 풀링을 사용해 문서 벡터를 만들고, <span class="math inline">\(\mathbf{z} = W\mathbf{h}_{\text{CLS}} + b,\mathbf{p} = softmax(\mathbf{z})\)</span>로 분류한다.</p>
<p>실무 파이프라인은 대개 토크나이즈 → 사전학습 Transformer 로딩, head 부착 → (동결 후 head 학습) → 점진적 fine-tuning, 불균형이면 class weight / 샘플링, 운영 전 calibration/threshold 튜닝으로 정리된다.</p>
<p><strong>불균형/임계값/보정의 적용 포인트</strong></p>
<p>문서 분류(특히 멀티라벨, 희귀 라벨)에서는 <span dir="rtl">”</span>학습 성능”보다 <span dir="rtl">”</span>운영 품질”이 더 중요해지는 경우가 많다.</p>
<ul>
<li>불균형: 희귀 라벨 Recall이 급락 → class weight, focal, 라벨별 임계값 <span class="math inline">\(t_{k}\)</span> 고려</li>
<li>임계값: 멀티라벨이면 <span class="math inline">\({\widehat{y}}_{k} = \mathbf{1}\{ p_{k} \geq t_{k}\}\)</span>이며 global t보다 라벨별 t_k가 실무적으로 유리한 경우가 많다.</li>
<li>보정(calibration): Transformer도 과신이 흔하므로 calibration curve/ECE 확인 후 temperature scaling 적용, 그리고 보정된 확률로 임계값 재튜닝까지 한 세트로 운영하는 것이 안정적이다.</li>
</ul>
</section>
</section>
<section id="불확실성uncertainty과-안정적-의사결정" class="level4">
<h4 class="anchored" data-anchor-id="불확실성uncertainty과-안정적-의사결정">5. 불확실성(uncertainty)과 안정적 의사결정</h4>
<p>딥러닝 분류에서 <span dir="rtl">”</span>확률 p(x)“은 흔히 모델의 확신(confidence)처럼 해석되지만, 실제 안전한 운영을 위해서는 <span dir="rtl">”</span>모델이 얼마나 모르는가”를 따로 다루어야 한다. 즉 정확도/PR뿐 아니라 불확실성(uncertainty)을 추정하고, 그 불확실성을 의사결정(보류·검토·거절·모니터링)과 연결해야 안정적인 시스템이 된다. 이 장에서는 불확실성의 유형을 구분하고, 대표 추정 기법(MC Dropout/Ensemble/TTA)과 선택적 예측(Abstention), 그리고 OOD/분포이동에서의 안전장치를 calibration과 함께 정리한다.</p>
<section id="불확실성-유형-aleatoric-vs-epistemic" class="level5">
<h5 class="anchored" data-anchor-id="불확실성-유형-aleatoric-vs-epistemic">(1) 불확실성 유형: aleatoric vs epistemic</h5>
<p>불확실성은 크게 두 종류로 나눈다.</p>
<p>(1) Aleatoric uncertainty (우연/잡음 불확실성)</p>
<p>데이터 자체에 내재된 잡음 때문에 발생한다. 예를 들어, 입력이 흐릿한 이미지, 센서 노이즈, 라벨 자체가 애매한 경우(경계 사례), 관측이 불완전한 경우이다.</p>
<p>이 불확실성은 데이터를 더 모아도 완전히 사라지지 않는 성격이 강하다(<span dir="rtl">”</span>본질적 잡음”).</p>
<p>(2) Epistemic uncertainty (지식/모델 불확실성)</p>
<p>모델이 충분히 학습하지 못했거나, 훈련 분포 밖(OOD)이라서 생기는 불확실성이다. 예를 들어 훈련에 거의 없는 패턴(희귀 영역), 새로운 도메인, 분포 이동, 모델 용량/학습 부족 등이다.</p>
<p>이 불확실성은 데이터를 더 수집하거나 모델을 개선하면 줄어들 수 있는 성격을 가진다(<span dir="rtl">”</span>지식 부족”).</p>
<p>운영 관점에서는 특히 epistemic이 중요하다. 왜냐하면 <span dir="rtl">”</span>모델이 모르는 상황에서 과신”하면 사고로 이어지기 때문이다.</p>
</section>
<section id="불확실성-추정-mc-dropout-ensemble-tta개념" class="level5">
<h5 class="anchored" data-anchor-id="불확실성-추정-mc-dropout-ensemble-tta개념">(2) 불확실성 추정: MC Dropout / Ensemble / TTA(개념)</h5>
<p>불확실성 추정의 대표 접근은 <span dir="rtl">”</span>한 번의 forward로 끝내지 않고, 예측을 여러 번 만들어 변동성을 본다”는 아이디어로 요약된다.</p>
<p><strong>MC Dropout (Monte Carlo Dropout)</strong></p>
<p>드롭아웃을 학습 때만 쓰는 것이 아니라, 추론 시에도 드롭아웃을 켠 채로 M번 예측한다.</p>
<ul>
<li>m번째 예측 확률: <span class="math inline">\(\mathbf{p}^{(m)}(x)\)</span></li>
<li>평균 예측: <span class="math inline">\(\overline{\mathbf{p}}(x) = \frac{1}{M}\overset{M}{\sum_{m = 1}}\mathbf{p}^{(m)}(x)\)</span></li>
<li>변동성(불확실성) 지표: 예측 분산 또는 엔트로피 기반 지표</li>
</ul>
<p>드롭아웃이 만든 여러 <span dir="rtl">”</span>부분 모델”의 예측이 서로 크게 다르면 epistemic 불확실성이 높다고 본다.</p>
<p><strong>Ensemble (모델 앙상블)</strong></p>
<p>서로 다른 초기화/데이터 샘플/구조로 학습한 모델 M개를 준비하여 평균을 낸다. <span class="math inline">\(\overline{\mathbf{p}}(x) = \frac{1}{M}\overset{M}{\sum_{m = 1}}\mathbf{p}_{m}(x)\)</span></p>
<p>대체로 앙상블은 가장 강력한 불확실성/일반화 개선 수단으로 평가되지만, 학습·서빙 비용이 증가한다.</p>
<p><strong>TTA (Test-Time Augmentation)</strong></p>
<p>추론 시 입력에 증강을 적용해 여러 버전 x^{(m)}을 만들고 예측을 평균낸다. <span class="math inline">\(\overline{\mathbf{p}}(x) = \frac{1}{M}\overset{M}{\sum_{m = 1}}\mathbf{p}(x^{(m)})\)</span></p>
<p>이는 데이터 변형에 대한 민감도를 평균화하여 안정성을 높이며, 특히 이미지에서 흔하다. 다만 TTA는 <span dir="rtl">”</span>입력 변환에 대한 불확실성”을 반영하는 성격이 강하다.</p>
<p><strong>불확실성 수치화(대표 지표)</strong></p>
<ul>
<li>예측 확률 \mathbf{p}로부터 가장 흔히 쓰는 불확실성 지표는 다음이다.</li>
<li>최대 확률(신뢰도 점수): <span class="math inline">\(conf(x) = \max_{k}{\overline{p}}_{k}(x)\)</span></li>
<li>예측 엔트로피: <span class="math inline">\(H(\overline{\mathbf{p}}) = - \overset{K}{\sum_{k = 1}}{\overline{p}}_{k}\log{\overline{p}}_{k}\)</span></li>
</ul>
<p>(앙상블/MC/TTA) 예측 분산: 클래스별 분산 또는 <span class="math inline">\(\max_{k}\)</span> 분산 등</p>
<p>운영에서는 보통 <span dir="rtl">”</span><span class="math inline">\(conf\)</span>가 낮다” 또는 <span dir="rtl">”</span>엔트로피가 높다”를 위험 신호로 쓴다.</p>
</section>
<section id="선택적-예측abstention-보류-영역-인간검토-연결" class="level5">
<h5 class="anchored" data-anchor-id="선택적-예측abstention-보류-영역-인간검토-연결">(3) 선택적 예측(Abstention): 보류 영역, 인간검토 연결</h5>
<p>선택적 예측은 <span dir="rtl">”</span>모델이 확신할 때만 자동결정하고, 애매하면 보류한다”는 정책이다. 이는 분류 성능을 단순히 끌어올리기보다 사고를 줄이고 운영 품질을 안정화하는 목적을 가진다.</p>
<p><strong>보류 규칙의 기본형</strong></p>
<p>이진분류에서 p(x)가 0.5 근처면 애매하다. 예를 들어 보류 구간을 <span class="math inline">\(\lbrack t_{L},t_{U}\rbrack\)</span>로 두면 <span class="math inline">\(\text{자동 결정:}p(x) \leq t_{L}\text{또는}p(x) \geq t_{U},\text{보류:}t_{L} &lt; p(x) &lt; t_{U}\)</span></p>
<p>다중분류에서는 <span class="math inline">\(\max_{k}p_{k}(x) &lt; \tau \Rightarrow \text{보류}\)</span> 같은 규칙이 많이 쓰인다.</p>
<p><strong>보류율–성능의 trade-off(coverage 관점)</strong></p>
<p>보류를 허용하면 <span dir="rtl">”</span>자동으로 처리하는 비율(coverage)“이 줄어드는 대신, 자동 처리된 케이스의 정확도/정밀도가 올라간다. 따라서 운영 목적은 보통 coverage를 일정 수준 이상 유지하면서 자동 처리 품질을 최대화 하는 형태로 설정한다.</p>
<p><strong>인간검토(human-in-the-loop) 연결</strong></p>
<p>보류 샘플은 인간 검토로 보내거나, 추가 정보 수집/추가 모델로 재판단한다. 보류 정책은 곧 <span dir="rtl">”</span>검토량 제약”과 직결되므로, 제약 기반 임계값 선택과 동일한 프레임으로 설계한다(예: 보류율 <span class="math inline">\(\leq K\)</span>).</p>
</section>
<section id="ood분포이동에서의-안전장치와-calibration-연계" class="level5">
<h5 class="anchored" data-anchor-id="ood분포이동에서의-안전장치와-calibration-연계">(4) OOD/분포이동에서의 안전장치와 calibration 연계</h5>
<p>불확실성이 특히 중요한 순간은 분포가 바뀌는 순간이다. 훈련 분포 <span class="math inline">\(P_{\text{train}}(X,Y)\)</span>와 운영 분포 <span class="math inline">\(P_{\text{deploy}}(X,Y)\)</span>가 달라지면(분포 이동), 정확도 하락과 과신 증가(특히 OOD에서)가 동시에 발생할 수 있다.</p>
<p><strong>OOD/분포이동의 신호</strong></p>
<p>대표적으로 (1) 입력 통계 변화(특징 분포, 임베딩 분포), (2) 예측 분포 변화(<span class="math inline">\(\max p\)</span>의 평균/분산, 엔트로피 변화) (3) calibration 악화(ECE 증가), 그리고 (4) 특정 클래스 쏠림 증가 등이다.</p>
<p><strong>안전장치: 거절/보류/다단계 파이프라인</strong></p>
<ul>
<li>보류(Abstention): <span class="math inline">\(\max_{k}p_{k} &lt; \tau\)</span>이면 자동결정 중단</li>
<li>OOD 점수 기반 거절: 임베딩 거리 기반 또는 에너지/엔트로피 기반 점수로 unknown 처리</li>
<li>2-stage(retrieval+rerank, 또는 rule-based + model): 위험 구간에서 더 보수적 절차로 전환</li>
</ul>
<p><strong>Calibration과의 연결</strong></p>
<p>Calibration은 <span dir="rtl">”</span>IID 상황에서의 확률 신뢰도”를 개선하는 데 매우 유효하지만, OOD에서는 calibration만으로 안전이 보장되지 않는다. 그럼에도 calibration은 중요한 역할을 한다.</p>
<p>보정된 확률은 임계값/보류 기준을 더 일관되게 만든다. 배포 후 ECE/Brier를 모니터링하면 <span dir="rtl">”</span>확률 품질 악화”를 조기 경보로 사용할 수 있다.</p>
<p>따라서 운영에서는 (i) calibration 유지(temperature scaling 등) + (ii) 불확실성 기반 보류/거절 정책 + (iii) 분포이동 모니터링을 함께 둬야 안정적이다.</p>
</section>
<section id="실전-체크-리스트" class="level5">
<h5 class="anchored" data-anchor-id="실전-체크-리스트">(5) 실전 체크 리스트</h5>
<p>딥러닝 분류는 <span dir="rtl">”</span>모델을 학습시키고 정확도를 확인하는 것”으로 끝나지 않는다. 실제 운영에서는 학습 성능, 평가 지표, 확률의 신뢰도(calibration), 임계값 정책, 그리고 불확실성 기반 안전장치가 한 덩어리로 연결되어야 안정적인 의사결정이 가능하다. 다음 절차는 이 전체 흐름을 최소 구성으로 묶은 실전 체크리스트이다.</p>
<p>먼저 문제 정의 단계에서는 라벨 구조를 확정해야 한다. 이진 분류인지, 다중 분류(단일 정답)인지, 멀티라벨인지에 따라 출력층과 손실함수가 달라진다.</p>
<p>이진 분류는 로짓 z에 sigmoid를 적용해 p=\sigma(z)를 출력하고, 다중 분류는 <span class="math inline">\(\mathbf{p} = softmax(\mathbf{z})\)</span>를, 멀티라벨은 각 라벨별로 <span class="math inline">\(p_{k} = \sigma(z_{k})\)</span>를 사용한다.</p>
<p>동시에 운영 목표를 수치로 명시하는 것이 중요하다. 미탐 비용 <span class="math inline">\(c_{FN}\)</span>과 오경보 비용 <span class="math inline">\(c_{FP}\)</span> 중 무엇이 더 치명적인지, 하루 검토 가능한 최대 건수 K가 얼마인지, 또는 <span class="math inline">\(FPR \leq \alpha\)</span>같은 안전 제약이 있는지를 먼저 못 박아야 한다. 이 정의가 없으면 이후 임계값 설계가 <span dir="rtl">’</span>감<span dir="rtl">’</span>에 의존하게 된다.</p>
<p>그 다음은 데이터 분할과 누수 방지다. train/valid/test를 분리하되, 가능한 경우 시간·사용자 단위로 분할해 정보 누수를 막는 것이 좋다. 분할 이후에는 클래스 비율(불균형 정도), 라벨 노이즈, 운영 환경 차이에 따른 OOD 가능성을 사전에 점검한다. 특</p>
<p>히 불균형이 강하면 정확도 대신 PR 중심 지표를 기본 평가 축으로 잡아야 한다. 그렇지 않으면 <span dir="rtl">”</span>정확도는 높지만 양성을 거의 못 잡는” 모델이 쉽게 통과한다.</p>
<p>학습은 정석 조합에서 시작하는 것이 안정적이다. 다중 분류는 softmax와 cross-entropy를 결합해 <span class="math inline">\(\mathcal{L} = - \log p_{y}\)</span>로 학습하고, 멀티라벨은 라벨별 sigmoid 확률에 대해 BCE를 합산한 <span class="math inline">\(\mathcal{L} = - \sum_{k}(y_{k}\log p_{k} + (1 - y_{k})\log(1 - p_{k}))\)</span>를 사용한다.</p>
<p>학습 중에는 손실이 감소하는지뿐 아니라, 검증 손실이 올라가는 과적합 신호가 나타나는지 꾸준히 모니터링해야 한다. 이 단계에서 불안정이 보이면 모델 구조보다 데이터/라벨/학습률·정규화 문제인 경우가 많다.</p>
<p>데이터가 불균형하거나 <span dir="rtl">”</span>어려운 샘플”이 성능을 좌우한다면, 그때에만 추가 대응을 한다. 학습 단계에서는 class weight를 주거나 over/under-sampling으로 배치 구성을 조정할 수 있고, 더 나아가 어려운 샘플에 학습을 집중시키는 focal loss나 hard example mining을 고려한다.</p>
<p>다만 이런 기법들은 예측 점수 분포 자체를 바꾸는 경우가 많아서, 운영 단계에서는 임계값을 다시 설정해야 한다. 특히 불균형 문제에서 t=0.5를 고정하는 것은 거의 항상 비효율적이며, PR 곡선을 기반으로 정책을 설계하는 편이 안전하다.</p>
<p>성능 평가에서는 <span dir="rtl">”</span>정확도만 보지 않는다”는 원칙을 끝까지 유지해야 한다. 이진 분류나 희귀 양성 탐지에서는 PR/AP, Recall, Precision, 그리고 <span class="math inline">\(\frac{FNR}{FPR}\)</span> 같은 운영지표가 핵심이다.</p>
<p>다중 분류는 top-1 정확도 외에도 필요하면 top-k를 확인해 <span dir="rtl">”</span>후보 회수 성능”까지 평가한다. 멀티라벨은 micro/macro F1을 함께 보고, 희귀 라벨이 중요하면 라벨별 PR을 점검해야 한다. micro는 빈도 큰 라벨에 끌리고, macro는 희귀 라벨의 성능 저하를 드러내기 때문에 둘의 해석이 서로 보완적이다.</p>
<p>운영으로 넘어가면 임계값 설계가 가장 중요해진다. 이진 분류는 <span class="math inline">\(\widehat{y} = \mathbf{1}\{ p \geq t\}\)</span>로 결정하고, 멀티라벨은 \hat y_k=\mathbb{1}\{p_k\ge t_k\}로 라벨별로 결정한다. 임계값 선택은 검증셋에서 수행하되, 가능한 경우 비용 기반 임계값 <span class="math inline">\(t^{*} = \frac{c_{FP}}{c_{FP} + c_{FN}}\)</span>를 기준점으로 삼는다.</p>
<p>비용 수치가 불명확하면 <span class="math inline">\(FPR \leq \alpha\)</span>또는 검토량 \le K 같은 제약을 먼저 만족시키고, 그 안에서 Recall 또는 Precision을 최적화한다. 또는 PR 관점에서 F1을 최대화하는 t를 택하는 방식도 실무에서 자주 사용된다.</p>
<p>확률 품질(calibration) 점검은 과신을 줄이는 운영 루틴이다. 먼저 calibration curve로 어느 확률 구간에서 과신/과소신이 발생하는지 확인하고, ECE와 Brier score로 이를 수치화해 모델 버전별로 비교·추적한다.</p>
<p>필요하면 temperature scaling을 적용해 <span class="math inline">\(\mathbf{p}^{(T)} = softmax(\mathbf{z}/T)\)</span> 형태로 확률을 보정한다. 여기서 중요한 실무 규칙은 <span dir="rtl">”</span>보정 후 확률이 바뀌면 임계값도 다시 튜닝해야 한다”는 점이다. 이 단계를 생략하면 보정의 효과가 운영 성능으로 이어지지 않는다.</p>
<p>현대적 파이프라인에서는 사전학습과 전이학습이 표준이다. 이미지 분류는 사전학습 CNN에 증강을 결합하고, 작은 데이터에서는 backbone을 동결한 채 head-only로 시작한 뒤 점진적으로 unfreeze하는 절차가 안정적이다.</p>
<p>문서 분류는 TF-IDF+선형분류로 강한 베이스라인을 먼저 확보하고, 이후 사전학습 Transformer를 fine-tuning한다. 작은 데이터에서는 backbone 학습률을 낮게 두고, 증강·정규화·early stopping으로 과적합을 제어한 뒤, 마지막에 calibration과 threshold까지 묶어 마무리하는 것이 재현성과 운영 안정성 측면에서 가장 좋다.</p>
<p>클래스 수 K가 매우 큰 문제에서는 분류를 끝까지 softmax로 밀어붙일지, 검색형(retrieval) 문제로 전환할지 판단해야 한다. 확률분포가 꼭 필요하다면 sampled softmax 같은 근사 학습 기법을 고려하고, Top-k 응답이 핵심이거나 지연 제한이 강하거나 카탈로그가 동적으로 변하면 retrieval + rerank(2-stage)로 구조를 바꾸는 것이 일반적이다.</p>
<p>또한 metric learning 기반 임베딩과 ANN 검색은 확장성과 오픈셋에 강하므로 Large-K에서 유력한 선택지다.</p>
<p>안전장치 관점에서는 불확실성과 선택적 예측(Abstention)을 설계한다. 불확실성은 데이터 잡음에 기인한 aleatoric과 지식 부족에 기인한 epistemic으로 구분하며, 실무에서는 MC dropout, ensemble, TTA 같은 방법으로 예측을 여러 번 만들어 변동성을 본다.</p>
<p>운영 정책으로는 <span dir="rtl">”</span>확신할 때만 자동 결정하고 애매하면 보류”를 도입한다. 예를 들어 다중 분류에서는 <span class="math inline">\(\max_{k}p_{k} &lt; \tau\)</span>이면 보류하고, 이진 분류에서는 <span class="math inline">\(t_{L} &lt; p &lt; t_{U}\)</span>구간을 보류 영역으로 둔다. 보류 정책은 결국 검토량 제약과 직결되므로, 보류율 자체를 운영 가능한 범위로 함께 설계해야 한다.</p>
<p>마지막으로 배포 후 모니터링은 <span dir="rtl">”</span>성능이 무너지는 순간”을 조기에 잡는 장치다. 입력/임베딩 분포가 변하거나, <span class="math inline">\(\max p\)</span>의 평균이 변하고 엔트로피가 증가하거나, ECE/Brier가 악화되면 분포 이동을 의심해야 한다.</p>
<p>이런 신호가 포착되면 임계값과 보류 기준을 재튜닝하고, 필요하면 최신 검증 데이터로 calibration을 재적합한다. 위험 구간에서는 2-stage나 인간검토를 강화해 보수적으로 운영하는 것이 사고를 줄이는 현실적인 선택이다.</p>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>