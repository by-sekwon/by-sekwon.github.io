<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>MLDL 딥러닝 분류 - 파트1 – 세상의 모든 통계 이야기</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-2757cfadcc89ddbfb9e61569f8c3689f.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">세상의 모든 통계 이야기</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../notes/math_stat/index.html"> 
<span class="menu-text">기초수학·수리통계</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../notes/intro_stat/index.html"> 
<span class="menu-text">기초통계·조사방법</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../notes/linear_model/index.html"> 
<span class="menu-text">회귀·다변량</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../notes/mldl_intro/index.html"> 
<span class="menu-text">MLDL개념</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../notes/mldl_prediction/index.html"> 
<span class="menu-text">MLDL예측</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../../notes/mldl_classification/index.html" aria-current="page"> 
<span class="menu-text">MLDL분류</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../cardnews/index.html"> 
<span class="menu-text">카드뉴스</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../consult.html"> 
<span class="menu-text">통계상담</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../notes/mldl_classification/classification_deeplearning01.html">📄 딥러닝 분류 파트1</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">【머신·딥러닝 분류문제】</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/classification_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📄 분류문제: 정의</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/lm_logistic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📄 예측분류-로지스틱회귀</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/mda_discriminant.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📄 예측분류-판별분석</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/prediction_treebase.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📄 예측분류-ML 트리기반</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/classification_ml.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📄 머신러닝 kNN SVM</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/classification_deeplearning01.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">📄 딥러닝 분류 파트1</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/classification_deeplearning02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📄 딥러닝 분류 파트2</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notes/mldl_classification/classification_evaluation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📄 분류모델 평가</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">목차</h2>
   
  <ul>
  <li><a href="#chapter-1.-딥러닝-분류-파트1" id="toc-chapter-1.-딥러닝-분류-파트1" class="nav-link active" data-scroll-target="#chapter-1.-딥러닝-분류-파트1">Chapter 1. 딥러닝 분류 (파트1)</a>
  <ul>
  <li><a href="#개요-딥러닝-분류는-무엇을-학습하나" id="toc-개요-딥러닝-분류는-무엇을-학습하나" class="nav-link" data-scroll-target="#개요-딥러닝-분류는-무엇을-학습하나">1. 개요: 딥러닝 분류는 무엇을 학습하나?</a></li>
  <li><a href="#출력층과-확률모형" id="toc-출력층과-확률모형" class="nav-link" data-scroll-target="#출력층과-확률모형">2. 출력층과 확률모형</a></li>
  <li><a href="#손실함수-cross-entropy의-원리" id="toc-손실함수-cross-entropy의-원리" class="nav-link" data-scroll-target="#손실함수-cross-entropy의-원리">3. 손실함수: Cross-Entropy의 원리</a></li>
  <li><a href="#결정규칙과-임계값운영-관점" id="toc-결정규칙과-임계값운영-관점" class="nav-link" data-scroll-target="#결정규칙과-임계값운영-관점">4. 결정규칙과 임계값(운영 관점)</a></li>
  <li><a href="#멀티라벨-분류-multi-label-classification" id="toc-멀티라벨-분류-multi-label-classification" class="nav-link" data-scroll-target="#멀티라벨-분류-multi-label-classification">5. 멀티라벨 분류 (Multi-label Classification)</a></li>
  <li><a href="#불균형-데이터와-어려운-샘플-학습" id="toc-불균형-데이터와-어려운-샘플-학습" class="nav-link" data-scroll-target="#불균형-데이터와-어려운-샘플-학습">6. 불균형 데이터와 어려운 샘플 학습</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">MLDL 딥러닝 분류 - 파트1</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="chapter-1.-딥러닝-분류-파트1" class="level3">
<h3 class="anchored" data-anchor-id="chapter-1.-딥러닝-분류-파트1">Chapter 1. 딥러닝 분류 (파트1)</h3>
<p>딥러닝 분류는 입력 <span class="math inline">\(x \in \mathbb{R}^{d}\)</span>가 주어졌을 때, 출력 y가 어떤 클래스에 속하는지 예측하는 문제이다. 전통적 분류(로지스틱 회귀, LDA 등)가 비교적 명시적 확률모형 혹은 선형 결정규칙을 강조했다면, 딥러닝 분류는 표현학습을 통해 복잡한 비선형 결정경계를 자동으로 학습한다는 점이 핵심이다.</p>
<p>딥러닝 분류를 이해할 때는 <span dir="rtl">”</span>모형이 무엇을 내놓고(출력층), 그 출력을 어떻게 확률로 바꾸며, 어떤 손실을 최소화하는가”를 한 덩어리로 보는 것이 중요하다. 특히 분류에서 실무적 의사결정은 다음의 3단계를 분리해서 생각하면 정리된다.</p>
<p>아직 확률이 아니라, 클래스별로 얼마나 그럴듯한지를 나타내는 원시적인 척도이며 보통 <span class="math inline">\(logitz = (z_{1},\ldots,z_{K})\)</span> 형태로 출력된다.</p>
<p>다음으로 이 점수 벡터를 확률로 해석할 수 있도록 변환한다. 다중분류라면 점수들 사이의 상대적 크기를 반영해 합이 1이 되도록 만드는 softmax를 적용하고, 이진분류나 멀티라벨이라면 각 클래스의 <span dir="rtl">”</span>존재 확률”을 독립적으로 해석하기 위해 sigmoid를 적용해 p를 얻는다.</p>
<p>마지막으로 이렇게 얻어진 확률 p를 실제 의사결정으로 연결한다. 다중분류에서는 가장 큰 확률을 가진 클래스를 선택하여 <span class="math inline">\(\widehat{y} = \arg\max_{k}p_{k}\)</span>로 예측하고, 이진/멀티라벨에서는 특정 임계값 t를 기준으로 <span class="math inline">\(p \geq t\)</span>이면 양성, 그렇지 않으면 음성으로 판정한다. 즉 딥러닝 분류는 <span dir="rtl">”</span>점수를 계산하고 → 확률로 바꾸고 → 운영 규칙에 따라 결정한다”는 흐름으로 정리할 수 있다.</p>
<section id="개요-딥러닝-분류는-무엇을-학습하나" class="level4">
<h4 class="anchored" data-anchor-id="개요-딥러닝-분류는-무엇을-학습하나">1. 개요: 딥러닝 분류는 무엇을 학습하나?</h4>
<p>딥러닝 분류는 입력 X로부터 클래스에 대한 <span dir="rtl">”</span>점수(score)“를 만들고, 그 점수를 확률로 바꾼 뒤, 운영 목적에 맞게 결정을 내리도록 학습하는 과정이다. 핵심은 <span dir="rtl">”</span>정답 라벨을 맞추는 것”만이 아니라, 얼마나 확신하는지(확률의 품질)까지 포함해 모델을 설계·학습·평가하는 데 있다.</p>
<section id="분류-문제와-목표-점수확률결정" class="level5">
<h5 class="anchored" data-anchor-id="분류-문제와-목표-점수확률결정">(1) 분류 문제와 목표: 점수–확률–결정</h5>
<p><strong>점수(score): 신경망이 직접 출력하는 값</strong></p>
<p>신경망 분류기는 보통 마지막 층에서 클래스별 로짓(logit) 혹은 점수를 출력한다.</p>
<ul>
<li>이진 분류(positive vs negative): <span class="math inline">\(z = f_{\theta}(x) \in \mathbb{R}\)</span></li>
<li>다중 분류(K개 클래스): <span class="math inline">\(\mathbf{z} = f_{\theta}(x) = (z_{1},\ldots,z_{K}) \in \mathbb{R}^{K}\)</span></li>
</ul>
<p>여기서 <span class="math inline">\(\theta\)</span>는 신경망 파라미터(가중치/편향)이며, <span class="math inline">\(f_{\theta}\)</span>는 여러 층의 합성함수로 표현된다. <span class="math inline">\(f_{\theta}(x) = W_{L}\phi(W_{L - 1}\phi(\cdots\phi(W_{1}x + b_{1})\cdots) + b_{L - 1}) + b_{L}\)</span>(<span class="math inline">\(\phi\)</span>: ReLU 등 비선형 활성함수)</p>
<p>점수 z 자체는 확률이 아니다. 임의의 실수이며, <span dir="rtl">”</span>양성일수록 크게” 혹은 <span dir="rtl">”</span>해당 클래스일수록 크게” 만들도록 학습된다.</p>
<p><strong>확률(probability): 점수를 확률로 변환</strong></p>
<p>점수를 확률로 바꾸는 대표 변환은 다음과 같다.</p>
<ul>
<li>이진 분류: 시그모이드(sigmoid) <span class="math inline">\(p(x) = P(Y = 1 \mid X = x) = \sigma(z) = \frac{1}{1 + e^{- z}}\)</span></li>
<li>다중 분류: 소프트맥스(softmax) <span class="math inline">\(p_{k}(x) = P(Y = k \mid X = x) = \frac{e^{z_{k}}}{\sum_{j = 1}^{K}e^{z_{j}}},k = 1,\ldots,K\)</span>. softmax는 <span class="math inline">\(\sum_{k}p_{k}(x) = 1\)</span>을 만족하는 <span dir="rtl">”</span>단일 정답(one-of-K)” 확률 모델이다.</li>
</ul>
<p><strong>결정: 확률을 임계값/규칙으로 행동으로 바꾸기</strong></p>
<p>운영에서는 확률을 바로 쓰지 않고, 어떤 의사결정 규칙을 적용한다.</p>
<ul>
<li>이진 분류(임계값 t): <span class="math inline">\(\widehat{y} = \{\begin{matrix}
1 &amp; \text{if}p(x) \geq t \\
0 &amp; \text{otherwise}
\end{matrix}\)</span></li>
<li>다중 분류: <span class="math inline">\(\widehat{y} = \arg\max_{k}p_{k}(x) = \arg\max_{k}z_{k}\)</span></li>
</ul>
<p>중요한 점은 학습 목적(손실 최소화)과 운영 목적(오경보/미탐 비용, 정책 제약)이 반드시 동일하지 않다는 것이다. 예를 들어, 사기탐지에서는 t를 낮추면 재현율(Recall)은 올라가지만 오경보(FP)도 늘어난다. 즉 분류는 <span dir="rtl">”</span>모델 출력 \rightarrow 확률 \rightarrow 임계값/정책”까지 포함한 전체 파이프라인 문제다.</p>
</section>
<section id="데이터라벨-구조이진-다중-멀티라벨" class="level5">
<h5 class="anchored" data-anchor-id="데이터라벨-구조이진-다중-멀티라벨">(2) 데이터/라벨 구조(이진, 다중, 멀티라벨)</h5>
<p>분류에서 가장 먼저 확인해야 할 것은 라벨 Y의 구조이다. 라벨 구조에 따라 출력층/손실함수/평가가 달라진다.</p>
<p><strong>이진 분류(Binary): <span class="math inline">\(Y \in \{ 0,1\}\)</span></strong></p>
<ul>
<li>출력: <span class="math inline">\(z \in \mathbb{R},p = \sigma(z)\)</span></li>
<li>대표 손실(이진 교차엔트로피, BCE): <span class="math inline">\(\mathcal{L}_{\text{BCE}}(y,p) = - (y\log p + (1 - y)\log(1 - p))\)</span></li>
</ul>
<p><strong>다중 분류(Multiclass, 단일 정답) <span class="math inline">\(Y \in \{ 1,2,\ldots,K\}\)</span></strong></p>
<ul>
<li>출력: <span class="math inline">\(\mathbf{z} \in \mathbb{R}^{K},\mathbf{p} = \text{softmax}(\mathbf{z})\)</span></li>
<li>손실(범주형 교차엔트로피, CE): <span class="math inline">\(\mathcal{L}_{\text{CE}}(y,\mathbf{p}) = - \log p_{y}\)</span></li>
</ul>
<p>원-핫(one-hot) 벡터 <span class="math inline">\(\mathbf{y}\)</span>로 쓰면 <span class="math inline">\(\mathcal{L}_{\text{CE}}(\mathbf{y},\mathbf{p}) = - \overset{K}{\sum_{k = 1}}y_{k}\log p_{k}\)</span></p>
<p><strong>멀티라벨 분류(Multilabel, 여러 라벨 동시)</strong></p>
<p>한 관측치가 여러 클래스를 동시에 가질 수 있다. <span class="math inline">\(\mathbf{Y} \in \{ 0,1\}^{K},Y_{k} = 1\)</span> 이면 k번째 라벨이 존재한다.</p>
<ul>
<li>출력: 각 라벨별 독립 로짓 <span class="math inline">\(z_{k}\)</span>, 확률 <span class="math inline">\(p_{k} = \sigma(z_{k})\)</span></li>
<li>손실(라벨별 BCE의 합): <span class="math inline">\(\mathcal{L}_{\text{ML}}(\mathbf{y},\mathbf{p}) = - \overset{K}{\sum_{k = 1}}(y_{k}\log p_{k} + (1 - y_{k})\log(1 - p_{k}))\)</span></li>
</ul>
<p>멀티라벨에서는 softmax(합이 1인 확률)보다 sigmoid를 쓰는 것이 자연스럽다(각 라벨이 <span dir="rtl">”</span>독립적으로 참/거짓”이기 때문).</p>
</section>
<section id="학습과-일반화-개요과적합-정규화-데이터-규모" class="level5">
<h5 class="anchored" data-anchor-id="학습과-일반화-개요과적합-정규화-데이터-규모">(3) 학습과 일반화 개요(과적합, 정규화, 데이터 규모)</h5>
<p>딥러닝 분류의 성능은 단순히 <span dir="rtl">”</span>학습 정확도”가 아니라 일반화 성능(새 데이터에서의 성능)으로 평가된다. 신경망은 표현력이 매우 커서 훈련데이터를 거의 외워버릴 수 있으므로, 과적합을 통제하는 것이 핵심이다.</p>
<p><strong>경험위험 최소화와 일반화</strong></p>
<p>훈련 데이터 <span class="math inline">\(\{(x_{i},y_{i})\}_{i = 1}^{n}\)</span>에 대해 <span class="math inline">\(\widehat{\theta} = \arg\min_{\theta}\frac{1}{n}\overset{n}{\sum_{i = 1}}\mathcal{L}(y_{i},f_{\theta}(x_{i}))\)</span>을 최소화하면 훈련 손실은 내려가지만, 테스트 손실이 함께 내려간다는 보장은 없다. 일반화 관점에서는 <span class="math inline">\(\text{Test risk}\mathbb{E}_{(X,Y)}\lbrack\mathcal{L}(Y,f_{\theta}(X))\rbrack\)</span>를 낮추는 것이 목표다.</p>
<p><strong>과적합의 전형적 징후</strong></p>
<ul>
<li>훈련 손실은 계속 감소하지만, 검증 손실이 어느 시점부터 증가한다.</li>
<li>훈련 정확도는 매우 높지만, 테스트 정확도는 정체/하락 한다.</li>
<li>예측 확률이 과도하게 0 또는 1로 쏠리는(과신) 현상이다.</li>
</ul>
<p><strong>정규화(Regularization)의 큰 축</strong></p>
<p>딥러닝 분류에서는 다음이 <span dir="rtl">”</span>일반화”를 좌우하는 실무적 레버다.</p>
<ul>
<li>가중치 규제(Weight decay, <span class="math inline">\(L_{2}\)</span>): <span class="math inline">\(\min_{\theta}\frac{1}{n}\overset{n}{\sum_{i = 1}}\mathcal{L}_{i}(\theta) + \lambda \parallel \theta \parallel_{2}^{2}\)</span></li>
<li>드롭아웃(Dropout): 학습 중 일부 뉴런을 확률적으로 제거하여 공적응(co-adaptation)을 억제</li>
<li>조기종료(Early stopping): 검증 손실이 나빠지기 시작하면 학습 중단</li>
<li>데이터 증강(Data augmentation): 입력 변형으로 유효 샘플 수를 늘려 과적합 완화</li>
<li>배치정규화(BatchNorm) 등 학습 안정화: 최적화가 안정되면 일반화도 개선되는 경우가 많음</li>
</ul>
</section>
<section id="데이터-규모와-모델-규모의-균형" class="level5">
<h5 class="anchored" data-anchor-id="데이터-규모와-모델-규모의-균형">(4) 데이터 규모와 모델 규모의 균형</h5>
<p>일반적으로 데이터가 작을수록: 모델을 단순화(파라미터 수↓), 정규화 강하게(드롭아웃/weight decay↑), 사전학습 모델 활용(transfer learning) 비중↑</p>
<p>반대로 데이터가 충분히 크면: 모델 규모를 키워 표현력을 확보, 데이터 증강/정규화는 <span dir="rtl">”</span>안정성 확보” 용도로 조절</p>
</section>
</section>
<section id="출력층과-확률모형" class="level4">
<h4 class="anchored" data-anchor-id="출력층과-확률모형">2. 출력층과 확률모형</h4>
<p>딥러닝 분류에서 출력층(output layer)은 <span dir="rtl">”</span>신경망이 만든 점수를 확률로 해석 가능한 형태로 바꾸는 구간”이다. 즉, 출력층은 단순한 마지막 층이 아니라 확률모형의 형태를 결정한다. 라벨 구조(이진/다중/멀티라벨)에 맞는 출력층을 선택하지 않으면, 손실함수·평가·의사결정 규칙이 서로 충돌하여 학습이 불안정해진다.</p>
<section id="이진분류-logit-sigmoid-py1mid-x" class="level5">
<h5 class="anchored" data-anchor-id="이진분류-logit-sigmoid-py1mid-x">(1) 이진분류: logit, sigmoid, P(Y=1\mid X)</h5>
<p>이진분류에서는 라벨이 <span class="math inline">\(Y \in \{ 0,1\}\)</span>이며, 신경망은 마지막에서 단일 실수 점수(logit)를 출력한다.</p>
<p><strong>logit의 정의</strong></p>
<p><span class="math inline">\(z = f_{\theta}(x) \in \mathbb{R}\)</span>, 여기서 z는 <span dir="rtl">”</span>양성일 가능성이 높을수록 크게” 학습되는 점수다. 확률이 아니라는 점이 중요하다.</p>
<p><strong>sigmoid로 확률화</strong></p>
<p>이 점수를 확률로 바꾸기 위해 sigmoid를 사용한다. <span class="math inline">\(p(x) = P(Y = 1 \mid X = x) = \sigma(z) = \frac{1}{1 + e^{- z}}\)</span>. 그럼 <span class="math inline">\(P(Y = 0 \mid x) = 1 - p(x)\)</span>가 된다.</p>
<p><strong>logit과 odds 해석(확률모형 관점)</strong></p>
<p>sigmoid는 다음 관계를 만족한다. <span class="math inline">\(\frac{p(x)}{1 - p(x)} = e^{z} \Rightarrow \log\frac{p(x)}{1 - p(x)} = z\)</span>. 즉 <span class="math inline">\(logitz\)</span>는 조건부 확률의 로그 오즈(log-odds)에 해당한다. 딥러닝 이진분류는 <span dir="rtl">”</span>입력 x로부터 <span class="math inline">\(P(Y = 1 \mid x)\)</span>“를 직접 학습한다기보다, 우선 log-odds를 예측하고 이를 확률로 변환하는 구조라고 이해하면 정리된다.</p>
</section>
<section id="다중분류-확률모형-softmax" class="level5">
<h5 class="anchored" data-anchor-id="다중분류-확률모형-softmax">(2) 다중분류 확률모형: Softmax</h5>
<p>다중분류(멀티클래스, 단일 정답)에서는 <span class="math inline">\(Y \in \{ 1,\ldots,K\}\)</span>이고 관측치마다 정답 클래스가 정확히 하나 존재한다. 신경망은 클래스별 점수 벡터를 출력한다.</p>
<p><strong>클래스별 logit</strong></p>
<p><span class="math display">\[\mathbf{z} = f_{\theta}(x) = (z_{1},\ldots,z_{K}) \in \mathbb{R}^{K}\]</span></p>
<p><strong>softmax로 확률 벡터 생성</strong></p>
<p><span class="math display">\[p_{k}(x) = P(Y = k \mid X = x) = \frac{e^{z_{k}}}{\sum_{j = 1}^{K}e^{z_{j}}},k = 1,\ldots,K\]</span></p>
<p>softmax의 핵심 성질은 <span class="math inline">\(p_{k}(x) \in (0,1),\overset{K}{\sum_{k = 1}}p_{k}(x) = 1\)</span>. 즉 <span dir="rtl">”</span>확률 질량이 K개 클래스에 분배”되는 구조이며, 클래스들이 서로 경쟁한다.</p>
<p><strong>softmax의 불변성(중요한 성질)</strong></p>
<p>모든 로짓에 같은 상수 c를 더해도 확률은 변하지 않는다. <span class="math inline">\(\frac{e^{z_{k} + c}}{\sum_{j}^{}e^{z_{j} + c}} = \frac{e^{z_{k}}}{\sum_{j}^{}e^{z_{j}}}\)</span>. 이 성질 때문에 실제 구현에서는 수치안정성을 위해 <span class="math inline">\(p_{k} = \frac{e^{z_{k} - \max_{j}z_{j}}}{\sum_{j}^{}e^{z_{j} - \max_{j}z_{j}}}\)</span>처럼 계산한다(overflow 방지).</p>
</section>
<section id="다중분류의-결정규칙-argmax_k-p_k" class="level5">
<h5 class="anchored" data-anchor-id="다중분류의-결정규칙-argmax_k-p_k">(3) 다중분류의 결정규칙: <span class="math inline">\(\\argmax_k~ p_k\)</span></h5>
<p>확률모형이 정해지면, 의사결정 규칙을 통해 최종 예측 클래스가 결정된다.</p>
<p><strong>MAP 결정규칙</strong></p>
<p>다중분류에서 가장 기본 규칙은 최대확률(MAP)이다. <span class="math inline">\(\widehat{y}(x) = \arg\max_{k \in \{ 1,\ldots,K\}}p_{k}(x)\)</span>. softmax는 단조 변환이므로 다음도 동일하다. <span class="math inline">\(\widehat{y}(x) = \arg\max_{k}z_{k}\)</span>. 즉 <span dir="rtl">”</span>확률이 가장 큰 클래스”는 <span dir="rtl">”</span>로짓이 가장 큰 클래스”와 같다.</p>
<p><strong>비용민감(cost-sensitive) 상황의 일반화</strong></p>
<p>현실에서는 오분류 비용이 클래스별로 다를 수 있다. 비용행렬 C(a,y)가 있을 때 최적 규칙은 <span class="math inline">\(\widehat{a}(x) = \arg\min_{a}\overset{K}{\sum_{k = 1}}C(a,k)p_{k}(x)\)</span>이며, <span class="math inline">\(\arg\max\)</span>는 <span dir="rtl">”</span>모든 오분류 비용이 동일”한 특수한 경우로 볼 수 있다. (이 점 때문에 운영단에서는 단순 정확도보다 임계값/정책 설계가 중요해진다.)</p>
</section>
<section id="멀티클래스-vs-멀티라벨-출력-구조-비교softmax-vs-sigmoid" class="level5">
<h5 class="anchored" data-anchor-id="멀티클래스-vs-멀티라벨-출력-구조-비교softmax-vs-sigmoid">(4) 멀티클래스 vs 멀티라벨 출력 구조 비교(softmax vs sigmoid)</h5>
<p>둘은 이름이 비슷하지만 라벨의 의미 자체가 다르다. 따라서 출력층과 확률 해석도 완전히 달라진다.</p>
<p><strong>멀티클래스(Multiclass, 단일 정답)</strong></p>
<ul>
<li>라벨: <span class="math inline">\(Y \in \{ 1,\ldots,K\}\)</span></li>
<li>의미: 정답은 하나, 클래스들은 상호배타적(mutually exclusive)</li>
<li>출력: <span class="math inline">\(\mathbf{z} \in \mathbb{R}^{K}\)</span></li>
<li>확률화: softmax <span class="math inline">\(p_{k} = \frac{e^{z_{k}}}{\sum_{j}^{}e^{z_{j}}},\sum_{k}p_{k} = 1\)</span></li>
<li>결정: <span class="math inline">\(\widehat{y} = \arg\max_{k}p_{k}\)</span></li>
<li>해석: <span dir="rtl">”</span>이 샘플은 K개 중 정확히 하나다”라는 확률모형.</li>
</ul>
<p><strong>멀티라벨(Multilabel, 여러 라벨 동시)</strong></p>
<ul>
<li>라벨: <span class="math inline">\(\mathbf{Y} \in \{ 0,1\}^{K}\)</span></li>
<li>의미: 여러 라벨이 동시에 참일 수 있음(비배타)</li>
<li>출력: <span class="math inline">\(\mathbf{z} \in \mathbb{R}^{K}\)</span> (라벨별 로짓)</li>
<li>확률화: 라벨별 sigmoid <span class="math inline">\(p_{k} = \sigma(z_{k}),k = 1,\ldots,K\)</span>. 여기서 <span class="math inline">\(p_{k} = P(Y_{k} = 1 \mid x)\)</span>로 해석된다.</li>
<li>결정: 라벨별 임계값 <span class="math inline">\({\widehat{y}}_{k} = 1\{ p_{k} \geq t_{k}\}\)</span> (라벨마다 임계값 <span class="math inline">\(t_{k}\)</span>를 다르게 두는 것이 흔하다)</li>
<li>해석: <span dir="rtl">”</span>각 라벨이 존재할 확률을 따로 추정한다.” (클래스 간 경쟁 구조가 없다)</li>
</ul>
<p><strong>softmax를 멀티라벨에 쓰면 왜 문제가 되나?</strong></p>
<p>softmax는 <span class="math inline">\(\sum_{k}p_{k} = 1\)</span>을 강제하므로, <span dir="rtl">”</span>여러 라벨이 동시에 1”이어야 하는 데이터에서 확률 질량을 나눠 가지게 되어 구조적으로 충돌한다. 예를 들어 이미지에 <span dir="rtl">”</span>사람”과 <span dir="rtl">”</span>자전거”가 함께 있으면 둘 다 높은 확률이어야 하는데, softmax는 둘이 동시에 0.9가 되는 것을 허용하지 않는다.</p>
</section>
</section>
<section id="손실함수-cross-entropy의-원리" class="level4">
<h4 class="anchored" data-anchor-id="손실함수-cross-entropy의-원리">3. 손실함수: Cross-Entropy의 원리</h4>
<p>딥러닝 분류에서 손실함수는 <span dir="rtl">”</span>정답을 맞추게 하라”는 막연한 지시가 아니라, 확률모형 <span class="math inline">\(P_{\theta}(Y \mid X)\)</span>을 데이터에 맞게 추정하도록 만드는 통계적 기준이다. 분류에서 가장 표준인 손실이 Cross-Entropy이며, 이는 곧 음의 로그우도(NLL) 최소화와 동치다. (즉, 딥러닝 분류는 <span dir="rtl">’</span>확률모형의 최대우도추정<span dir="rtl">’</span>을 SGD로 수행한다고 볼 수 있다.)</p>
<section id="최대우도음의-로그우도nllcross-entropy-연결" class="level5">
<h5 class="anchored" data-anchor-id="최대우도음의-로그우도nllcross-entropy-연결">(1) 최대우도–음의 로그우도(NLL)–Cross-Entropy 연결</h5>
<p>데이터 <span class="math inline">\(\{(x_{i},y_{i})\}_{i = 1}^{n}\)</span>가 i.i.d.라고 할 때, 모델이 조건부확률 <span class="math inline">\(P_{\theta}(Y \mid X)\)</span>를 준다고 하자. 최대우도추정(MLE)은 <span class="math inline">\(\widehat{\theta} = \arg\max_{\theta}\overset{n}{\prod_{i = 1}}P_{\theta}(y_{i} \mid x_{i})\)</span>.</p>
<p>로그를 취하면 곱이 합으로 바뀌어 최적화가 쉬워진다.<span class="math inline">\(\widehat{\theta} = \arg\max_{\theta}\overset{n}{\sum_{i = 1}}\log P_{\theta}(y_{i} \mid x_{i})\)</span></p>
<p>최대화를 최소화 문제로 바꾸기 위해 마이너스를 붙이면 음의 로그우도는 <span class="math inline">\(\widehat{\theta} = \arg\min_{\theta}\overset{n}{\sum_{i = 1}}( - \log P_{\theta}(y_{i} \mid x_{i}))\)</span>, 여기서 분류에서 <span class="math inline">\(y_{i}\)</span>를 원-핫 벡터 <span class="math inline">\(\mathbf{y}_{i}\)</span>로 쓰고, 모델 확률을 <span class="math inline">\(\mathbf{p}_{i}\)</span>로 쓰면 <span class="math inline">\(- \log P_{\theta}(y_{i} \mid x_{i}) = - \overset{K}{\sum_{k = 1}}y_{ik}\log p_{ik}\)</span>. 이 식이 바로 Cross-Entropy(교차엔트로피)다. 즉 <span class="math inline">\(MLE \leftrightarrow NLL\)</span> 최소화 <span class="math inline">\(\leftrightarrow Cross - Entropy\)</span> 최소화가 한 줄로 연결된다.</p>
<p>정답 클래스에 부여한 확률 <span class="math inline">\(p_{i,y_{i}}\)</span>가 작을수록 <span class="math inline">\(- \log p_{i,y_{i}}\)</span>는 크게 벌점을 준다. 특히 <span class="math inline">\(p \rightarrow 0\)</span>이면 손실이 <span class="math inline">\(\rightarrow \infty\)</span>로 발산하므로 <span dir="rtl">”</span>정답인데 거의 0이라고 확신하는 예측”을 강하게 교정한다.</p>
</section>
<section id="다중분류-손실-softmax-cross-entropy" class="level5">
<h5 class="anchored" data-anchor-id="다중분류-손실-softmax-cross-entropy">(2) 다중분류 손실: Softmax + Cross-Entropy</h5>
<p>다중분류(단일 정답)에서 신경망은 로짓 <span class="math inline">\(\mathbf{z} \in \mathbb{R}^{K}\)</span>를 출력하고, softmax로 확률 <span class="math inline">\(\mathbf{p}\)</span>를 만든다. <span class="math inline">\(p_{k} = \frac{e^{z_{k}}}{\sum_{j = 1}^{K}e^{z_{j}}}\)</span>. 정답이 <span class="math inline">\(y \in \{ 1,\ldots,K\}\)</span>일 때 Cross-Entropy는 <span class="math inline">\(\mathcal{L}_{\text{CE}}(y,\mathbf{p}) = - \log p_{y}\)</span>이다.</p>
<p>원-핫 벡터 <span class="math inline">\(\mathbf{y}\)</span>로 쓰면 더 일반적으로 <span class="math inline">\(\mathcal{L}_{\text{CE}}(\mathbf{y},\mathbf{p}) = - \overset{K}{\sum_{k = 1}}y_{k}\log p_{k}\)</span>이다. 따라서 다중분류 표준 학습은 <span class="math inline">\(\min_{\theta}\frac{1}{n}\overset{n}{\sum_{i = 1}}( - \log p_{i,y_{i}})\text{where}\mathbf{p}_{i} = \text{softmax}(f_{\theta}(x_{i}))\)</span>으로 정리된다.</p>
</section>
<section id="gradient-직관-p---y-형태와-학습-안정성" class="level5">
<h5 class="anchored" data-anchor-id="gradient-직관-p---y-형태와-학습-안정성">(3) gradient 직관: <span class="math inline">\((p - y)\)</span> 형태와 학습 안정성</h5>
<p>Cross-Entropy가 실무에서 압도적으로 쓰이는 이유 중 하나는, softmax와 결합했을 때 기울기가 매우 깔끔해져 학습이 안정적이기 때문이다.</p>
<p>한 샘플에 대해, 로짓 \mathbf{z}에 대한 손실의 미분은 <span class="math inline">\(\frac{\partial\mathcal{L}}{\partial z_{k}} = p_{k} - y_{k}\)</span>이다. 즉 <span dir="rtl">”</span>예측확률 p에서 정답 y를 뺀 오차”가 그대로 역전파된다.</p>
<ul>
<li>정답 클래스(<span class="math inline">\(y_{k} = 1\)</span>)에서는 <span class="math inline">\(\frac{\partial\mathcal{L}}{\partial z_{k}} = p_{k} - 1\)</span> → 정답 확률 <span class="math inline">\(p_{k}\)</span> 가 1보다 작으면 음수이므로 <span class="math inline">\(z_{k}\)</span>를 키우는 방향으로 업데이트 된다.</li>
<li>오답 클래스(<span class="math inline">\(y_{k} = 0\)</span>)에서는 <span class="math inline">\(\frac{\partial\mathcal{L}}{\partial z_{k}} = p_{k}\)</span> → 오답 확률이 클수록 z_k를 줄이는 방향으로 업데이트 된다.</li>
</ul>
<p>이 형태는 <span dir="rtl">”</span>출력층에서의 오차 신호”가 직관적이고 크기 조절도 잘 되어, 단순한 제곱오차(MSE)를 분류에 억지로 쓰는 것보다 훨씬 학습이 잘 된다.</p>
<p>특히 softmax의 미분(야코비안)과 <span class="math inline">\(- \log( \cdot )\)</span> 미분이 결합되며 복잡한 항이 상쇄되어 <span class="math inline">\((p - y)\)</span>로 단순화된다. 이 단순화가 수치적으로도 유리하고, 최적화 관점에서 안정적인 신호를 제공한다.</p>
</section>
<section id="실무-옵션-class-weight-label-smoothing" class="level5">
<h5 class="anchored" data-anchor-id="실무-옵션-class-weight-label-smoothing">(4) 실무 옵션: class weight / label smoothing</h5>
<p>현장 데이터는 <span dir="rtl">”</span>클래스 불균형”과 <span dir="rtl">”</span>라벨 노이즈(오표기)“가 흔하다. Cross-Entropy는 기본형으로도 강력하지만, 아래 옵션을 붙이면 성능/안정성이 좋아지는 경우가 많다.</p>
<p><strong>Class weight (불균형 대응)</strong></p>
<p>소수 클래스의 손실을 더 크게 벌점 주어 모델이 놓치지 않게 만드는 방식이다.</p>
<p>다중분류 가중 CE: <span class="math inline">\(\mathcal{L} = - \overset{K}{\sum_{k = 1}}w_{k}y_{k}\log p_{k}\)</span></p>
<p>정답 클래스가 y라면 <span class="math inline">\(\mathcal{L} = - w_{y}\log p_{y}\)</span>로 단순화된다.</p>
<p>이진분류 가중 BCE(양성 가중 <span class="math inline">\(w_{1}\)</span>, 음성 가중 <span class="math inline">\(w_{0}\)</span>): <span class="math inline">\(\mathcal{L} = - (w_{1}y\log p + w_{0}(1 - y)\log(1 - p))\)</span></p>
<p>실무 포인트는 <span dir="rtl">”</span>가중치를 올리면 Recall은 좋아질 수 있지만 FP도 같이 늘 수 있다”는 점이다. 결국 운영 목적(놓침 비용 vs 오경보 비용)에 맞춰 임계값과 함께 튜닝한다.</p>
<p><strong>Label smoothing (과신 완화, 일반화 개선)</strong></p>
<p>원-핫 정답 <span class="math inline">\(\mathbf{y}\)</span>는 <span dir="rtl">”</span>정답 클래스 확률 1”을 강제해 모델이 과도하게 확신하게 만들 수 있다. 이를 완화하기 위해 정답 분포를 약간 부드럽게 만든다.</p>
<p><span class="math inline">\({\overset{˜}{y}}_{k} = (1 - \varepsilon)y_{k} + \frac{\varepsilon}{K}\)</span>. 그리고 <span class="math inline">\(\overset{˜}{\mathbf{y}}\)</span>로 Cross-Entropy를 계산한다. <span class="math inline">\(\mathcal{L} = - \overset{K}{\sum_{k = 1}}{\overset{˜}{y}}_{k}\log p_{k}\)</span></p>
<p>효과: 과신 감소(확률 보정에 유리), 라벨 노이즈에 덜 민감, 일부 데이터셋에서 일반화 성능 개선. 단, <span class="math inline">\(\varepsilon\)</span>를 너무 크게 잡으면(정답을 너무 희석하면) 성능이 떨어질 수 있어 보통 작은 값(예: 0.05~0.1)을 후보로 둔다.</p>
</section>
</section>
<section id="결정규칙과-임계값운영-관점" class="level4">
<h4 class="anchored" data-anchor-id="결정규칙과-임계값운영-관점">4. 결정규칙과 임계값(운영 관점)</h4>
<p>딥러닝 분류 모델은 보통 확률 <span class="math inline">\(p(x) = P(Y = 1 \mid x)\)</span> 또는 <span class="math inline">\(\{ p_{k}(x)\}\)</span>를 출력한다. 하지만 운영(실제 의사결정)은 <span dir="rtl">”</span>확률을 어떻게 행동으로 바꿀지”가 핵심이며, 그 연결고리가 임계값이다. 같은 모델이라도 임계값을 어떻게 두느냐에 따라 미탐/오경보/검토량/비용이 크게 달라진다.</p>
<section id="왜-임계값이-필요한가-확률-예측과-의사결정의-분리" class="level5">
<h5 class="anchored" data-anchor-id="왜-임계값이-필요한가-확률-예측과-의사결정의-분리">(1) 왜 임계값이 필요한가: 확률 예측과 의사결정의 분리</h5>
<p>이진분류에서 모델은 확률 p(x)를 준다. 그러나 실제 행동은 보통 <span class="math inline">\(\widehat{y} = 1\{ p(x) \geq t\}\)</span>처럼 임계값 t로 결정된다.</p>
<ul>
<li>학습(모형 추정): 교차엔트로피(NLL) 최소화로 p(x)를 <span dir="rtl">”</span>잘” 예측</li>
<li>운영(정책 결정): 비용/제약/리소스에 맞춰 t를 선택</li>
</ul>
<p>즉, 모델링과 정책을 분리해야 한다. 학습은 <span dir="rtl">”</span>확률을 잘 맞추는 것”이고, 운영은 <span dir="rtl">”</span>그 확률을 이용해 최적 행동을 선택”하는 문제다.</p>
</section>
<section id="confusion-matrix-기반-운영지표precisionrecallfprfnr" class="level5">
<h5 class="anchored" data-anchor-id="confusion-matrix-기반-운영지표precisionrecallfprfnr">(2) Confusion Matrix 기반 운영지표(Precision/Recall/FPR/FNR)</h5>
<p>이진분류에서 혼동행렬(Confusion Matrix)은 다음 네 개로 요약된다.</p>
<ul>
<li>TP: 실제 1(양성)을 1(양성)로 예측</li>
<li>FP: 실제 0(음성)을 1(양성)로 예측 (오경보)</li>
<li>FN: 실제 1(양성)을 0(음성)로 예측 (미탐)</li>
<li>TN: 실제 0(음성)을 0(음성)로 예측</li>
</ul>
<p>운영에서 자주 쓰는 지표는 다음이다.</p>
<ul>
<li>Precision (정밀도) <span class="math inline">\(Precision = \frac{TP}{TP + FP}\)</span> <span dir="rtl">”</span>양성이라고 예측했을 때, 진짜 양성 비율”</li>
<li>Recall (재현율, 민감도, TPR) <span class="math inline">\(Recall = TPR = \frac{TP}{TP + FN}\)</span> <span dir="rtl">”</span>진짜 양성 중 얼마나 양성이라고 예측했나”</li>
<li>Spevification(특이도) <span class="math inline">\(Specification = \frac{TN}{YN + FP}\)</span> <span dir="rtl">”</span>음성이라고 예측했을 때, 진짜 음성 비율”</li>
<li>FPR (False Positive Rate 거짓 양성률) <span class="math inline">\(FPR = \frac{FP}{FP + TN}\)</span> <span dir="rtl">”</span>진짜 음성 중 얼마나 오경보를 냈나” <span class="math inline">\(FPR = 1 - Specification\)</span></li>
<li>FNR (False Negative Rate 거짓 음성률) <span class="math inline">\(FNR = \frac{FN}{TP + FN} = 1 - Recall\)</span> <span dir="rtl">”</span>진짜 양성 중 얼마나 음성으로 예측하였나”</li>
</ul>
<p>임계값 t를 올리면 보통 FP가 줄어 Precision은 오르기 쉽지만 Recall은 떨어진다. t를 내리면 그 반대가 된다. 이 trade-off가 운영의 핵심이다.</p>
</section>
<section id="roc-auc와-임계값-선택" class="level5">
<h5 class="anchored" data-anchor-id="roc-auc와-임계값-선택">(3) ROC, AUC와 임계값 선택</h5>
<p>ROC는 임계값 t를 바꿔가며 x축은 <span class="math inline">\(FPR(t) = 1 - Spec(t)\)</span>, y축은 <span class="math inline">\(TPR(t) = Recall(t)\)</span>를 그린 곡선이다.</p>
<p>AUC(Area Under ROC Curve)는 <span dir="rtl">”</span>무작위 양성 샘플이 무작위 음성 샘플보다 더 높은 점수를 받을 확률”로도 해석된다. 즉, 순위 분리력을 보는 지표다.</p>
<p>ROC/AUC는 불균형에서 상대적으로 덜 흔들리지만, 운영에서 중요한 <span dir="rtl">”</span>양성 경보의 품질(Precision)“을 직접 보여주진 않는다.</p>
<p><span dir="rtl">”</span>어떤 t가 좋은가?“는 ROC 자체가 답을 주기보다, FPR 제한이나 비용 기준 같은 운영 조건을 함께 줘야 결정된다.</p>
</section>
<section id="precision-recall-ap불균형에서의-핵심-평가" class="level5">
<h5 class="anchored" data-anchor-id="precision-recall-ap불균형에서의-핵심-평가">(4) Precision-Recall, AP(불균형에서의 핵심 평가)</h5>
<p>불균형(양성이 희귀)인 경우, ROC는 꽤 좋아 보여도 실제로는 FP가 대량 발생할 수 있다. 이때 더 직접적인 지표가 Precision–Recall(PR) 곡선이다.</p>
<p>PR 곡선은 임계값 t를 바꾸며 x축에는 Recall(재현율), y축은 Precision(정밀도)을 그린다. AP (Average Precision)는 PR 곡선 아래 면적(정확히는 Precision의 Recall-가중 평균)으로, 불균형에서 모델 비교에 자주 쓴다.</p>
<p>희귀 양성 탐지(사기, 결함, 이상탐지)는 <span dir="rtl">”</span>Recall을 조금 올리려다 FP가 폭증”하기 쉬우므로, PR/AP가 의사결정에 더 실용적이다.</p>
</section>
<section id="cost-based-threshold-비용행렬-기반-최적-t" class="level5">
<h5 class="anchored" data-anchor-id="cost-based-threshold-비용행렬-기반-최적-t">(5) Cost-based threshold: 비용행렬 기반 최적 <span class="math inline">\(t^{*}\)</span></h5>
<p>이진분류에서 <span dir="rtl">”</span>양성으로 띄울 때의 오경보 비용”을 <span class="math inline">\(c_{FP}\)</span>, <span dir="rtl">”</span>음성으로 넘길 때의 미탐 비용”을 <span class="math inline">\(c_{FN}\)</span>이라 하자. (정답 비용은 0이라고 두는 단순화)</p>
<p>확률 <span class="math inline">\(p = P(Y = 1 \mid x)\)</span>에 대해, <span class="math inline">\(\widehat{y} = 1\)</span>로 결정 시 기대비용은 <span class="math inline">\(\mathbb{E}\lbrack C \mid \widehat{y} = 1\rbrack = c_{FP} \cdot P(Y = 0 \mid x) = c_{FP}(1 - p)\)</span>이다.</p>
<p><span class="math inline">\(\widehat{y} = 0\)</span>로 결정 시 기대비용은 <span class="math inline">\(\mathbb{E}\lbrack C \mid \widehat{y} = 0\rbrack = c_{FN} \cdot P(Y = 1 \mid x) = c_{FN}p\)</span></p>
<p>따라서 <span class="math inline">\(\widehat{y} = 1\)</span>이 유리한 조건은 <span class="math inline">\(c_{FP}(1 - p) \leq c_{FN}p \Longleftrightarrow p \geq \frac{c_{FP}}{c_{FP} + c_{FN}}\)</span>.</p>
<p>즉, <span class="math inline">\(t^{*} = \frac{c_{FP}}{c_{FP} + c_{FN}}\)</span></p>
<ul>
<li>미탐지 비용 <span class="math inline">\(c_{FN}\)</span>이 크면 <span class="math inline">\(t^{*}\)</span>가 내려가서(더 쉽게 양성) Recall을 우선한다.</li>
<li>오경보 비용 <span class="math inline">\(c_{FP}\)</span>이 크면 <span class="math inline">\(t^{*}\)</span>가 올라가서(더 보수적으로 양성) FP를 줄인다.</li>
</ul>
<p>일반 비용행렬, 클래스 사전확률/운영 분포 변화, 검토 비용 포함 등으로 확장 가능하지만, 위 식이 가장 자주 쓰는 핵심 형태다.</p>
</section>
<section id="제약-기반-임계값-선택fpr-leq-alpha-검토량k-등" class="level5">
<h5 class="anchored" data-anchor-id="제약-기반-임계값-선택fpr-leq-alpha-검토량k-등">(6) 제약 기반 임계값 선택(<span class="math inline">\(FPR \leq \alpha\)</span>, 검토량≤K 등)</h5>
<p>현장에서는 <span dir="rtl">”</span>비용 숫자를 정확히 못 박기 어렵다”거나 <span dir="rtl">”</span>정책/규제/리소스 제약이 먼저”인 경우가 많다. 이때는 제약을 만족하는 t를 검증셋에서 찾는다.</p>
<p><strong>FPR 제약: <span class="math inline">\(FPR(t) \leq \alpha\)</span></strong></p>
<p>예를 들면 <span dir="rtl">”</span>오경보율은 1% 이하”가 필수인 알림 시스템이다. 절차(검증셋 기준는 (1) 여러 t에 대해 <span class="math inline">\(FPR(t)\)</span> 계산하고 (2) <span class="math inline">\(FPR(t) \leq \alpha\)</span>를 만족하는 후보 중 Recall 최대 또는 비용 최소 선택한다.</p>
<p><strong>검토량(알람 수) 제약: <span dir="rtl">”</span>하루 최대 K건만 검토 가능”</strong></p>
<p>예를 들면, 사기 의심 거래 상위 K건만 조사이다. 이 경우 임계값 대신 Top-K 정책이 자연스럽다. 점수 s(x) 또는 확률 p(x)를 내림차순 정렬 후 상위 K개만 양성(검토 대상) 처리 또는 <span dir="rtl">”</span>양성 예측 비율 \le r” 제약을 두고 t를 선택한다.</p>
<p><strong>복합 제약: \mathrm{FPR}\le \alpha AND 검토량 \le K</strong></p>
<p>실무에서는 다중 제약이 흔하다. 이때는 검증셋에서 임계값 후보를 스윕하면서 제약을 모두 만족하는 구간에서 목표(Recall 최대, 비용 최소, Precision 최대 등)를 최적화 하는 방식으로 결정한다.</p>
</section>
</section>
<section id="멀티라벨-분류-multi-label-classification" class="level4">
<h4 class="anchored" data-anchor-id="멀티라벨-분류-multi-label-classification">5. 멀티라벨 분류 (Multi-label Classification)</h4>
<p>멀티라벨 분류는 한 관측치 x에 대해 라벨이 하나로 끝나지 않고, 여러 라벨이 동시에 참(True)일 수 있는 문제를 다룬다. 따라서 <span dir="rtl">”</span>클래스들 간 경쟁”을 가정하는 softmax 다중분류와 달리, 멀티라벨에서는 각 라벨에 대해 독립적인 존재 여부를 추정하는 확률모형이 자연스럽다.</p>
<section id="문제-정의-여러-라벨-동시-예측" class="level5">
<h5 class="anchored" data-anchor-id="문제-정의-여러-라벨-동시-예측">(1) 문제 정의: 여러 라벨 동시 예측</h5>
<p>라벨 집합이 K개일 때, 멀티라벨의 정답은 하나의 값이 아니라 벡터다. <span class="math inline">\(\mathbf{Y} = (Y_{1},\ldots,Y_{K}) \in \{ 0,1\}^{K}\)</span>, 여기서 <span class="math inline">\(Y_{k} = 1\)</span>이면 <span dir="rtl">”</span>k번째 라벨이 존재”, <span class="math inline">\(Y_{k} = 0\)</span>이면 <span dir="rtl">”</span>없음”을 의미한다.</p>
<ul>
<li>이미지 태깅:{사람, 자동차, 자전거}가 동시에 1 가능</li>
<li>문서 분류:{정치, 경제} 동시 분류 가능</li>
<li>의학 진단: 다수 질환 공존 가능</li>
</ul>
<p>목표는 각 라벨에 대해 조건부확률을 추정하는 것이다. <span class="math inline">\(p_{k}(x) = P(Y_{k} = 1 \mid X = x),k = 1,\ldots,K\)</span></p>
</section>
<section id="출력층-라벨별-sigmoid-독립-bce" class="level5">
<h5 class="anchored" data-anchor-id="출력층-라벨별-sigmoid-독립-bce">(2) 출력층: 라벨별 sigmoid, 독립 BCE</h5>
<p>멀티라벨 신경망은 마지막에 K개의 로짓을 출력한다. <span class="math inline">\(\mathbf{z} = f_{\theta}(x) = (z_{1},\ldots,z_{K}) \in \mathbb{R}^{K}\)</span>. 각 로짓을 sigmoid로 변환해 라벨별 확률을 얻는다. <span class="math inline">\(p_{k} = \sigma(z_{k}) = \frac{1}{1 + e^{- z_{k}}}\)</span></p>
<p>가장 표준 손실은 라벨별 이진 교차엔트로피(BCE)를 합산한 형태다.</p>
<p><span class="math display">\[\mathcal{L}_{\text{ML}}(\mathbf{y},\mathbf{p}) = - \overset{K}{\sum_{k = 1}}(y_{k}\log p_{k} + (1 - y_{k})\log(1 - p_{k}))\]</span></p>
<p>이 구성은 <span dir="rtl">”</span>각 라벨이 독립적인 베르누이 타깃”이라는 모델링 관점과 대응된다. (현실에서는 라벨 간 상관이 존재해도, 예측 자체는 독립 확률로 두고 표현력은 신경망의 공유 표현이 흡수하는 방식이 실무적으로 많이 쓰인다.)</p>
</section>
<section id="임계값-전략-global-t-vs-라벨별-t_k" class="level5">
<h5 class="anchored" data-anchor-id="임계값-전략-global-t-vs-라벨별-t_k">(3) 임계값 전략: global t vs 라벨별 t_k</h5>
<p>멀티라벨의 최종 예측은 라벨별 임계값을 적용해 이진화한다. <span class="math inline">\({\widehat{y}}_{k} = 1\{ p_{k} \geq t_{k}\}\)</span>. 임계값 선택이 성능을 좌우하며, 대표 전략은 두 가지다.</p>
<p><strong>Global threshold t (전 라벨 공통 임계값) <span class="math inline">\(t_{k} = t\forall k\)</span></strong></p>
<ul>
<li>장점: 단순, 운영/설명이 쉬움, 튜닝 비용 낮음</li>
<li>단점: 라벨별 빈도(희귀도)·오류비용이 다르면 비효율적 (희귀 라벨은 보통 t를 낮춰야 잡히는데, 공통 t는 놓치기 쉬움)</li>
</ul>
<p><strong>라벨별 threshold t_k <span class="math inline">\(t_{1},\ldots,t_{K}\)</span> 을 각각 튜닝</strong></p>
<ul>
<li>장점: 라벨별 불균형/비용/난이도를 반영 가능 → 실무 성능 향상 흔함</li>
<li>단점: 관리 복잡도 증가(라벨 수가 많을수록), 데이터가 적으면 과적합 위험</li>
</ul>
<p>라벨별 <span class="math inline">\(t_{k}\)</span>는 보통 검증셋에서 라벨별로 다음 같은 기준으로 고른다.</p>
<ul>
<li>F1 최대화: <span class="math inline">\(t_{k} = \arg\max_{t}F1_{k}(t)\)</span></li>
<li>제약 기반: <span class="math inline">\({FPR}_{k}(t) \leq \alpha_{k}\)</span>만족하는 최소 t</li>
<li>운영량 기반: 라벨 k에 대해 하루 알람 수 상한을 만족하는 t</li>
</ul>
</section>
<section id="평가-micromacro-f1-pr-관점-정리" class="level5">
<h5 class="anchored" data-anchor-id="평가-micromacro-f1-pr-관점-정리">(4) 평가: micro/macro F1, PR 관점 정리</h5>
<p>멀티라벨에서는 <span dir="rtl">”</span>정확도”가 의미가 약해지는 경우가 많아, 보통 Precision/Recall/F1을 micro/macro로 요약한다.</p>
<p>먼저 라벨 k별 혼동행렬을 <span class="math inline">\({TP}_{k},{FP}_{k},{FN}_{k},{TN}_{k}\)</span>을 정의하면</p>
<p>라벨 k의 정밀도/재현율/F1은 다음과 같다. <span class="math inline">\({Precision}_{k} = \frac{{TP}_{k}}{{TP}_{k} + {FP}_{k}},{Recall}_{k} = \frac{{TP}_{k}}{{TP}_{k} + {FN}_{k}}F1_{k} = \frac{2{Precision}_{k}{Recall}_{k}}{{Precision}_{k} + {Recall}_{k}}\)</span></p>
<p><strong>Micro 평균 (전체 사건을 한데 모아 계산)</strong></p>
<p><span class="math display">\[\begin{matrix}
{TP}_{\text{micro}} &amp; = \sum_{k}{TP}_{k},{FP}_{\text{micro}} = \sum_{k}{FP}_{k},{FN}_{\text{micro}} = \sum_{k}{FN}_{k} \\
{Precision}_{\text{micro}} &amp; = \frac{\sum_{k}^{}{TP}_{k}}{\sum_{k}({TP}_{k} + {FP}_{k})} \\
{Recall}_{\text{micro}} &amp; = \frac{\sum_{k}^{}{TP}_{k}}{\sum_{k}({TP}_{k} + {FN}_{k})} \\
F1_{\text{micro}} &amp; = \frac{2{Precision}_{\text{micro}}{Recall}_{\text{micro}}}{{Precision}_{\text{micro}} + {Recall}_{\text{micro}}}
\end{matrix}\]</span></p>
<ul>
<li>특징: 빈도가 큰 라벨(자주 등장)이 지표를 강하게 좌우</li>
<li>해석: 시스템 전체에서 <span dir="rtl">”</span>맞춘 양성 사건 비율”을 강조</li>
</ul>
<p><strong>Macro 평균 (라벨별 점수를 평균)</strong></p>
<p><span class="math display">\[\begin{array}{r}
{Precision}_{\text{macro}} = \frac{1}{K}\overset{K}{\sum_{k = 1}}{Precision}_{k}, \\
{Recall}_{\text{macro}} = \frac{1}{K}\overset{K}{\sum_{k = 1}}{Recall}_{k},F1_{\text{macro}} = \frac{1}{K}\overset{K}{\sum_{k = 1}}F1_{k}
\end{array}\]</span></p>
<ul>
<li>특징: 희귀 라벨도 동일 가중치로 반영</li>
<li>해석: <span dir="rtl">”</span>모든 라벨을 고르게 잘하나?“를 평가</li>
</ul>
<p><strong>PR 관점: 불균형에서 핵심</strong></p>
<p>멀티라벨은 라벨별로 양성 비율이 크게 다르므로, ROC보다 PR(Precision–Recall) 곡선이 더 직접적이다. 라벨별 PR 곡선/라벨별 AP를 산출한 뒤 macro 평균을 내기도 한다. 운영에서는 <span dir="rtl">”</span>Recall을 조금 올리려다 FP가 폭증”하는 구간이 흔하므로, PR 곡선으로 임계값 민감도를 확인하는 것이 중요하다</p>
</section>
</section>
<section id="불균형-데이터와-어려운-샘플-학습" class="level4">
<h4 class="anchored" data-anchor-id="불균형-데이터와-어려운-샘플-학습">6. 불균형 데이터와 어려운 샘플 학습</h4>
<p>현실의 분류 문제에서는 양성이 희귀한 경우가 많고, 그 희귀한 양성 중에서도 모델이 특히 헷갈리는 샘플(경계 사례, 노이즈 포함)이 존재한다.</p>
<p>이때 성능을 좌우하는 것은 단순히 모델 구조가 아니라, (i) 학습에서 어떤 샘플에 더 큰 학습 신호를 줄 것인가와 (ii) 운영에서 어떤 기준으로 양성을 선언할 것인가(임계값 정책)이다.</p>
<p>불균형 문제는 학습과 운영을 함께 보지 않으면 <span dir="rtl">”</span>훈련 성능은 좋아 보이는데 실제 운영 성능은 나쁜” 상황이 쉽게 발생한다.</p>
<section id="클래스-불균형과-오류비용은-다른-문제다" class="level5">
<h5 class="anchored" data-anchor-id="클래스-불균형과-오류비용은-다른-문제다">(1) 클래스 불균형과 오류비용은 다른 문제다</h5>
<p>클래스 불균형은 데이터에서 양성 비율이 작은 현상으로, <span class="math inline">\(\pi = P(Y = 1) \ll 1\)</span>처럼 표현된다. 양성이 희귀하면 학습 과정에서 모델이 양성 패턴을 충분히 보지 못해, 양성에 대한 민감도가 떨어지기 쉽다.</p>
<p>반면 오류비용은 데이터 비율과 무관하게 <span dir="rtl">”</span>틀렸을 때의 손해”가 비대칭인 상황이다. 예컨대 미탐 비용 <span class="math inline">\(c_{FN}\)</span>이 크면 양성을 놓치는 것이 치명적이고, 오경보 비용 <span class="math inline">\(c_{FP}\)</span>이 크면 괜히 양성으로 띄우는 것이 더 위험하다.</p>
<p>이 비용 비대칭은 운영 의사결정에서 임계값을 바꾸는 이유가 된다. 비용 기준으로는 <span class="math inline">\(t^{*} = \frac{c_{FP}}{c_{FP} + c_{FN}}\)</span>가 자연스러운 선택이 된다. 즉 불균형은 <span dir="rtl">”</span>학습 신호의 희소화” 문제이고, 비용 비대칭은 <span dir="rtl">”</span>결정 정책” 문제다.</p>
</section>
<section id="학습단에서의-대응-손실을-가중하거나-데이터를-재구성한다" class="level5">
<h5 class="anchored" data-anchor-id="학습단에서의-대응-손실을-가중하거나-데이터를-재구성한다">(2) 학습단에서의 대응: 손실을 가중하거나, 데이터를 재구성한다</h5>
<p>불균형 대응의 가장 기본은 손실에서 양성의 기여를 키우는 것이다. 이진분류에서 확률 <span class="math inline">\(p = P(Y = 1 \mid x)\)</span>에 대한 BCE는 <span class="math inline">\(\mathcal{L}_{BCE} = - (y\log p + (1 - y)\log(1 - p))\)</span>인데, 여기에 가중치를 주면 <span class="math inline">\(\mathcal{L} = - (w_{1}y\log p + w_{0}(1 - y)\log(1 - p))\)</span>가 된다.</p>
<p>이 방식은 구현이 단순하고 효과가 빠르게 나타나지만, 가중치가 과하면 FP가 늘어나거나 예측 확률이 <span dir="rtl">”</span>양성 쪽으로 치우친” 형태가 될 수 있어, 운영 임계값을 다시 맞추는 작업이 거의 항상 필요하다.</p>
<p>다른 축은 샘플링이다. 오버샘플링은 소수 클래스를 더 자주 뽑아 학습 배치에서 양성을 자주 보게 하고, 언더샘플링은 다수 클래스를 줄여 균형을 맞춘다. 오버샘플링은 Recall 개선에 도움이 되지만 반복으로 인한 과적합 위험이 있고, 언더샘플링은 음성의 다양성을 잃어 FP가 늘 수 있다.</p>
<p>특히 샘플링으로 클래스 비율을 바꾸면 학습된 확률이 운영 분포의 확률과 어긋날 수 있으므로, <span dir="rtl">”</span>점수의 순위”는 좋아져도 <span dir="rtl">”</span>확률의 정확도(calibration)“는 나빠질 수 있다는 점을 염두에 둔다.</p>
</section>
<section id="어려운-샘플-대응-focal-loss와-hard-example-mining" class="level5">
<h5 class="anchored" data-anchor-id="어려운-샘플-대응-focal-loss와-hard-example-mining">(3) 어려운 샘플 대응: focal loss와 hard example mining</h5>
<p>불균형에서 모델을 힘들게 하는 것은 <span dir="rtl">”</span>양성이 적다”는 사실뿐 아니라 <span dir="rtl">”</span>학습이 쉬운 음성”이 너무 많아 업데이트가 그쪽으로 쏠리는 현상이다. 이때는 <span dir="rtl">”</span>쉬운 샘플의 영향은 줄이고 어려운 샘플에 집중”시키는 설계가 유효하다.</p>
<p><strong>focal loss</strong>는 정답 확률 <span class="math inline">\(p_{t}\)</span>에 대해 <span class="math inline">\(\mathcal{L}_{focal} = - \alpha(1 - p_{t})^{\gamma}\log(p_{t})\)</span>로 정의된다. <span class="math inline">\(p_{t} \approx 1\)</span>인 쉬운 샘플은 <span class="math inline">\((1 - p_{t})^{\gamma}\)</span>가 매우 작아져 학습 기여가 거의 사라지고, <span class="math inline">\(p_{t}\)</span>가 작은 어려운 샘플은 상대적으로 큰 기여를 갖는다. 결과적으로 결정경계 근처의 샘플이 학습을 주도하게 된다.</p>
<p><strong>hard example mining</strong>은 손실이 큰 샘플을 더 자주 학습에 포함시키거나, 미니배치에서 손실 상위 일부만으로 역전파하는 방식으로 <span dir="rtl">”</span>학습 신호를 어려운 사례에 집중”한다. 다만 라벨 노이즈가 있으면, 모델이 <span dir="rtl">”</span>사실 틀린 라벨”을 어려운 샘플로 착각해 과도하게 끌려갈 수 있어, 정규화나 label smoothing 같은 안정화가 함께 필요해질 수 있다.</p>
</section>
<section id="학습단에서의-대응-임계값-이동과-pr-최적화가-핵심이다" class="level5">
<h5 class="anchored" data-anchor-id="학습단에서의-대응-임계값-이동과-pr-최적화가-핵심이다">(3) 학습단에서의 대응: 임계값 이동과 PR 최적화가 핵심이다</h5>
<p>학습단에서 가중치, 샘플링, focal loss를 적용하면 모델의 점수/확률 분포가 바뀌므로, 운영에서 임계값 t를 다시 설계해야 한다.</p>
<p>이진분류의 결정은 <span class="math inline">\(\widehat{y} = 1\{ p(x) \geq t\}\)</span>로 표현되며, t를 내리면 Recall은 올라가지만 FP도 늘고, t를 올리면 FP는 줄지만 Recall이 떨어진다. 따라서 <span dir="rtl">”</span>기본값 t=0.5”는 불균형 문제에서 거의 최적이 아니다.</p>
<p>불균형에서는 ROC보다 PR 관점이 운영 품질을 더 직접적으로 보여준다. 즉 임계값은 검증셋에서 PR 곡선을 확인하면서, 운영 목적에 맞게 다음 중 하나로 선택하는 것이 일반적이다.</p>
<p>예를 들어 F1(t)를 최대화하는 t를 고르거나, <span dir="rtl">”</span><span class="math inline">\(Recall \geq r\)</span>” 같은 제약 하에 Precision을 최대화하거나, <span dir="rtl">”</span>검토량 <span class="math inline">\(\leq K\)</span>” 같은 리소스 제약을 만족하도록 t를 조정한다. 결국 불균형 대응은 학습 기법만으로 끝나지 않고, 임계값 정책까지 포함한 최적화 문제로 완성된다.</p>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>