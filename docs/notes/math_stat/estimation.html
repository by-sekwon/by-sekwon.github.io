<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>수리 통계 6. 추정 – 세상의 모든 통계 이야기</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-c1fac2584b48ed01fb6e278e36375074.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="floating nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">세상의 모든 통계 이야기</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">기초수학</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-">    
        <li>
    <a class="dropdown-item" href="../../notes/math/function.html">
 <span class="dropdown-text">함수</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/math/function_slides.html">
 <span class="dropdown-text">함수(슬라이드)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/math/derivate_integral.html">
 <span class="dropdown-text">미분적분</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/math/vector.html">
 <span class="dropdown-text">벡터</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/math/matrix.html">
 <span class="dropdown-text">행렬</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu--1" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">수리통계</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu--1">    
        <li>
    <a class="dropdown-item" href="../../notes/math_stat/probability.html">
 <span class="dropdown-text">확률</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/math_stat/random_variable.html">
 <span class="dropdown-text">확률변수</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/math_stat/famous_distribution.html">
 <span class="dropdown-text">유명한분포</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/math_stat/multi_variate.html">
 <span class="dropdown-text">다변량확률변수</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/math_stat/random_sample.html">
 <span class="dropdown-text">확률표본_난수생성</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/math_stat/estimation.html">
 <span class="dropdown-text">추정</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/math_stat/hypothesis_testing.html">
 <span class="dropdown-text">가설검정_신뢰구간</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu--2" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">조사방법론</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu--2">    
        <li>
    <a class="dropdown-item" href="../../notes/survey/survey_intro.html">
 <span class="dropdown-text">조사방법 기초</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/survey/sample_design.html">
 <span class="dropdown-text">표본설계</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/survey/questionnaire.html">
 <span class="dropdown-text">설문지</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/survey/nonresponse.html">
 <span class="dropdown-text">무응답 대체</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/survey/data_process.html">
 <span class="dropdown-text">데이터 처리</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/survey/survey_scale.html">
 <span class="dropdown-text">조사지 척도</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/survey/delphi_ahp_conjoint.html">
 <span class="dropdown-text">델파이_AHP_컨조인트</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/survey/psm.html">
 <span class="dropdown-text">PSM 성향점수매칭</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu--3" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">일변량분석</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu--3">    
        <li>
    <a class="dropdown-item" href="../../notes/intro_stat/concept_of_stat.html">
 <span class="dropdown-text">일변량분석 개념</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/intro_stat/data.html">
 <span class="dropdown-text">데이터와 통계</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/intro_stat/univariate.html">
 <span class="dropdown-text">일변량분석</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/intro_stat/crosstab.html">
 <span class="dropdown-text">교차표분석</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/intro_stat/goodness_of_fits.html">
 <span class="dropdown-text">적합성검정</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/intro_stat/normality.html">
 <span class="dropdown-text">정규변환</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/intro_stat/correlation.html">
 <span class="dropdown-text">상관분석</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/intro_stat/anova.html">
 <span class="dropdown-text">실험설계 분산분석</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/intro_stat/time_series.html">
 <span class="dropdown-text">시계열분석</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu--4" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">회귀분석</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu--4">    
        <li>
    <a class="dropdown-item" href="../../notes/linear_model/lm_concept.html">
 <span class="dropdown-text">개념&amp;추정</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/linear_model/lm_selection.html">
 <span class="dropdown-text">변수선택</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/linear_model/lm_multicolin.html">
 <span class="dropdown-text">다중공선성</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/linear_model/lm_diagnosis.html">
 <span class="dropdown-text">회귀진단</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/linear_model/lm_logistic.html">
 <span class="dropdown-text">로지스틱회귀</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../cardnews/index.html"> 
<span class="menu-text">카드뉴스</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../consult.html"> 
<span class="menu-text">통계상담</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu--5" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">📡스트리밍</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu--5">    
        <li>
    <a class="dropdown-item" href="https://by-sekwonappio-esqshnv7wueapp4da6jrizn.streamlit.app" target="_blank">
 <span class="dropdown-text">실시간주가[5대종목]</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://by-sekwonappio-k5e5n7wasvj3kveyqbwmgc.streamlit.app/" target="_blank">
 <span class="dropdown-text">대전유성구 일기예보</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">목차</h2>
   
  <ul>
  <li><a href="#chapter-1.-데이터-축소-원칙" id="toc-chapter-1.-데이터-축소-원칙" class="nav-link active" data-scroll-target="#chapter-1.-데이터-축소-원칙"><span style="color:green">chapter 1. 데이터 축소 원칙</span></a>
  <ul>
  <li><a href="#충분성-원리" id="toc-충분성-원리" class="nav-link" data-scroll-target="#충분성-원리"><span style="color:blue">1. 충분성 원리</span></a></li>
  <li><a href="#우도함수" id="toc-우도함수" class="nav-link" data-scroll-target="#우도함수"><span style="color:blue">2. 우도함수</span></a></li>
  </ul></li>
  <li><a href="#chapter-2.-점-추정" id="toc-chapter-2.-점-추정" class="nav-link" data-scroll-target="#chapter-2.-점-추정"><span style="color:green">chapter 2. 점 추정</span></a>
  <ul>
  <li><a href="#개념" id="toc-개념" class="nav-link" data-scroll-target="#개념"><span style="color:blue">1. 개념</span></a></li>
  <li><a href="#추정량-구하는-방법" id="toc-추정량-구하는-방법" class="nav-link" data-scroll-target="#추정량-구하는-방법"><span style="color:blue">2. 추정량 구하는 방법</span></a></li>
  <li><a href="#추정량-평가" id="toc-추정량-평가" class="nav-link" data-scroll-target="#추정량-평가"><span style="color:blue">3. 추정량 평가</span></a></li>
  <li><a href="#rao-balckwell-정리-mvue" id="toc-rao-balckwell-정리-mvue" class="nav-link" data-scroll-target="#rao-balckwell-정리-mvue"><span style="color:blue">4. Rao balckwell 정리 &amp; MVUE</span></a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">수리 통계 6. 추정</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><br></p>
<section id="chapter-1.-데이터-축소-원칙" class="level3">
<h3 class="anchored" data-anchor-id="chapter-1.-데이터-축소-원칙"><span style="color:green">chapter 1. 데이터 축소 원칙</span></h3>
<p>확률표본 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>으로부터 미지의 모수 <span class="math inline">\(\theta\)</span>에 대해 추론을 시도한다. 표본크기 <span class="math inline">\(n\)</span>이 크면 관찰된 표본 데이터 <span class="math inline">\(x_{1},\ldots,x_{n}\)</span>은 해석하기 어려운 긴 수열이 될 수 있으므로, 데이터 내 정보를 요약하기 위해 확률표본의 함수인 통계량을 계산한다. 데이터 축소 또는 요약의 한 형태인 <span class="math inline">\(T(\mathbf{X})\)</span>는 동일한 값을 갖더라도 상이한 표본일 수 있다.</p>
<p>여기서는 데이터 축소의 세 가지 원리에 대해 살펴본다. 미지의 모수 <span class="math inline">\(\theta\)</span>에 대한 중요한 정보를 버리지 않고 데이터 요약을 수행하는 방법과, 반대로 <span class="math inline">\(\theta\)</span>에 대한 지식 획득에 무관한 정보를 성공적으로 제거하는 방법이다.</p>
<ul>
<li><p>충분성 원리 sufficiency principle: 데이터를 요약하는 과정에서도 <span class="math inline">\(\theta\)</span>에 관한 정보를 버리지 않는 방법을 제시</p></li>
<li><p>우도 원리 likelihood principle: 관찰된 확률표본을 통해 얻어진 <span class="math inline">\(\theta\)</span>에 대한 모든 정보를 담고 있는 파라미터의 함수를 기술</p></li>
<li><p>등분산성 원리 equivariance principle: 모형의 중요한 특성들을 유지하면서 또 다른 형태의 데이터 축소를 가능하게 하는 방법을 제시</p></li>
</ul>
<section id="충분성-원리" class="level4">
<h4 class="anchored" data-anchor-id="충분성-원리"><span style="color:blue">1. 충분성 원리</span></h4>
<p>충분통계량은 어떤 모수 <span class="math inline">\(\theta\)</span>에 대해, 확률표본에 포함된 <span class="math inline">\(\theta\)</span>에 관한 모든 정보를 포착하는 통계량을 의미한다. 확률표본의 충분통계량 값 이외에 추가로 얻을 수 있는 표본의 다른 정보는 <span class="math inline">\(\theta\)</span>에 대해 더 이상 아무런 정보를 제공하지 않는다.</p>
<p><strong>【정의】</strong> <span class="math inline">\(T(\mathbf{X})\)</span>가 모수 <span class="math inline">\(\theta\)</span>에 대한 충분통계량이라면 <span class="math inline">\(\theta\)</span>에 대한 모든 추론은 확률표본 <span class="math inline">\(\mathbf{X}\)</span>의 전체 값이 아니라 <span class="math inline">\(T(\mathbf{X})\)</span>의 값만을 통해 이루어져야 한다. 즉, 두 표본 점 <span class="math inline">\(\mathbf{x}\)</span>와 <span class="math inline">\(\mathbf{y}\)</span>가 <span class="math inline">\(T(\mathbf{x}) = T(\mathbf{y})\)</span>를 만족하면, <span class="math inline">\(\theta\)</span>에 대한 추론은 <span class="math inline">\(\mathbf{X} = \mathbf{x}\)</span>가 관측되었을 때와 <span class="math inline">\(\mathbf{X} = \mathbf{y}\)</span>가 관측되었을 때 동일해야 한다.</p>
<section id="충분통계량" class="level5">
<h5 class="anchored" data-anchor-id="충분통계량">(1) 충분통계량</h5>
<p><strong>【정의】</strong> 통계량 <span class="math inline">\(T(\mathbf{X})\)</span>가 모수 <span class="math inline">\(\theta\)</span>에 대한 충분통계량이 되기 위한 조건은 다음과 같다: 조건부 분포 <span class="math inline">\(f_{\mathbf{X}|T(\mathbf{X})}(\mathbf{x}|T(\mathbf{X}) = t)\)</span>가 모수 <span class="math inline">\(\theta\)</span>에 의존하지 않을 때, <span class="math inline">\(T(\mathbf{X})\)</span>는 <span class="math inline">\(\theta\)</span>에 대한 충분통계량이다.</p>
<p>즉, 확률표본 <span class="math inline">\(\mathbf{X}\)</span>에 대한 조건부 분포가 통계량 <span class="math inline">\(T(\mathbf{X})\)</span>의 값만 주어진 상태에서 <span class="math inline">\(\theta\)</span>와 무관하다면, <span class="math inline">\(T(\mathbf{X})\)</span>만 가지고도 <span class="math inline">\(\theta\)</span>에 대해 모든 정보를 담고 있다고 본다.</p>
<p><strong>【정리】</strong> <span class="math inline">\(p(\mathbf{x}|\theta)\)</span>를 확률표본 <span class="math inline">\(\mathbf{X}\)</span>의 결합확률밀도함수라 하고, 통계량 <span class="math inline">\(T(\mathbf{X})\)</span>의 확률밀도함수를 <span class="math inline">\(q(t|\theta)\)</span>라 하자. 통계량 <span class="math inline">\(T(\mathbf{X})\)</span>가 모수 <span class="math inline">\(\theta\)</span>에 대한 충분통계량이 되기 위한 필요충분조건은, 모든 표본 <span class="math inline">\(\mathbf{x}\)</span>에 대하여 비율 <span class="math inline">\(\frac{p(\mathbf{x}|\theta)}{q(T(\mathbf{X})|\theta)}\)</span>이 모수 <span class="math inline">\(\theta\)</span>의 함수로 상수가 되는 것이다.</p>
<p><strong>【예제 ①】</strong> <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>을 모수 <span class="math inline">\(\theta \in (0,1)\)</span>인 베르누이 분포를 따르는 확률표본이라 하자. <span class="math inline">\(T(\mathbf{X}) = \sum X_{i}\)</span>는 <span class="math inline">\(\theta\)</span>에 대한 충분통계량이다.</p>
<p><span class="math inline">\(T(\mathbf{X}) = \sum X_{i} \sim B(n,\theta)\)</span>이므로 <span class="math inline">\(q(T(\mathbf{x})|\theta) \sim \binom{n}{t}\theta^{t}(1 - \theta)^{n - t}\)</span></p>
<p>결합확률밀도함수는 <span class="math inline">\(p(\mathbf{x}|\theta) = \prod\theta^{x_{i}}(1 - \theta)^{1 - x_{i}}\)</span>이다.</p>
<p><span class="math display">\[\frac{p(\mathbf{x}|\theta)}{q(T(\mathbf{x})|\theta)} = = \frac{\theta^{t}(1 - \theta)^{n - t}}{\binom{n}{t}\theta^{t}(1 - \theta)^{n - t}} = \frac{1}{\binom{n}{t}} = \frac{1}{\binom{n}{\sum x_{i}}}\]</span></p>
<p><strong>【예제 ②】</strong> <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>을 <span class="math inline">\(\sigma^{2}\)</span>가 알려진 <span class="math inline">\(N(\mu,\sigma^{2})\)</span> 정규분포를 따르는 확률표본이라 하자. <span class="math inline">\(T(\mathbf{X}) = \sum X_{i}/n\)</span>는 <span class="math inline">\(\mu\)</span>에 대한 충분통계량이다.</p>
<p><span class="math display">\[f(\mathbf{x}|\mu) = \overset{n}{\prod_{i = 1}}(2\pi\sigma^{2})^{- 1/2}\exp\left( - \frac{(x_{i} - \mu)^{2}}{2\sigma^{2}} \right)\]</span></p>
<p><span class="math display">\[\overline{X} \sim N(\mu,\sigma^{2}/n)\]</span></p>
<p><span class="math display">\[\frac{f(\mathbf{x}|\theta)}{q(T(\mathbf{x})|\theta)} = (2\pi\sigma^{2})^{- n/2}\exp\left( - \frac{\sum_{i = 1}^{n}(x_{i} - \overline{x})^{2} + n(\overline{x} - \mu)^{2}}{2\sigma^{2}} \right)/(2\pi\sigma^{2}/n)^{- 1/2}\exp\left( - \frac{n(\overline{x} - \mu)^{2}}{2\sigma^{2}} \right)\]</span></p>
<p><span class="math display">\[= n^{- 1/2}(2\pi\sigma^{2})^{- (n - 1)/2}\exp\left( - \frac{\sum_{i = 1}^{n}(x_{i} - \overline{x})^{2}}{2\sigma^{2}} \right)\]</span></p>
<p><strong>【예제 ③】</strong> 지수족 분포를 벗어나면 순서통계량보다 작은 차원의 충분통계량을 찾는 것은 불가능 하다. 비모수 검정이 필요하다.</p>
<p><span class="math inline">\(X_{1},\ldots,X_{n}\)</span>이 임의의 확률밀도함수 <span class="math inline">\(f(x)\)</span>로부터 확률분포로 추출되었다고 하자. 이때 <span class="math inline">\(f(x)\)</span>에 대한 추가적인 정보가 없는 경우(비모수 추정 상황)에는 확률표본의 순서통계량만이 정보를 담는다. 즉,</p>
<p><span class="math inline">\(f(\mathbf{x}) = \overset{n}{\prod_{i = 1}}f(x_{i}) = \overset{n}{\prod_{i = 1}}f(x_{(i)})\)</span>가 성립하므로 위의 정리에 따라 순서통계량이 충분통계량이 된다.</p>
<p><strong>(분해 정리, Factorization Theorem)</strong> <span class="math inline">\(f(\mathbf{x}|\theta)\)</span>를 표본 <span class="math inline">\(\mathbf{X}\)</span>의 결합확률밀도함수라 하자. 통계량 <span class="math inline">\(T(\mathbf{X})\)</span>가 <span class="math inline">\(\theta\)</span>에 대한 충분통계량이 되기 위한 필요충분조건은 다음과 같다. 모든 <span class="math inline">\(\mathbf{x}\)</span>와 <span class="math inline">\(\theta\)</span>에 대해, 함수 <span class="math inline">\(g(t|\theta)\)</span>와 <span class="math inline">\(h(\mathbf{x})\)</span>가 존재하여 <span class="math inline">\(f(\mathbf{x}|\theta) = g(T(\mathbf{x})|\theta)h(\mathbf{x})\)</span>를 만족할 때, <span class="math inline">\(T(\mathbf{X})\)</span>는 <span class="math inline">\(\theta\)</span>에 대한 충분통계량이다.</p>
<p>표본의 확률함수를 충분통계량만을 통한 함수 <span class="math inline">\(g\)</span>와 <span class="math inline">\(\mathbf{x}\)</span>에만 의존하는 함수 <span class="math inline">\(h\)</span>로 분해할 수 있으면, 그 통계량은 충분하다. 분해정리를 이용하여 충분통계량을 찾기 위해서는 확률표본의 결합확률밀도함수를 두 부분으로 분해한다. 한 부분은 모수 <span class="math inline">\(\theta\)</span>에 의존하지 않는 부분이고 다른 부분은 <span class="math inline">\(\theta\)</span>에 의존하는 부분이다.</p>
<p><strong>【예제 ② 계속】</strong> <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>을 <span class="math inline">\(\sigma^{2}\)</span>가 알려진 <span class="math inline">\(N(\mu,\sigma^{2})\)</span> 정규분포를 따르는 확률표본이라 하자. <span class="math inline">\(T(\mathbf{X}) = \sum X_{i}/n\)</span>는 <span class="math inline">\(\mu\)</span>에 대한 충분통계량이다.</p>
<p><span class="math display">\[f(\mathbf{x}|\mu) = (2\pi\sigma^{2})^{- n/2}\exp\left( - \overset{n}{\sum_{i = 1}}(x_{i} - \overline{x})^{2}/(2\sigma^{2}) \right)\exp\left( - n(\overline{x} - \mu)^{2}/(2\sigma^{2}) \right)\]</span></p>
<p><span class="math display">\[h(\mathbf{x}) = (2\pi\sigma^{2})^{- n/2}\exp\left( - \frac{1}{2\sigma^{2}}\overset{n}{\sum_{i = 1}}(x_{i} - \overline{x})^{2} \right)\]</span></p>
<p><span class="math inline">\(g(t|\mu) = \exp\left( - \frac{n(t - \mu)^{2}}{2\sigma^{2}} \right)\)</span>이므로 <span class="math inline">\(f(\mathbf{x}|\mu) = g(t|\mu)h(\mathbf{x})\)</span></p>
<p><strong>【예제 ④】</strong> <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>을 <span class="math inline">\(f(x|\theta) = \frac{1}{\theta},x = 1,2,...,\theta\)</span> 이산형 균일분포를 따르는 확률표본이라 하자. <span class="math inline">\(max(x_{i})\)</span>는 <span class="math inline">\(\theta\)</span>에 대한 충분통계량이다.</p>
<p><span class="math display">\[f(\mathbf{x}|\theta) = \{\begin{matrix}
\theta^{- n}, &amp; \text{if}x_{i} \in \{ 1,2,\ldots,\theta\}\text{for all}i = 1,\ldots,n \\
0, &amp; \text{otherwise}
\end{matrix}\]</span></p>
<p><span class="math display">\[h(\mathbf{x}) = \{\begin{matrix}
1, &amp; \text{if}x_{i} \in \{ 1,2,\ldots\}\text{for all}i = 1,\ldots,n \\
0, &amp; \text{otherwise}
\end{matrix}\]</span></p>
<p><span class="math inline">\(T(\mathbf{x}) = \max_{i}x_{i}\)</span>이면, <span class="math inline">\(g(t|\theta) = \{\begin{matrix}
\theta^{- n}, &amp; \text{if}t \leq \theta \\
0, &amp; \text{otherwise}
\end{matrix}\)</span></p>
<p><strong>【예제 ⑤】</strong> <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>을 <span class="math inline">\(N(\mu,\sigma^{2})\)</span> 정규분포를 따르는 확률표본이라 하자. <span class="math inline">\(T_{1}(\mathbf{x}) = \overline{X}\)</span>, <span class="math inline">\(T_{2}(\mathbf{x}) = S^{2} = \frac{1}{n - 1}\overset{n}{\sum_{i = 1}}(X_{i} - \overline{X})^{2}\)</span>은 모수 <span class="math inline">\((\mu,\sigma^{2})\)</span>에 대한 충분통계량이다.</p>
<p><span class="math inline">\(T_{1}(\mathbf{x}) = \overline{X}\)</span>, <span class="math inline">\(T_{2}(\mathbf{x}) = S^{2}\)</span>에 대하여 <span class="math inline">\(h(x) = 1\)</span>이고</p>
<p><span class="math display">\[g(t_{1},t_{2} \mid \mu,\sigma^{2}) = (2\pi\sigma^{2})^{- n/2}\exp\left( - \frac{n(t_{1} - \mu)^{2} + (n - 1)t_{2}}{2\sigma^{2}} \right)\]</span></p>
<p><span class="math display">\[f(\mathbf{x} \mid \mu,\sigma^{2}) = g\left( T_{1}(\mathbf{x}),T_{2}(\mathbf{x}) \mid \mu,\sigma^{2} \right)h(\mathbf{x})\]</span></p>
<p><strong>【정리】</strong> <span class="math inline">\(f(x \mid \theta) = h(x)c(\mathbf{\theta})\exp\left( \overset{k}{\sum_{i = 1}}w_{i}(\mathbf{\theta})t_{i}(x) \right)\)</span> 지수족 분포로부터의 충분통계량은 <span class="math inline">\(T(\mathbf{X}) = \left( \overset{n}{\sum_{j = 1}}t_{1}(X_{j}),\overset{n}{\sum_{j = 1}}t_{2}(X_{j}),\ldots,\overset{n}{\sum_{j = 1}}t_{k}(X_{j}) \right)\)</span>이다.</p>
</section>
<section id="최소-충분통계량" class="level5">
<h5 class="anchored" data-anchor-id="최소-충분통계량">(2) 최소 충분통계량</h5>
<p>충분통계량은 모수 <span class="math inline">\(\theta\)</span>에 대한 정보를 표본에서 손실 없이 요약할 수 있는 통계량이다. 그런데 모든 충분통계량이 <span dir="rtl">”</span>작거나 간단한” 것은 아닙니다. 어떤 충분통계량은 더 많은 정보를 담고 있을 수도 있다. 최소 minimal 충분통계량은 다음을 만족한다.</p>
<p>정보를 모두 보존하면서 가장 작고 요약된 형태로 되어 있는 충분통계량이다.</p>
<p>즉, 중복 없이 핵심 정보만 유지하는 가장 효율적인 통계량이다.</p>
<p><strong>【정의】</strong> 어떤 충분통계량 <span class="math inline">\(T(\mathbf{X})\)</span>이 모든 다른 충분통계량 <span class="math inline">\(T'(\mathbf{X})\)</span>에 대해, <span class="math inline">\(T(\mathbf{X})\)</span>이 <span class="math inline">\(T'(\mathbf{X})\)</span>의 함수로 표현될 수 있으면 <span class="math inline">\(T(\mathbf{X})\)</span>을 최소 충분통계량이라고 한다.</p>
<p><strong>【정리】</strong> 확률표본 <span class="math inline">\(\mathbf{X}\)</span>의 확률밀도함수가 <span class="math inline">\(f(\mathbf{x}|\theta)\)</span>로 주어졌다고 하자.</p>
<p>어떤 함수 <span class="math inline">\(T(\mathbf{x})\)</span>가 존재하여, 모든 표본점 <span class="math inline">\(\mathbf{x},\mathbf{y}\)</span>에 대해 <span class="math inline">\(\frac{f(\mathbf{x}|\theta)}{f(\mathbf{y}|\theta)}\)</span>가 <span class="math inline">\(\theta\)</span>에 대해 상수가 되는 경우가 <span class="math inline">\(T(\mathbf{x}) = T(\mathbf{y})\)</span>일 때와 정확히 일치한다면, <span class="math inline">\(T(\mathbf{X})\)</span>는 <span class="math inline">\(\theta\)</span>에 대한 최소 충분통계량이다.</p>
<p><strong>【예제 ⑥】</strong> 확률표본 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>이 <span class="math inline">\(\text{N}(\mu,\sigma^{2})\)</span>에서 추출되었고 모수 <span class="math inline">\((\mu,\sigma^{2})\)</span> 둘 다 모를 경우 <span class="math inline">\((\overline{x},s^{2})\)</span>는 최소 충분통계량이다.</p>
<p><span class="math display">\[\frac{f(\mathbf{x}|\mu,\sigma^{2})}{f(\mathbf{y}|\mu,\sigma^{2})} = \exp\left( \left\lbrack - n({\overline{x}}^{2} - {\overline{y}}^{2}) + 2n\mu(\overline{x} - \overline{y}) - (n - 1)(s_{x}^{2} - s_{y}^{2}) \right\rbrack/(2\sigma^{2}) \right)\]</span></p>
<p>이 비가 <span class="math inline">\((\mu,\sigma^{2})\)</span>에 대해 상수가 되려면 <span class="math inline">\(\overline{x} = \overline{y},s_{x}^{2} = s_{y}^{2}\)</span></p>
<p>이어야 한다. 따라서, 표본평균 <span class="math inline">\(\overline{X}\)</span>와 표본분산 <span class="math inline">\(S^{2}\)</span>는 <span class="math inline">\((\mu,\sigma^{2})\)</span></p>
<p>에 대한 최소 충분통계량이다.</p>
<p><strong>【예제 ⑦】</strong> 확률표본 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>이 <span class="math inline">\(U(\theta,\theta + 1)\)</span>에서 추출되었다고 하자. <span class="math inline">\(T(\mathbf{X}) = (X_{(1)},X_{(n)})\)</span>은 모수 <span class="math inline">\(\theta\)</span>에 대한 최소 충분통계량이다.</p>
<p><span class="math display">\[f(\mathbf{x}|\theta) = \{\begin{matrix}
1 &amp; \text{if}\theta &lt; x_{i} &lt; \theta + 1,\text{for all}i = 1,\ldots,n \\
0 &amp; \text{otherwise}
\end{matrix}\]</span></p>
<p><span class="math display">\[f(\mathbf{x}|\theta) = \{\begin{matrix}
1 &amp; \text{if}\max_{i}x_{i} - 1 &lt; \theta &lt; \min_{i}x_{i} \\
0 &amp; \text{otherwise}
\end{matrix}\]</span></p>
<p>두 표본 <span class="math inline">\(\mathbf{x},\mathbf{y}\)</span>에 대하여, 비율 <span class="math inline">\(\frac{f(\mathbf{x}|\theta)}{f(\mathbf{y}|\theta)}\)</span>이 <span class="math inline">\(\theta\)</span>에 대해 항상 일정하려면 <span class="math inline">\(\min_{i}x_{i} = \min_{i}y_{i},\max_{i}x_{i} = \max_{i}y_{i}\)</span>이어야 한다.</p>
<p>최소 충분통계량은 유일하지 않다.</p>
<p><span class="math inline">\(T'(\mathbf{X}) = (X_{(n)} - X_{(1)},(X_{(n)} + X_{(1)})/2)\)</span>,</p>
<p><span class="math inline">\(T'(\mathbf{X}) = \left( \overset{n}{\sum_{i = 1}}X_{i},\overset{n}{\sum_{i = 1}}X_{i}^{2} \right)\)</span> 또한 최소 충분통계량이다.</p>
</section>
<section id="보조-통계량" class="level5">
<h5 class="anchored" data-anchor-id="보조-통계량">(3) 보조 통계량</h5>
<p><strong>【정의】</strong> 통계량 <span class="math inline">\(S(\mathbf{X})\)</span>의 분포가 모수 <span class="math inline">\(\theta\)</span>와 무관할 때, 이를 보조 ancillary 통계량이라고 한다.</p>
<p><strong>【예제 ⑦ 계속】</strong> 확률표본 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>이 <span class="math inline">\(U(\theta,\theta + 1)\)</span>에서 추출되었다고 하자. <span class="math inline">\(T(\mathbf{X}) = (X_{(1)},X_{(n)})\)</span>은 모수 <span class="math inline">\(\theta\)</span>에 대한 최소 충분통계량이므로 <span class="math inline">\(R = X_{(n)} - X_{(1)}\)</span>은 보조 통계량이다.</p>
<p><span class="math display">\[g(x_{(1)},x_{(n)} \mid \theta) = \{\begin{matrix}
n(n - 1)(x_{(n)} - x_{(1)})^{n - 2} &amp; \text{if}\theta &lt; x_{(1)} &lt; x_{(n)} &lt; \theta + 1 \\
0 &amp; \text{otherwise}.
\end{matrix}\]</span></p>
<p><span class="math inline">\(R = X_{(n)} - X_{(1)},M = \frac{X_{(1)} + X_{(n)}}{2}\)</span> 변수변환 하면,</p>
<p><span class="math display">\[h(r,m \mid \theta) = \{\begin{matrix}
n(n - 1)r^{n - 2}, &amp; \text{if}0 &lt; r &lt; 1,\theta + \frac{r}{2} &lt; m &lt; \theta + 1 - \frac{r}{2} \\
0, &amp; \text{otherwise}.
\end{matrix}\]</span></p>
<p><span class="math display">\[h(r \mid \theta) = n(n - 1)r^{n - 2}(1 - r),0 &lt; r &lt; 1 \sim Beta(n - 1,2)\]</span></p>
<p><span class="math inline">\(R = X_{(n)} - X_{(1)}\)</span>의 확률밀도함수는 모수 <span class="math inline">\(\theta\)</span>에 의존하지 않는다.</p>
</section>
<section id="완비-통계량" class="level5">
<h5 class="anchored" data-anchor-id="완비-통계량">(4) 완비 통계량</h5>
<p>최소 충분통계량은 표본으로부터 모수 <span class="math inline">\(\theta\)</span>에 대한 모든 정보를 유지하면서, 그 외의 불필요한 정보를 최대한 제거한 통계량이다. 즉, 표본에서 모수와 관련된 핵심 정보만을 남기는 데이터 축약 방법이다. 반면, 보조 통계량은 그 분포가 모수 <span class="math inline">\(\theta\)</span>에 의존하지 않는 통계량으로 모수에 대한 정보를 전혀 담고 있지 않다.</p>
<p>이 둘은 개념적으로 구별되지만, 반드시 독립적이지는 않다. 예를 들어, <span class="math inline">\(uniform(\theta,\theta + 1)\)</span>에서, 최소값과 최대값의 조합인 <span class="math inline">\((X_{(n)} - X_{(1)},(X_{(n)} + X_{(1)})/2)\)</span>은 최소 충분통계량이 되고, 그 중 <span class="math inline">\(X_{(n)} - X_{(1)}\)</span>은 보조 통계량이 된다. 이 경우, 최소 충분통계량과 보조 통계량은 서로 독립하지 않으며, 오히려 하나의 구성요소가 된다.</p>
<p><strong>보조 통계량은 모수 추정 정밀도에 기여</strong></p>
<p><span class="math inline">\(X_{1},X_{2}\)</span>가 다음 이산분포 에서 독립적으로 관측되었다.<span class="math inline">\(P_{\theta}(X = \theta) = P_{\theta}(X = \theta + 1) = P_{\theta}(X = \theta + 2) = \frac{1}{3}\)</span>. 순서 통계량 <span class="math inline">\(X_{(1)},X_{(2)}\)</span>으로 <span class="math inline">\(R = X_{(2)} - X_{(1)},M = (X_{(1)} + X_{(2)})/2\)</span>를 정의하면, <span class="math inline">\((R,M)\)</span>은 최소 충분통계량이고, <span class="math inline">\(R\)</span>은 보조 통계량이다.</p>
<p>그러나 <span class="math inline">\(R\)</span>이 보조 통계량임에도 불구하고 모수 <span class="math inline">\(\theta\)</span>에 대해 간접적으로 중요한 정보를 제공할 수 있다. 예를 들어, 단순히 <span class="math inline">\(M = m\)</span>이라는 정보만 알고 있을 때, 가능한 <span class="math inline">\(\theta\)</span> 값은 <span class="math inline">\(m,m - 1,m - 2\)</span> 세 가지가 된다. 하지만 추가로 <span class="math inline">\(R = 2\)</span>라는 정보를 알게 되면, <span class="math inline">\(X_{(1)} = m - 1,X_{(2)} = m + 1\)</span>이 되어, 가능한 <span class="math inline">\(\theta\)</span> 값이 유일하게 <span class="math inline">\(m - 1\)</span>로 결정된다. 즉, 보조 통계량 <span class="math inline">\(R\)</span>이 모수 추정의 정밀도를 높이는 데 기여한 것이다.</p>
<p><strong>【정의】</strong> 어떤 통계량 <span class="math inline">\(T(\mathbf{X})\)</span>에 대해 확률분포족 <span class="math inline">\(f(t|\theta)\)</span>가 있을 때, 이 분포족을 완비라고 부른다. 완비란, 모든 <span class="math inline">\(\theta\)</span>에 대해 <span class="math inline">\(\mathbb{E}\theta\lbrack g(T)\rbrack = 0\)</span>이면서도, <span class="math inline">\(P_{\theta}(g(T) = 0) = 1\)</span>이 되는 경우를 말한다. 즉, 기대값이 0인 함수 <span class="math inline">\(g(T)\)</span>는 거의 확률 1로 항상 0이어야 한다는 뜻이다. 이 경우, <span class="math inline">\(T(\mathbf{X})\)</span>를 완비 통계량 complete 이라고 한다.</p>
<p><strong>【예제 ①】</strong> <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>을 모수 <span class="math inline">\(\theta \in (0,1)\)</span>인 베르누이 분포를 따르는 확률표본이라 하자. <span class="math inline">\(T(\mathbf{X}) = \sum X_{i} \sim B(n,\theta)\)</span>는 <span class="math inline">\(\theta\)</span>에 대한 완비 충분 통계량이다.</p>
<p><strong>【예제 ②】</strong> 확률표본 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>이 <span class="math inline">\(U(0,\theta)\)</span>에서 추출되었다고 하자. <span class="math inline">\(T(\mathbf{X}) = max(x_{i}) = x_{(n)}\)</span>은 모수 <span class="math inline">\(\theta\)</span>에 대한 완비 충분 통계량이다.</p>
<p><strong>(Basu<span dir="rtl">’</span>s Theorem)</strong> 만약 <span class="math inline">\(T(\mathbf{X})\)</span>가 완비하고 최소 충분 통계량이라면, <span class="math inline">\(T(\mathbf{X})\)</span>는 모든 보조 통계량과 서로 독립이다.</p>
<p>완비성과 최소충분성이라는 강력한 조건을 만족할 경우, 매개변수 <span class="math inline">\(\theta\)</span>와 무관하게 분포하는 보조통계량들과 <span class="math inline">\(T(\mathbf{X})\)</span>사이에는 어떠한 의존성도 존재하지 않음을 의미한다. 최소충분 통계량과 모수와 무관한 정보보조통계량를 분리할 수 있게 해주기 때문에, 통계 추론이나 신뢰구간 설정에 매우 유용하게 사용된다.</p>
<p><strong>【정리】</strong> <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>이 지수족 분포를 따르는 확률표본이라고 하자.</p>
<p><span class="math inline">\(f(x|\theta) = h(x)c(\theta)\exp\left( \overset{k}{\sum_{j = 1}}w(\theta_{j})t_{j}(x) \right)\)</span>. 다음 <span class="math inline">\(T(\mathbf{X})\)</span>는 완비통계량이다. <span class="math inline">\(T(\mathbf{X}) = \left( \overset{n}{\sum_{i = 1}}t_{1}(X_{i}),\overset{n}{\sum_{i = 1}}t_{2}(X_{i}),\ldots,\overset{n}{\sum_{i = 1}}t_{k}(X_{i}) \right)\)</span></p>
<p><strong>(Minimal Complete Statistic)</strong> 만약 최소 충분통계량이 존재한다면, 모든 완비통계량도 최소 충분통계량이다.</p>
<p>【예제 ③】 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>을 <span class="math inline">\(exp(\theta)\)</span>, 지수분포(지수족)를 따르는 확률표본이라 하자. <span class="math inline">\(T(\mathbf{X}) = \sum X_{i} \sim Gamma(n,\theta)\)</span>는 <span class="math inline">\(\theta\)</span>에 대한 완비 최소 충분 통계량이다.</p>
<p>【예제 ④】 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>을 <span class="math inline">\(N(\mu,\sigma^{2})\)</span>, 정규분포(지수족)를 따르는 확률표본이라 하자. <span class="math inline">\(T(\mathbf{X}) = (\overline{X},S^{2})\)</span>는 <span class="math inline">\(\theta\)</span>에 대한 완비 최소 충분 통계량이다.</p>
</section>
</section>
<section id="우도함수" class="level4">
<h4 class="anchored" data-anchor-id="우도함수"><span style="color:blue">2. 우도함수</span></h4>
<p>통계적 추론에서는 데이터로부터 정보를 요약하는 방법이 중요하다. 우도함수는 단순히 하나의 요약 방법이 아니라, 특정 원칙을 수용할 경우 필수적인 데이터 축약 장치로 간주된다.</p>
<ul>
<li><p>충분성 원칙: 관찰된 데이터가 어떤 충분한 통계량에 의해서만 정보를 제공한다면, 모든 추론은 이 충분한 통계량에만 의존해야 한다.</p></li>
<li><p>조건화 원칙: 실험 설계상 복수의 실험이 가능한 경우, 실제로 수행된 실험의 결과만을 기반으로 추론해야 한다.</p></li>
<li><p>우도 원칙: 주어진 데이터에 대한 우도함수의 형태만이 추론에 중요하며, 데이터가 관찰된 경로는 중요하지 않다.</p></li>
</ul>
<p>위의 원칙들을 받아들인다면, 우도함수는 주어진 데이터로부터 정보를 요약하는 유일하고 필수적인 수단이 된다.</p>
<section id="우도함수-1" class="level5">
<h5 class="anchored" data-anchor-id="우도함수-1">(1) 우도함수</h5>
<p><strong>【정의】</strong> 확률표본 <span class="math inline">\(\mathbf{X} = (X_{1},\ldots,X_{n})\)</span>의 결합 확률밀도함수를 <span class="math inline">\(f(\mathbf{x}|\theta)\)</span>라고 하자. 이때 표본 데이터 <span class="math inline">\(\mathbf{X} = \mathbf{x}\)</span>가 관측되었을 때, 모수 <span class="math inline">\(\theta\)</span>의 함수로 정의되는 <span class="math inline">\(L(\theta|\mathbf{x}) = f(\mathbf{x}|\theta)\)</span>를 우도함수 likelihood function 라고 한다.</p>
<p>우도함수는 관측된 데이터 <span class="math inline">\(\mathbf{x}\)</span>를 기준으로 다양한 <span class="math inline">\(\theta\)</span> 값들에 대해 상대적 타당성을 비교하는 도구이다. 이산형, 연속형 모두 우도비를 통해 두 모수에 대한 비교가 가능하다. 즉, 실제 데이터가 관측되어 우도 값이 계산된다면 우도 값이 큰 모수가 진짜 모수일 가능성이 높다.</p>
<p><strong>【예제 ①】</strong> <span class="math inline">\(NB(r = 3,p)\)</span>, 음이항분포로부터 <span class="math inline">\(X_{1} = 2\)</span> 관측되었다면 우도함수는 <span class="math inline">\(P_{p}(X = 2) = \binom{4}{2}p^{3}(1 - p)^{2}\)</span>이다.</p>
<p><strong>【우도 원리】</strong> 표본점 <span class="math inline">\(\mathbf{x},\mathbf{y}\)</span>가 다음 조건을 만족한다고 하자.</p>
<p>두 표본에 대해 우도함수 <span class="math inline">\(L(\theta|\mathbf{x})\)</span>, <span class="math inline">\(L(\theta|\mathbf{y})\)</span>가 서로 비례한다.</p>
<p>즉, 모든 <span class="math inline">\(\theta\)</span>에 대해 다음을 만족하는 상수 <span class="math inline">\(C(\mathbf{x},\mathbf{y})\)</span>가 존재한다.</p>
<p><span class="math display">\[L(\theta|\mathbf{x}) = C(\mathbf{x},\mathbf{y})L(\theta|\mathbf{y}),\text{for all}\theta\]</span></p>
<p>두 표본 <span class="math inline">\(\mathbf{x},\mathbf{y}\)</span>가 관찰되었을 때, 만약 이들의 우도함수가 비례한다면, 이 두 표본은 동일한 정보를 제공한다. 통계적 결론은 오직 우도함수 에만 의존해야 하며, 표본의 다른 세부사항에는 의존하지 않는다.</p>
</section>
<section id="공식-formal-충분-통계량-원칙" class="level5">
<h5 class="anchored" data-anchor-id="공식-formal-충분-통계량-원칙">(2) 공식 formal 충분 통계량 원칙</h5>
<p>어떤 실험 <span class="math inline">\(E = (X,\theta,\{ f(x|\theta)\})\)</span>이 수행되었고, <span class="math inline">\(T(X)\)</span>이 <span class="math inline">\(\theta\)</span>에 대한 충분통계량이라 할 때, 만약 두 관측값 <span class="math inline">\(x\)</span>와 <span class="math inline">\(y\)</span>가 <span class="math inline">\(T(x) = T(y)\)</span>를 만족한다면, 이 두 관측값이 제공하는 증거는 동일해야 한다는 것이다. 즉, 관측 데이터 전체 <span class="math inline">\(x\)</span> 자체가 아니라, 그로부터 계산된 충분통계량 <span class="math inline">\(T(x)\)</span>만이 <span class="math inline">\(\theta\)</span>에 관한 모든 정보를 요약하므로, 두 데이터가 동일한 충분통계량 값을 가질 때는, 둘 모두 <span class="math inline">\(\theta\)</span>에 대해 동일한 결론을 가져야 한다.</p>
</section>
<section id="조건화-conditionality-원칙" class="level5">
<h5 class="anchored" data-anchor-id="조건화-conditionality-원칙">(3) 조건화 conditionality 원칙</h5>
<p>여러 개의 가능한 실험이 있을 때, 어떤 실험이 실제로 수행되었는지가 매우 중요하다는 사실을 강조한다. 예를 들어, 두 개의 실험 <span class="math inline">\(E_{1},E_{2}\)</span> 중 무작위로 하나를 선택하여 시행한다고 가정하자. 이때, 어느 실험이 선택되었는지는 관측값과 함께 반드시 고려되어야 하며, 실제로 수행된 실험에 기반하여 추론이 이루어져야 한다.</p>
<p>보다 공식적으로, 혼합 실험 <span class="math inline">\(E^{*}\)</span>이 정의될 때, 실험 <span class="math inline">\(E_{j}(j = 1,2)\)</span>가 수행되고 관측값 <span class="math inline">\(x_{j}\)</span>가 주어진 경우, <span class="math inline">\(\text{Ev}(E^{,}(j,x_{j})) = \text{Ev}(E_{j},x_{j})\)</span>이어야 한다. 즉, 실험 <span class="math inline">\(E\)</span>로부터 얻어진 데이터라도 실제로 수행된 <span class="math inline">\(E_{j}\)</span>에 기반하여 해석되어야 한다. 조건화 원칙은 <span dir="rtl">”</span>오직 수행된 실험만이 중요하며, 선택되지 않은 실험들은 전혀 고려되어서는 안 된다”는 점을 명확히 한다. 이는 실험 설계 단계에서 무작위성이 개입되더라도, 실제로 수행된 실험만이 추론의 근거가 되어야 한다는 점에서 자연스럽고 설득력 있는 원칙이다.</p>
</section>
<section id="우도-원칙" class="level5">
<h5 class="anchored" data-anchor-id="우도-원칙">(4) 우도 원칙</h5>
<p>공식 충분성 원칙과 조건화 원칙을 함께 받아들이면, 우도 원칙이 도출된다. 즉, 두 실험에서 수집된 두 데이터 <span class="math inline">\(x_{1}^{*},x_{2}^{*}\)</span>가 생성하는 우도함수가 다음과 같은 비례 관계를 만족할 때, <span class="math inline">\(L(\theta|x_{2}^{*}) = CL(\theta|x_{1}^{*})\)</span>이 두 데이터는 <span class="math inline">\(\theta\)</span>에 대해 동일한 증거를 제공해야 한다.</p>
<p>따라서 관측 데이터가 생성하는 우도함수만이 파라미터에 관한 모든 정보를 담고 있으며, 우도함수가 같으면 추론 결과도 같아야 한다는 결론에 도달한다. 이는 바로 우도 원칙의 본질이다.</p>
</section>
<section id="동등성-equivariance-원칙" class="level5">
<h5 class="anchored" data-anchor-id="동등성-equivariance-원칙">(5) 동등성 Equivariance 원칙</h5>
<p>동등성 원칙에서는 함수 <span class="math inline">\(T(x)\)</span>가 지정되지만, <span class="math inline">\(T(x) = T(y)\)</span>일 때 <span class="math inline">\(x\)</span>를 관찰했을 경우와 <span class="math inline">\(y\)</span>를 관찰했을 경우 추론 결과가 <span dir="rtl">”</span>일정한 관계<span dir="rtl">”</span>를 가져야 한다고 요구한다. 반드시 동일할 필요는 없지만, 정해진 관계를 따라야 한다는 점이 특징이다. 또한 동등성 원칙은 실제로 두 가지 다른 고려사항을 결합한 것으로 이해할 수 있다:</p>
<p><strong>Measurement Equivariance</strong></p>
<p>측정 단위에 의존하지 않는 추론을 요구한다. 예를 들어, 두 산림 조사원이 각각 나무의 평균 직경을 측정한다고 하자. 한 명은 인치 단위로, 다른 한 명은 미터 단위로 데이터를 수집하였다. 비록 단위가 다르더라도, 최종적으로 동일한 추정값을 제시해야 한다. 즉, 단위 변환(예: 인치를 미터로 변환) 이후 결과가 일치해야 한다.</p>
<p><strong>Formal Invariance</strong></p>
<p>수학적 모델의 구조가 동일하다면 추론 절차 역시 동일해야 한다고 요구한다. 이는 물리적 의미(예: 단위 등)와는 무관하게, 다음 세 가지가 같다면, 동일한 추론 방법을 사용해야 한다는 것이다.</p>
<ul>
<li><p>모수 공간 <span class="math inline">\(\Theta\)</span></p></li>
<li><p>확률밀도함수 <span class="math inline">\(f(x|\theta)\)</span></p></li>
<li><p>허용 가능한 추론 및 오차</p></li>
</ul>
<p>만약 <span class="math inline">\(Y = g(X)\)</span>가 <span class="math inline">\(X\)</span>의 측정 단위 변환이고, <span class="math inline">\(Y\)</span>의 모델이 <span class="math inline">\(X\)</span>의 모델과 동일한 수학적 구조를 갖는다면, 추론 절차는 측정 단위 변화에 대해 불변하며 동시에 수학적 구조에 대해 불변해야 한다.</p>
<p><strong>【예제 ①】</strong> <span class="math inline">\(X \sim \text{Binomial}(n,p)\)</span>일 때, 성공 횟수 <span class="math inline">\(x\)</span>를 관찰한 경우를 생각한다. 실패 횟수는 <span class="math inline">\(Y = n - X\)</span>로 표현할 수 있으며, 역시 <span class="math inline">\(\text{Binomial}(n,q = 1 - p)\)</span>분포를 따른다.</p>
<p>Measurement Equivariance 요구</p>
<p>성공 수 <span class="math inline">\(x\)</span>를 기반으로 한 추정값 <span class="math inline">\(T(x)\)</span>와 실패 수 <span class="math inline">\(y = n - x\)</span>를 기반으로 한 추정값 <span class="math inline">\(T(y)\)</span>는 다음을 만족해야 한다.</p>
<p><span class="math display">\[T(x) = 1 - T(n - x)\text{or}T(x) = 1 - T(n - x)\]</span></p>
</section>
</section>
</section>
<section id="chapter-2.-점-추정" class="level3">
<h3 class="anchored" data-anchor-id="chapter-2.-점-추정"><span style="color:green">chapter 2. 점 추정</span></h3>
<section id="개념" class="level4">
<h4 class="anchored" data-anchor-id="개념"><span style="color:blue">1. 개념</span></h4>
<p>첫 번째 부분은 추정량을 찾는 방법을, 두 번째 부분은 추정량(및 기타 다른 추정량)을 평가하는 방법을 다룬다. 점추정의 논리는 매우 단순하다. 모집단이 확률밀도함수 <span class="math inline">\(f(x|\theta)\)</span>로 기술될 때 <span class="math inline">\(\theta\)</span>에 대한 지식은 모집단 전체에 대한 정보를 제공한다. 따라서, <span class="math inline">\(\theta\)</span>의 좋은 추정량을 찾는 방법을 모색하는 것은 자연스러운 일이다. 또한, 경우에 따라서는 <span class="math inline">\(\theta\)</span>의 함수, 즉 <span class="math inline">\(\tau(\theta)\)</span>가 관심 대상이 될 수도 있다.</p>
<p><strong>【정의】</strong> 점추정량은 확률표본의 함수 <span class="math inline">\(W(X_{1},\ldots,X_{n})\)</span>이다. 즉, 모든 통계량은 점추정량이다.</p>
<p>모집단 확률분포함수 <span class="math inline">\(f(x;\theta),\theta \in \Omega\)</span>의 확률표본에서 얻은 통계량이 추정에 사용된다면 이를 추정량 estimator 이라 한다. 근사할 것이라고 생각하는 하나의 값으로 제시한다면 이를 점추정 point estimate, <span class="math inline">\(\theta\)</span>을 포함하고 있을 가능성이 높은 구간을 제시하는 것은 구간추정 interval estimate이라 한다. 계산되는 공식을 추정량, 실제 데이터를 이용하여 계산된 값을 추정치 estimates 이라 한다.</p>
<p><strong>【정의】</strong> 모집단 확률분포함수 <span class="math inline">\(f(x;\theta),\theta \in \Omega\)</span>의 확률표본에서 얻은 통계량 <span class="math inline">\(T = T\left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>이 모수 추정에 사용되면 이를 추정량 이라 하고 <span class="math inline">\(\overset{\hat{}}{\theta}\)</span>이라 표현한다.</p>
<ul>
<li><p>추정량 : <span class="math inline">\(\overset{\hat{}}{\theta} = T(X_{1},X_{2},\ldots,X_{n})\)</span> 대문자로 표현</p></li>
<li><p>추정치 : : <span class="math inline">\(t(x_{1},x,\ldots,x_{n})\)</span> 관측된 값으로 소문자로 표현</p></li>
</ul>
</section>
<section id="추정량-구하는-방법" class="level4">
<h4 class="anchored" data-anchor-id="추정량-구하는-방법"><span style="color:blue">2. 추정량 구하는 방법</span></h4>
<section id="적률법" class="level5">
<h5 class="anchored" data-anchor-id="적률법">(1) 적률법</h5>
<p>가장 오랜 방법으로 적률을 이용하여 모수 추정하는 방법으로 매우 간단하나 좋은 추정량의 조건을 갖추지 않을 수 있다.</p>
<p>알려지지 않은 모집단 확률분포함수 <span class="math inline">\(f(x;\theta),\theta \in \Omega\)</span>, 확률표본 <span class="math inline">\(\left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>에서 모집단의 <span class="math inline">\(k\)</span>차 적률 <span class="math inline">\({\mu'}_{k} = E(X^{k})\)</span>과 표본의 <span class="math inline">\(k\)</span>차 적률 <span class="math inline">\(m_{k}' = E(X_{i}^{k})\)</span>이라 하자.</p>
<p><span class="math inline">\(\mu_{k}' = m_{k}\)</span>이라 놓고 풀면 모수 추정량 얻게 된다. 만약 모수 한 개 이상이면 적률에 의한 방정식을 모수 수만큼 얻어 사용하면 된다.</p>
<p><strong>【예제 ①】</strong> 모집단 <span class="math inline">\(B(n,p)\)</span>으로부터 확률표본 <span class="math inline">\(\left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>이다. 적률방법으로 추정량 <span class="math inline">\(\overset{\hat{}}{n},\overset{\hat{}}{p}\)</span> 구하라.</p>
<ul>
<li><p>모집단 적률: <span class="math inline">\(\mu_{1}' = E(X) = np,\mu_{2}' = E\left( X^{2} \right) = np(1 - p) + {(np)}^{2}\)</span></p></li>
<li><p>표본적률: <span class="math inline">\(m_{1}' = E(X) = \overset{¯}{X}\)</span>, <span class="math inline">\(m_{2}' = E\left( X^{2} \right) = \frac{1}{n}\sum X_{i}^{2}\)</span></p></li>
<li><p>방정식: <span class="math inline">\(np = \overset{¯}{X}\)</span>, <span class="math inline">\(\frac{1}{n}\sum X_{i}^{2}\)</span>=<span class="math inline">\(= np(1 - p) + {(np)}^{2}\)</span></p></li>
<li><p>모비율 추정량 : <span class="math inline">\(\widehat{p} = \overline{x}\)</span></p></li>
</ul>
<p><strong>【예제 ②】</strong> 모집단 <span class="math inline">\(N(\mu,\sigma^{2})\)</span>으로부터 확률표본 <span class="math inline">\(\left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>이다. 적률방법으로 &nbsp;<span class="math inline">\(추정량\overset{\hat{}}{\mu},\overset{\hat{}}{\sigma^{2}}\)</span> 구하라.</p>
<ul>
<li><p>모집단 적률: <span class="math inline">\(\mu_{1}' = E(X) = \mu,\mu_{2}' = E\left( X^{2} \right) = \sigma^{2} + \mu^{2}\)</span></p></li>
<li><p>표본 적률: <span class="math inline">\(m_{1}' = E(X) = \overset{¯}{X}\)</span>, <span class="math inline">\(m_{2}' = E\left( X^{2} \right) = \frac{1}{n}\sum X_{i}^{2}\)</span></p></li>
<li><p>방정식: <span class="math inline">\(\mu = \overset{¯}{X}\)</span>, <span class="math inline">\(\sigma^{2} + \mu^{2} = \frac{\sum X_{i}^{2}}{n}\)</span></p></li>
<li><p>평균 추정량: <span class="math inline">\(\overset{\hat{}}{\mu} = \overset{¯}{x}\)</span></p></li>
<li><p>분산 추정량: <span class="math inline">\(\overset{\hat{}}{\sigma^{2}} = \frac{1}{n}\sum X_{i}^{2} - {\overset{¯}{X}}^{2} = \frac{1}{n}\sum\left( X_{i} - \overset{¯}{X} \right)^{2}\)</span></p></li>
</ul>
<p><strong>【예제 ③】</strong> 모집단 <span class="math inline">\(U(0,\theta)\)</span>으로부터 확률표본 <span class="math inline">\(\left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>이다. 적률방법으로 &nbsp;추정량 <span class="math inline">\(\widehat{\theta}\)</span> 구하라.</p>
<ul>
<li><p>모집단 적률: <span class="math inline">\(\mu_{1}' = E(X) = \frac{\theta}{2}\)</span></p></li>
<li><p>표본 적률: <span class="math inline">\(m_{1}' = \overset{¯}{X}\)</span></p></li>
<li><p><span class="math inline">\(\overset{¯}{X} = \frac{\theta}{2}\)</span> 이므로 적률에 의한 추정량은 <span class="math inline">\(\overset{\hat{}}{\theta} = 2\overset{¯}{X}\)</span>이다.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 100%">
</colgroup>
<tbody>
<tr class="odd">
<td style="text-align: left;">추정량 <span class="math inline">\(\overset{\hat{}}{\theta} = 2\overset{¯}{X}\)</span>은 불편 추정량은 (<span class="math inline">\(E\left( 2\overset{¯}{X} \right) = 2\theta \neq \theta\)</span>)아니지만 일치 추정량이다. 【정리】 만약 <span class="math inline">\(\lim_{n \rightarrow \infty}{V\left( \overset{\hat{}}{\theta} \right)( = 4\frac{\theta^{2}}{12n}) = 0}\)</span>이면 &nbsp;<span class="math inline">\(\overset{\hat{}}{\theta}\)</span>는 일치 추정량이다.</td>
</tr>
</tbody>
</table></li>
</ul>
<p><strong>【예제 ④】</strong> 모집단 <span class="math inline">\(Gamma(\alpha,\beta)\)</span>으로부터 확률표본 <span class="math inline">\(\left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>이다. 적률방법으로 모수 <span class="math inline">\(\alpha,\beta\)</span> 추정량을 구하라.</p>
<ul>
<li><p>모집단 적률: <span class="math inline">\(\mu_{1}' = E(X) = \alpha\beta,\mu_{2}' = E\left( X^{2} \right) = \alpha\beta^{2} + (\alpha{\beta)}^{2}\)</span></p></li>
<li><p>표본 적률: <span class="math inline">\(m_{1}' = E(X) = \overset{¯}{X}\)</span>, <span class="math inline">\(m_{2}' = E\left( X^{2} \right) = \frac{1}{n}\sum X_{i}^{2}\)</span></p></li>
<li><p>방정식: <span class="math inline">\(\alpha\beta = \overset{¯}{X}\)</span>, <span class="math inline">\(\alpha\beta^{2} + \alpha\beta^{2} = \frac{\sum X_{i}^{2}}{n}\)</span></p></li>
<li><p>추정량: <span class="math inline">\(\overset{\hat{}}{\alpha} = \frac{n\overset{¯}{X}}{n\sum\left( X_{i} - \overset{¯}{X} \right)^{2}}\)</span>, <span class="math inline">\(\overset{\hat{}}{\beta} = \frac{\sum\left( X_{i} - \overset{¯}{X} \right)^{2}}{n\overset{¯}{X}}\)</span></p></li>
</ul>
<p>불편 추정량은 아니지만 <span class="math inline">\(\overset{¯}{X}\)</span>는 <span class="math inline">\(\alpha\beta\)</span>의 일치 추정량이고 <span class="math inline">\(\frac{1}{n}\sum X_{i}^{2}\)</span>은 <span class="math inline">\(\alpha\beta^{2} + (\alpha{\beta)}^{2}\)</span>의 일치 추정량이다. 적률에 의해 구한 추정량은 일치 추정량이기는 하지만 불편성 보장은 물론 MVUE라는 보장이 없다. 쉽게 얻을 수 있다는 장점으로 인하여 추정량을 이해하기 위하여 시작점이 된다.</p>
</section>
<section id="최대우도-추정량-mle" class="level5">
<h5 class="anchored" data-anchor-id="최대우도-추정량-mle">(2) 최대우도 추정량 MLE</h5>
<p><strong>개념</strong></p>
<p>최종적으로 최량 추정량, MVUE(minimum variance unbiased estimator 최소분산 불편 추정량)를 구하기 위하여 ⑴Factorial criterion에 의해 충분 통계량을 구하고 ⑵충분 통계량의 함수이면서 불편성을 갖는 추정량을 구하면 Rao-Blackwell 정리에 의해 이것이 MVUE이다. 그러나 불편 추정량을 구하는 것이 그렇게 쉽지만은 않다.</p>
<p>한편, 적률에 의한 추정량은 일치성은 보장하지만 불편성, MVUE는 아닐 가능성이 높다. 이제 MVUE일 가능성이 높은 추정 방법을 소개하고자 한다. 추출된(수집된) 확률표본(데이터)이 어떤 모수 값일 경우 그 값들이 추정될 가능성이 가장 높은가? 이를 최대 우도 추정량이라 한다. 통계추론에서 사용되는 추정량은 대부분 MLE이다.</p>
<p>주머니 속에 공이 3개 들어 있다. 공의 색깔은 하양, 파랑일 수 있다. 그러나 각 몇 개씩 들어 있는지는 모른다고 가정하자. 2개의 공을 뽑아 색을 보고 주머니에 있는 공의 색을 맞춘다고 하자. 공 2개를 뽑았더니 파랑이었다. 그럼? 주머니의 공은?</p>
<p>하얀 공일 확률: 1/3(<span class="math inline">\(= \binom{2}{2}\binom{1}{0}/\binom{3}{2}\)</span>), 파란 공일 확률: 1(<span class="math inline">\(= \binom{3}{2}/\binom{3}{2}\)</span>) 파랑 공이 가능성이 높다. 이렇게 모수에 대한 추정량을 구하는 방법이 최대우도 추정법이다.</p>
<p><strong>MLE 구하기</strong></p>
<p><strong>【우도함수】</strong> 알려지지 않은 모집단 확률분포함수 <span class="math inline">\(f(x;\theta),\theta \in \Omega\)</span>에 대한 정보를 얻기 위하여 추출한 크기 <span class="math inline">\(n\)</span>의 (확률)표본 <span class="math inline">\(\overline{X} = \left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>의 결합 확률밀도함수를 모수 포함한 함수로 표현한 것을 우도함수 likelihood function 이라 하며 모수의 함수이다.</p>
<p><span class="math inline">\(L\left( \theta;x_{1},x_{2},\ldots,x_{n} \right) = L(\theta;\overline{x}) = \prod_{i}^{n}{f(x_{i};}\theta)\)</span></p>
<p>확률표본(데이터) 결합 확률(표본 데이터가 수집되었다면 어떤 모수 값일 가능성이 가장 높은가)을 최대화 하는 모수 값을 MLE라 한다.</p>
<p><strong>【MLE】</strong> 우도함수 최대화 하는 <span class="math inline">\(\theta\)</span>를 최대우도 maximum likelihood 추정량 이라 한다.</p>
<p><span class="math inline">\(\frac{\partial L(\theta)}{\partial\theta} = 0\)</span>을 만족하는 추정량 <span class="math inline">\(\overset{\hat{}}{\theta}(\overline{x})\)</span>을 <span class="math inline">\(MLE\)</span> 이라 한다.</p>
<p><strong>【로그 우도함수】</strong> 우도 함수는 항상 0보다 크므로 우도함수 최대화 하는 <span class="math inline">\(\theta\)</span> 계산 ⬄ 로그 우도함수 최대화 하는 <span class="math inline">\(\theta\)</span> 계산</p>
<p><strong>【예제 ①】</strong> 어느 지역의 암 환자 비율 <span class="math inline">\(p\)</span>을 추정하려고 한다. 모수 <span class="math inline">\(p\)</span>인 베르누이 확률밀도함수로부터 확률표본을 추출하였다고 하자.</p>
<ul>
<li><p>모집단 확률밀도함수 : <span class="math inline">\(f(x;\theta = p) = p^{x}(1 - p)^{1 - x},x = 0,1\)</span></p></li>
<li><p>우도 함수: <span class="math inline">\(L(\theta;\overline{x}) = \prod_{i}^{n}{f(x_{i};p)} = \sum_{i}^{n}{p^{x_{i}}(1 - p)^{1 - x_{i}}} = p^{\sum x_{i}}(1 - p)^{n - \sum x_{i}}\)</span></p></li>
<li><p>로그 우도함수: <span class="math inline">\(l(\theta) = \ln\left( L(\theta) \right) = \sum x_{i}\ln(p) + (n - \sum x_{i})ln(1 - p)\)</span></p></li>
<li><p>MLE: <span class="math inline">\(\frac{\partial l(\theta)}{\partial\theta} = \sum x_{i}\left( \frac{1}{p} \right) + (n - \sum x_{i})\frac{1}{1 - p}( - 1) = 0\)</span>,</p></li>
</ul>
<p>그러므로 <span class="math inline">\(\overset{\hat{}}{p} = \frac{\sum x_{i}}{n}\)</span>이다.</p>
<p><strong>【예제 ②】</strong> 빼빼로 중량이 <span class="math inline">\(N(\mu,\sigma^{2})\)</span>을 따른다고 하자. 중량 평균을 추정하기 위하여 확률표본을 추출하였다고 하였다. 모집단 모수 <span class="math inline">\(\overline{\theta} = (\mu,\sigma)\)</span>는 2개이나 평균에 관심이 있으므로 <span class="math inline">\(\mu\)</span>는 목표 모수, 분산 <span class="math inline">\(\sigma^{2}\)</span>은 불필요 nuisance 모수 이다.</p>
<ul>
<li><p>모집단 확률밀도함수: <span class="math inline">\(f(x;\mu,\sigma) = \frac{1}{2\sqrt{}\pi\sigma}\exp\left( - \frac{(x - \mu)^{2}}{2\sigma^{2}} \right), - \infty &lt; x &lt; \infty\)</span></p></li>
<li><p>로그 우도함수: <span class="math inline">\(l\left( \mu,\sigma^{2} \right) = \frac{n}{2}\ln(2\pi) - \frac{1}{2}\sum\left( \frac{x_{i} - \mu}{\sigma} \right)^{2}\)</span></p></li>
<li><p>MLE: <span class="math inline">\(\frac{\partial l(\mu,\sigma)}{\partial\mu} = 0,\frac{\partial l\left( \mu,\sigma^{2} \right)}{\partial\sigma^{2}} = 0\)</span> 그러므로 <span class="math inline">\(\overset{\hat{}}{\mu} = \overset{¯}{X},{\overset{\hat{}}{\sigma}}^{2} = \frac{\sum\left( x_{i} - \overset{¯}{x} \right)^{2}}{n}\)</span>이다.</p></li>
</ul>
<p><strong>【예제 ③】</strong> 모집단 확률분포 <span class="math inline">\(U(0,\theta)\)</span>, 확률표본에서 MLE을 구하시오.</p>
<ul>
<li><p>모집단 확률밀도함수 : <span class="math inline">\(f(x;\theta) = \frac{1}{\theta},0 &lt; x &lt; \theta\)</span></p></li>
<li><p>우도함수 : <span class="math inline">\(L(\theta) = \Pi\left( \frac{1}{\theta} \right)I_{(x_{i},\theta)} = \Pi\left( \frac{1}{\theta} \right)I_{(\max\left\{ x_{i} \right\},\theta)}\)</span></p></li>
</ul>
<p><span class="math inline">\(I_{\lbrack a,b\rbrack}\)</span>은 지시 indicator 함수로 <span class="math inline">\((a &lt; b)\)</span>이면 1, 그렇지 않으면 0이다. 우도함수 최대화 되려면 <span class="math inline">\(\overset{\hat{}}{\theta} = \max\left\{ x_{i} \right\} = x_{(n)}\)</span></p>
<p><strong>【예제 ④】</strong> 라플라스분포 <span class="math inline">\(f(x;\theta) = \frac{1}{2}e^{- |x - \theta|}, - \infty &lt; x &lt; \infty, - \infty &lt; \theta &lt; \infty\)</span>을 따르는 확률표본을 이용하여 <span class="math inline">\(\theta\)</span>에 대한 MLE 구하라.</p>
<ul>
<li><p>로그 우도함수: <span class="math inline">\(l(\theta) = - nln(2) - \sum_{i}^{n}{|x_{i} - \theta|}\)</span></p></li>
<li><p>미분: $ = <em>{i}^{n}{sgn(x</em>{i} - )} = 0,wheresgn(t) = { \begin{array}{r}</p></li>
<li><p>1,t &lt; 0 \ 0,t = 0 \ 1,t &gt; 0 \end{array} .&nbsp;$</p></li>
</ul>
<p>그러므로 <span class="math inline">\(\overset{\hat{}}{\theta} = Median\)</span>, MLE이다.</p>
<p><strong>【예제 ⑤】</strong> <span class="math inline">\(N(\mu,1),where\mu &gt; 0\)</span>을 따르는 확률표본을 이용하여 <span class="math inline">\(\mu\)</span>에 대한 MLE 구하라.</p>
<ul>
<li>로그 우도함수 최대화 하는 MLE <span class="math inline">\(\overset{\hat{}}{\mu} = \overline{X}\)</span> 이므로 <span class="math inline">\(\overset{\hat{}}{\mu} = \left\{ \begin{array}{r}
\overline{X}if\overline{X} \geq 0 \\
0if\overline{X} &lt; 0
\end{array} \right.\ \)</span></li>
</ul>
<p><strong>【예제 ⑥】</strong> <span class="math inline">\(B(n,p)\)</span>을 따르는 확률표본을 이용하여 <span class="math inline">\(n\)</span>에 대한 MLE 구하라(단, <span class="math inline">\(p\)</span>는 알려져 있음). (적용) 동전의 공정성을 평가하기 위하여 몇 번을 던져야 하나?</p>
<p>우도함수 : <span class="math inline">\(L\left( k;\overline{x},p \right) = \prod_{i}^{n}{\binom{k}{x_{i}}p^{x_{i}}(1 - p)^{k - x_{i}}}\)</span></p>
<p><span class="math inline">\(k\)</span>에 대한 우도함수 미분은 쉽지 않다. 만약 <span class="math inline">\(k &lt; x_{(n)}\)</span>이면 <span class="math inline">\(L\left( k;\overline{x},p \right) = 0\)</span> 이므로 다음 조건을 만족하는 <span class="math inline">\(k \geq x_{(n)}\)</span>이 MLE이다.</p>
<p><span class="math inline">\(\frac{L\left( k;\overline{x},p \right)}{L\left( k - 1;\overline{x},p \right)} \geq 1,\frac{L\left( k + 1;\overline{x},p \right)}{L\left( k;\overline{x},p \right)} &lt; 1\)</span>.</p>
<p>그러므로 최대화 조건은 다음과 같다.<span class="math inline">\(\left( k(1 - p) \right)^{n} \geq \prod_{1}^{n}\left( k - x_{i} \right)and\left( (k + 1)(1 - p) \right)^{n} \geq \prod_{1}^{n}{(k + 1 - x_{i})}\)</span>이다. 결론적으로 <span class="math inline">\((1 - p)^{n} = \overset{n}{\prod_{i = 1}}(1 - x_{i}z)\)</span>. 구간 <span class="math inline">\(0 \leq z \leq 1/\max_{i}x_{i}\)</span> 범위 내에서 MLE 구하면 <span class="math inline">\(\widehat{k} = \lfloor 1/\widehat{z}\rfloor\)</span> 소숫점 버리고 내림한 값이다.</p>
<p><strong>MLE 성질</strong></p>
<p><strong>【invariance property】</strong> <span class="math inline">\(f(x;\theta),\theta \in \Omega\)</span>을 따르는 확률표본으로부터 <span class="math inline">\(\overset{\hat{}}{\theta}\)</span>은 MLE, <span class="math inline">\(\theta \rightarrow \tau(\theta)\)</span> 일대일 맵핑이라면 <span class="math inline">\(\tau(\theta)\)</span> MLE은 <span class="math inline">\(\tau\left( \overset{\hat{}}{\theta} \right)\)</span>이다.</p>
<p><strong>【예제 ①】</strong> <span class="math inline">\(N\left( \mu,\sigma^{2} \right)\)</span>에서 <span class="math inline">\(\overline{\theta} = (\mu,\sigma^{2})\)</span> MLE는 <span class="math inline">\(\overset{\hat{}}{\mu} = \overset{¯}{X},{\overset{\hat{}}{\sigma}}^{2} = \frac{\sum\left( x_{i} - \overset{¯}{x} \right)^{2}}{n}\)</span>.</p>
<p>invariance property에 의해 표준편차 <span class="math inline">\(\sigma = \sqrt{\sigma^{2}}(\tau(\theta))\)</span> MLE는 <span class="math inline">\(\overset{\hat{}}{\sigma} = \sqrt{\frac{\sum\left( x_{i} - \overset{¯}{x} \right)^{2}}{n}}\)</span>이다.</p>
<p><strong>【예제 ②】</strong> <span class="math inline">\(B(p)\)</span>에서 확률표본 <span class="math inline">\((X_{1},X_{2},\ldots,X_{n})\)</span>이다. <span class="math inline">\(V(X)\)</span>의 MLE 구하라.</p>
<p><span class="math inline">\(V(X) = p(1 - p)\)</span>이고 모수 <span class="math inline">\(p\)</span>에 대한 MLE은 <span class="math inline">\(\overset{\hat{}}{p} = \frac{\sum X_{i}}{n}\)</span> 이므로 분산의 MLE는 <span class="math inline">\(\overset{\hat{}}{V(X)} = \frac{\sum X_{i}}{n}(1 - \frac{\sum X_{i}}{n})\)</span>이다.</p>
<p><strong>【정의】</strong> 모수 <span class="math inline">\(\theta\)</span>에 대한 MLE <span class="math inline">\({\overset{\hat{}}{\theta}}_{mle}\)</span>은 일치 추정량이다.</p>
</section>
<section id="베이즈-추정량" class="level5">
<h5 class="anchored" data-anchor-id="베이즈-추정량">(3) 베이즈 추정량</h5>
<p>베이지안 접근법은 통계학에 대한 고전적인 접근법과 근본적으로 다른데 고전적인 접근법에서는 모수 <span class="math inline">\(\theta\)</span>가 알려지지 않지만 고정된 값으로 간주된다. 모수 <span class="math inline">\(\theta\)</span>에 대한 정보는 확률표본 <span class="math inline">\(\overline{X} = \left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>을 추출한 후 계산된 통계량을 기초하여 얻어진다.</p>
<p>베이지안 접근법에서는 모수 <span class="math inline">\(\theta\)</span>는 확률변수로서의 변동성을 갖는 양으로 간주되며 이를 사전 확률밀도함수라 한다. 이는 분석자의 믿음에 기반한 주관적인 분포로서 데이터가 관찰되기 전에 정의하고 그런 다음 모수 <span class="math inline">\(\theta\)</span>인 모집단에서 표본을 추출하고 이 표본 정보를 사용하여 사전 분포를 업데이트한다. 이 업데이트된 사전 분포를 사후 분포라고 하고 이러한 업데이트는 베이즈 정리를 사용하여 수행한다.</p>
<p><strong>【사후확률】</strong> <span class="math inline">\(\pi(\theta)\)</span> 모수 사전 prior 확률밀도함수, <span class="math inline">\(L(\theta;\overline{x})\)</span>을 우도 함수이면 확률표본 <span class="math inline">\(\overline{x} = \left( x_{1},x_{2},\ldots,x_{n} \right)\)</span>이 주어진 경우 모수에 대한 조건부 확률밀도함수를 사후 posterior 확률밀도함수라 한다.</p>
<p><span class="math inline">\(\pi\left( \theta \middle| \overline{x} \right) = \frac{\pi(\theta)L(\theta;\overline{x})}{m(\overline{x})} \propto \pi(\theta)L(\theta;\overline{x}),wherem\left( \overline{x} \right) = \int\pi(\theta)L\left( \theta;\overline{x} \right)d\theta\)</span></p>
<p><strong>【bayes estimator 베이지안 추정량 정의】</strong></p>
<ul>
<li><p>최소 squared error loss function(제곱 오차 손실함수) <span class="math inline">\(Loss\left( \theta,\overset{\hat{}}{\theta} \right) = \left( \theta - \overset{\hat{}}{\theta} \right)^{2}\)</span>: 사후 확률함수 평균</p></li>
<li><p>최소 absolute error loss function(절대 오차 손실함수) <span class="math inline">\(Loss\left( \theta,\overset{\hat{}}{\theta} \right) = |\theta - \overset{\hat{}}{\theta}|\)</span>: 사후 확률함수 중앙값</p></li>
</ul>
<p><strong>【예제 ①】</strong> <span class="math inline">\(B(p)\)</span>에서 추출한 확률표본 <span class="math inline">\(\overline{X} = \left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>을 이용하여 베이즈 추정량 구하라.</p>
<ul>
<li><p>우도함수 : <span class="math inline">\(L\left( p;\overline{x} \right) = \binom{n}{y}p^{y}(1 - p)^{n - y}wherey = \sum_{i}^{n}x_{i}\)</span></p></li>
<li><p>사전확률 : (1) uniform prior <span class="math inline">\(\pi(p) \sim U(0,1)\)</span>, (2) conjugate prior <span class="math inline">\(\pi(p) \sim Beta(\alpha,\beta)\)</span></p></li>
</ul>
<p>conjugate prior: 사후 확률밀도함수와 동일한 분포를 갖는 사전 확률밀도함수를 conjugate prior라 한다. 비율의 사후 확률밀도함수가 베타분포 이므로 사전 확률밀도함수를 베타분포이면 이를 conjugate prior라 한다.</p>
<ul>
<li><p>uniform prior 사후확률: <span class="math inline">\(\pi\left( p \middle| \overline{x} \right) \propto 1_{(0,1)}^{p}\binom{n}{y}p^{y}(1 - p)^{n - y} \sim Beta(y + 1,n - y + 1)\)</span></p></li>
<li><p>conjugate prior 사후확률: <span class="math inline">\(\pi\left( p \middle| \overline{x} \right) \propto Beta(\alpha,\beta)\binom{n}{y}p^{y}(1 - p)^{n - y} \sim Beta(\alpha + y,\beta + n - y)\)</span></p></li>
<li><p>베이즈 추정량 (제곱 오차 손실 함수 적용): <span class="math inline">\(\overset{\hat{}}{p} = \frac{y + 1}{(n + 2)}\)</span>(uniform prior), <span class="math inline">\(\overset{\hat{}}{p} = \frac{\alpha + y}{(n + \alpha + \beta)}\)</span>(conjugate prior)</p></li>
</ul>
<p><strong>【예제 ②】</strong> <span class="math inline">\(N\left( \theta,\sigma^{2} \right)\)</span>에서 추출한 확률표본 <span class="math inline">\(\overline{X} = \left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>을 이용하여 <span class="math inline">\(\left( \theta,\sigma^{2} \right)\)</span>베이즈 추정량 구하라.</p>
<ul>
<li><p>Conjugate 사전 확률밀도 함수: <span class="math inline">\(\pi(\theta) \sim N(\mu,\tau^{2})\)</span></p></li>
<li><p>사후 확률밀도함수: <span class="math inline">\(\pi\left( \theta \middle| \overline{x} \right) \sim N(\frac{\tau^{2}}{\tau^{2} + \sigma^{2}}\overline{x} + \frac{\sigma^{2}}{\tau^{2} + \sigma^{2}}\mu,\frac{\sigma^{2}\tau^{2}}{\tau^{2} + \sigma^{2}})\)</span></p></li>
<li><p>제곱 오차 손실함수 최소화 베이즈 추정량: <span class="math inline">\(\overset{\hat{}}{\theta} = \frac{\tau^{2}}{\tau^{2} + \sigma^{2}}\overline{x} + \frac{\sigma^{2}}{\tau^{2} + \sigma^{2}}\mu\)</span>.</p></li>
</ul>
</section>
</section>
<section id="추정량-평가" class="level4">
<h4 class="anchored" data-anchor-id="추정량-평가"><span style="color:blue">3. 추정량 평가</span></h4>
<p>앞 절에서는 모수의 점추정량을 구하는 여러 가지 합리적인 방법들을 소개하였다. 그러나 실제 통계 분석에서는 동일한 상황에 대해 서로 다른 추정 방법을 적용할 수 있는 경우가 많다. 따라서 여러 추정량 후보 중에서 어떤 추정량을 선택할 것인지 결정해야 하는 중요한 과제가 남는다.</p>
<p>점추정은 흔히 과녁에 화살을 쏘는 것에 비유된다. 모집단으로부터 확률표본을 얻고, 이를 바탕으로 모수를 추정하는 것은 마치 과녁을 향해 한 발의 화살을 쏘는 것과 같다. 과연 이 화살은 과녁 한가운데, 즉 bull-eye에 명중했을까? 만약 단 한 번의 시도에서 bull-eye에 명중했다고 해도, 그 사람을 진정한 명궁이라 부를 수 있을까? 아마도 아닐 것이다. 동일한 조건에서 여러 차례 화살을 쏘아, 일관되게 bull-eye에 가까운 결과를 보여줘야 비로소 실력을 인정받을 수 있을 것이다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/추정량 분포함수.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:60.0%"></p>
</figure>
</div>
<p>이와 마찬가지로, 한 번의 점추정으로는 그 추정치가 얼마나 좋은지를 판단할 수 없다. 좋은 추정량인지 판단하려면, 동일한 절차를 여러 번 반복하여 얻은 추정치들의 분포를 살펴보아야 한다. 즉, 추정치들의 평균과 분산, 그리고 그 특성을 분석함으로써 해당 추정량의 성능을 평가할 수 있다.</p>
<p>목표 모수 <span class="math inline">\(\theta\)</span>에 대한 추정량 <span class="math inline">\(\overset{\hat{}}{\theta}\)</span>을 여러 번 얻는다면(<span class="math inline">\(\overset{\hat{}}{\theta}\)</span> 확률밀도함수, <span class="math inline">\(f(\overset{\hat{}}{\theta})\)</span>,샘플링 분포도 얻을 수 있음) 그 추정량은 모수 <span class="math inline">\(\theta\)</span>을 중심으로 흩어져 있을 것이다. 모수 부근에 있을 가능성은 높고 멀어질수록 가능성은 떨어질 것이다.</p>
<section id="평균제곱오차" class="level5">
<h5 class="anchored" data-anchor-id="평균제곱오차">(1) 평균제곱오차</h5>
<p><strong>【MSE】</strong> 추정량 <span class="math inline">\(W\)</span>와 모수 <span class="math inline">\(\theta\)</span>에 대해, 평균제곱오차(Mean Squared Error, MSE)는 <span class="math inline">\(MSE(W) = E_{\theta}(W - \theta)^{2}\)</span>로 정의된다.</p>
<p>평균 절대오차 <span class="math inline">\(E_{\theta}(|W - \theta|)\)</span>)도 점추정량 성능 척도의 대안이 될 수 있으나, MSE는 다음과 같은 두 가지 강점을 가진다.</p>
<ul>
<li><p>수학적으로 다루기 쉬움</p></li>
<li><p>분산과 편향이라는 명확한 해석 가능</p></li>
</ul>
<p><span class="math display">\[MSE = E_{\theta}(W - \theta)^{2} = {Var}_{\theta}(W) + (E_{\theta}W - \theta)^{2}\]</span></p>
<p><span class="math inline">\({Var}_{\theta}(W)\)</span>: 추정량 <span class="math inline">\(W\)</span>의 분산(추정분산) - 추정량의 변동성</p>
<p><span class="math inline">\((E_{\theta}W - \theta)^{2}\)</span>: 추정량 <span class="math inline">\(W\)</span>의 편향 bias의 제곱 - 추정량이 모수에 얼마나 가까운지</p>
<p><strong>【편향】</strong> 추정량 <span class="math inline">\(W\)</span> 의 편향은 <span class="math inline">\({Bias}_{\theta}(W) = E_{\theta}W - \theta\)</span> 으로 정의된다.</p>
<p>만약 <span class="math inline">\({Bias}_{\theta}(W) = 0\)</span>이면, 추정량 W는 불편 unbiased 추정량이라 한다. 이는 모든 <span class="math inline">\(\theta\)</span>에 대해 <span class="math inline">\(E_{\theta}W = \theta\)</span>를 만족한다는 뜻이다. 불편 추정량인 경우 <span class="math inline">\(MSE_{\theta}(W) = V_{\theta}(W)\)</span>이다.</p>
<p><strong>【예제 ①】</strong> <span class="math inline">\(f(x;\theta) \sim N(\mu,\sigma^{2})\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. MLE 추정량 <span class="math inline">\(\overline{X},S^{2}\)</span>이 불편 추정량 인지 보이고 MSE 구하라.</p>
<ul>
<li><p><span class="math inline">\(E(\overline{X}) = \mu,E(S^{2}) = \sigma^{2}\)</span></p></li>
<li><p><span class="math inline">\(MSE(\overline{X}) = E(\overline{X} - \mu)^{2} = Var(\overline{X}) = \frac{\sigma^{2}}{n}\)</span></p></li>
<li><p><span class="math inline">\(MSE(S^{2}) = E(S^{2} - \sigma^{2})^{2} = Var(S^{2}) = \frac{2\sigma^{4}}{n - 1}\)</span></p></li>
</ul>
<p><strong>【예제 ②】</strong> <span class="math inline">\(f(x;\theta) \sim U(\theta,\theta + 1)\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. 추정량 <span class="math inline">\(\overset{¯}{X}\)</span>가 편의 추정량 임을 보이고 MSE 구하라.</p>
<ul>
<li><p><span class="math inline">\(E(X) = \frac{2\theta + 1}{2},V(X) = \frac{1}{12}\)</span>.</p></li>
<li><p>편의: <span class="math inline">\(B\left( \overline{x} \right) = \frac{2\theta + 1}{2} - \theta = \frac{1}{2}\)</span>.</p></li>
<li><p>추정분산 <span class="math inline">\(V\left( \overline{x} \right) = \frac{1}{12n}\)</span> 이므로 <span class="math inline">\(MSE\left( \overline{x} \right) = \frac{1}{12n} + \frac{1}{4}\)</span>이다.</p></li>
</ul>
<p><strong>【예제 ③】</strong> <span class="math inline">\(f(x;\theta) = \frac{1}{\theta}e^{- x/\theta},0 &lt; x\)</span> 에서 표본크기 3인 확률표본 <span class="math inline">\((X_{1},X_{2},X_{3})\)</span> 추출하였다. 4개 추정량 중 MSE가 가장 작은 것은?</p>
<p><span class="math inline">\((1){\overset{\hat{}}{\theta}}_{1} = X_{1}(2){\overset{\hat{}}{\theta}}_{2} = \frac{X_{1} + X_{2}}{2}(3){\overset{\hat{}}{\theta}}_{3} = \frac{X_{1} + 2X_{2}}{3}(4){\overset{\hat{}}{\theta}}_{4} = \frac{X_{1} + X_{2} + X_{3}}{3}\)</span></p>
<p><span class="math inline">\(E(X) = \theta,V(X) = \theta^{2}\)</span>이므로, <span class="math inline">\(E\left( {\overset{\hat{}}{\theta}}_{1} \right) = \theta,E\left( {\overset{\hat{}}{\theta}}_{2} \right) = \theta,E\left( {\overset{\hat{}}{\theta}}_{3} \right) = \theta,E\left( {\overset{\hat{}}{\theta}}_{4} \right) = \theta\)</span> 이므로 모두 불편 추정량 이다.</p>
<p><span class="math inline">\(MSE\left( {\overset{\hat{}}{\theta}}_{1} \right) = V\left( {\overset{\hat{}}{\theta}}_{1} \right) = \theta^{2}\)</span>, <span class="math inline">\(MSE\left( {\overset{\hat{}}{\theta}}_{2} \right) = \frac{\theta^{2}}{2}\)</span>, <span class="math inline">\(MSE\left( {\overset{\hat{}}{\theta}}_{3} \right) = \frac{5\theta^{2}}{9}\)</span>, <span class="math inline">\(MSE\left( {\overset{\hat{}}{\theta}}_{4} \right) = \frac{\theta^{2}}{3}\)</span>, 4번째 추정량 MSE가 최소</p>
<p><strong>【예제 ④】</strong> <span class="math inline">\(f(x;p) = p^{x}(1 - p)^{1 - x},x = 0,1\)</span> 베르누이 분포에서 표본크기 n인 확률표본을 추출하였다. MLE 추정량과 베이지 추정량의 MLE을 구하시오.</p>
<ul>
<li><p>모집단 평균 및 분산: <span class="math inline">\(E(X) = p,V(X) = p(1 - p)\)</span></p></li>
<li><p>MLE: <span class="math inline">\(\widehat{p} = \frac{\sum X_{i}}{n}\)</span>, <span class="math inline">\(MSE = E_{p}(\widehat{p} - p)^{2} = {Var}_{p}(\overline{X}) = \frac{p(1 - p)}{n}\)</span></p></li>
<li><p>베이지 추정량: <span class="math inline">\({\widehat{p}}_{B} = \frac{Y + \alpha}{\alpha + \beta + n}\)</span></p></li>
</ul>
<p><span class="math display">\[E_{p}({\widehat{p}}_{B} - p)^{2} = {Var}_{p}({\widehat{p}}_{B}) + ({Bias}_{p}({\widehat{p}}_{B}))^{2}\]</span></p>
<p><span class="math display">\[= {Var}_{p}\left( \frac{Y + \alpha}{\alpha + \beta + n} \right) + \left( E_{p}\left( \frac{Y + \alpha}{\alpha + \beta + n} \right) - p \right)^{2} = \frac{np(1 - p)}{(\alpha + \beta + n)^{2}} + \left( \frac{np + \alpha}{\alpha + \beta + n} - p \right)^{2}\]</span></p>
</section>
<section id="상대효율" class="level5">
<h5 class="anchored" data-anchor-id="상대효율">(2) 상대효율</h5>
<p>앞에서 살펴보았듯이 모수 <span class="math inline">\(\theta\)</span>에 대한 불편 추정량은 무수히 많이 존재한다. 두 불편 추정량 <span class="math inline">\({\overset{\hat{}}{\theta}}_{1},{\overset{\hat{}}{\theta}}_{2}\)</span>을 생각해 보자. 만약 <span class="math inline">\({V(\overset{\hat{}}{\theta}}_{1}) \leq V({\overset{\hat{}}{\theta}}_{2})\)</span>라면 <span class="math inline">\({\overset{\hat{}}{\theta}}_{1}\)</span>은 <span class="math inline">\({\overset{\hat{}}{\theta}}_{2}\)</span>에 비해 상대적으로 효율적 efficient 이라고 정의한다.</p>
<p><strong>【상대효율】</strong> <span class="math inline">\({eff(\overset{\hat{}}{\theta}}_{1},{\overset{\hat{}}{\theta}}_{2}) = \frac{{V(\overset{\hat{}}{\theta}}_{2})}{V({\overset{\hat{}}{\theta}}_{1})}\)</span>, 추정량 <span class="math inline">\({\overset{\hat{}}{\theta}}_{2}\)</span>에 대한 <span class="math inline">\({\overset{\hat{}}{\theta}}_{1}\)</span>의 상대효율이라 한다.</p>
<p><span class="math inline">\({\overset{\hat{}}{\theta}}_{1},{\overset{\hat{}}{\theta}}_{2}\)</span>가 불편 추정량이면 추정 분산과 추정 평균제곱오차은 동일하므로 추정 분산이 적은 추정량이 (즉 효율적인 추정량) 좋은 추정량이다.</p>
<p><strong>【예제 ①】</strong> <span class="math inline">\(f(x;\theta) \sim U(0,\theta)\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. <span class="math inline">\(({\overset{\hat{}}{\theta}}_{1} = 2\overline{X},{\overset{\hat{}}{\theta}}_{2} = \frac{n + 1}{n}X_{(n)})\)</span> 추정량이 불편 추정량임을 보이고 상대효율을 구하라.</p>
<ul>
<li><p><span class="math inline">\(E(X) = \frac{\theta}{2},V(\theta) = \frac{\theta^{2}}{12}\)</span>. <span class="math inline">\(E\left( {\overset{\hat{}}{\theta}}_{1} \right) = E\left( 2\overline{X} \right) = 2\frac{\theta}{2} = \theta\)</span> 불편 추정량이다.</p></li>
<li><p><span class="math inline">\(V\left( {\overset{\hat{}}{\theta}}_{1} \right) = V\left( 2\overline{X} \right) = 4\frac{\theta^{2}}{12n} = \frac{\theta^{2}}{3n}\)</span>.</p></li>
<li><p>순서 통계량 <span class="math inline">\(Y = X_{(n)}\)</span> 확률밀도함수: <span class="math inline">\(f(y) = n\left( \frac{y}{\theta} \right)^{n - 1}\left( \frac{1}{\theta} \right),0 &lt; y &lt; \theta\)</span>.</p></li>
<li><p><span class="math inline">\(E(Y) = \frac{n}{n + 1}\theta,V(Y) = \left( \frac{n}{n + 2} - \left( \frac{n}{n + 2} \right)^{2} \right)\theta^{2}\)</span>.</p></li>
<li><p><span class="math inline">\(E\left( {\overset{\hat{}}{\theta}}_{2} \right) = E\left( \frac{n + 1}{n}X_{(n)} \right) = \frac{n + 1}{n}\frac{n}{n + 1}\theta = \theta\)</span> 불편 추정량이다. .</p></li>
<li><p><span class="math inline">\(V\left( {\overset{\hat{}}{\theta}}_{2} \right) = \frac{1}{n(n + 2)}\theta^{2}\)</span>.</p></li>
<li><p><span class="math inline">\({eff(\overset{\hat{}}{\theta}}_{1},{\overset{\hat{}}{\theta}}_{2}) = \frac{{V(\overset{\hat{}}{\theta}}_{2})}{V({\overset{\hat{}}{\theta}}_{1})} = \frac{3}{n + 2}\)</span> 이므로 <span class="math inline">\(n \geq 1\)</span> 이면 <span class="math inline">\({\overset{\hat{}}{\theta}}_{1}\)</span>이 <span class="math inline">\({\overset{\hat{}}{\theta}}_{2}\)</span>에 비해 상대적으로 효율적이다.</p></li>
</ul>
<p><strong>【예제 ②】</strong> <span class="math inline">\(f(x;\theta) = \frac{1}{\theta}e^{- x/\theta},0 &lt; x\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본 <span class="math inline">\((X_{1},X_{2},\ldots,X_{n})\)</span> 추출하였다. <span class="math inline">\(({\overset{\hat{}}{\theta}}_{1} = \frac{X_{1} + X_{2}}{2},{\overset{\hat{}}{\theta}}_{2} = {\overline{X}}_{n})\)</span> 불편 추정량임을 보이고 상대효율을 구하라.</p>
<ul>
<li><p><span class="math inline">\(E(X) = \theta,V(\theta) = \theta^{2}\)</span></p></li>
<li><p><span class="math inline">\(E\left( {\overset{\hat{}}{\theta}}_{1} \right) = E\left( \frac{X_{1} + X_{2}}{2} \right) = \theta\)</span> 불편 추정량이다. <span class="math inline">\(V\left( {\overset{\hat{}}{\theta}}_{1} \right) = V\left( \frac{X_{1} + X_{2}}{2} \right) = \frac{\theta^{2}}{2}\)</span></p></li>
<li><p><span class="math inline">\(E\left( {\overset{\hat{}}{\theta}}_{2} \right) = E\left( \frac{X_{1} + X_{2} + \ldots + X_{n}}{n} \right) = \theta\)</span> 불편 추정량이다 <span class="math inline">\(V\left( {\overset{\hat{}}{\theta}}_{1} \right) = V\left( {\overline{X}}_{n} \right) = \frac{\theta^{2}}{n}\)</span></p></li>
<li><p><span class="math inline">\({eff(\overset{\hat{}}{\theta}}_{1},{\overset{\hat{}}{\theta}}_{2}) = \frac{{V(\overset{\hat{}}{\theta}}_{2})}{V({\overset{\hat{}}{\theta}}_{1})} = \frac{n}{2}\)</span> 이므로 <span class="math inline">\(n \geq 2\)</span> 이면 <span class="math inline">\({\overset{\hat{}}{\theta}}_{2}\)</span>이 <span class="math inline">\({\overset{\hat{}}{\theta}}_{1}\)</span>에 비해 상대적으로 효율적이다.</p></li>
</ul>
</section>
<section id="최량-불편-추정량" class="level5">
<h5 class="anchored" data-anchor-id="최량-불편-추정량">(3) 최량 불편 추정량</h5>
<p>최소 MSE을 갖는 추정량을 최량 추정량으로 정의하였는데 실제 MSE을 최소화 하는 추정량을 구하는 것은 쉽지 않거나(수학적 접근 매우 어려움) 실제 <span dir="rtl">”</span>최고의 MSE 추정량”은 존재하지 않는다. 이는 후보 추정량의 범위가 너무 넓기 때문인데, <span class="math inline">\(\widehat{\theta} = 17\)</span>은 <span class="math inline">\(\theta = 17\)</span>일 때 MSE가 최솟값이지만 다른 값에서는 매우 나쁜 추정량이다.</p>
<p>불편추정량으로 범위를 제한하면 후보 추정량의 범위를 불편추정량으로 제한한다. MSE 비교는 단순히 분산 비교로 귀결되므로 추정분산이 더 작은 불편추정량을 선택하면 된다.</p>
<p><strong>【정의】</strong> 추정량 <span class="math inline">\(W^{*}\)</span>가 다음 조건을 만족하면 <span class="math inline">\(\tau(\theta)\)</span>에 대한 최량 불편추정량 best unbiased estimator 이라 한다.</p>
<p>모든 <span class="math inline">\(\theta\)</span>에 대해 <span class="math inline">\(E_{\theta}W^{*} = \tau(\theta)\)</span></p>
<p>임의의 다른 추정량 <span class="math inline">\(W\)</span>에 대해 <span class="math inline">\(Var\theta(W^{*}) \leq Var\theta(W)\text{for all}\theta\)</span></p>
<p><strong>【예제 ①】</strong> <span class="math inline">\(f(x;\theta) \sim B(n,p)\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. 다음 2개 추정량에 대하여 (1) 불편 추정량인지 보이고 (2) MSE을 비교하라. <span class="math inline">\((1){\overset{\hat{}}{p}}_{1} = \frac{\sum X_{i}}{n}(2){\overset{\hat{}}{p}}_{2} = \frac{\sum X_{i} + 1}{n + 2}\)</span>.</p>
<ul>
<li><p><span class="math inline">\(E(X) = p,V(X) = p(1 - p)\)</span>.</p></li>
<li><p><span class="math inline">\(E\left( \frac{\sum X_{i}}{n} \right) = p\)</span> 이므로 <span class="math inline">\({\overset{\hat{}}{p}}_{1}\)</span>는 불편 추정량 이다.</p></li>
<li><p><span class="math inline">\(E\left( \frac{\sum X_{i} + 1}{n + 2} \right) = \frac{p + 1}{n + 2}\)</span> 이므로 <span class="math inline">\({\overset{\hat{}}{p}}_{2}\)</span>는 불편 추정량 아니다.</p></li>
<li><p><span class="math inline">\(B\left( {\overset{\hat{}}{p}}_{2} \right) = \frac{1 - np - p}{n + 2}\)</span>.</p></li>
<li><p><span class="math inline">\(MSE\left( {\overset{\hat{}}{p}}_{1} \right) = MSE\left( \frac{\sum X_{i}}{n} \right) = V\left( \frac{\sum X_{i}}{n} \right) = \frac{p(1 - p)}{n}\)</span></p></li>
<li><p><span class="math inline">\(MSE\left( {\overset{\hat{}}{p}}_{2} \right) = MSE\left( \frac{\sum X_{i} + 1}{n + 2} \right) = V\left( \frac{\sum X_{i} + 1}{n + 2} \right) + B^{2}\left( \frac{\sum X_{i} + 1}{n + 2} \right) = \frac{np(1 - p)}{(n + 2)^{2}} + \frac{(1 - np - p)^{2}}{(n + 2)^{2}}\)</span></p></li>
</ul>
<p>그러므로 <span class="math inline">\(MSE\left( {\overset{\hat{}}{p}}_{1} \right) &gt; MSE\left( {\overset{\hat{}}{p}}_{2} \right)for0 &lt; p &lt; 1\)</span>.</p>
<p><strong>【예제 ②】</strong> <span class="math inline">\(f(x;\theta) \sim Poisson(\lambda)\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. 포아송 분포는 평균, 분산이 동일하므로 표본평균(<span class="math inline">\(\overline{x}\)</span>), 표본분산(<span class="math inline">\(S^{2}\)</span>) 모두 불편 추정량이다. 어느 추정량을 사용할 것인가? 추정 분산이 적은 통계량을 사용해야 한다.</p>
<ul>
<li><p>표본평균 추정분산: <span class="math inline">\(V\left( \overset{¯}{x} \right) = \frac{\lambda}{n}\)</span>.</p></li>
<li><p>표본분산 추정분산: <span class="math inline">\(\frac{(n - 1)S^{2}}{\sigma^{2}( = \lambda)} \sim \chi^{2}(n - 1)\)</span> 이므로 <span class="math inline">\(V(S^{2}) = \frac{2\lambda^{2}}{n - 1}\)</span>이다.</p></li>
<li><p><span class="math inline">\(V(\overline{X}) \leq V(S^{2})\)</span></p></li>
</ul>
<p>최량 불편추정량을 찾는 과정은 매우 복잡하다. 만약 어떤 분포 <span class="math inline">\(f(x|\theta)\)</span>에 대해 모수 <span class="math inline">\(\tau(\theta)\)</span>의 불편추정량의 분산에 대한 하한 <span class="math inline">\(B(\theta)\)</span>를 설정할 수 있다면,<span class="math inline">\({Var}_{\theta}(W) = B(\theta)\)</span>를 만족하는 추정량을 찾으면 최량 불편추정량을 찾은 것이 된다.</p>
<p><strong>【Cramér–Rao Lower Bound, CRLB】</strong> 확률밀도함수 <span class="math inline">\(f(x|\theta)\)</span>의 확률표본으로부터의 추정량 <span class="math inline">\(W(\mathbf{X}) = W(X_{1},\ldots,X_{n})\)</span>는 다음을 만족한다면, <span class="math inline">\({Var}_{\theta}(W(\mathbf{X})) \geq \frac{\left( \frac{d}{d\theta}E_{\theta}W(\mathbf{X}) \right)^{2}}{nE_{\theta}\left( \left( \frac{\partial}{\partial\theta}\log f(\mathbf{X}|\theta) \right)^{2} \right)}\)</span></p>
<ol type="1">
<li><p><span class="math inline">\(\frac{d}{d\theta}E_{\theta}W(\mathbf{X}) = \int_{x}\frac{\partial}{\partial\theta}\lbrack W(x)f(x|\theta)\rbrack dx\)</span></p></li>
<li><p><span class="math inline">\({Var}_{\theta}(W(\mathbf{X})) &lt; \infty\)</span></p></li>
</ol>
<p><strong>【Fisher Information】</strong> 확률밀도함수 <span class="math inline">\(f(x|\theta)\)</span>가 지수족을 따르다면 <span class="math inline">\(E_{\theta}\left( \left( \frac{\partial}{\partial\theta}\log f(X|\theta) \right)^{2} \right) = - E_{\theta}\left( \frac{\partial^{2}}{\partial\theta^{2}}\log f(X|\theta) \right)\)</span></p>
<p><strong>【예제 ② 계속】</strong> <span class="math inline">\(f(x;\theta) \sim Poisson(\lambda)\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. 모수 <span class="math inline">\(\lambda\)</span>에 대한 추정량의 분산 그레머 라오 하한을 구하시오.</p>
<p>포아송분포는 지수족이므로 Fisher Information은 다음과 같다.</p>
<p><span class="math inline">\(E_{\lambda}\left( \left( \frac{\partial}{\partial\lambda}\log\overset{n}{\prod_{i = 1}}f(X_{i}|\lambda) \right)^{2} \right) = - nE_{\lambda}\left( \frac{\partial^{2}}{\partial\lambda^{2}}\log f(X|\lambda) \right)\)</span></p>
<p><span class="math inline">\(= - nE_{\lambda}\left( \frac{\partial^{2}}{\partial\lambda^{2}}\log\left( \frac{e^{- \lambda}\lambda^{X}}{X!} \right) \right) = - nE_{\lambda}\left( \frac{\partial^{2}}{\partial\lambda^{2}}\left( - \lambda + X\log\lambda - \log X! \right) \right) = \frac{n}{\lambda}\)</span></p>
<p><span class="math inline">\(V_{\lambda}(\overline{X}) = \frac{\lambda}{n}\)</span>이므로 표본평균이 크레머 라오 하한을 보장한다.</p>
<p><strong>【예제 ③】</strong> <span class="math inline">\(f(x;\theta) \sim N(\mu,\sigma^{2})\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. 모수 <span class="math inline">\(\sigma^{2}\)</span>에 대한 추정량의 분산 그레머 라오 하한을 구하시오.</p>
<p>정규분포는 지수족이므로 <span class="math display">\[\frac{\partial^{2}}{\partial(\sigma^{2})^{2}}\log\left( \frac{1}{(2\pi\sigma^{2})^{\frac{1}{2}}}e^{- (1/2)(x - \mu)^{2}/\sigma^{2}} \right) = \frac{1}{2\sigma^{4}} - \frac{(x - \mu)^{2}}{\sigma^{6}}\]</span> <span class="math display">\[- E\left( \frac{\partial^{2}}{\partial(\sigma^{2})^{2}}\log f(X|\mu,\sigma^{2}) \right) = - E\left( \frac{1}{2\sigma^{4}} - \frac{(X - \mu)^{2}}{\sigma^{6}} \right) = \frac{1}{2\sigma^{4}}\]</span></p>
<p>표본분산의 추정분산은 <span class="math inline">\(Var(S^{2} \mid \mu,\sigma^{2}) = \frac{2\sigma^{4}}{n - 1}\)</span>이므로 표본분산은 그레머 라오 하한을 만족하지 못한다.</p>
</section>
</section>
<section id="rao-balckwell-정리-mvue" class="level4">
<h4 class="anchored" data-anchor-id="rao-balckwell-정리-mvue"><span style="color:blue">4. Rao balckwell 정리 &amp; MVUE</span></h4>
<p><strong>【MVUE 정의】</strong> <span class="math inline">\(f(x;\theta)\)</span> 에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본 <span class="math inline">\((X_{1},X_{2},\ldots,X_{n})\)</span> 추출하였고 <span class="math inline">\(T(\overline{x})\)</span>은 모수 <span class="math inline">\(\theta\)</span>의 충분 통계량이다. 만약 <span class="math inline">\(T(\overline{x})\)</span> 불편 추정량이고 다른 불편 추정량의 추정 분산보다 적은 추정 분산을 가진다면 <span class="math inline">\(T(\overline{x})\)</span>를 최소분산 불편 추정량 minimum variance unbiased estimator 이라 한다.</p>
<p>충분 통계량은 모수에 대한 좋은 추정량을 발견하는데 주요 역할을 한다. 추정량 <span class="math inline">\(\widehat{\theta}\)</span>을 모수 <span class="math inline">\(\theta\)</span>의 불편 추정량, 통계량 <span class="math inline">\(U\)</span>을 모수 <span class="math inline">\(\theta\)</span>에 대한 충분 통계량이라 하자. 불편 추정량인 충분 통계량 함수는 불편 추정량 중 최소 분산을 갖는다. 만약 최소 분산을 갖는 불편 추정량을 찾는 것은 충분 통계량의 함수인 추정량에 한정하며 된다. 이에 관련된 이론이 Rao-Blackwell 정리라 한다.</p>
<p><strong>【rao-blackwell theorem】</strong> 추정량 &nbsp;<span class="math inline">\(\overset{\hat{}}{\theta}\)</span>는 모수 <span class="math inline">\(\theta\)</span>의 불편 추정량이고 추정 분산을 <span class="math inline">\(V(\overset{\hat{}}{\theta})\)</span>이라 하자. 만약 통계량 <span class="math inline">\(U\)</span>을 모수 <span class="math inline">\(\theta\)</span>에 대한 충분 통계량이라 하면 <span class="math inline">\(E(\overset{\hat{}}{\theta}|U)\)</span>은 불편 추정량이고 불편 추정량 중 최소 분산을 갖는다.</p>
<p><span class="math inline">\(X_{1},X_{2}\)</span> 확률변수에 대하여 (1) <span class="math inline">\(E\left( X_{2} \right) = E(E\left( X_{2}|X_{1} \right))\)</span> (2) <span class="math inline">\(V\left( X_{2} \right) \geq V(E\left( X_{2}|X_{1} \right))\)</span></p>
<p><span class="math inline">\(X_{1}\)</span>=모수 <span class="math inline">\(\theta\)</span> 충분 통계량 <span class="math inline">\(U\)</span>, <span class="math inline">\(X_{2}\)</span>=모수 <span class="math inline">\(\theta\)</span> 불편 통계량 <span class="math inline">\(\overset{\hat{}}{\theta}\)</span>이라 하자.</p>
<p>= <span class="math inline">\(E\left( \overset{\hat{}}{\theta} \right) = E(E\left( \overset{\hat{}}{\theta}|U \right))\)</span> 이므로 <span class="math inline">\(E(\overset{\hat{}}{\theta}|U)\)</span> 불편 추정량이다.</p>
<ul>
<li><span class="math inline">\(V\left( \overset{\hat{}}{\theta} \right) \geq V(E(\overset{\hat{}}{\theta}|U))\)</span> 이므로 불편 추정량이면서 이전보다 추정분산이 적은 추정량을 얻는다.</li>
</ul>
<p>R-B 정리는 최소분산을 갖는 불편 추정량은 충분 통계량으로 만들어질 수 있다. 만약 우리가 불편 추정량을 갖고 있다면 R-B 정리를 이용하여 이 불편 추정량을 향상 시킬 수 있다. 이렇게 얻는 추정량에 R-B 정리를 반복 적용하면 된다. 그러나 만약 동일한 충분 통계량을 사용한다면 더 이상 나아지는 것도 없다.</p>
<p><span class="math inline">\({\overset{\hat{}}{\theta}}^{*} = E(\overset{\hat{}}{\theta}|U)\)</span>을 새로 얻은 불편 추정량이라 하자. <span class="math inline">\(E\left( {\overset{\hat{}}{\theta}}^{*} \middle| U \right) = {\overset{\hat{}}{\theta}}^{*}\)</span> 이므로 충분 통계량은 수없이 많다. 그럼 어떤 충분 통계량을 시작점으로 하여 R-B 정리에 사용될까? Factorization criterion이 가장 좋은 충분 통계량을 얻게 한다. 가장 좋은 통계량이란 데이터(확률표본)에 있는 모수에 대한 정보를 가장 잘(best) 요약한 것을 의미하며 이를 Minimal 충분 통계량이라 한다.</p>
<p><strong>【정리】</strong> <span class="math inline">\(f(x;\theta)\)</span> 에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본 <span class="math inline">\((X_{1},X_{2},\ldots,X_{n})\)</span> 추출하였고 <span class="math inline">\(T(\overline{x})\)</span>을 모수 <span class="math inline">\(\theta\)</span>의 충분 통계량이라 하자. 또 다른 확률표본 <span class="math inline">\((Y_{1},Y_{2},\ldots,Y_{n})\)</span>에 대하여 <span class="math inline">\(\frac{L(x_{1},x_{2},\ldots,x_{n};\theta)}{L(y_{1},y_{2},\ldots,y_{n};\theta)}\)</span>가 모수 <span class="math inline">\(\theta\)</span>의 함수가 성립한다. ⬄ (필요 충분 조건) <span class="math inline">\(T\left( \overline{x} \right) = T(\overline{y})\)</span>. 그리고 <span class="math inline">\(T(\overline{x})\)</span>을 최소 minimal 충분 통계량이라 한다.</p>
<p>일반적으로 Factorization criterion에서 얻은 충분 통계량과 Minimal 충분 통계량은 같다. 이런 통계량이 갖는 성질을 Completeness(완비성)라 한다.</p>
<p><strong>【ancillary statistics】</strong> 모수 <span class="math inline">\(\theta\)</span>에 의존하지 않는 통계량 <span class="math inline">\(S(\overline{x})\)</span>을 보조 ancillary 통계량이라 한다.확률 분포의 모수에 관련된 정보가 아닌 추가적인 정보를 제공하는 통계량을 나타내고 모수 추정이나 가설 검정과 같은 통계적 추론에서 사용되는데, 주로 추정된 모수들의 분포나 특성을 이해하고 분석하는 데 활용된다.</p>
<p><strong>【예제】</strong> <span class="math inline">\(f(x;\theta) \sim U(\theta,\theta + 1)\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본 <span class="math inline">\((X_{1},X_{2},\ldots,X_{n})\)</span> 추출하였다. 통계량 <span class="math inline">\(R = x_{(n)} - x_{(1)}\)</span>의 확률밀도함수가 모수 <span class="math inline">\(\theta\)</span>에 의존하지 않으므로 보조 통계량이다.</p>
<p><strong>【예제】</strong> <span class="math inline">\(f(x;\theta) \sim B(\theta = p)\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본 <span class="math inline">\((X_{1},X_{2},\ldots,X_{n})\)</span> 추출하였다. 충분 통계량 <span class="math inline">\(\sum X_{i}\)</span>의 확률밀도함수는 <span class="math inline">\(B(np,np(1 - p))\)</span>로 모수 <span class="math inline">\(\theta = p\)</span>에 의존하므로 보조 통계량은 아니다. 그러나 <span class="math inline">\(\frac{\sum X_{i} - np}{\sqrt{np(1 - p)}}\)</span> 확률밀도함수는 표준정규분포(<span class="math inline">\(N(0,1)\)</span>)에 근사하므로 모수에 의존하지 않아 보조 통계량이다. 다음 장에서 이를 검정 통계량이라 한다.</p>
<p><strong>【완비성 completeness】</strong> 충분 통계량 <span class="math inline">\(T\left( \overline{x} \right) \sim f(t;\theta)\)</span>을 갖는다고 하자. 만약 <span class="math inline">\(E_{\theta}\left( g(T) \right) = 0forall\theta\)</span>가 <span class="math inline">\(P_{\theta}\left( g(T) = 0 \right) = 1forall\theta\)</span>을 포함하면 <span class="math inline">\(T\left( \overline{x} \right)\)</span>는 완비 통계량이다.</p>
<p><strong>【예제】</strong> <span class="math inline">\(f(x;\theta) \sim B(\theta = p)\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. 충분 통계량 <span class="math inline">\(\sum X_{i}\)</span>은 완비 통계량임을 보이시오.</p>
<ul>
<li><p><span class="math inline">\(T = \sum X_{i} \sim B(n,p)\)</span> 이다.</p></li>
<li><p><span class="math inline">\(0 = E_{p}\left( g(T) \right) = \sum_{t}^{n}{g(t)\binom{n}{t}p^{t}(1 - p)^{n - t} = (1 - p)^{n}}\sum_{t}^{n}{g(t)\binom{n}{t}{(\frac{p}{1 - p})}^{t}forall0 &lt; p &lt; 1}\)</span></p></li>
<li><p><span class="math inline">\(0 = \sum_{t}^{n}{g(t)\binom{n}{t}{(\frac{p}{1 - p})}^{t}}\)</span> 이 조건이 만족하기 위해서는 <span class="math inline">\(P_{\theta}\left( g(T) = 0 \right) = 1\)</span> 이므로 완비 통계량이다.</p></li>
</ul>
<p><strong>【예제】</strong> <span class="math inline">\(f(x;\theta) \sim U(0,\theta)\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본 <span class="math inline">\((X_{1},X_{2},\ldots,X_{n})\)</span> 추출하였다. 충분 통계량 <span class="math inline">\({T = x}_{(n)}\)</span>은 완비 통계량이다.</p>
<p><span class="math inline">\(T \sim f(t;\theta) = nt^{n - 1}\theta^{- n},0 &lt; t &lt; \theta\)</span> 이다. <span class="math inline">\(E_{\theta}\left( g(T) \right)\)</span>은 모수 <span class="math inline">\(\theta\)</span>의 함수이고 상수이므로 <span class="math inline">\(E_{p}\left( g(T) \right) = 0\)</span>을 보이는 것은 <span class="math inline">\({\frac{\partial}{\partial\theta}E}_{\theta}\left( g(T) \right) = 0\)</span>을 보이는 것은 동일하다.</p>
<p><span class="math inline">\({0 = \frac{\partial}{\partial\theta}E}_{\theta}\left( g(T) \right) = \frac{\partial}{\partial\theta}\int_{0}^{\theta}{g(t)}nt^{n - 1}\theta^{- n}dt = \theta^{- 1}ng(\theta)\)</span></p>
<p><span class="math inline">\(\theta^{- 1}n \neq 0\)</span> 이므로 <span class="math inline">\(g(\theta) = 0\)</span>이어야 한다. 그러므로 <span class="math inline">\({T = x}_{(n)}\)</span> 완비 통계량이다.</p>
<p><strong>【basu theorem】</strong> 최소 충분 통계량이고 완비 통계량 <span class="math inline">\(T\left( \overline{x} \right)\)</span>는 다른 모든 보조 통계량과 독립이다.</p>
<p><strong>【정리】</strong> 완비 통계량 <span class="math inline">\(T\left( \overline{x} \right)\)</span>는 최소 충분 통계량이다.</p>
<p>⑴ Factorization에 의해 충분 통계량 <span class="math inline">\(U\)</span>을 구하고 (2) <span class="math inline">\(U\)</span> 확률밀도함수의 완비성을 보이고 (3) 완비 충분 통계량 <span class="math inline">\(U\)</span>의 함수로 된 불편 추정량을 얻으면 이것이 Rao-Blackwell 정리에 의하여 MVUE가 된다.</p>
<p><strong>【lehmann and scheffe theorem】</strong> <span class="math inline">\(f(x;\theta),\theta \in \Omega\)</span> 에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였고 <span class="math inline">\(T(x_{1},x_{2},\ldots,x_{n})\)</span>은 모수 <span class="math inline">\(\theta\)</span>의 충분 통계량이라 하자. <span class="math inline">\(T(\overline{x})\)</span>의 확률밀도함수 <span class="math inline">\(f(t;\theta)\)</span>가 완비성을 갖는다면 불편성을 갖는 <span class="math inline">\(T(\overline{x})\)</span> 함수, <span class="math inline">\(g(T\left( \overline{x} \right),E(g\left( T\left( \overline{x} \right) \right) = \theta)\)</span>는 유일 최소분산불편 추정량(MVUE)이다.</p>
<p><strong>【정리】</strong> <span class="math inline">\(f(x;\theta)\)</span> 에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였고 <span class="math inline">\(T(\overline{x})\)</span>을 모수 <span class="math inline">\(\theta\)</span>의 충분 통계량, 그리고 <span class="math inline">\({\overset{\hat{}}{\theta}}_{mle}\)</span>는 MLE 추정량이라 하자. <span class="math inline">\({\overset{\hat{}}{\theta}}_{mle}\)</span>는 충분 통계량, <span class="math inline">\(T(\overline{x})\)</span>의 함수이다.</p>
<p>충분 통계량의 완비성을 증명하는 것은 쉽지 않다. 단 지수족 모집단으로부터 확률표본의 통계량 <span class="math inline">\(T = \sum K(X_{i})\)</span>는 모수 <span class="math inline">\(\theta\)</span>의 완비 충분 통계량이다.</p>
<p><strong>【정리】</strong> 지수족 확률밀도함수를 갖는 경우 <span class="math inline">\(c(\theta)\)</span>의 최소 충분 통계량은 <span class="math inline">\(\sum K(x)\)</span>이다.</p>
<p>지수족 확률밀도함수를 다음과 같이 쓸 수 있다.</p>
<p><span class="math inline">\(f(x;\theta) = h(x)g(\theta)\exp{\left( c(\theta)K(x) \right) \Longleftrightarrow}exp(c(\theta)K(x) + h(x) + g(\theta))\)</span></p>
<p><span class="math inline">\(h(x),K(x)\)</span> : 확률변수 <span class="math inline">\(x\)</span>의 함수, <span class="math inline">\(g(\theta),c(\theta)\)</span> : 모수 <span class="math inline">\(\theta\)</span>의 함수</p>
<p><strong>【예제】</strong> <span class="math inline">\(f(x;\theta) = \frac{1}{\theta},0 &lt; x &lt; \theta\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. MVUE 구하라.</p>
<ol type="1">
<li><p><span class="math inline">\({T = X}_{(n)} \sim f(t;\theta) = \frac{nt^{n - 1}}{\theta^{n}},0 &lt; t &lt; \theta\)</span>는 충분 통계량이다.</p></li>
<li><p><span class="math display">\[E_{\theta}\left( g(T) \right) = \int_{0}^{\theta}{g(t)\frac{nt^{n - 1}}{\theta^{n}}dt} = (\theta &gt; 0,n \geq 1)\int_{0}^{\theta}{g(t)t^{n - 1}dt} = 0\]</span> <span class="math inline">\(0 = g(\theta)\theta^{n - 1}\)</span>을 만족하려면 <span class="math inline">\(g(\theta) = 0\)</span>이어야 하므로 <span class="math inline">\({T = X}_{(n)}\)</span> 완비 통계량이다.</p></li>
<li><p><span class="math inline">\(E(T) = \int_{0}^{\theta}{t\frac{nt^{n - 1}}{\theta^{n}}dt = \frac{n}{n + 1}\theta}\)</span> 이므로 <span class="math inline">\(\frac{n + 1}{n}X_{(n)}\)</span>은 MVUE</p></li>
</ol>
<p><strong>【예제】</strong> <span class="math inline">\(f(x;\theta) = B(\theta = p)\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. MVUE 구하라.</p>
<p><span class="math inline">\(f(x;\theta = p) = p^{x}(1 - p)^{1 - x} = 1(1 - p)exp(ln(\frac{p}{1 - p})x)\)</span> 이므로 지수족이고 <span class="math inline">\(K\left( x_{i} \right) = x_{i}\)</span>. 그러므로 <span class="math inline">\(\sum x_{i}\)</span> 완비 충분 통계량이고 <span class="math inline">\(\sum x_{i} \sim B(n,p)\)</span> 이다. <span class="math inline">\(E\left( \sum x_{i} \right) = np\)</span> 이므로 <span class="math inline">\(\overline{X} = \frac{\sum x_{i}}{n}\)</span>는 MVUE이다.</p>
<p><strong>【예제】</strong> <span class="math inline">\(f(x;\theta = \lambda) = e^{- \lambda}\frac{\lambda^{x}}{x!}\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. MVUE 구하라.</p>
<p><span class="math inline">\(f(x;\lambda) = {\frac{1}{x!}e}^{- \lambda}(ln(\lambda)x)\)</span> 이므로 지수족이고 <span class="math inline">\(K\left( x_{i} \right) = x_{i}\)</span>. 그러므로 <span class="math inline">\(\sum x_{i}\)</span> 완비 충분 통계량이고 <span class="math inline">\(\sum x_{i} \sim P(n\lambda)\)</span> 이다.</p>
<p><span class="math inline">\(E\left( \sum x_{i} \right) = n\lambda\)</span> 이므로 <span class="math inline">\(\overline{X} = \frac{\sum x_{i}}{n}\)</span>는 MVUE이다.</p>
<p><strong>【예제】</strong> <span class="math inline">\(f(x;\theta) = \left( \frac{2x}{\theta} \right)e^{- x^{2}/\theta} \sim Weibull(\gamma = 2,\theta)\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. MVUE 구하라.</p>
<p><span class="math inline">\(f(x;\theta) = 2x\left( \frac{1}{\theta} \right)exp( - x^{2}/\theta)\)</span> 이므로 지수족이고 <span class="math inline">\(K\left( x_{i} \right) = x_{i}^{2}\)</span>. 그러므로 <span class="math inline">\(\sum x_{i}^{2}\)</span> 완비 충분 통계량이다. 변수 변환 방법 <span class="math inline">\(W = X^{2},X = \sqrt{W},J = \frac{1}{2\sqrt{w}}\)</span> 이므로 <span class="math inline">\(W \sim exponential(\theta)\)</span>이다. <span class="math inline">\(E\left( \sum x_{i}^{2} \right) = n\theta\)</span> 이므로 <span class="math inline">\(\frac{\sum x_{i}^{2}}{n}\)</span> 은 MVUE이다.</p>
<p><strong>【예제】</strong> <span class="math inline">\(f(x;\theta = \mu) = N\left( \mu,\sigma^{2} \right),where\sigma^{2}isknown\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. 모수 <span class="math inline">\(\theta = \mu\)</span>MVUE 구하라.</p>
<p><span class="math inline">\(f(x;\theta) = \frac{1}{\sqrt{2\pi}\sigma}e^{( - \mu/2\sigma^{2})}exp(\frac{\mu}{\sigma^{2}}x - \frac{x^{2}}{2\sigma^{2}})\)</span> 이므로 지수족이고 <span class="math inline">\(K\left( x_{i} \right) = x_{i}\)</span>. <span class="math inline">\(E\left( \sum x_{i} \right) = n\mu\)</span> 이므로 <span class="math inline">\(\overline{X} = \frac{\sum x_{i}}{n}\)</span>는 MVUE이다.</p>
<p><strong>【정리】</strong> 추정량 <span class="math inline">\(\overset{\hat{}}{\theta}\)</span>은 모수 <span class="math inline">\(\theta\)</span>에 대한 MVUE이고 <span class="math inline">\(g(.)\)</span>은 일대일 함수이면 <span class="math inline">\(g(\theta)\)</span>의 MVUE는 <span class="math inline">\(g(\overset{\hat{}}{\theta})\)</span> 중 불편성을 갖는 추정량이다.</p>
<p><strong>【예제】</strong> <span class="math inline">\(f(x;\theta) = B(\theta = p)\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. <span class="math inline">\(\frac{p(1 - p)}{n}\)</span>에 대한 MVUE 구하라.</p>
<p>모수 <span class="math inline">\(\theta = p\)</span>에 대한 MVUE는 <span class="math inline">\(\overline{X} = \frac{\sum x_{i}}{n}\)</span> 임을 보였다. 그러므로 <span class="math inline">\(\frac{p(1 - \theta p)}{n}\)</span>에 대한 MVUE을 구하기 위하여 분포를 알고 있는 <span class="math inline">\(Y = \sum x_{i} \sim B(n,p)\)</span> 함수를 이용하는 것이 적절하다. <span class="math inline">\(Y\)</span>는 완비 충분 통계량이므로 <span class="math inline">\(Y(1 - Y)\)</span>도 완비 충분 통계량이다.</p>
<p><span class="math inline">\(E\left( Y(1 - Y) \right) = E(Y) - E\left( Y^{2} \right) = E(Y) - \left( V(X) + E(Y)^{2} \right) = np - np(1 - p) - n^{2}p^{2}\)</span></p>
<p><span class="math inline">\(= (n - 1)p(1 - p)\)</span> 이므로 <span class="math inline">\(\frac{\theta(1 - \theta)}{n}\)</span> 의 MVUE는 <span class="math inline">\(\frac{Y(1 - Y)}{n(n - 1)}\)</span></p>
<p><strong>【예제】</strong> <span class="math inline">\(f(x;\theta) = \left( \frac{1}{\theta} \right)e^{- x/\theta} \sim exponential(\theta)\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. <span class="math inline">\(V(X) = \theta^{2}\)</span> MVUE 구하라.</p>
<p>지수분포는 지수족이고 <span class="math inline">\(K\left( x_{i} \right) = x_{i}\)</span>이므로<span class="math inline">\(\sum x_{i}\)</span> 완비 충분 통계량이므로 <span class="math inline">\(\overline{X}\)</span>는 모수 <span class="math inline">\(\theta\)</span>의 MVUE이다. 그러므로 <span class="math inline">\(V(X) = \theta^{2}\)</span>의 MVUE을 <span class="math inline">\({\overline{X}}^{2}\)</span>의 함수 중 불편 추정량을 찾으면 된다.<span class="math inline">\(E\left( {\overline{X}}^{2} \right) = V\left( \overline{X} \right) + E\left( \overline{X} \right)^{2} = \frac{\theta^{2}}{n} + \theta^{2} = \frac{n + 1}{n}\theta^{2}\)</span> 이므로 <span class="math inline">\(\frac{n\overline{X}}{n + 1}\)</span> 은 MVUE이다.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>