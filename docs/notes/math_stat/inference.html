<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>inference – 세상의 모든 통계 이야기</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-c1fac2584b48ed01fb6e278e36375074.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="floating nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">세상의 모든 통계 이야기</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">기초수학</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-">    
        <li>
    <a class="dropdown-item" href="../../notes/math/function.html">
 <span class="dropdown-text">함수</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/math/derivate_integral.html">
 <span class="dropdown-text">미분적분</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/math/vector.html">
 <span class="dropdown-text">벡터</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/math/matrix.html">
 <span class="dropdown-text">행렬</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu--1" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">수리통계</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu--1">    
        <li>
    <a class="dropdown-item" href="../../notes/math_stat/probability.html">
 <span class="dropdown-text">확률</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/math_stat/random_variable.html">
 <span class="dropdown-text">확률변수</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/math_stat/famous_distribution.html">
 <span class="dropdown-text">유명한분포</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/math_stat/multi_variate.html">
 <span class="dropdown-text">다변량확률변수</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/math_stat/random_sample.html">
 <span class="dropdown-text">확률표본</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/math_stat/inference.html">
 <span class="dropdown-text">추정과검정</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu--2" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">조사방법</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu--2">    
        <li>
    <a class="dropdown-item" href="../../notes/survey/survey_intro.html">
 <span class="dropdown-text">조사방법 기초</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/survey/sample_design.html">
 <span class="dropdown-text">표본설계</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/survey/questionnaire.html">
 <span class="dropdown-text">설문지</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/survey/nonresponse.html">
 <span class="dropdown-text">무응답 대체</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/survey/data_process.html">
 <span class="dropdown-text">데이터 처리</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/survey/survey_scale.html">
 <span class="dropdown-text">조사지 척도</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/survey/delphi_ahp_conjoint.html">
 <span class="dropdown-text">델파이 AHP 컨조인트</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../cardnews/index.html"> 
<span class="menu-text">|카드뉴스|</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../consult.html"> 
<span class="menu-text">|통계상담|</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu--3" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">📡스트리밍</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu--3">    
        <li>
    <a class="dropdown-item" href="https://by-sekwonappio-esqshnv7wueapp4da6jrizn.streamlit.app">
 <span class="dropdown-text">실시간주가[5대종목]</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://by-sekwonappio-k5e5n7wasvj3kveyqbwmgc.streamlit.app/">
 <span class="dropdown-text">대전유성구 일기예보</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<p><img src="media/image1.png" style="width:4.07621in;height:2.98414in" alt="myself.png">Chapter 1. 데이터 축소 원칙</p>
<p>vol 3. 추론통계</p>
<p>section 6. 추정과 검정</p>
<p>wolfpack se kwon</p>
<p><a href="https://sites.google.com/view/wolfpack61" class="uri">https://sites.google.com/view/wolfpack61</a></p>
<p>권세혁교수 통계노트시리즈</p>
<p>확률표본 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>으로부터 미지의 모수 <span class="math inline">\(\theta\)</span>에 대해 추론을 시도한다. 표본크기 <span class="math inline">\(n\)</span>이 크면 관찰된 표본 데이터 <span class="math inline">\(x_{1},\ldots,x_{n}\)</span>은 해석하기 어려운 긴 수열이 될 수 있으므로, 데이터 내 정보를 요약하기 위해 확률표본의 함수인 통계량을 계산한다. 데이터 축소 또는 요약의 한 형태인 <span class="math inline">\(T(\mathbf{X})\)</span>는 동일한 값을 갖더라도 상이한 표본일 수 있다.</p>
<p>여기서는 데이터 축소의 세 가지 원리에 대해 살펴본다. 미지의 모수 <span class="math inline">\(\theta\)</span>에 대한 중요한 정보를 버리지 않고 데이터 요약을 수행하는 방법과, 반대로 <span class="math inline">\(\theta\)</span>에 대한 지식 획득에 무관한 정보를 성공적으로 제거하는 방법이다.</p>
<p>충분성 원리 sufficiency principle: 데이터를 요약하는 과정에서도 <span class="math inline">\(\theta\)</span>에 관한 정보를 버리지 않는 방법을 제시</p>
<p>우도 원리 likelihood principle: 관찰된 확률표본을 통해 얻어진 <span class="math inline">\(\theta\)</span>에 대한 모든 정보를 담고 있는 파라미터의 함수를 기술</p>
<p>등분산성 원리 equivariance principle: 모형의 중요한 특성들을 유지하면서 또 다른 형태의 데이터 축소를 가능하게 하는 방법을 제시</p>
<p>1충분성 원리</p>
<p>충분통계량은 어떤 모수 <span class="math inline">\(\theta\)</span>에 대해, 확률표본에 포함된 <span class="math inline">\(\theta\)</span>에 관한 모든 정보를 포착하는 통계량을 의미한다. 확률표본의 충분통계량 값 이외에 추가로 얻을 수 있는 표본의 다른 정보는 <span class="math inline">\(\theta\)</span>에 대해 더 이상 아무런 정보를 제공하지 않는다.</p>
<p><span class="math inline">\(T(\mathbf{X})\)</span>가 모수 <span class="math inline">\(\theta\)</span>에 대한 충분통계량이라면 <span class="math inline">\(\theta\)</span>에 대한 모든 추론은 확률표본 <span class="math inline">\(\mathbf{X}\)</span>의 전체 값이 아니라 <span class="math inline">\(T(\mathbf{X})\)</span>의 값만을 통해 이루어져야 한다. 즉, 두 표본 점 <span class="math inline">\(\mathbf{x}\)</span>와 <span class="math inline">\(\mathbf{y}\)</span>가 <span class="math inline">\(T(\mathbf{x}) = T(\mathbf{y})\)</span>를 만족하면, <span class="math inline">\(\theta\)</span>에 대한 추론은 <span class="math inline">\(\mathbf{X} = \mathbf{x}\)</span>가 관측되었을 때와 <span class="math inline">\(\mathbf{X} = \mathbf{y}\)</span>가 관측되었을 때 동일해야 한다.</p>
<p>정의</p>
<p>충분통계량</p>
<p>통계량 <span class="math inline">\(T(\mathbf{X})\)</span>가 모수 <span class="math inline">\(\theta\)</span>에 대한 충분통계량이 되기 위한 조건은 다음과 같다: 조건부 분포 <span class="math inline">\(f_{\mathbf{X}|T(\mathbf{X})}(\mathbf{x}|T(\mathbf{X}) = t)\)</span>가 모수 <span class="math inline">\(\theta\)</span>에 의존하지 않을 때, <span class="math inline">\(T(\mathbf{X})\)</span>는 <span class="math inline">\(\theta\)</span>에 대한 충분통계량이다.</p>
<p>정의</p>
<p>즉, 확률표본 <span class="math inline">\(\mathbf{X}\)</span>에 대한 조건부 분포가 통계량 <span class="math inline">\(T(\mathbf{X})\)</span>의 값만 주어진 상태에서 <span class="math inline">\(\theta\)</span>와 무관하다면, <span class="math inline">\(T(\mathbf{X})\)</span>만 가지고도 <span class="math inline">\(\theta\)</span>에 대해 모든 정보를 담고 있다고 본다.</p>
<p><span class="math inline">\(p(\mathbf{x}|\theta)\)</span>를 확률표본 <span class="math inline">\(\mathbf{X}\)</span>의 결합확률밀도함수라 하고, 통계량 <span class="math inline">\(T(\mathbf{X})\)</span>의 확률밀도함수를 <span class="math inline">\(q(t|\theta)\)</span>라 하자. 통계량 <span class="math inline">\(T(\mathbf{X})\)</span>가 모수 <span class="math inline">\(\theta\)</span>에 대한 충분통계량이 되기 위한 필요충분조건은, 모든 표본 <span class="math inline">\(\mathbf{x}\)</span>에 대하여 비율 <span class="math inline">\(\frac{p(\mathbf{x}|\theta)}{q(T(\mathbf{X})|\theta)}\)</span>이 모수 <span class="math inline">\(\theta\)</span>의 함수로 상수가 되는 것이다.</p>
<p>정리</p>
<p>【예제 ①】 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>을 모수 <span class="math inline">\(\theta \in (0,1)\)</span>인 베르누이 분포를 따르는 확률표본이라 하자. <span class="math inline">\(T(\mathbf{X}) = \sum X_{i}\)</span>는 <span class="math inline">\(\theta\)</span>에 대한 충분통계량이다.</p>
<p><span class="math inline">\(T(\mathbf{X}) = \sum X_{i} \sim B(n,\theta)\)</span>이므로 <span class="math inline">\(q(T(\mathbf{x})|\theta) \sim \binom{n}{t}\theta^{t}(1 - \theta)^{n - t}\)</span></p>
<p>결합확률밀도함수는 <span class="math inline">\(p(\mathbf{x}|\theta) = \prod\theta^{x_{i}}(1 - \theta)^{1 - x_{i}}\)</span>이다.</p>
<p><span class="math display">\[\frac{p(\mathbf{x}|\theta)}{q(T(\mathbf{x})|\theta)} = = \frac{\theta^{t}(1 - \theta)^{n - t}}{\binom{n}{t}\theta^{t}(1 - \theta)^{n - t}} = \frac{1}{\binom{n}{t}} = \frac{1}{\binom{n}{\sum x_{i}}}\]</span></p>
<p>【예제 ②】 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>을 <span class="math inline">\(\sigma^{2}\)</span>가 알려진 <span class="math inline">\(N(\mu,\sigma^{2})\)</span> 정규분포를 따르는 확률표본이라 하자. <span class="math inline">\(T(\mathbf{X}) = \sum X_{i}/n\)</span>는 <span class="math inline">\(\mu\)</span>에 대한 충분통계량이다.</p>
<p><span class="math display">\[f(\mathbf{x}|\mu) = \overset{n}{\prod_{i = 1}}(2\pi\sigma^{2})^{- 1/2}\exp\left( - \frac{(x_{i} - \mu)^{2}}{2\sigma^{2}} \right)\]</span></p>
<p><span class="math display">\[\overline{X} \sim N(\mu,\sigma^{2}/n)\]</span></p>
<p><span class="math display">\[\frac{f(\mathbf{x}|\theta)}{q(T(\mathbf{x})|\theta)} = (2\pi\sigma^{2})^{- n/2}\exp\left( - \frac{\sum_{i = 1}^{n}(x_{i} - \overline{x})^{2} + n(\overline{x} - \mu)^{2}}{2\sigma^{2}} \right)/(2\pi\sigma^{2}/n)^{- 1/2}\exp\left( - \frac{n(\overline{x} - \mu)^{2}}{2\sigma^{2}} \right)\]</span></p>
<p><span class="math display">\[= n^{- 1/2}(2\pi\sigma^{2})^{- (n - 1)/2}\exp\left( - \frac{\sum_{i = 1}^{n}(x_{i} - \overline{x})^{2}}{2\sigma^{2}} \right)\]</span></p>
<p>【예제 ③】 지수족 분포를 벗어나면 순서통계량보다 작은 차원의 충분통계량을 찾는 것은 불가능 하다. 비모수 검정이 필요하다.</p>
<p><span class="math inline">\(X_{1},\ldots,X_{n}\)</span>이 임의의 확률밀도함수 <span class="math inline">\(f(x)\)</span>로부터 확률분포로 추출되었다고 하자. 이때 <span class="math inline">\(f(x)\)</span>에 대한 추가적인 정보가 없는 경우(비모수 추정 상황)에는 확률표본의 순서통계량만이 정보를 담는다. 즉,</p>
<p><span class="math inline">\(f(\mathbf{x}) = \overset{n}{\prod_{i = 1}}f(x_{i}) = \overset{n}{\prod_{i = 1}}f(x_{(i)})\)</span>가 성립하므로 위의 정리에 따라 순서통계량이 충분통계량이 된다.</p>
<p>(분해 정리, Factorization Theorem) <span class="math inline">\(f(\mathbf{x}|\theta)\)</span>를 표본 <span class="math inline">\(\mathbf{X}\)</span>의 결합확률밀도함수라 하자. 통계량 <span class="math inline">\(T(\mathbf{X})\)</span>가 <span class="math inline">\(\theta\)</span>에 대한 충분통계량이 되기 위한 필요충분조건은 다음과 같다. 모든 <span class="math inline">\(\mathbf{x}\)</span>와 <span class="math inline">\(\theta\)</span>에 대해, 함수 <span class="math inline">\(g(t|\theta)\)</span>와 <span class="math inline">\(h(\mathbf{x})\)</span>가 존재하여 <span class="math inline">\(f(\mathbf{x}|\theta) = g(T(\mathbf{x})|\theta)h(\mathbf{x})\)</span>를 만족할 때, <span class="math inline">\(T(\mathbf{X})\)</span>는 <span class="math inline">\(\theta\)</span>에 대한 충분통계량이다.</p>
<p>정리</p>
<p>표본의 확률함수를 충분통계량만을 통한 함수 <span class="math inline">\(g\)</span>와 <span class="math inline">\(\mathbf{x}\)</span>에만 의존하는 함수 <span class="math inline">\(h\)</span>로 분해할 수 있으면, 그 통계량은 충분하다. 분해정리를 이용하여 충분통계량을 찾기 위해서는 확률표본의 결합확률밀도함수를 두 부분으로 분해한다. 한 부분은 모수 <span class="math inline">\(\theta\)</span>에 의존하지 않는 부분이고 다른 부분은 <span class="math inline">\(\theta\)</span>에 의존하는 부분이다.</p>
<p>【예제 ② 계속】 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>을 <span class="math inline">\(\sigma^{2}\)</span>가 알려진 <span class="math inline">\(N(\mu,\sigma^{2})\)</span> 정규분포를 따르는 확률표본이라 하자. <span class="math inline">\(T(\mathbf{X}) = \sum X_{i}/n\)</span>는 <span class="math inline">\(\mu\)</span>에 대한 충분통계량이다.</p>
<p><span class="math display">\[f(\mathbf{x}|\mu) = (2\pi\sigma^{2})^{- n/2}\exp\left( - \overset{n}{\sum_{i = 1}}(x_{i} - \overline{x})^{2}/(2\sigma^{2}) \right)\exp\left( - n(\overline{x} - \mu)^{2}/(2\sigma^{2}) \right)\]</span></p>
<p><span class="math display">\[h(\mathbf{x}) = (2\pi\sigma^{2})^{- n/2}\exp\left( - \frac{1}{2\sigma^{2}}\overset{n}{\sum_{i = 1}}(x_{i} - \overline{x})^{2} \right)\]</span></p>
<p><span class="math inline">\(g(t|\mu) = \exp\left( - \frac{n(t - \mu)^{2}}{2\sigma^{2}} \right)\)</span>이므로 <span class="math inline">\(f(\mathbf{x}|\mu) = g(t|\mu)h(\mathbf{x})\)</span></p>
<p>【예제 ④】 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>을 <span class="math inline">\(f(x|\theta) = \frac{1}{\theta},x = 1,2,...,\theta\)</span> 이산형 균일분포를 따르는 확률표본이라 하자. <span class="math inline">\(max(x_{i})\)</span>는 <span class="math inline">\(\theta\)</span>에 대한 충분통계량이다.</p>
<p><span class="math display">\[f(\mathbf{x}|\theta) = \{\begin{matrix}
\theta^{- n}, &amp; \text{if}x_{i} \in \{ 1,2,\ldots,\theta\}\text{for all}i = 1,\ldots,n \\
0, &amp; \text{otherwise}
\end{matrix}\]</span></p>
<p><span class="math display">\[h(\mathbf{x}) = \{\begin{matrix}
1, &amp; \text{if}x_{i} \in \{ 1,2,\ldots\}\text{for all}i = 1,\ldots,n \\
0, &amp; \text{otherwise}
\end{matrix}\]</span></p>
<p><span class="math inline">\(T(\mathbf{x}) = \max_{i}x_{i}\)</span>이면, <span class="math inline">\(g(t|\theta) = \{\begin{matrix}
\theta^{- n}, &amp; \text{if}t \leq \theta \\
0, &amp; \text{otherwise}
\end{matrix}\)</span></p>
<p>【예제 ⑤】 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>을 <span class="math inline">\(N(\mu,\sigma^{2})\)</span> 정규분포를 따르는 확률표본이라 하자. <span class="math inline">\(T_{1}(\mathbf{x}) = \overline{X}\)</span>, <span class="math inline">\(T_{2}(\mathbf{x}) = S^{2} = \frac{1}{n - 1}\overset{n}{\sum_{i = 1}}(X_{i} - \overline{X})^{2}\)</span>은 모수 <span class="math inline">\((\mu,\sigma^{2})\)</span>에 대한 충분통계량이다.</p>
<p><span class="math inline">\(T_{1}(\mathbf{x}) = \overline{X}\)</span>, <span class="math inline">\(T_{2}(\mathbf{x}) = S^{2}\)</span>에 대하여 <span class="math inline">\(h(x) = 1\)</span>이고</p>
<p><span class="math display">\[g(t_{1},t_{2} \mid \mu,\sigma^{2}) = (2\pi\sigma^{2})^{- n/2}\exp\left( - \frac{n(t_{1} - \mu)^{2} + (n - 1)t_{2}}{2\sigma^{2}} \right)\]</span></p>
<p><span class="math display">\[f(\mathbf{x} \mid \mu,\sigma^{2}) = g\left( T_{1}(\mathbf{x}),T_{2}(\mathbf{x}) \mid \mu,\sigma^{2} \right)h(\mathbf{x})\]</span></p>
<p><span class="math inline">\(f(x \mid \theta) = h(x)c(\mathbf{\theta})\exp\left( \overset{k}{\sum_{i = 1}}w_{i}(\mathbf{\theta})t_{i}(x) \right)\)</span> 지수족 분포로부터의 충분통계량은 <span class="math inline">\(T(\mathbf{X}) = \left( \overset{n}{\sum_{j = 1}}t_{1}(X_{j}),\overset{n}{\sum_{j = 1}}t_{2}(X_{j}),\ldots,\overset{n}{\sum_{j = 1}}t_{k}(X_{j}) \right)\)</span>이다.</p>
<p>정리</p>
<p>최소 충분통계량</p>
<p>충분통계량은 모수 <span class="math inline">\(\theta\)</span>에 대한 정보를 표본에서 손실 없이 요약할 수 있는 통계량이다. 그런데 모든 충분통계량이 <span dir="rtl">”</span>작거나 간단한” 것은 아닙니다. 어떤 충분통계량은 더 많은 정보를 담고 있을 수도 있다. 최소 minimal 충분통계량은 다음을 만족한다.</p>
<p>정보를 모두 보존하면서 가장 작고 요약된 형태로 되어 있는 충분통계량이다.</p>
<p>즉, 중복 없이 핵심 정보만 유지하는 가장 효율적인 통계량이다.</p>
<p>어떤 충분통계량 <span class="math inline">\(T(\mathbf{X})\)</span>이 모든 다른 충분통계량 <span class="math inline">\(T'(\mathbf{X})\)</span>에 대해, <span class="math inline">\(T(\mathbf{X})\)</span>이 <span class="math inline">\(T'(\mathbf{X})\)</span>의 함수로 표현될 수 있으면 <span class="math inline">\(T(\mathbf{X})\)</span>을 최소 충분통계량이라고 한다.</p>
<p>정의</p>
<p>확률표본 <span class="math inline">\(\mathbf{X}\)</span>의 확률밀도함수가 <span class="math inline">\(f(\mathbf{x}|\theta)\)</span>로 주어졌다고 하자.</p>
<p>정리</p>
<p>어떤 함수 <span class="math inline">\(T(\mathbf{x})\)</span>가 존재하여, 모든 표본점 <span class="math inline">\(\mathbf{x},\mathbf{y}\)</span>에 대해 <span class="math inline">\(\frac{f(\mathbf{x}|\theta)}{f(\mathbf{y}|\theta)}\)</span>가 <span class="math inline">\(\theta\)</span>에 대해 상수가 되는 경우가 <span class="math inline">\(T(\mathbf{x}) = T(\mathbf{y})\)</span>일 때와 정확히 일치한다면, <span class="math inline">\(T(\mathbf{X})\)</span>는 <span class="math inline">\(\theta\)</span>에 대한 최소 충분통계량이다.</p>
<p>【예제 ⑤】 확률표본 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>이 <span class="math inline">\(\text{N}(\mu,\sigma^{2})\)</span>에서 추출되었고 모수 <span class="math inline">\((\mu,\sigma^{2})\)</span> 둘 다 모를 경우 <span class="math inline">\((\overline{x},s^{2})\)</span>는 최소 충분통계량이다.</p>
<p><span class="math display">\[\frac{f(\mathbf{x}|\mu,\sigma^{2})}{f(\mathbf{y}|\mu,\sigma^{2})} = \exp\left( \left\lbrack - n({\overline{x}}^{2} - {\overline{y}}^{2}) + 2n\mu(\overline{x} - \overline{y}) - (n - 1)(s_{x}^{2} - s_{y}^{2}) \right\rbrack/(2\sigma^{2}) \right)\]</span></p>
<p>이 비가 <span class="math inline">\((\mu,\sigma^{2})\)</span>에 대해 상수가 되려면 <span class="math inline">\(\overline{x} = \overline{y},s_{x}^{2} = s_{y}^{2}\)</span></p>
<p>이어야 한다. 따라서, 표본평균 <span class="math inline">\(\overline{X}\)</span>와 표본분산 <span class="math inline">\(S^{2}\)</span>는 <span class="math inline">\((\mu,\sigma^{2})\)</span></p>
<p>에 대한 최소 충분통계량이다.</p>
<p>【예제 ⑥】 확률표본 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>이 <span class="math inline">\(U(\theta,\theta + 1)\)</span>에서 추출되었다고 하자. <span class="math inline">\(T(\mathbf{X}) = (X_{(1)},X_{(n)})\)</span>은 모수 <span class="math inline">\(\theta\)</span>에 대한 최소 충분통계량이다.</p>
<p><span class="math display">\[f(\mathbf{x}|\theta) = \{\begin{matrix}
1 &amp; \text{if}\theta &lt; x_{i} &lt; \theta + 1,\text{for all}i = 1,\ldots,n \\
0 &amp; \text{otherwise}
\end{matrix}\]</span></p>
<p><span class="math display">\[f(\mathbf{x}|\theta) = \{\begin{matrix}
1 &amp; \text{if}\max_{i}x_{i} - 1 &lt; \theta &lt; \min_{i}x_{i} \\
0 &amp; \text{otherwise}
\end{matrix}\]</span></p>
<p>두 표본 <span class="math inline">\(\mathbf{x},\mathbf{y}\)</span>에 대하여, 비율 <span class="math inline">\(\frac{f(\mathbf{x}|\theta)}{f(\mathbf{y}|\theta)}\)</span>이 <span class="math inline">\(\theta\)</span>에 대해 항상 일정하려면 <span class="math inline">\(\min_{i}x_{i} = \min_{i}y_{i},\max_{i}x_{i} = \max_{i}y_{i}\)</span>이어야 한다.</p>
<p>최소 충분통계량은 유일하지 않다.</p>
<p><span class="math inline">\(T'(\mathbf{X}) = (X_{(n)} - X_{(1)},(X_{(n)} + X_{(1)})/2)\)</span>,</p>
<p><span class="math inline">\(T'(\mathbf{X}) = \left( \overset{n}{\sum_{i = 1}}X_{i},\overset{n}{\sum_{i = 1}}X_{i}^{2} \right)\)</span> 또한 최소 충분통계량이다.</p>
<p>보조 통계량</p>
<p>통계량 <span class="math inline">\(S(\mathbf{X})\)</span>의 분포가 모수 <span class="math inline">\(\theta\)</span>와 무관할 때, 이를 보조 ancillary 통계량이라고 한다.</p>
<p>정의</p>
<p>【예제 ⑥ 계속】 확률표본 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>이 <span class="math inline">\(U(\theta,\theta + 1)\)</span>에서 추출되었다고 하자. <span class="math inline">\(T(\mathbf{X}) = (X_{(1)},X_{(n)})\)</span>은 모수 <span class="math inline">\(\theta\)</span>에 대한 최소 충분통계량이므로 <span class="math inline">\(R = X_{(n)} - X_{(1)}\)</span>은 보조 통계량이다.</p>
<p><span class="math display">\[g(x_{(1)},x_{(n)} \mid \theta) = \{\begin{matrix}
n(n - 1)(x_{(n)} - x_{(1)})^{n - 2} &amp; \text{if}\theta &lt; x_{(1)} &lt; x_{(n)} &lt; \theta + 1 \\
0 &amp; \text{otherwise}.
\end{matrix}\]</span></p>
<p><span class="math inline">\(R = X_{(n)} - X_{(1)},M = \frac{X_{(1)} + X_{(n)}}{2}\)</span> 변수변환 하면,</p>
<p><span class="math display">\[h(r,m \mid \theta) = \{\begin{matrix}
n(n - 1)r^{n - 2}, &amp; \text{if}0 &lt; r &lt; 1,\theta + \frac{r}{2} &lt; m &lt; \theta + 1 - \frac{r}{2} \\
0, &amp; \text{otherwise}.
\end{matrix}\]</span></p>
<p><span class="math display">\[h(r \mid \theta) = n(n - 1)r^{n - 2}(1 - r),0 &lt; r &lt; 1 \sim Beta(n - 1,2)\]</span></p>
<p><span class="math inline">\(R = X_{(n)} - X_{(1)}\)</span>의 확률밀도함수는 모수 <span class="math inline">\(\theta\)</span>에 의존하지 않는다.</p>
<p>완비 통계량</p>
<p>최소 충분통계량은 표본으로부터 모수 <span class="math inline">\(\theta\)</span>에 대한 모든 정보를 유지하면서, 그 외의 불필요한 정보를 최대한 제거한 통계량이다. 즉, 표본에서 모수와 관련된 핵심 정보만을 남기는 데이터 축약 방법이다. 반면, 보조 통계량은 그 분포가 모수 <span class="math inline">\(\theta\)</span>에 의존하지 않는 통계량으로 모수에 대한 정보를 전혀 담고 있지 않다.</p>
<p>이 둘은 개념적으로 구별되지만, 반드시 독립적이지는 않다. 예를 들어, <span class="math inline">\(uniform(\theta,\theta + 1)\)</span>에서, 최소값과 최대값의 조합인 <span class="math inline">\((X_{(n)} - X_{(1)},(X_{(n)} + X_{(1)})/2)\)</span>은 최소 충분통계량이 되고, 그 중 <span class="math inline">\(X_{(n)} - X_{(1)}\)</span>은 보조 통계량이 된다. 이 경우, 최소 충분통계량과 보조 통계량은 서로 독립하지 않으며, 오히려 하나의 구성요소가 된다.</p>
<p>보조 통계량은 모수 추정 정밀도에 기여</p>
<p><span class="math inline">\(X_{1},X_{2}\)</span>가 다음 이산분포 에서 독립적으로 관측되었다.<span class="math inline">\(P_{\theta}(X = \theta) = P_{\theta}(X = \theta + 1) = P_{\theta}(X = \theta + 2) = \frac{1}{3}\)</span>. 순서 통계량 <span class="math inline">\(X_{(1)},X_{(2)}\)</span>으로 <span class="math inline">\(R = X_{(2)} - X_{(1)},M = (X_{(1)} + X_{(2)})/2\)</span>를 정의하면, <span class="math inline">\((R,M)\)</span>은 최소 충분통계량이고, <span class="math inline">\(R\)</span>은 보조 통계량이다.</p>
<p>그러나 <span class="math inline">\(R\)</span>이 보조 통계량임에도 불구하고 모수 <span class="math inline">\(\theta\)</span>에 대해 간접적으로 중요한 정보를 제공할 수 있다. 예를 들어, 단순히 <span class="math inline">\(M = m\)</span>이라는 정보만 알고 있을 때, 가능한 <span class="math inline">\(\theta\)</span> 값은 <span class="math inline">\(m,m - 1,m - 2\)</span> 세 가지가 된다. 하지만 추가로 <span class="math inline">\(R = 2\)</span>라는 정보를 알게 되면, <span class="math inline">\(X_{(1)} = m - 1,X_{(2)} = m + 1\)</span>이 되어, 가능한 <span class="math inline">\(\theta\)</span> 값이 유일하게 <span class="math inline">\(m - 1\)</span>로 결정된다. 즉, 보조 통계량 <span class="math inline">\(R\)</span>이 모수 추정의 정밀도를 높이는 데 기여한 것이다.</p>
<p>어떤 통계량 <span class="math inline">\(T(\mathbf{X})\)</span>에 대해 확률분포족 <span class="math inline">\(f(t|\theta)\)</span>가 있을 때, 이 분포족을 완비라고 부른다. 완비란, 모든 <span class="math inline">\(\theta\)</span>에 대해 <span class="math inline">\(\mathbb{E}\theta\lbrack g(T)\rbrack = 0\)</span>이면서도, <span class="math inline">\(P_{\theta}(g(T) = 0) = 1\)</span>이 되는 경우를 말한다. 즉, 기대값이 0인 함수 <span class="math inline">\(g(T)\)</span>는 거의 확률 1로 항상 0이어야 한다는 뜻이다. 이 경우, <span class="math inline">\(T(\mathbf{X})\)</span>를 완비 통계량 complete 이라고 한다.</p>
<p>정의</p>
<p>【예제 ①】 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>을 모수 <span class="math inline">\(\theta \in (0,1)\)</span>인 베르누이 분포를 따르는 확률표본이라 하자. <span class="math inline">\(T(\mathbf{X}) = \sum X_{i} \sim B(n,\theta)\)</span>는 <span class="math inline">\(\theta\)</span>에 대한 완비 충분 통계량이다.</p>
<p>【예제 ②】 확률표본 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>이 <span class="math inline">\(U(0,\theta)\)</span>에서 추출되었다고 하자. <span class="math inline">\(T(\mathbf{X}) = max(x_{i}) = x_{(n)}\)</span>은 모수 <span class="math inline">\(\theta\)</span>에 대한 완비 충분 통계량이다.</p>
<p>(Basu<span dir="rtl">’</span>s Theorem) 만약 <span class="math inline">\(T(\mathbf{X})\)</span>가 완비하고 최소 충분 통계량이라면, <span class="math inline">\(T(\mathbf{X})\)</span>는 모든 보조 통계량과 서로 독립이다.</p>
<p>정리</p>
<p>완비성과 최소충분성이라는 강력한 조건을 만족할 경우, 매개변수 <span class="math inline">\(\theta\)</span>와 무관하게 분포하는 보조통계량들과 <span class="math inline">\(T(\mathbf{X})\)</span>사이에는 어떠한 의존성도 존재하지 않음을 의미한다. 최소충분 통계량과 모수와 무관한 정보보조통계량를 분리할 수 있게 해주기 때문에, 통계 추론이나 신뢰구간 설정에 매우 유용하게 사용된다.</p>
<p><span class="math inline">\(X_{1},\ldots,X_{n}\)</span>이 지수족 분포를 따르는 확률표본이라고 하자.</p>
<p>정리</p>
<p><span class="math inline">\(f(x|\theta) = h(x)c(\theta)\exp\left( \overset{k}{\sum_{j = 1}}w(\theta_{j})t_{j}(x) \right)\)</span>. 다음 <span class="math inline">\(T(\mathbf{X})\)</span>는 완비통계량이다. <span class="math inline">\(T(\mathbf{X}) = \left( \overset{n}{\sum_{i = 1}}t_{1}(X_{i}),\overset{n}{\sum_{i = 1}}t_{2}(X_{i}),\ldots,\overset{n}{\sum_{i = 1}}t_{k}(X_{i}) \right)\)</span></p>
<p>(Minimal Complete Statistic) 만약 최소 충분통계량이 존재한다면, 모든 완비통계량도 최소 충분통계량이다.</p>
<p>정리</p>
<p>【예제 ③】 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>을 <span class="math inline">\(exp(\theta)\)</span>, 지수분포(지수족)를 따르는 확률표본이라 하자. <span class="math inline">\(T(\mathbf{X}) = \sum X_{i} \sim Gamma(n,\theta)\)</span>는 <span class="math inline">\(\theta\)</span>에 대한 완비 최소 충분 통계량이다.</p>
<p>【예제 ④】 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>을 <span class="math inline">\(N(\mu,\sigma^{2})\)</span>, 정규분포(지수족)를 따르는 확률표본이라 하자. <span class="math inline">\(T(\mathbf{X}) = (\overline{X},S^{2})\)</span>는 <span class="math inline">\(\theta\)</span>에 대한 완비 최소 충분 통계량이다.</p>
<p>2우도함수 원리</p>
<p>통계적 추론에서는 데이터로부터 정보를 요약하는 방법이 중요하다. 우도함수는 단순히 하나의 요약 방법이 아니라, 특정 원칙을 수용할 경우 필수적인 데이터 축약 장치로 간주된다.</p>
<p>충분성 원칙: 관찰된 데이터가 어떤 충분한 통계량에 의해서만 정보를 제공한다면, 모든 추론은 이 충분한 통계량에만 의존해야 한다.</p>
<p>조건화 원칙: 실험 설계상 복수의 실험이 가능한 경우, 실제로 수행된 실험의 결과만을 기반으로 추론해야 한다.</p>
<p>우도 원칙: 주어진 데이터에 대한 우도함수의 형태만이 추론에 중요하며, 데이터가 관찰된 경로는 중요하지 않다.</p>
<p>위의 원칙들을 받아들인다면, 우도함수는 주어진 데이터로부터 정보를 요약하는 유일하고 필수적인 수단이 된다.</p>
<p>우도함수</p>
<p>확률표본 <span class="math inline">\(\mathbf{X} = (X_{1},\ldots,X_{n})\)</span>의 결합 확률밀도함수를 <span class="math inline">\(f(\mathbf{x}|\theta)\)</span>라고 하자. 이때 표본 데이터 <span class="math inline">\(\mathbf{X} = \mathbf{x}\)</span>가 관측되었을 때,</p>
<p>정의</p>
<p>모수 <span class="math inline">\(\theta\)</span>의 함수로 정의되는 <span class="math inline">\(L(\theta|\mathbf{x}) = f(\mathbf{x}|\theta)\)</span>를 우도함수 likelihood function 라고 한다.</p>
<p>우도함수는 관측된 데이터 <span class="math inline">\(\mathbf{x}\)</span>를 기준으로 다양한 <span class="math inline">\(\theta\)</span> 값들에 대해 상대적 타당성을 비교하는 도구이다. 이산형, 연속형 모두 우도비를 통해 두 모수에 대한 비교가 가능하다. 즉, 실제 데이터가 관측되어 우도 값이 계산된다면 우도 값이 큰 모수가 진짜 모수일 가능성이 높다.</p>
<p>【예제 ①】 <span class="math inline">\(NB(r = 3,p)\)</span>, 음이항분포로부터 <span class="math inline">\(X_{1} = 2\)</span> 관측되었다면 우도함수는 <span class="math inline">\(P_{p}(X = 2) = \binom{4}{2}p^{3}(1 - p)^{2}\)</span>이다.</p>
<p>【우도 원리】 표본점 <span class="math inline">\(\mathbf{x},\mathbf{y}\)</span>가 다음 조건을 만족한다고 하자.</p>
<p>두 표본에 대해 우도함수 <span class="math inline">\(L(\theta|\mathbf{x})\)</span>, <span class="math inline">\(L(\theta|\mathbf{y})\)</span>가 서로 비례한다.</p>
<p>즉, 모든 <span class="math inline">\(\theta\)</span>에 대해 다음을 만족하는 상수 <span class="math inline">\(C(\mathbf{x},\mathbf{y})\)</span>가 존재한다.</p>
<p><span class="math display">\[L(\theta|\mathbf{x}) = C(\mathbf{x},\mathbf{y})L(\theta|\mathbf{y}),\text{for all}\theta\]</span></p>
<p>두 표본 <span class="math inline">\(\mathbf{x},\mathbf{y}\)</span>가 관찰되었을 때, 만약 이들의 우도함수가 비례한다면, 이 두 표본은 동일한 정보를 제공한다. 통계적 결론은 오직 우도함수 에만 의존해야 하며, 표본의 다른 세부사항에는 의존하지 않는다.</p>
<p>공식 formal 충분 통계량 원칙</p>
<p>어떤 실험 <span class="math inline">\(E = (X,\theta,\{ f(x|\theta)\})\)</span>이 수행되었고, <span class="math inline">\(T(X)\)</span>이 <span class="math inline">\(\theta\)</span>에 대한 충분통계량이라 할 때, 만약 두 관측값 <span class="math inline">\(x\)</span>와 <span class="math inline">\(y\)</span>가 <span class="math inline">\(T(x) = T(y)\)</span>를 만족한다면, 이 두 관측값이 제공하는 증거는 동일해야 한다는 것이다. 즉, 관측 데이터 전체 <span class="math inline">\(x\)</span> 자체가 아니라, 그로부터 계산된 충분통계량 <span class="math inline">\(T(x)\)</span>만이 <span class="math inline">\(\theta\)</span>에 관한 모든 정보를 요약하므로, 두 데이터가 동일한 충분통계량 값을 가질 때는, 둘 모두 <span class="math inline">\(\theta\)</span>에 대해 동일한 결론을 가져야 한다.</p>
<p>조건화 conditionality 원칙</p>
<p>여러 개의 가능한 실험이 있을 때, 어떤 실험이 실제로 수행되었는지가 매우 중요하다는 사실을 강조한다. 예를 들어, 두 개의 실험 <span class="math inline">\(E_{1},E_{2}\)</span> 중 무작위로 하나를 선택하여 시행한다고 가정하자. 이때, 어느 실험이 선택되었는지는 관측값과 함께 반드시 고려되어야 하며, 실제로 수행된 실험에 기반하여 추론이 이루어져야 한다.</p>
<p>보다 공식적으로, 혼합 실험 <span class="math inline">\(E^{*}\)</span>이 정의될 때, 실험 <span class="math inline">\(E_{j}(j = 1,2)\)</span>가 수행되고 관측값 <span class="math inline">\(x_{j}\)</span>가 주어진 경우, <span class="math inline">\(\text{Ev}(E^{,}(j,x_{j})) = \text{Ev}(E_{j},x_{j})\)</span>이어야 한다. 즉, 실험 <span class="math inline">\(E\)</span>로부터 얻어진 데이터라도 실제로 수행된 <span class="math inline">\(E_{j}\)</span>에 기반하여 해석되어야 한다. 조건화 원칙은 <span dir="rtl">”</span>오직 수행된 실험만이 중요하며, 선택되지 않은 실험들은 전혀 고려되어서는 안 된다”는 점을 명확히 한다. 이는 실험 설계 단계에서 무작위성이 개입되더라도, 실제로 수행된 실험만이 추론의 근거가 되어야 한다는 점에서 자연스럽고 설득력 있는 원칙이다.</p>
<ol type="1">
<li>우도 원칙</li>
</ol>
<p>공식 충분성 원칙과 조건화 원칙을 함께 받아들이면, 우도 원칙이 도출된다. 즉, 두 실험에서 수집된 두 데이터 <span class="math inline">\(x_{1}^{*},x_{2}^{*}\)</span>가 생성하는 우도함수가 다음과 같은 비례 관계를 만족할 때, <span class="math inline">\(L(\theta|x_{2}^{*}) = CL(\theta|x_{1}^{*})\)</span>이 두 데이터는 <span class="math inline">\(\theta\)</span>에 대해 동일한 증거를 제공해야 한다.</p>
<p>따라서 관측 데이터가 생성하는 우도함수만이 파라미터에 관한 모든 정보를 담고 있으며, 우도함수가 같으면 추론 결과도 같아야 한다는 결론에 도달한다. 이는 바로 우도 원칙의 본질이다.</p>
<ol start="2" type="1">
<li>동등성 Equivariance 원칙</li>
</ol>
<p>동등성 원칙에서는 함수 <span class="math inline">\(T(x)\)</span>가 지정되지만, <span class="math inline">\(T(x) = T(y)\)</span>일 때 <span class="math inline">\(x\)</span>를 관찰했을 경우와 <span class="math inline">\(y\)</span>를 관찰했을 경우 추론 결과가 <span dir="rtl">”</span>일정한 관계<span dir="rtl">”</span>를 가져야 한다고 요구한다. 반드시 동일할 필요는 없지만, 정해진 관계를 따라야 한다는 점이 특징이다. 또한 동등성 원칙은 실제로 두 가지 다른 고려사항을 결합한 것으로 이해할 수 있다:</p>
<p>Measurement Equivariance</p>
<p>측정 단위에 의존하지 않는 추론을 요구한다. 예를 들어, 두 산림 조사원이 각각 나무의 평균 직경을 측정한다고 하자. 한 명은 인치 단위로, 다른 한 명은 미터 단위로 데이터를 수집하였다. 비록 단위가 다르더라도, 최종적으로 동일한 추정값을 제시해야 한다. 즉, 단위 변환(예: 인치를 미터로 변환) 이후 결과가 일치해야 한다.</p>
<p>Formal Invariance</p>
<p>수학적 모델의 구조가 동일하다면 추론 절차 역시 동일해야 한다고 요구한다. 이는 물리적 의미(예: 단위 등)와는 무관하게, 다음 세 가지가 같다면, 동일한 추론 방법을 사용해야 한다는 것이다.</p>
<p>모수 공간 <span class="math inline">\(\Theta\)</span></p>
<p>확률밀도함수 <span class="math inline">\(f(x|\theta)\)</span></p>
<p>허용 가능한 추론 및 오차</p>
<p>만약 <span class="math inline">\(Y = g(X)\)</span>가 <span class="math inline">\(X\)</span>의 측정 단위 변환이고, <span class="math inline">\(Y\)</span>의 모델이 <span class="math inline">\(X\)</span>의 모델과 동일한 수학적 구조를 갖는다면, 추론 절차는 측정 단위 변화에 대해 불변하며 동시에 수학적 구조에 대해 불변해야 한다.</p>
<p>【예제 ①】 <span class="math inline">\(X \sim \text{Binomial}(n,p)\)</span>일 때, 성공 횟수 <span class="math inline">\(x\)</span>를 관찰한 경우를 생각한다. 실패 횟수는 <span class="math inline">\(Y = n - X\)</span>로 표현할 수 있으며, 역시 <span class="math inline">\(\text{Binomial}(n,q = 1 - p)\)</span>분포를 따른다.</p>
<p>Measurement Equivariance 요구</p>
<p>성공 수 <span class="math inline">\(x\)</span>를 기반으로 한 추정값 <span class="math inline">\(T(x)\)</span>와 실패 수 <span class="math inline">\(y = n - x\)</span>를 기반으로 한 추정값 <span class="math inline">\(T(y)\)</span>는 다음을 만족해야 한다.</p>
<p><span class="math display">\[T(x) = 1 - T(n - x)\text{or}T(x) = 1 - T(n - x)\]</span></p>
<p>Chapter 2. 점 추정</p>
<p>1개념</p>
<p>첫 번째 부분은 추정량을 찾는 방법을, 두 번째 부분은 추정량(및 기타 다른 추정량)을 평가하는 방법을 다룬다. 점추정의 논리는 매우 단순하다. 모집단이 확률밀도함수 <span class="math inline">\(f(x|\theta)\)</span>로 기술될 때 <span class="math inline">\(\theta\)</span>에 대한 지식은 모집단 전체에 대한 정보를 제공한다. 따라서, <span class="math inline">\(\theta\)</span>의 좋은 추정량을 찾는 방법을 모색하는 것은 자연스러운 일이다. 또한, 경우에 따라서는 <span class="math inline">\(\theta\)</span>의 함수, 즉 <span class="math inline">\(\tau(\theta)\)</span>가 관심 대상이 될 수도 있다.</p>
<p>점추정량은 확률표본의 함수 <span class="math inline">\(W(X_{1},\ldots,X_{n})\)</span>이다. 즉, 모든 통계량은 점추정량이다.</p>
<p>정의</p>
<p>모집단 확률분포함수 <span class="math inline">\(f(x;\theta),\theta \in \Omega\)</span>의 확률표본에서 얻은 통계량이 추정에 사용된다면 이를 추정량 estimator 이라 한다. 근사할 것이라고 생각하는 하나의 값으로 제시한다면 이를 점추정 point estimate, <span class="math inline">\(\theta\)</span>을 포함하고 있을 가능성이 높은 구간을 제시하는 것은 구간추정 interval estimate이라 한다. 계산되는 공식을 추정량, 실제 데이터를 이용하여 계산된 값을 추정치 estimates 이라 한다.</p>
<p>모집단 확률분포함수 <span class="math inline">\(f(x;\theta),\theta \in \Omega\)</span>의 확률표본에서 얻은 통계량 <span class="math inline">\(T = T\left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>이 모수 추정에 사용되면 이를 추정량 이라 하고 <span class="math inline">\(\overset{\hat{}}{\theta}\)</span>이라 표현한다.</p>
<p>정의</p>
<p>추정량 : <span class="math inline">\(\overset{\hat{}}{\theta} = T(X_{1},X_{2},\ldots,X_{n})\)</span> 대문자로 표현</p>
<p>추정치 : : <span class="math inline">\(t(x_{1},x,\ldots,x_{n})\)</span> 관측된 값으로 소문자로 표현</p>
<p>2추정량 구하는 방법</p>
<p>적률법</p>
<p>가장 오랜 방법으로 적률을 이용하여 모수 추정하는 방법으로 매우 간단하나 좋은 추정량의 조건을 갖추지 않을 수 있다.</p>
<p>알려지지 않은 모집단 확률분포함수 <span class="math inline">\(f(x;\theta),\theta \in \Omega\)</span>, 확률표본 <span class="math inline">\(\left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>에서 모집단의 <span class="math inline">\(k\)</span>차 적률 <span class="math inline">\({\mu'}_{k} = E(X^{k})\)</span>과 표본의 <span class="math inline">\(k\)</span>차 적률 <span class="math inline">\(m_{k}' = E(X_{i}^{k})\)</span>이라 하자.</p>
<p><span class="math inline">\(\mu_{k}' = m_{k}\)</span>이라 놓고 풀면 모수 추정량 얻게 된다.</p>
<p>만약 모수 한 개 이상이면 적률에 의한 방정식을 모수 수만큼 얻어 사용하면 된다.</p>
<p>【예제 ①】 모집단 <span class="math inline">\(B(n,p)\)</span>으로부터 확률표본 <span class="math inline">\(\left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>이다. 적률방법으로 추정량 <span class="math inline">\(\overset{\hat{}}{n},\overset{\hat{}}{p}\)</span> 구하라.</p>
<p>모집단 적률 : <span class="math inline">\(\mu_{1}' = E(X) = np,\mu_{2}' = E\left( X^{2} \right) = np(1 - p) + {(np)}^{2}\)</span></p>
<p>표본적률 : <span class="math inline">\(m_{1}' = E(X) = \overset{¯}{X}\)</span>, <span class="math inline">\(m_{2}' = E\left( X^{2} \right) = \frac{1}{n}\sum X_{i}^{2}\)</span></p>
<p>방정식 : <span class="math inline">\(np = \overset{¯}{X}\)</span>, <span class="math inline">\(\frac{1}{n}\sum X_{i}^{2}\)</span>=<span class="math inline">\(= np(1 - p) + {(np)}^{2}\)</span></p>
<p>모비율 추정량 : <span class="math inline">\(\widehat{p} = \overline{x}\)</span></p>
<p>【예제 ②】 모집단 <span class="math inline">\(N(\mu,\sigma^{2})\)</span>으로부터 확률표본 <span class="math inline">\(\left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>이다. 적률방법으로 &nbsp;<span class="math inline">\(추정량\overset{\hat{}}{\mu},\overset{\hat{}}{\sigma^{2}}\)</span> 구하라.</p>
<p>모집단 적률 : <span class="math inline">\(\mu_{1}' = E(X) = \mu,\mu_{2}' = E\left( X^{2} \right) = \sigma^{2} + \mu^{2}\)</span></p>
<p>표본 적률 : <span class="math inline">\(m_{1}' = E(X) = \overset{¯}{X}\)</span>, <span class="math inline">\(m_{2}' = E\left( X^{2} \right) = \frac{1}{n}\sum X_{i}^{2}\)</span></p>
<p>방정식 : <span class="math inline">\(\mu = \overset{¯}{X}\)</span>, <span class="math inline">\(\sigma^{2} + \mu^{2} = \frac{\sum X_{i}^{2}}{n}\)</span></p>
<p>평균 추정량 : <span class="math inline">\(\overset{\hat{}}{\mu} = \overset{¯}{x}\)</span></p>
<p>분산 추정량 : <span class="math inline">\(\overset{\hat{}}{\sigma^{2}} = \frac{1}{n}\sum X_{i}^{2} - {\overset{¯}{X}}^{2} = \frac{1}{n}\sum\left( X_{i} - \overset{¯}{X} \right)^{2}\)</span></p>
<p>【예제 ③】 모집단 <span class="math inline">\(U(0,\theta)\)</span>으로부터 확률표본 <span class="math inline">\(\left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>이다. 적률방법으로 &nbsp;추정량 <span class="math inline">\(\widehat{\theta}\)</span> 구하라.</p>
<p>모집단 적률 : <span class="math inline">\(\mu_{1}' = E(X) = \frac{\theta}{2}\)</span></p>
<p>표본 적률 : <span class="math inline">\(m_{1}' = \overset{¯}{X}\)</span></p>
<p><span class="math inline">\(\overset{¯}{X} = \frac{\theta}{2}\)</span> 이므로 적률에 의한 추정량은 <span class="math inline">\(\overset{\hat{}}{\theta} = 2\overset{¯}{X}\)</span>이다.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 98%">
</colgroup>
<tbody>
<tr class="odd">
<td style="text-align: left;">추정량 <span class="math inline">\(\overset{\hat{}}{\theta} = 2\overset{¯}{X}\)</span>은 불편 추정량은 (<span class="math inline">\(E\left( 2\overset{¯}{X} \right) = 2\theta \neq \theta\)</span>)아니지만 일치 추정량이다. 【정리】 만약 <span class="math inline">\(\lim_{n \rightarrow \infty}{V\left( \overset{\hat{}}{\theta} \right)( = 4\frac{\theta^{2}}{12n}) = 0}\)</span>이면 &nbsp;<span class="math inline">\(\overset{\hat{}}{\theta}\)</span>는 일치 추정량이다.</td>
</tr>
</tbody>
</table>
<p>【예제 ④】 모집단 <span class="math inline">\(Gamma(\alpha,\beta)\)</span>으로부터 확률표본 <span class="math inline">\(\left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>이다. 적률방법으로 모수 <span class="math inline">\(\alpha,\beta\)</span> 추정량을 구하라.</p>
<p>모집단 적률 : <span class="math inline">\(\mu_{1}' = E(X) = \alpha\beta,\mu_{2}' = E\left( X^{2} \right) = \alpha\beta^{2} + (\alpha{\beta)}^{2}\)</span></p>
<p>표본 적률 : <span class="math inline">\(m_{1}' = E(X) = \overset{¯}{X}\)</span>, <span class="math inline">\(m_{2}' = E\left( X^{2} \right) = \frac{1}{n}\sum X_{i}^{2}\)</span></p>
<p>방정식: <span class="math inline">\(\alpha\beta = \overset{¯}{X}\)</span>, <span class="math inline">\(\alpha\beta^{2} + \alpha\beta^{2} = \frac{\sum X_{i}^{2}}{n}\)</span></p>
<p>추정량 : <span class="math inline">\(\overset{\hat{}}{\alpha} = \frac{n\overset{¯}{X}}{n\sum\left( X_{i} - \overset{¯}{X} \right)^{2}}\)</span>, <span class="math inline">\(\overset{\hat{}}{\beta} = \frac{\sum\left( X_{i} - \overset{¯}{X} \right)^{2}}{n\overset{¯}{X}}\)</span></p>
<p>불편 추정량은 아니지만 <span class="math inline">\(\overset{¯}{X}\)</span>는 <span class="math inline">\(\alpha\beta\)</span>의 일치 추정량이고 <span class="math inline">\(\frac{1}{n}\sum X_{i}^{2}\)</span>은 <span class="math inline">\(\alpha\beta^{2} + (\alpha{\beta)}^{2}\)</span>의 일치 추정량이다. 적률에 의해 구한 추정량은 일치 추정량이기는 하지만 불편성 보장은 물론 MVUE라는 보장이 없다. 쉽게 얻을 수 있다는 장점으로 인하여 추정량을 이해하기 위하여 시작점이 된다.</p>
<p>최대우도 추정량 MLE</p>
<p>개념</p>
<p>최종적으로 최량 추정량, MVUE(minimum variance unbiased estimator 최소분산 불편 추정량)를 구하기 위하여 ⑴Factorial criterion에 의해 충분 통계량을 구하고 ⑵충분 통계량의 함수이면서 불편성을 갖는 추정량을 구하면 Rao-Blackwell 정리에 의해 이것이 MVUE이다. 그러나 불편 추정량을 구하는 것이 그렇게 쉽지만은 않다.</p>
<p>한편, 적률에 의한 추정량은 일치성은 보장하지만 불편성, MVUE는 아닐 가능성이 높다. 이제 MVUE일 가능성이 높은 추정 방법을 소개하고자 한다. 추출된(수집된) 확률표본(데이터)이 어떤 모수 값일 경우 그 값들이 추정될 가능성이 가장 높은가? 이를 최대 우도 추정량이라 한다. 통계추론에서 사용되는 추정량은 대부분 MLE이다.</p>
<p>주머니 속에 공이 3개 들어 있다. 공의 색깔은 하양, 파랑일 수 있다. 그러나 각 몇 개씩 들어 있는지는 모른다고 가정하자. 2개의 공을 뽑아 색을 보고 주머니에 있는 공의 색을 맞춘다고 하자. 공 2개를 뽑았더니 파랑이었다. 그럼? 주머니의 공은?</p>
<p>하얀 공일 확률: 1/3(<span class="math inline">\(= \binom{2}{2}\binom{1}{0}/\binom{3}{2}\)</span>),</p>
<p>파란 공일 확률: 1(<span class="math inline">\(= \binom{3}{2}/\binom{3}{2}\)</span>)</p>
<p>파랑 공이 가능성이 높다. 이렇게 모수에 대한 추정량을 구하는 방법이 최대우도 추정법이다.</p>
<p>MLE 구하기</p>
<p>【우도함수】 알려지지 않은 모집단 확률분포함수 <span class="math inline">\(f(x;\theta),\theta \in \Omega\)</span>에 대한 정보를 얻기 위하여 추출한 크기 <span class="math inline">\(n\)</span>의 (확률)표본 <span class="math inline">\(\overline{X} = \left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>의 결합 확률밀도함수를 모수 포함한 함수로 표현한 것을 우도함수 likelihood function 이라 하며 모수의 함수이다.</p>
<p>정의</p>
<p>우도함수 : <span class="math inline">\(L\left( \theta;x_{1},x_{2},\ldots,x_{n} \right) = L(\theta;\overline{x}) = \prod_{i}^{n}{f(x_{i};}\theta)\)</span></p>
<p>확률표본(데이터) 결합 확률(표본 데이터가 수집되었다면 어떤 모수 값일 가능성이 가장 높은가)을 최대화 하는 모수 값을 MLE라 한다.</p>
<p>【MLE】 우도함수 최대화 하는 <span class="math inline">\(\theta\)</span>를 최대우도 maximum likelihood 추정량 이라 한다.</p>
<p>정의</p>
<p><span class="math inline">\(\frac{\partial L(\theta)}{\partial\theta} = 0\)</span>을 만족하는 추정량 <span class="math inline">\(\overset{\hat{}}{\theta}(\overline{x})\)</span>을 <span class="math inline">\(MLE\)</span> 이라 한다.</p>
<p>【로그 우도함수】 우도 함수는 항상 0보다 크므로 우도함수 최대화 하는 <span class="math inline">\(\theta\)</span> 계산 ⬄ 로그 우도함수 최대화 하는 <span class="math inline">\(\theta\)</span> 계산</p>
<p>【예제 ①】 어느 지역의 암 환자 비율 <span class="math inline">\(p\)</span>을 추정하려고 한다. 모수 <span class="math inline">\(p\)</span>인 베르누이 확률밀도함수로부터 확률표본을 추출하였다고 하자.</p>
<p>모집단 확률밀도함수 : <span class="math inline">\(f(x;\theta = p) = p^{x}(1 - p)^{1 - x},x = 0,1\)</span></p>
<p>우도 함수 : <span class="math inline">\(L(\theta;\overline{x}) = \prod_{i}^{n}{f(x_{i};p)} = \sum_{i}^{n}{p^{x_{i}}(1 - p)^{1 - x_{i}}} = p^{\sum x_{i}}(1 - p)^{n - \sum x_{i}}\)</span></p>
<p>로그 우도함수 : <span class="math inline">\(l(\theta) = \ln\left( L(\theta) \right) = \sum x_{i}\ln(p) + (n - \sum x_{i})ln(1 - p)\)</span></p>
<p>MLE : <span class="math inline">\(\frac{\partial l(\theta)}{\partial\theta} = \sum x_{i}\left( \frac{1}{p} \right) + (n - \sum x_{i})\frac{1}{1 - p}( - 1) = 0\)</span>,</p>
<p>그러므로 <span class="math inline">\(\overset{\hat{}}{p} = \frac{\sum x_{i}}{n}\)</span>이다.</p>
<p>【예제 ②】 빼빼로 중량이 <span class="math inline">\(N(\mu,\sigma^{2})\)</span>을 따른다고 하자. 중량 평균을 추정하기 위하여 확률표본을 추출하였다고 하였다. 모집단 모수 <span class="math inline">\(\overline{\theta} = (\mu,\sigma)\)</span>는 2개이나 평균에 관심이 있으므로 <span class="math inline">\(\mu\)</span>는 목표 모수, 분산 <span class="math inline">\(\sigma^{2}\)</span>은 불필요 nuisance 모수 이다.</p>
<p>모집단 확률밀도함수 : <span class="math inline">\(f(x;\mu,\sigma) = \frac{1}{2\sqrt{}\pi\sigma}\exp\left( - \frac{(x - \mu)^{2}}{2\sigma^{2}} \right), - \infty &lt; x &lt; \infty\)</span></p>
<p>로그 우도함수 : <span class="math inline">\(l\left( \mu,\sigma^{2} \right) = \frac{n}{2}\ln(2\pi) - \frac{1}{2}\sum\left( \frac{x_{i} - \mu}{\sigma} \right)^{2}\)</span></p>
<p>MLE : <span class="math inline">\(\frac{\partial l(\mu,\sigma)}{\partial\mu} = 0,\frac{\partial l\left( \mu,\sigma^{2} \right)}{\partial\sigma^{2}} = 0\)</span> 그러므로 <span class="math inline">\(\overset{\hat{}}{\mu} = \overset{¯}{X},{\overset{\hat{}}{\sigma}}^{2} = \frac{\sum\left( x_{i} - \overset{¯}{x} \right)^{2}}{n}\)</span>이다.</p>
<p>【예제 ③】 모집단 확률분포 <span class="math inline">\(U(0,\theta)\)</span>, 확률표본에서 MLE을 구하시오.</p>
<p>모집단 확률밀도함수 : <span class="math inline">\(f(x;\theta) = \frac{1}{\theta},0 &lt; x &lt; \theta\)</span></p>
<p>우도함수 : <span class="math inline">\(L(\theta) = \Pi\left( \frac{1}{\theta} \right)I_{(x_{i},\theta)} = \Pi\left( \frac{1}{\theta} \right)I_{(\max\left\{ x_{i} \right\},\theta)}\)</span></p>
<p><span class="math inline">\(I_{\lbrack a,b\rbrack}\)</span>은 지시 indicator 함수로 <span class="math inline">\((a &lt; b)\)</span>이면 1, 그렇지 않으면 0이다. 우도함수 최대화 되려면 <span class="math inline">\(\overset{\hat{}}{\theta} = \max\left\{ x_{i} \right\} = x_{(n)}\)</span></p>
<p>【예제 ④】 라플라스분포 <span class="math inline">\(f(x;\theta) = \frac{1}{2}e^{- |x - \theta|}, - \infty &lt; x &lt; \infty, - \infty &lt; \theta &lt; \infty\)</span>을 따르는 확률표본을 이용하여 <span class="math inline">\(\theta\)</span>에 대한 MLE 구하라.</p>
<p>로그 우도함수 : <span class="math inline">\(l(\theta) = - nln(2) - \sum_{i}^{n}{|x_{i} - \theta|}\)</span></p>
<p>미분 : <span class="math inline">\(\frac{\partial l}{\partial\theta} = \sum_{i}^{n}{sgn(x_{i} - \theta)} = 0,wheresgn(t) = \left\{ \begin{array}{r}
- 1,t &lt; 0 \\
0,t = 0 \\
1,t &gt; 0
\end{array} \right.\ \)</span></p>
<p>그러므로 <span class="math inline">\(\overset{\hat{}}{\theta} = Median\)</span>, MLE이다.</p>
<p>【예제 ⑤】 <span class="math inline">\(N(\mu,1),where\mu &gt; 0\)</span>을 따르는 확률표본을 이용하여 <span class="math inline">\(\mu\)</span>에 대한 MLE 구하라.</p>
<p>로그 우도함수 최대화 하는 MLE <span class="math inline">\(\overset{\hat{}}{\mu} = \overline{X}\)</span> 이므로 <span class="math inline">\(\overset{\hat{}}{\mu} = \left\{ \begin{array}{r}
\overline{X}if\overline{X} \geq 0 \\
0if\overline{X} &lt; 0
\end{array} \right.\ \)</span></p>
<p>【예제 ⑥】 <span class="math inline">\(B(n,p)\)</span>을 따르는 확률표본을 이용하여 <span class="math inline">\(n\)</span>에 대한 MLE 구하라(단, <span class="math inline">\(p\)</span>는 알려져 있음). (적용) 동전의 공정성을 평가하기 위하여 몇 번을 던져야 하나?</p>
<p>우도함수 : <span class="math inline">\(L\left( k;\overline{x},p \right) = \prod_{i}^{n}{\binom{k}{x_{i}}p^{x_{i}}(1 - p)^{k - x_{i}}}\)</span></p>
<p><span class="math inline">\(k\)</span>에 대한 우도함수 미분은 쉽지 않다. 만약 <span class="math inline">\(k &lt; x_{(n)}\)</span>이면 <span class="math inline">\(L\left( k;\overline{x},p \right) = 0\)</span> 이므로 다음 조건을 만족하는 <span class="math inline">\(k \geq x_{(n)}\)</span>이 MLE이다.</p>
<p><span class="math inline">\(\frac{L\left( k;\overline{x},p \right)}{L\left( k - 1;\overline{x},p \right)} \geq 1,\frac{L\left( k + 1;\overline{x},p \right)}{L\left( k;\overline{x},p \right)} &lt; 1\)</span>.</p>
<p>그러므로 최대화 조건은 다음과 같다.<span class="math inline">\(\left( k(1 - p) \right)^{n} \geq \prod_{1}^{n}\left( k - x_{i} \right)and\left( (k + 1)(1 - p) \right)^{n} \geq \prod_{1}^{n}{(k + 1 - x_{i})}\)</span>이다. 결론적으로 <span class="math inline">\((1 - p)^{n} = \overset{n}{\prod_{i = 1}}(1 - x_{i}z)\)</span>. 구간 <span class="math inline">\(0 \leq z \leq 1/\max_{i}x_{i}\)</span> 범위 내에서 MLE 구하면 <span class="math inline">\(\widehat{k} = \lfloor 1/\widehat{z}\rfloor\)</span> 소숫점 버리고 내림한 값이다.</p>
<p>MLE 성질</p>
<p>【invariance property】 <span class="math inline">\(f(x;\theta),\theta \in \Omega\)</span>을 따르는 확률표본으로부터 <span class="math inline">\(\overset{\hat{}}{\theta}\)</span>은 MLE, <span class="math inline">\(\theta \rightarrow \tau(\theta)\)</span> 일대일 맵핑이라면 <span class="math inline">\(\tau(\theta)\)</span> MLE은 <span class="math inline">\(\tau\left( \overset{\hat{}}{\theta} \right)\)</span>이다.</p>
<p>정리</p>
<p>【예제 ①】 <span class="math inline">\(N\left( \mu,\sigma^{2} \right)\)</span>에서 <span class="math inline">\(\overline{\theta} = (\mu,\sigma^{2})\)</span> MLE는 <span class="math inline">\(\overset{\hat{}}{\mu} = \overset{¯}{X},{\overset{\hat{}}{\sigma}}^{2} = \frac{\sum\left( x_{i} - \overset{¯}{x} \right)^{2}}{n}\)</span>.</p>
<p>invariance property에 의해 표준편차 <span class="math inline">\(\sigma = \sqrt{\sigma^{2}}(\tau(\theta))\)</span> MLE는 <span class="math inline">\(\overset{\hat{}}{\sigma} = \sqrt{\frac{\sum\left( x_{i} - \overset{¯}{x} \right)^{2}}{n}}\)</span>이다.</p>
<p>【예제 ②】 <span class="math inline">\(B(p)\)</span>에서 확률표본 <span class="math inline">\((X_{1},X_{2},\ldots,X_{n})\)</span>이다. <span class="math inline">\(V(X)\)</span>의 MLE 구하라.</p>
<p><span class="math inline">\(V(X) = p(1 - p)\)</span>이고 모수 <span class="math inline">\(p\)</span>에 대한 MLE은 <span class="math inline">\(\overset{\hat{}}{p} = \frac{\sum X_{i}}{n}\)</span> 이므로 분산의 MLE 는 <span class="math inline">\(\overset{\hat{}}{V(X)} = \frac{\sum X_{i}}{n}(1 - \frac{\sum X_{i}}{n})\)</span>이다.</p>
<p>모수 <span class="math inline">\(\theta\)</span>에 대한 MLE <span class="math inline">\({\overset{\hat{}}{\theta}}_{mle}\)</span>은 일치 추정량이다.</p>
<p>정리</p>
<p>베이즈 추정량</p>
<p>베이지안 접근법은 통계학에 대한 고전적인 접근법과 근본적으로 다른데 고전적인 접근법에서는 모수 <span class="math inline">\(\theta\)</span>가 알려지지 않지만 고정된 값으로 간주된다. 모수 <span class="math inline">\(\theta\)</span>에 대한 정보는 확률표본 <span class="math inline">\(\overline{X} = \left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>을 추출한 후 계산된 통계량을 기초하여 얻어진다.</p>
<p>베이지안 접근법에서는 모수 <span class="math inline">\(\theta\)</span>는 확률변수로서의 변동성을 갖는 양으로 간주되며 이를 사전 확률밀도함수라 한다. 이는 분석자의 믿음에 기반한 주관적인 분포로서 데이터가 관찰되기 전에 정의하고 그런 다음 모수 <span class="math inline">\(\theta\)</span>인 모집단에서 표본을 추출하고 이 표본 정보를 사용하여 사전 분포를 업데이트한다. 이 업데이트된 사전 분포를 사후 분포라고 하고 이러한 업데이트는 베이즈 정리를 사용하여 수행한다.</p>
<p>【사후확률】 <span class="math inline">\(\pi(\theta)\)</span> 모수 사전 prior 확률밀도함수, <span class="math inline">\(L(\theta;\overline{x})\)</span>을 우도 함수이면 확률표본 <span class="math inline">\(\overline{x} = \left( x_{1},x_{2},\ldots,x_{n} \right)\)</span>이 주어진 경우 모수에 대한 조건부 확률밀도함수를 사후 posterior 확률밀도함수라 한다.</p>
<p>정의</p>
<blockquote class="blockquote">
<p><span class="math display">\[\pi\left( \theta \middle| \overline{x} \right) = \frac{\pi(\theta)L(\theta;\overline{x})}{m(\overline{x})} \propto \pi(\theta)L(\theta;\overline{x}),wherem\left( \overline{x} \right) = \int\pi(\theta)L\left( \theta;\overline{x} \right)d\theta\]</span></p>
</blockquote>
<p>【bayes estimator 베이지안 추정량】</p>
<p>정의</p>
<p>최소 squared error loss function(제곱 오차 손실함수) <span class="math inline">\(Loss\left( \theta,\overset{\hat{}}{\theta} \right) = \left( \theta - \overset{\hat{}}{\theta} \right)^{2}\)</span> : 사후 확률함수 평균</p>
<p>최소 absolute error loss function(절대 오차 손실함수) <span class="math inline">\(Loss\left( \theta,\overset{\hat{}}{\theta} \right) = |\theta - \overset{\hat{}}{\theta}|\)</span> : 사후 확률함수 중앙값</p>
<p>【예제 ①】 <span class="math inline">\(B(p)\)</span>에서 추출한 확률표본 <span class="math inline">\(\overline{X} = \left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>을 이용하여 베이즈 추정량 구하라.</p>
<p>우도함수 : <span class="math inline">\(L\left( p;\overline{x} \right) = \binom{n}{y}p^{y}(1 - p)^{n - y}wherey = \sum_{i}^{n}x_{i}\)</span></p>
<p>사전확률 : (1) uniform prior <span class="math inline">\(\pi(p) \sim U(0,1)\)</span>, (2) conjugate prior <span class="math inline">\(\pi(p) \sim Beta(\alpha,\beta)\)</span></p>
<p>conjugate prior: 사후 확률밀도함수와 동일한 분포를 갖는 사전 확률밀도함수를 conjugate prior라 한다. 비율의 사후 확률밀도함수가 베타분포 이므로 사전 확률밀도함수를 베타분포이면 이를 conjugate prior라 한다.</p>
<p>uniform prior 사후확률 : <span class="math inline">\(\pi\left( p \middle| \overline{x} \right) \propto 1_{(0,1)}^{p}\binom{n}{y}p^{y}(1 - p)^{n - y} \sim Beta(y + 1,n - y + 1)\)</span></p>
<p>conjugate prior 사후확률 : <span class="math inline">\(\pi\left( p \middle| \overline{x} \right) \propto Beta(\alpha,\beta)\binom{n}{y}p^{y}(1 - p)^{n - y} \sim Beta(\alpha + y,\beta + n - y)\)</span></p>
<p>베이즈 추정량 (제곱 오차 손실 함수 적용) : <span class="math inline">\(\overset{\hat{}}{p} = \frac{y + 1}{(n + 2)}\)</span>(uniform prior), <span class="math inline">\(\overset{\hat{}}{p} = \frac{\alpha + y}{(n + \alpha + \beta)}\)</span>(conjugate prior)</p>
<p>【예제 ②】 <span class="math inline">\(N\left( \theta,\sigma^{2} \right)\)</span>에서 추출한 확률표본 <span class="math inline">\(\overline{X} = \left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>을 이용하여 <span class="math inline">\(\left( \theta,\sigma^{2} \right)\)</span>베이즈 추정량 구하라.</p>
<p>Conjugate 사전 확률밀도 함수 : <span class="math inline">\(\pi(\theta) \sim N(\mu,\tau^{2})\)</span></p>
<p>사후 확률밀도함수 : <span class="math inline">\(\pi\left( \theta \middle| \overline{x} \right) \sim N(\frac{\tau^{2}}{\tau^{2} + \sigma^{2}}\overline{x} + \frac{\sigma^{2}}{\tau^{2} + \sigma^{2}}\mu,\frac{\sigma^{2}\tau^{2}}{\tau^{2} + \sigma^{2}})\)</span></p>
<p>제곱 오차 손실함수 최소화 베이즈 추정량 : <span class="math inline">\(\overset{\hat{}}{\theta} = \frac{\tau^{2}}{\tau^{2} + \sigma^{2}}\overline{x} + \frac{\sigma^{2}}{\tau^{2} + \sigma^{2}}\mu\)</span>.</p>
<p>3추정량 평가</p>
<p>앞 절에서는 모수의 점추정량을 찾기 위한 합리적인 방법들을 소개하였다. 하지만 문제는, 특정 상황에서는 여러 방법을 적용할 수 있다는 점이다. 따라서 여러 추정량 후보 중에서 어떤 추정량을 선택할지 결정해야 하는 과제가 생긴다.</p>
<p>점추정은 과녁에 화살을 쏘는 것과 같다. 모집단으로부터 확률표본을 얻고 이로부터 모수에 대한 예측 값(추정치)을 얻는다. 즉 과녁에 한 발의 화살을 쏘는 것과 같다. 과연 bull-eye일까? 좋은 추정치라면 한 번에 bull-eye일까?</p>
<p>화살을 한 발 쏘아<img src="media/image2.png" style="width:2.75486in;height:1.68681in" alt="라인, 도표이(가) 표시된 사진 자동 생성된 설명"> bull-eye를 했다고 하자. 명궁이라 할 수 있나? 아닐 것이다. 2발, 아니 20발쯤 연속 명중시킨다면 명궁이라 할 수 있을 것이다. 이처럼 한 번의 추정치로는 그 추정치가 좋은지를 판단할 수는 없다. 추정치 good 여부를 판단하려면 추정치를 여러 번 구해야 한다. 즉 추정치의 평균과 분산이 필요하게 되는 것이다.</p>
<p>목표 모수 <span class="math inline">\(\theta\)</span>에 대한 추정량 <span class="math inline">\(\overset{\hat{}}{\theta}\)</span>을 여러 번 얻는다면(<span class="math inline">\(\overset{\hat{}}{\theta}\)</span> 확률밀도함수, <span class="math inline">\(f(\overset{\hat{}}{\theta})\)</span>,샘플링 분포도 얻을 수 있음) 그 추정량은 모수 <span class="math inline">\(\theta\)</span>을 중심으로 흩어져 있을 것이다. 모수 부근에 있을 가능성은 높고 멀어질수록 가능성은 떨어질 것이다.</p>
<p>평균제곱오차</p>
<p>【MSE】 추정량 <span class="math inline">\(W\)</span>와 모수 <span class="math inline">\(\theta\)</span>에 대해, 평균제곱오차(Mean Squared Error, MSE)는 <span class="math inline">\(MSE(W) = E_{\theta}(W - \theta)^{2}\)</span>로 정의된다.</p>
<p>정의</p>
<p>평균 절대오차 <span class="math inline">\(E_{\theta}(|W - \theta|)\)</span>)도 점추정량 성능 척도의 대안이 될 수 있으나, MSE는 다음과 같은 두 가지 강점을 가진다.</p>
<p>수학적으로 다루기 쉬움</p>
<p>분산과 편향이라는 명확한 해석 가능</p>
<p><span class="math display">\[MSE = E_{\theta}(W - \theta)^{2} = {Var}_{\theta}(W) + (E_{\theta}W - \theta)^{2}\]</span></p>
<p><span class="math inline">\({Var}_{\theta}(W)\)</span>: 추정량 <span class="math inline">\(W\)</span>의 분산(추정분산) - 추정량의 변동성</p>
<p><span class="math inline">\((E_{\theta}W - \theta)^{2}\)</span>: 추정량 <span class="math inline">\(W\)</span>의 편향 bias의 제곱 - 추정량이 모수에 얼마나 가까운지</p>
<p>【편향】 추정량 <span class="math inline">\(W\)</span> 의 편향은 <span class="math inline">\({Bias}_{\theta}(W) = E_{\theta}W - \theta\)</span></p>
<p>정의</p>
<p>으로 정의된다.</p>
<p>만약 <span class="math inline">\({Bias}_{\theta}(W) = 0\)</span>이면, 추정량 W는 불편 unbiased 추정량이라 한다. 이는 모든 <span class="math inline">\(\theta\)</span>에 대해 <span class="math inline">\(E_{\theta}W = \theta\)</span>를 만족한다는 뜻이다. 불편 추정량인 경우 <span class="math inline">\(MSE_{\theta}(W) = V_{\theta}(W)\)</span>이다.</p>
<p>【예제 ①】 <span class="math inline">\(f(x;\theta) \sim N(\mu,\sigma^{2})\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. MLE 추정량 <span class="math inline">\(\overline{X},S^{2}\)</span>이 불편 추정량 인지 보이고 MSE 구하라.</p>
<p><span class="math display">\[E(\overline{X}) = \mu,E(S^{2}) = \sigma^{2}\]</span></p>
<p><span class="math display">\[MSE(\overline{X}) = E(\overline{X} - \mu)^{2} = Var(\overline{X}) = \frac{\sigma^{2}}{n}\]</span></p>
<p><span class="math display">\[MSE(S^{2}) = E(S^{2} - \sigma^{2})^{2} = Var(S^{2}) = \frac{2\sigma^{4}}{n - 1}\]</span></p>
<p>【예제 ②】 <span class="math inline">\(f(x;\theta) \sim U(\theta,\theta + 1)\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. 추정량 <span class="math inline">\(\overset{¯}{X}\)</span>가 편의 추정량 임을 보이고 MSE 구하라.</p>
<p><span class="math inline">\(E(X) = \frac{2\theta + 1}{2},V(X) = \frac{1}{12}\)</span>.</p>
<p>편의 <span class="math inline">\(B\left( \overline{x} \right) = \frac{2\theta + 1}{2} - \theta = \frac{1}{2}\)</span>.</p>
<p>추정분산 <span class="math inline">\(V\left( \overline{x} \right) = \frac{1}{12n}\)</span> 이므로 <span class="math inline">\(MSE\left( \overline{x} \right) = \frac{1}{12n} + \frac{1}{4}\)</span>이다.</p>
<p>【예제 ③】 <span class="math inline">\(f(x;\theta) = \frac{1}{\theta}e^{- x/\theta},0 &lt; x\)</span> 에서 표본크기 3인 확률표본 <span class="math inline">\((X_{1},X_{2},X_{3})\)</span> 추출하였다. 4개 추정량 중 MSE가 가장 작은 것은?</p>
<p><span class="math display">\[(1){\overset{\hat{}}{\theta}}_{1} = X_{1}(2){\overset{\hat{}}{\theta}}_{2} = \frac{X_{1} + X_{2}}{2}(3){\overset{\hat{}}{\theta}}_{3} = \frac{X_{1} + 2X_{2}}{3}(4){\overset{\hat{}}{\theta}}_{4} = \frac{X_{1} + X_{2} + X_{3}}{3}\]</span></p>
<p><span class="math inline">\(E(X) = \theta,V(X) = \theta^{2}\)</span>.</p>
<p><span class="math inline">\(E\left( {\overset{\hat{}}{\theta}}_{1} \right) = \theta,E\left( {\overset{\hat{}}{\theta}}_{2} \right) = \theta,E\left( {\overset{\hat{}}{\theta}}_{3} \right) = \theta,E\left( {\overset{\hat{}}{\theta}}_{4} \right) = \theta\)</span> 이므로 모두 불편 추정량 이다.</p>
<p><span class="math inline">\(MSE\left( {\overset{\hat{}}{\theta}}_{1} \right) = V\left( {\overset{\hat{}}{\theta}}_{1} \right) = \theta^{2}\)</span>, <span class="math inline">\(MSE\left( {\overset{\hat{}}{\theta}}_{2} \right) = \frac{\theta^{2}}{2}\)</span>, <span class="math inline">\(MSE\left( {\overset{\hat{}}{\theta}}_{3} \right) = \frac{5\theta^{2}}{9}\)</span>, <span class="math inline">\(MSE\left( {\overset{\hat{}}{\theta}}_{4} \right) = \frac{\theta^{2}}{3}\)</span> 4번째 추정량 MSE가 최소</p>
<p>【예제 ④】 <span class="math inline">\(f(x;p) = p^{x}(1 - p)^{1 - x},x = 0,1\)</span> 베르누이 분포에서 표본크기 n인 확률표본을 추출하였다. MLE 추정량과 베이지 추정량의 MLE을 구하시오.</p>
<p>모집단 평균 및 분산: <span class="math inline">\(E(X) = p,V(X) = p(1 - p)\)</span></p>
<p>MLE : <span class="math inline">\(\widehat{p} = \frac{\sum X_{i}}{n}\)</span>, <span class="math inline">\(MSE = E_{p}(\widehat{p} - p)^{2} = {Var}_{p}(\overline{X}) = \frac{p(1 - p)}{n}\)</span></p>
<p>베이지 추정량 : <span class="math inline">\({\widehat{p}}_{B} = \frac{Y + \alpha}{\alpha + \beta + n}\)</span></p>
<p><span class="math display">\[E_{p}({\widehat{p}}_{B} - p)^{2} = {Var}_{p}({\widehat{p}}_{B}) + ({Bias}_{p}({\widehat{p}}_{B}))^{2}\]</span></p>
<p><span class="math display">\[= {Var}_{p}\left( \frac{Y + \alpha}{\alpha + \beta + n} \right) + \left( E_{p}\left( \frac{Y + \alpha}{\alpha + \beta + n} \right) - p \right)^{2} = \frac{np(1 - p)}{(\alpha + \beta + n)^{2}} + \left( \frac{np + \alpha}{\alpha + \beta + n} - p \right)^{2}\]</span></p>
<p>상대효율</p>
<p>앞에서 살펴보았듯이 모수 <span class="math inline">\(\theta\)</span>에 대한 불편 추정량은 무수히 많이 존재한다. 두 불편 추정량 <span class="math inline">\({\overset{\hat{}}{\theta}}_{1},{\overset{\hat{}}{\theta}}_{2}\)</span>을 생각해 보자. 만약 <span class="math inline">\({V(\overset{\hat{}}{\theta}}_{1}) \leq V({\overset{\hat{}}{\theta}}_{2})\)</span>라면 <span class="math inline">\({\overset{\hat{}}{\theta}}_{1}\)</span>은 <span class="math inline">\({\overset{\hat{}}{\theta}}_{2}\)</span>에 비해 상대적으로 효율적 efficient 이라고 정의한다.</p>
<p>【상대효율】 <span class="math inline">\({eff(\overset{\hat{}}{\theta}}_{1},{\overset{\hat{}}{\theta}}_{2}) = \frac{{V(\overset{\hat{}}{\theta}}_{2})}{V({\overset{\hat{}}{\theta}}_{1})}\)</span> : 추정량 <span class="math inline">\({\overset{\hat{}}{\theta}}_{2}\)</span>에 대한 <span class="math inline">\({\overset{\hat{}}{\theta}}_{1}\)</span>의 상대효율이라 한다.</p>
<p>정의</p>
<p><span class="math inline">\({\overset{\hat{}}{\theta}}_{1},{\overset{\hat{}}{\theta}}_{2}\)</span>가 불편 추정량이면 추정 분산과 추정 평균제곱오차은 동일하므로 추정 분산이 적은 추정량이 (즉 효율적인 추정량) 좋은 추정량이다.</p>
<p>【예제 ①】 <span class="math inline">\(f(x;\theta) \sim U(0,\theta)\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. <span class="math inline">\(({\overset{\hat{}}{\theta}}_{1} = 2\overline{X},{\overset{\hat{}}{\theta}}_{2} = \frac{n + 1}{n}X_{(n)})\)</span> 추정량이 불편 추정량임을 보이고 상대효율을 구하라.</p>
<p><span class="math inline">\(E(X) = \frac{\theta}{2},V(\theta) = \frac{\theta^{2}}{12}\)</span>. <span class="math inline">\(E\left( {\overset{\hat{}}{\theta}}_{1} \right) = E\left( 2\overline{X} \right) = 2\frac{\theta}{2} = \theta\)</span> 불편 추정량이다. <span class="math inline">\(V\left( {\overset{\hat{}}{\theta}}_{1} \right) = V\left( 2\overline{X} \right) = 4\frac{\theta^{2}}{12n} = \frac{\theta^{2}}{3n}\)</span>.</p>
<p>순서 통계량 <span class="math inline">\(Y = X_{(n)}\)</span> 확률밀도함수 : <span class="math inline">\(f(y) = n\left( \frac{y}{\theta} \right)^{n - 1}\left( \frac{1}{\theta} \right),0 &lt; y &lt; \theta\)</span>.</p>
<p><span class="math inline">\(E(Y) = \frac{n}{n + 1}\theta,V(Y) = \left( \frac{n}{n + 2} - \left( \frac{n}{n + 2} \right)^{2} \right)\theta^{2}\)</span>.</p>
<p><span class="math inline">\(E\left( {\overset{\hat{}}{\theta}}_{2} \right) = E\left( \frac{n + 1}{n}X_{(n)} \right) = \frac{n + 1}{n}\frac{n}{n + 1}\theta = \theta\)</span> 불편 추정량이다. . <span class="math inline">\(V\left( {\overset{\hat{}}{\theta}}_{2} \right) = \frac{1}{n(n + 2)}\theta^{2}\)</span>.</p>
<p><span class="math inline">\({eff(\overset{\hat{}}{\theta}}_{1},{\overset{\hat{}}{\theta}}_{2}) = \frac{{V(\overset{\hat{}}{\theta}}_{2})}{V({\overset{\hat{}}{\theta}}_{1})} = \frac{3}{n + 2}\)</span> 이므로 <span class="math inline">\(n \geq 1\)</span> 이면 <span class="math inline">\({\overset{\hat{}}{\theta}}_{1}\)</span>이 <span class="math inline">\({\overset{\hat{}}{\theta}}_{2}\)</span>에 비해 상대적으로 효율적이다.</p>
<p>【예제 ②】 <span class="math inline">\(f(x;\theta) = \frac{1}{\theta}e^{- x/\theta},0 &lt; x\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본 <span class="math inline">\((X_{1},X_{2},\ldots,X_{n})\)</span> 추출하였다. <span class="math inline">\(({\overset{\hat{}}{\theta}}_{1} = \frac{X_{1} + X_{2}}{2},{\overset{\hat{}}{\theta}}_{2} = {\overline{X}}_{n})\)</span> 불편 추정량임을 보이고 상대효율을 구하라.</p>
<p><span class="math inline">\(E(X) = \theta,V(\theta) = \theta^{2}\)</span>.</p>
<p><span class="math inline">\(E\left( {\overset{\hat{}}{\theta}}_{1} \right) = E\left( \frac{X_{1} + X_{2}}{2} \right) = \theta\)</span> 불편 추정량이다. <span class="math inline">\(V\left( {\overset{\hat{}}{\theta}}_{1} \right) = V\left( \frac{X_{1} + X_{2}}{2} \right) = \frac{\theta^{2}}{2}\)</span>.</p>
<p><span class="math inline">\(E\left( {\overset{\hat{}}{\theta}}_{2} \right) = E\left( \frac{X_{1} + X_{2} + \ldots + X_{n}}{n} \right) = \theta\)</span> 불편 추정량이다. <span class="math inline">\(V\left( {\overset{\hat{}}{\theta}}_{1} \right) = V\left( {\overline{X}}_{n} \right) = \frac{\theta^{2}}{n}\)</span>.</p>
<p><span class="math inline">\({eff(\overset{\hat{}}{\theta}}_{1},{\overset{\hat{}}{\theta}}_{2}) = \frac{{V(\overset{\hat{}}{\theta}}_{2})}{V({\overset{\hat{}}{\theta}}_{1})} = \frac{n}{2}\)</span> 이므로 <span class="math inline">\(n \geq 2\)</span> 이면 <span class="math inline">\({\overset{\hat{}}{\theta}}_{2}\)</span>이 <span class="math inline">\({\overset{\hat{}}{\theta}}_{1}\)</span>에 비해 상대적으로 효율적이다.</p>
<p>최량 불편 추정량</p>
<p>최소 MSE을 갖는 추정량을 최량 추정량으로 정의하였는데 실제 MSE을 최소화 하는 추정량을 구하는 것은 쉽지 않거나(수학적 접근 매우 어려움) 실제 <span dir="rtl">”</span>최고의 MSE 추정량”은 존재하지 않는다. 이는 후보 추정량의 범위가 너무 넓기 때문인데, <span class="math inline">\(\widehat{\theta} = 17\)</span>은 <span class="math inline">\(\theta = 17\)</span>일 때 MSE가 최솟값이지만 다른 값에서는 매우 나쁜 추정량이다.</p>
<p>불편추정량으로 범위를 제한하면 후보 추정량의 범위를 불편추정량으로 제한한다. MSE 비교는 단순히 분산 비교로 귀결되므로 추정분산이 더 작은 불편추정량을 선택하면 된다.</p>
<p>추정량 <span class="math inline">\(W^{*}\)</span>가 다음 조건을 만족하면 <span class="math inline">\(\tau(\theta)\)</span>에 대한 최량 불편추정량 best unbiased estimator 이라 한다.</p>
<p>정의</p>
<p>모든 <span class="math inline">\(\theta\)</span>에 대해 <span class="math inline">\(E_{\theta}W^{*} = \tau(\theta)\)</span></p>
<p>임의의 다른 추정량 <span class="math inline">\(W\)</span>에 대해 <span class="math inline">\(Var\theta(W^{*}) \leq Var\theta(W)\text{for all}\theta\)</span></p>
<p>【예제 ①】 <span class="math inline">\(f(x;\theta) \sim B(n,p)\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. 다음 2개 추정량에 대하여 (1) 불편 추정량인지 보이고 (2) MSE을 비교하라. <span class="math inline">\((1){\overset{\hat{}}{p}}_{1} = \frac{\sum X_{i}}{n}(2){\overset{\hat{}}{p}}_{2} = \frac{\sum X_{i} + 1}{n + 2}\)</span>.</p>
<p><span class="math inline">\(E(X) = p,V(X) = p(1 - p)\)</span>.</p>
<p><span class="math inline">\(E\left( \frac{\sum X_{i}}{n} \right) = p\)</span> 이므로 <span class="math inline">\({\overset{\hat{}}{p}}_{1}\)</span>는 불편 추정량 이다.</p>
<p><span class="math inline">\(E\left( \frac{\sum X_{i} + 1}{n + 2} \right) = \frac{p + 1}{n + 2}\)</span> 이므로 <span class="math inline">\({\overset{\hat{}}{p}}_{2}\)</span>는 불편 추정량 아니다. <span class="math inline">\(B\left( {\overset{\hat{}}{p}}_{2} \right) = \frac{1 - np - p}{n + 2}\)</span>.</p>
<p><span class="math display">\[MSE\left( {\overset{\hat{}}{p}}_{1} \right) = MSE\left( \frac{\sum X_{i}}{n} \right) = V\left( \frac{\sum X_{i}}{n} \right) = \frac{p(1 - p)}{n}\]</span></p>
<p><span class="math display">\[MSE\left( {\overset{\hat{}}{p}}_{2} \right) = MSE\left( \frac{\sum X_{i} + 1}{n + 2} \right) = V\left( \frac{\sum X_{i} + 1}{n + 2} \right) + B^{2}\left( \frac{\sum X_{i} + 1}{n + 2} \right) = \frac{np(1 - p)}{(n + 2)^{2}} + \frac{(1 - np - p)^{2}}{(n + 2)^{2}}\]</span></p>
<p>그러므로 <span class="math inline">\(MSE\left( {\overset{\hat{}}{p}}_{1} \right) &gt; MSE\left( {\overset{\hat{}}{p}}_{2} \right)for0 &lt; p &lt; 1\)</span>.</p>
<p>【예제 ②】 <span class="math inline">\(f(x;\theta) \sim Poisson(\lambda)\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. 포아송 분포는 평균, 분산이 동일하므로 표본평균(<span class="math inline">\(\overline{x}\)</span>), 표본분산(<span class="math inline">\(S^{2}\)</span>) 모두 불편 추정량이다. 어느 추정량을 사용할 것인가? 추정 분산이 적은 통계량을 사용해야 한다.</p>
<p>표본평균 추정분산 : <span class="math inline">\(V\left( \overset{¯}{x} \right) = \frac{\lambda}{n}\)</span>.</p>
<p>표본분산 추정분산 : <span class="math inline">\(\frac{(n - 1)S^{2}}{\sigma^{2}( = \lambda)} \sim \chi^{2}(n - 1)\)</span> 이므로<span class="math inline">\(V(S^{2}) = \frac{2\lambda^{2}}{n - 1}\)</span>이다. <span class="math inline">\(V(\overline{X}) \leq V(S^{2})\)</span></p>
<p>최량 불편추정량을 찾는 과정은 매우 복잡하다. 만약 어떤 분포 <span class="math inline">\(f(x|\theta)\)</span>에 대해 모수 <span class="math inline">\(\tau(\theta)\)</span>의 불편추정량의 분산에 대한 하한 <span class="math inline">\(B(\theta)\)</span>를 설정할 수 있다면,<span class="math inline">\({Var}_{\theta}(W) = B(\theta)\)</span>를 만족하는 추정량을 찾으면 최량 불편추정량을 찾은 것이 된다.</p>
<p>【Cramér–Rao Lower Bound, CRLB】 확률밀도함수 <span class="math inline">\(f(x|\theta)\)</span>의 확률표본으로부터의 추정량 <span class="math inline">\(W(\mathbf{X}) = W(X_{1},\ldots,X_{n})\)</span>는 다음을 만족한다면, <span class="math inline">\({Var}_{\theta}(W(\mathbf{X})) \geq \frac{\left( \frac{d}{d\theta}E_{\theta}W(\mathbf{X}) \right)^{2}}{nE_{\theta}\left( \left( \frac{\partial}{\partial\theta}\log f(\mathbf{X}|\theta) \right)^{2} \right)}\)</span></p>
<p>정리</p>
<ol type="1">
<li><p><span class="math display">\[\frac{d}{d\theta}E_{\theta}W(\mathbf{X}) = \int_{x}\frac{\partial}{\partial\theta}\lbrack W(x)f(x|\theta)\rbrack dx\]</span></p></li>
<li><p><span class="math display">\[{Var}_{\theta}(W(\mathbf{X})) &lt; \infty\]</span></p></li>
</ol>
<p>【Fisher Information】 확률밀도함수 <span class="math inline">\(f(x|\theta)\)</span>가 지수족을 따르다면 <span class="math inline">\(E_{\theta}\left( \left( \frac{\partial}{\partial\theta}\log f(X|\theta) \right)^{2} \right) = - E_{\theta}\left( \frac{\partial^{2}}{\partial\theta^{2}}\log f(X|\theta) \right)\)</span></p>
<p>따름정리</p>
<p>【예제 ② 계속】 <span class="math inline">\(f(x;\theta) \sim Poisson(\lambda)\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. 모수 <span class="math inline">\(\lambda\)</span>에 대한 추정량의 분산 그레머 라오 하한을 구하시오.</p>
<p>포아송분포는 지수족이므로 Fisher Information은 다음과 같다.</p>
<p><span class="math display">\[E_{\lambda}\left( \left( \frac{\partial}{\partial\lambda}\log\overset{n}{\prod_{i = 1}}f(X_{i}|\lambda) \right)^{2} \right) = - nE_{\lambda}\left( \frac{\partial^{2}}{\partial\lambda^{2}}\log f(X|\lambda) \right)\]</span></p>
<p><span class="math display">\[= - nE_{\lambda}\left( \frac{\partial^{2}}{\partial\lambda^{2}}\log\left( \frac{e^{- \lambda}\lambda^{X}}{X!} \right) \right) = - nE_{\lambda}\left( \frac{\partial^{2}}{\partial\lambda^{2}}\left( - \lambda + X\log\lambda - \log X! \right) \right) = \frac{n}{\lambda}\]</span></p>
<p><span class="math inline">\(V_{\lambda}(\overline{X}) = \frac{\lambda}{n}\)</span>이므로 표본평균이 크레머 라오 하한을 보장한다.</p>
<p>【예제 ③】 <span class="math inline">\(f(x;\theta) \sim N(\mu,\sigma^{2})\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. 모수 <span class="math inline">\(\sigma^{2}\)</span>에 대한 추정량의 분산 그레머 라오 하한을 구하시오.</p>
<p>정규분포는 지수족이므로</p>
<p><span class="math display">\[\frac{\partial^{2}}{\partial(\sigma^{2})^{2}}\log\left( \frac{1}{(2\pi\sigma^{2})^{\frac{1}{2}}}e^{- (1/2)(x - \mu)^{2}/\sigma^{2}} \right) = \frac{1}{2\sigma^{4}} - \frac{(x - \mu)^{2}}{\sigma^{6}}\]</span></p>
<p><span class="math display">\[- E\left( \frac{\partial^{2}}{\partial(\sigma^{2})^{2}}\log f(X|\mu,\sigma^{2}) \right) = - E\left( \frac{1}{2\sigma^{4}} - \frac{(X - \mu)^{2}}{\sigma^{6}} \right) = \frac{1}{2\sigma^{4}}\]</span></p>
<p>표본분산의 추정분산은 <span class="math inline">\(Var(S^{2} \mid \mu,\sigma^{2}) = \frac{2\sigma^{4}}{n - 1}\)</span>이므로 표본분산은 그레머 라오 하한을 만족하지 못한다.</p>
<p>4Rao balckwell 정리 &amp; MVUE</p>
<p>【MVUE 정의】 <span class="math inline">\(f(x;\theta)\)</span> 에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본 <span class="math inline">\((X_{1},X_{2},\ldots,X_{n})\)</span> 추출하였고 <span class="math inline">\(T(\overline{x})\)</span>은 모수 <span class="math inline">\(\theta\)</span>의 충분 통계량이다. 만약 <span class="math inline">\(T(\overline{x})\)</span> 불편 추정량이고 다른 불편 추정량의 추정 분산보다 적은 추정 분산을 가진다면 <span class="math inline">\(T(\overline{x})\)</span>를 최소분산 불편 추정량 minimum variance unbiased estimator 이라 한다.</p>
<p>정의</p>
<p>충분 통계량은 모수에 대한 좋은 추정량을 발견하는데 주요 역할을 한다. 추정량 <span class="math inline">\(\widehat{\theta}\)</span>을 모수 <span class="math inline">\(\theta\)</span>의 불편 추정량, 통계량 <span class="math inline">\(U\)</span>을 모수 <span class="math inline">\(\theta\)</span>에 대한 충분 통계량이라 하자. 불편 추정량인 충분 통계량 함수는 불편 추정량 중 최소 분산을 갖는다. 만약 최소 분산을 갖는 불편 추정량을 찾는 것은 충분 통계량의 함수인 추정량에 한정하며 된다. 이에 관련된 이론이 Rao-Blackwell 정리라 한다.</p>
<p>【rao-blackwell theorem】 추정량 &nbsp;<span class="math inline">\(\overset{\hat{}}{\theta}\)</span>는 모수 <span class="math inline">\(\theta\)</span>의 불편 추정량이고 추정 분산을 <span class="math inline">\(V(\overset{\hat{}}{\theta})\)</span>이라 하자. 만약 통계량 <span class="math inline">\(U\)</span>을 모수 <span class="math inline">\(\theta\)</span>에 대한 충분 통계량이라 하면 <span class="math inline">\(E(\overset{\hat{}}{\theta}|U)\)</span>은 불편 추정량이고 불편 추정량 중 최소 분산을 갖는다.</p>
<p>정리</p>
<p><span class="math inline">\(X_{1},X_{2}\)</span> 확률변수에 대하여</p>
<p>(1) <span class="math inline">\(E\left( X_{2} \right) = E(E\left( X_{2}|X_{1} \right))\)</span> (2) <span class="math inline">\(V\left( X_{2} \right) \geq V(E\left( X_{2}|X_{1} \right))\)</span></p>
<p><span class="math inline">\(X_{1}\)</span>=모수 <span class="math inline">\(\theta\)</span> 충분 통계량 <span class="math inline">\(U\)</span>, <span class="math inline">\(X_{2}\)</span>=모수 <span class="math inline">\(\theta\)</span> 불편 통계량 <span class="math inline">\(\overset{\hat{}}{\theta}\)</span>이라 하자.</p>
<p><span class="math inline">\(E\left( \overset{\hat{}}{\theta} \right) = E(E\left( \overset{\hat{}}{\theta}|U \right))\)</span> 이므로 <span class="math inline">\(E(\overset{\hat{}}{\theta}|U)\)</span> 불편 추정량이다.</p>
<p><span class="math inline">\(V\left( \overset{\hat{}}{\theta} \right) \geq V(E(\overset{\hat{}}{\theta}|U))\)</span> 이므로 불편 추정량이면서 이전보다 추정분산이 적은 추정량을 얻는다.</p>
<p>R-B 정리는 최소분산을 갖는 불편 추정량은 충분 통계량으로 만들어질 수 있다. 만약 우리가 불편 추정량을 갖고 있다면 R-B 정리를 이용하여 이 불편 추정량을 향상 시킬 수 있다. 이렇게 얻는 추정량에 R-B 정리를 반복 적용하면 된다. 그러나 만약 동일한 충분 통계량을 사용한다면 더 이상 나아지는 것도 없다.</p>
<p><span class="math inline">\({\overset{\hat{}}{\theta}}^{*} = E(\overset{\hat{}}{\theta}|U)\)</span>을 새로 얻은 불편 추정량이라 하자. <span class="math inline">\(E\left( {\overset{\hat{}}{\theta}}^{*} \middle| U \right) = {\overset{\hat{}}{\theta}}^{*}\)</span> 이므로 충분 통계량은 수없이 많다. 그럼 어떤 충분 통계량을 시작점으로 하여 R-B 정리에 사용될까? Factorization criterion이 가장 좋은 충분 통계량을 얻게 한다. 가장 좋은 통계량이란 데이터(확률표본)에 있는 모수에 대한 정보를 가장 잘(best) 요약한 것을 의미하며 이를 Minimal 충분 통계량이라 한다.</p>
<p><span class="math inline">\(f(x;\theta)\)</span> 에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본 <span class="math inline">\((X_{1},X_{2},\ldots,X_{n})\)</span> 추출하였고 <span class="math inline">\(T(\overline{x})\)</span>을 모수 <span class="math inline">\(\theta\)</span>의 충분 통계량이라 하자. 또 다른 확률표본 <span class="math inline">\((Y_{1},Y_{2},\ldots,Y_{n})\)</span>에 대하여 <span class="math inline">\(\frac{L(x_{1},x_{2},\ldots,x_{n};\theta)}{L(y_{1},y_{2},\ldots,y_{n};\theta)}\)</span>가 모수 <span class="math inline">\(\theta\)</span>의 함수가 성립한다. ⬄ (필요 충분 조건) <span class="math inline">\(T\left( \overline{x} \right) = T(\overline{y})\)</span>. 그리고 <span class="math inline">\(T(\overline{x})\)</span>을 최소 minimal 충분 통계량이라 한다.</p>
<p>정리</p>
<p>일반적으로 Factorization criterion에서 얻은 충분 통계량과 Minimal 충분 통계량은 같다. 이런 통계량이 갖는 성질을 Completeness(완비성)라 한다.</p>
<p>【ancillary statistics】 모수 <span class="math inline">\(\theta\)</span>에 의존하지 않는 통계량 <span class="math inline">\(S(\overline{x})\)</span>을 보조 ancillary 통계량이라 한다.확률 분포의 모수에 관련된 정보가 아닌 추가적인 정보를 제공하는 통계량을 나타내고 모수 추정이나 가설 검정과 같은 통계적 추론에서 사용되는데, 주로 추정된 모수들의 분포나 특성을 이해하고 분석하는 데 활용된다.</p>
<p>정의</p>
<p>【예제】 <span class="math inline">\(f(x;\theta) \sim U(\theta,\theta + 1)\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본 <span class="math inline">\((X_{1},X_{2},\ldots,X_{n})\)</span> 추출하였다. 통계량 <span class="math inline">\(R = x_{(n)} - x_{(1)}\)</span>의 확률밀도함수가 모수 <span class="math inline">\(\theta\)</span>에 의존하지 않으므로 보조 통계량이다.</p>
<p>【예제】 <span class="math inline">\(f(x;\theta) \sim B(\theta = p)\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본 <span class="math inline">\((X_{1},X_{2},\ldots,X_{n})\)</span> 추출하였다. 충분 통계량 <span class="math inline">\(\sum X_{i}\)</span>의 확률밀도함수는 <span class="math inline">\(B(np,np(1 - p))\)</span>로 모수 <span class="math inline">\(\theta = p\)</span>에 의존하므로 보조 통계량은 아니다. 그러나 <span class="math inline">\(\frac{\sum X_{i} - np}{\sqrt{np(1 - p)}}\)</span> 확률밀도함수는 표준정규분포(<span class="math inline">\(N(0,1)\)</span>)에 근사하므로 모수에 의존하지 않아 보조 통계량이다. 다음 장에서 이를 검정 통계량이라 한다.</p>
<p>【완비성 completeness 】 충분 통계량 <span class="math inline">\(T\left( \overline{x} \right) \sim f(t;\theta)\)</span>을 갖는다고 하자. 만약 <span class="math inline">\(E_{\theta}\left( g(T) \right) = 0forall\theta\)</span>가 <span class="math inline">\(P_{\theta}\left( g(T) = 0 \right) = 1forall\theta\)</span>을 포함하면 <span class="math inline">\(T\left( \overline{x} \right)\)</span>는 완비 통계량이다.</p>
<p>정의</p>
<p>【예제】 <span class="math inline">\(f(x;\theta) \sim B(\theta = p)\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. 충분 통계량 <span class="math inline">\(\sum X_{i}\)</span>은 완비 통계량임을 보이시오.</p>
<p><span class="math inline">\(T = \sum X_{i} \sim B(n,p)\)</span> 이다.</p>
<p><span class="math inline">\(0 = E_{p}\left( g(T) \right) = \sum_{t}^{n}{g(t)\binom{n}{t}p^{t}(1 - p)^{n - t} = (1 - p)^{n}}\sum_{t}^{n}{g(t)\binom{n}{t}{(\frac{p}{1 - p})}^{t}forall0 &lt; p &lt; 1}\)</span>.</p>
<p><span class="math inline">\(0 = \sum_{t}^{n}{g(t)\binom{n}{t}{(\frac{p}{1 - p})}^{t}}\)</span> 이 조건이 만족하기 위해서는 <span class="math inline">\(P_{\theta}\left( g(T) = 0 \right) = 1\)</span> 이므로 완비 통계량이다.</p>
<p>【예제】 <span class="math inline">\(f(x;\theta) \sim U(0,\theta)\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본 <span class="math inline">\((X_{1},X_{2},\ldots,X_{n})\)</span> 추출하였다. 충분 통계량 <span class="math inline">\({T = x}_{(n)}\)</span>은 완비 통계량이다.</p>
<p><span class="math inline">\(T \sim f(t;\theta) = nt^{n - 1}\theta^{- n},0 &lt; t &lt; \theta\)</span> 이다.</p>
<p><span class="math inline">\(E_{\theta}\left( g(T) \right)\)</span>은 모수 <span class="math inline">\(\theta\)</span>의 함수이고 상수이므로 <span class="math inline">\(E_{p}\left( g(T) \right) = 0\)</span>을 보이는 것은 <span class="math inline">\({\frac{\partial}{\partial\theta}E}_{\theta}\left( g(T) \right) = 0\)</span>을 보이는 것은 동일하다.</p>
<p><span class="math display">\[{0 = \frac{\partial}{\partial\theta}E}_{\theta}\left( g(T) \right) = \frac{\partial}{\partial\theta}\int_{0}^{\theta}{g(t)}nt^{n - 1}\theta^{- n}dt = \theta^{- 1}ng(\theta)\]</span></p>
<p><span class="math inline">\(\theta^{- 1}n \neq 0\)</span> 이므로 <span class="math inline">\(g(\theta) = 0\)</span>이어야 한다. 그러므로 <span class="math inline">\({T = x}_{(n)}\)</span> 완비 통계량이다.</p>
<p>【basu theorem】 최소 충분 통계량이고 완비 통계량 <span class="math inline">\(T\left( \overline{x} \right)\)</span>는 다른 모든 보조 통계량과 독립이다.</p>
<p>정리</p>
<p>완비 통계량 <span class="math inline">\(T\left( \overline{x} \right)\)</span>는 최소 충분 통계량이다.</p>
<p>정리</p>
<p>⑴ Factorization에 의해 충분 통계량 <span class="math inline">\(U\)</span>을 구하고 (2) <span class="math inline">\(U\)</span> 확률밀도함수의 완비성을 보이고 (3) 완비 충분 통계량 <span class="math inline">\(U\)</span>의 함수로 된 불편 추정량을 얻으면 이것이 Rao-Blackwell 정리에 의하여 MVUE가 된다.</p>
<p>【lehmann and scheffe theorem】 <span class="math inline">\(f(x;\theta),\theta \in \Omega\)</span> 에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였고 <span class="math inline">\(T(x_{1},x_{2},\ldots,x_{n})\)</span>은 모수 <span class="math inline">\(\theta\)</span>의 충분 통계량이라 하자. <span class="math inline">\(T(\overline{x})\)</span>의 확률밀도함수 <span class="math inline">\(f(t;\theta)\)</span>가 완비성을 갖는다면 불편성을 갖는 <span class="math inline">\(T(\overline{x})\)</span> 함수, <span class="math inline">\(g(T\left( \overline{x} \right),E(g\left( T\left( \overline{x} \right) \right) = \theta)\)</span>는 유일 최소분산불편 추정량(MVUE)이다.</p>
<p>정리</p>
<p><span class="math inline">\(f(x;\theta)\)</span> 에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였고 <span class="math inline">\(T(\overline{x})\)</span>을 모수 <span class="math inline">\(\theta\)</span>의 충분 통계량, 그리고 <span class="math inline">\({\overset{\hat{}}{\theta}}_{mle}\)</span>는 MLE 추정량이라 하자. <span class="math inline">\({\overset{\hat{}}{\theta}}_{mle}\)</span>는 충분 통계량, <span class="math inline">\(T(\overline{x})\)</span>의 함수이다.</p>
<p>정리</p>
<p>충분 통계량의 완비성을 증명하는 것은 쉽지 않다. 단 지수족 모집단으로부터 확률표본의 통계량 <span class="math inline">\(T = \sum K(X_{i})\)</span>는 모수 <span class="math inline">\(\theta\)</span>의 완비 충분 통계량이다.</p>
<p>지수족 확률밀도함수를 갖는 경우 <span class="math inline">\(c(\theta)\)</span>의 최소 충분 통계량은 <span class="math inline">\(\sum K(x)\)</span>이다.</p>
<p>정리</p>
<p>지수족 확률밀도함수를 다음과 같이 쓸 수 있다.</p>
<blockquote class="blockquote">
<p><span class="math display">\[f(x;\theta) = h(x)g(\theta)\exp{\left( c(\theta)K(x) \right) \Longleftrightarrow}exp(c(\theta)K(x) + h(x) + g(\theta))\]</span></p>
</blockquote>
<p><span class="math inline">\(h(x),K(x)\)</span> : 확률변수 <span class="math inline">\(x\)</span>의 함수, <span class="math inline">\(g(\theta),c(\theta)\)</span> : 모수 <span class="math inline">\(\theta\)</span>의 함수</p>
<p>【예제】 <span class="math inline">\(f(x;\theta) = \frac{1}{\theta},0 &lt; x &lt; \theta\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. MVUE 구하라.</p>
<ol type="1">
<li><span class="math inline">\({T = X}_{(n)} \sim f(t;\theta) = \frac{nt^{n - 1}}{\theta^{n}},0 &lt; t &lt; \theta\)</span>는 충분 통계량</li>
</ol>
<!-- -->
<ol type="1">
<li><span class="math display">\[E_{\theta}\left( g(T) \right) = \int_{0}^{\theta}{g(t)\frac{nt^{n - 1}}{\theta^{n}}dt} = (\theta &gt; 0,n \geq 1)\int_{0}^{\theta}{g(t)t^{n - 1}dt} = 0\]</span></li>
</ol>
<p><span class="math inline">\(0 = g(\theta)\theta^{n - 1}\)</span>을 만족하려면 <span class="math inline">\(g(\theta) = 0\)</span>이어야 하므로 <span class="math inline">\({T = X}_{(n)}\)</span> 완비 통계량이다.</p>
<ol start="3" type="1">
<li><span class="math inline">\(E(T) = \int_{0}^{\theta}{t\frac{nt^{n - 1}}{\theta^{n}}dt = \frac{n}{n + 1}\theta}\)</span> 이므로 <span class="math inline">\(\frac{n + 1}{n}X_{(n)}\)</span>은 MVUE</li>
</ol>
<p>【예제】 <span class="math inline">\(f(x;\theta) = B(\theta = p)\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. MVUE 구하라.</p>
<p><span class="math inline">\(f(x;\theta = p) = p^{x}(1 - p)^{1 - x} = 1(1 - p)exp(ln(\frac{p}{1 - p})x)\)</span> 이므로 지수족이고 <span class="math inline">\(K\left( x_{i} \right) = x_{i}\)</span>. 그러므로 <span class="math inline">\(\sum x_{i}\)</span> 완비 충분 통계량이고 <span class="math inline">\(\sum x_{i} \sim B(n,p)\)</span> 이다. <span class="math inline">\(E\left( \sum x_{i} \right) = np\)</span> 이므로 <span class="math inline">\(\overline{X} = \frac{\sum x_{i}}{n}\)</span>는 MVUE이다.</p>
<p>【예제】 <span class="math inline">\(f(x;\theta = \lambda) = e^{- \lambda}\frac{\lambda^{x}}{x!}\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. MVUE 구하라.</p>
<p><span class="math inline">\(f(x;\lambda) = {\frac{1}{x!}e}^{- \lambda}(ln(\lambda)x)\)</span> 이므로 지수족이고 <span class="math inline">\(K\left( x_{i} \right) = x_{i}\)</span>.</p>
<p>그러므로 <span class="math inline">\(\sum x_{i}\)</span> 완비 충분 통계량이고 <span class="math inline">\(\sum x_{i} \sim P(n\lambda)\)</span> 이다.</p>
<p><span class="math inline">\(E\left( \sum x_{i} \right) = n\lambda\)</span> 이므로 <span class="math inline">\(\overline{X} = \frac{\sum x_{i}}{n}\)</span>는 MVUE이다.</p>
<p>【예제】 <span class="math inline">\(f(x;\theta) = \left( \frac{2x}{\theta} \right)e^{- x^{2}/\theta} \sim Weibull(\gamma = 2,\theta)\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. MVUE 구하라.</p>
<p><span class="math inline">\(f(x;\theta) = 2x\left( \frac{1}{\theta} \right)exp( - x^{2}/\theta)\)</span> 이므로 지수족이고 <span class="math inline">\(K\left( x_{i} \right) = x_{i}^{2}\)</span>. 그러므로 <span class="math inline">\(\sum x_{i}^{2}\)</span> 완비 충분 통계량이다.</p>
<p>변수 변환 방법 <span class="math inline">\(W = X^{2},X = \sqrt{W},J = \frac{1}{2\sqrt{w}}\)</span> 이므로 <span class="math inline">\(W \sim exponential(\theta)\)</span>이다.</p>
<p><span class="math inline">\(E\left( \sum x_{i}^{2} \right) = n\theta\)</span> 이므로 <span class="math inline">\(\frac{\sum x_{i}^{2}}{n}\)</span> 은 MVUE이다.</p>
<p>【예제】 <span class="math inline">\(f(x;\theta = \mu) = N\left( \mu,\sigma^{2} \right),where\sigma^{2}isknown\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. 모수 <span class="math inline">\(\theta = \mu\)</span>MVUE 구하라.</p>
<p><span class="math inline">\(f(x;\theta) = \frac{1}{\sqrt{2\pi}\sigma}e^{( - \mu/2\sigma^{2})}exp(\frac{\mu}{\sigma^{2}}x - \frac{x^{2}}{2\sigma^{2}})\)</span> 이므로 지수족이고 <span class="math inline">\(K\left( x_{i} \right) = x_{i}\)</span>. <span class="math inline">\(E\left( \sum x_{i} \right) = n\mu\)</span> 이므로 <span class="math inline">\(\overline{X} = \frac{\sum x_{i}}{n}\)</span>는 MVUE이다.</p>
<p>추정량 <span class="math inline">\(\overset{\hat{}}{\theta}\)</span>은 모수 <span class="math inline">\(\theta\)</span>에 대한 MVUE이고 <span class="math inline">\(g(.)\)</span>은 일대일 함수이면 <span class="math inline">\(g(\theta)\)</span>의 MVUE는 <span class="math inline">\(g(\overset{\hat{}}{\theta})\)</span> 중 불편성을 갖는 추정량이다.</p>
<p>정리</p>
<p>【예제】 <span class="math inline">\(f(x;\theta) = B(\theta = p)\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. <span class="math inline">\(\frac{p(1 - p)}{n}\)</span>에 대한 MVUE 구하라.</p>
<p>모수 <span class="math inline">\(\theta = p\)</span>에 대한 MVUE는 <span class="math inline">\(\overline{X} = \frac{\sum x_{i}}{n}\)</span> 임을 보였다.</p>
<p>그러므로 <span class="math inline">\(\frac{p(1 - \theta p)}{n}\)</span>에 대한 MVUE을 구하기 위하여 분포를 알고 있는 <span class="math inline">\(Y = \sum x_{i} \sim B(n,p)\)</span> 함수를 이용하는 것이 적절하다. <span class="math inline">\(Y\)</span>는 완비 충분 통계량이므로 <span class="math inline">\(Y(1 - Y)\)</span>도 완비 충분 통계량이다.</p>
<p><span class="math inline">\(E\left( Y(1 - Y) \right) = E(Y) - E\left( Y^{2} \right) = E(Y) - \left( V(X) + E(Y)^{2} \right) = np - np(1 - p) - n^{2}p^{2}\)</span></p>
<p><span class="math inline">\(= (n - 1)p(1 - p)\)</span> 이므로 <span class="math inline">\(\frac{\theta(1 - \theta)}{n}\)</span> 의 MVUE는 <span class="math inline">\(\frac{Y(1 - Y)}{n(n - 1)}\)</span></p>
<p>【예제】 <span class="math inline">\(f(x;\theta) = \left( \frac{1}{\theta} \right)e^{- x/\theta} \sim exponential(\theta)\)</span>에서 표본크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. <span class="math inline">\(V(X) = \theta^{2}\)</span> MVUE 구하라.</p>
<p>지수분포는 지수족이고 <span class="math inline">\(K\left( x_{i} \right) = x_{i}\)</span>이므로<span class="math inline">\(\sum x_{i}\)</span> 완비 충분 통계량이므로 <span class="math inline">\(\overline{X}\)</span>는 모수 <span class="math inline">\(\theta\)</span>의 MVUE이다. 그러므로 <span class="math inline">\(V(X) = \theta^{2}\)</span>의 MVUE을 <span class="math inline">\({\overline{X}}^{2}\)</span>의 함수 중 불편 추정량을 찾으면 된다.<span class="math inline">\(E\left( {\overline{X}}^{2} \right) = V\left( \overline{X} \right) + E\left( \overline{X} \right)^{2} = \frac{\theta^{2}}{n} + \theta^{2} = \frac{n + 1}{n}\theta^{2}\)</span> 이므로 <span class="math inline">\(\frac{n\overline{X}}{n + 1}\)</span> 은 MVUE이다.</p>
<p>Chapter 3. 가설검정</p>
<p>1기초</p>
<p>개념</p>
<p>추론 통계학 inference statistics 은 모집단의 특성치인 모수 <span class="math inline">\(\theta\)</span>에 대한 추정치(점 추정치, 구간 추정치)를 구하는 추정 과 모수 값에 대한 가설의 진위 여부(통계적 유의성)를 알아보는 가설 검정 hypothesis testing이 있다.</p>
<p>가설 검정은 과학적 연구와 유사하다. ⑴자연 현상을 관찰하여 ⑵이론을 정립하고 (임의의 모수 값) ⑶관측치를 통하여 이론 진위 여부를 테스트 한다. 이론의 옳고 그름은 표본 관측치에 의해 판단된다.</p>
<p>가설검정은 무죄 추정의 원칙으로 범인의 유죄여부를 배심원의 결정과정과 동일하다. <span dir="rtl">’</span>범인은 무죄이다<span dir="rtl">’</span>를 시작으로 <span dir="rtl">’</span>검사가 제시한 여러 증거<span dir="rtl">’</span>(표본 데이터)를 기반하여 범인의 유죄, 무죄를 판결한다. 가설검정은 연역적 추론 과정과 유사하여 1) 자연현상, 사회현상을 관찰하여 이론을 도출하고 2)이를 통계적 가설로 만든 후 3)적절한 (확률표본) 데이터를 수집 분석하여 4)가설의 진위를 검증한다.</p>
<p>통계적 가설</p>
<p>통계적 가설은 모수에 관한 가정이다. <span class="math inline">\(X \sim f(x;\theta,\theta \in \Omega)\)</span>의 모수 <span class="math inline">\(\theta\)</span>가 가지는 값에 대한 가정이다. 설정한 통계적 가설은 통계적 방법으로 테스트 할 수 있도록 한 것으로 모수의 값에 관한 것이다.</p>
<p>불량률이 5%인 제조 공정을 개선하기 위한 새로운 공정이 제안되었다. 모수는 모집단 비율 <span class="math inline">\(\theta = p\)</span></p>
<p>기존의 약에 비해 두통에 효과적인 새로운 약을 개발하였다고 하자. 두 모집단 평균 차이 <span class="math inline">\(\theta = \mu_{old} - \mu_{new}\)</span></p>
<p>수능성적과 GPA의 관계? <span class="math inline">\(GPA = a + b \times SAT\)</span>, <span class="math inline">\(b = 0\)</span>?</p>
<p>모수 <span class="math inline">\((\theta \in \Omega = \left\{ \theta;\omega_{0} \cup \omega_{1} \right\},\omega_{0} \cap \omega_{1} = \phi)\)</span>에 관한 통계적 가설은 다음과 같이 2개의 가설로 나뉜다.</p>
<p>정의</p>
<p>귀무가설 null hypothesis : <span class="math inline">\(H_{0}:\theta \in \omega_{0}\)</span>, 집합 <span class="math inline">\(\omega_{0}\)</span>에는 하나의 값 <span class="math inline">\(\omega_{0}\)</span>만 있다.</p>
<p>대립가설 alternative hypothesis : <span class="math inline">\(H_{1}:\theta \in \omega_{1}\)</span>, 집합 <span class="math inline">\(\omega_{1} = \{\theta;\theta \neq \theta_{0}\}\)</span>이다.</p>
<p>양측 대립가설 : <span class="math inline">\(\omega_{1} = \{\theta;\theta \neq \theta_{0}\}\)</span></p>
<p>단측 대립가설 : <span class="math inline">\(\omega_{1} = \{\theta;\theta &lt; \theta_{0}\}\)</span>, <span class="math inline">\(\omega_{1} = \{\theta;\theta &gt; \theta_{0}\}\)</span></p>
<p>우리가 지지하는 가설은 연구가설 research hypothesis 혹은 대립가설이라 한다. 대립가설과 반대되는 가설을 귀무가설라 한다. 어떤 가설이 지지되느냐는 관측된 표본 데이터에 의존한다. <span dir="rtl">”</span>귀무”(null)의 의미는 아무 것도 없다는 것이다.</p>
<p>검정통계량</p>
<p>검정통계량은 통계적 가설 검정에서 사용되는 중요한 개념으로 확률표본 데이터를 기반으로 계산되며 귀무가설을 평가하는데 사용된다. 검정통계량은 일반적으로 확률표본 데이터의 요약된 값으로 귀무가설이 참일 때 얼마나 불일치하는지를 나타내는 역할을 한다. 검정통계량의 값은 귀무가설의 가정과 확률표본 데이터 간의 차이를 측정하며, 이 값을 기반으로 가설 검정의 결과를 판단한다.</p>
<p>예를 들어, 평균값의 차이에 대한 가설 검정을 수행한다고 가정해보자. 두 그룹의 평균을 비교하려면 먼저 평균의 차이를 계산하고, 이 차이를 그룹 간의 변동을 나타내는 표준 오차로 나누어 표준화된 차이를 얻을 수 있는데. 이 표준화된 차이가 검정통계량이 된다.</p>
<p>검정통계량의 값은 주어진 데이터에 따라 달라지며 이 값을 귀무가설에 대한 기대값과 비교하여 가설 검정의 결과를 결정한다. 일반적으로 검정통계량이 특정한 임계값보다 크거나 작으면 귀무가설을 기각하고 대립가설을 지지하는 결론을 내린다. 이 때 임계값은 유의수준에 따라 결정되며, 유의수준은 연구자가 허용하는 오류의 수준을 나타낸다.</p>
<p>【검정통계량】</p>
<p><span class="math inline">\(f(x;\theta)\)</span>에서 확률표본 <span class="math inline">\((X_{1},X_{2},\ldots,X_{n})\)</span>의 함수인 통계량 <span class="math inline">\(t(x_{1},x_{2},\ldots,x_{n})\)</span>이 가설 검정에 사용되면 이를 검정 통계량이라 한다.</p>
<p>【가설 검정 방법】</p>
<p>채택 영역 acceptance region: 어떤 확률표본 값들에 대하여 귀무가설을 참으로 받아들일지 결정</p>
<p>기각 영역 rejection region : 어떤 확률표본 값들에 대하여 귀무가설을 기각하고 대립가설을 참으로 받아들일지 결정</p>
<p>"귀무가설 기각"과 "대립가설 수용" 사이의 차이를 이해하는 것은 쉽지 않다. 첫 번째 경우에는 실험자가 어떤 상태를 수용하는지에 대한 내용은 함축되지 않으며, 오직 <span class="math inline">\(H_{0}\)</span>에 의해 정의된 상태가 기각된다는 것만을 나타낸다. 마찬가지로 "귀무가설 수용"과 "귀무가설 기각하지 않음" 사이에도 차이가 있을 수 있다. 첫 번째 구문은 실험자가 <span class="math inline">\(H_{0}\)</span>로 지정된 상태(단일 모수 값)를 주장하려고 하는 것을 의미하며, 두 번째 구문은 실험자가 실제로 <span class="math inline">\(H_{0}\)</span>를 믿지 않지만 기각할 증거가 없다는 것을 의미한다.</p>
<p>기각역</p>
<p>확률표본 <span class="math inline">\((X_{1},X_{2},\ldots,X_{n})\)</span>의 영역을 <span class="math inline">\(\mathcal{D}\)</span>라 하자. <span class="math inline">\(\mathcal{D}\)</span>의 부분 집합 <span class="math inline">\(RR\)</span> 에 확률표본 값이 포함되면 귀무가설을 기각한다면 <span class="math inline">\(RR\)</span> 영역을 기각역 critical region 이라 한다.</p>
<p>귀무가설 : <span class="math inline">\(H_{0}:\theta \in \omega_{0} = \{\theta;\theta_{0}\}\)</span> – 단일 simple 가설</p>
<p>대립가설 : <span class="math inline">\(H_{1},H_{a}:\theta \in \omega_{1} = \{\theta;{\theta \neq \theta}_{0}\}\)</span> 복합 composite 가설</p>
<p>만약 <span class="math inline">\(t\left( x_{1},x_{2},\ldots,x_{n} \right) \in RR\)</span>, 귀무가설 기각한다. ⬄ 대립가설 채택한다. 만약 <span class="math inline">\(t\left( x_{1},x_{2},\ldots,x_{n} \right) \in {RR}^{c}\)</span>, 귀무가설 채택한다. ⬄ 대립가설<img src="media/image3.png" style="width:2.93488in;height:1.07684in" alt="라인, 도표, 디자인이(가) 표시된 사진 자동 생성된 설명"> 기각한다.</p>
<p>귀무가설을 기각하는 검정통계량의 값이 포함된 영역을 기각역 이라 한다. 만약 확률표본으로부터 계산된 검정통계량의 값이 기각역에 포함되면 귀무가설을 기각(대립가설 채택)하고 그렇지 않으면 귀무가설을 채택한다. 빨간 영역 부분이 기각역이다. 영역이 시작되는 값을 기각값, 임계값 critical value 이라 한다.</p>
<p>1종오류, 2종 오류</p>
<p>【1종 오류, 2종 오류】</p>
<p>1종 오류 : 귀무가설이 사실일 때 귀무가설을 기각할 확률이다. type I error, <span class="math inline">\(\alpha\)</span> 라고 표기한다.</p>
<p>2종 오류 : 대립가설이 사실일 때 귀무가설을 채택하는 확률이다. type II error, <span class="math inline">\(\beta\)</span>라 표기한다.</p>
<p>즉 <span class="math inline">\(\alpha,\beta\)</span>는 통계적 가설 검정의 정확도를 측정하는데 매우 유용하다.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 31%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<tbody>
<tr class="odd">
<td style="text-align: right;"><p>실제 모집단</p>
<p>가설 판단</p></td>
<td style="text-align: center;">귀무가설(<span class="math inline">\(H_{0}\)</span>) 진실</td>
<td style="text-align: center;">대립가설(<span class="math inline">\(H_{1}\)</span>) 진실</td>
</tr>
<tr class="even">
<td style="text-align: right;">귀무가설 기각</td>
<td style="text-align: center;">1종 오류 <span class="math inline">\(\alpha\)</span></td>
<td style="text-align: center;">옳은 판단</td>
</tr>
<tr class="odd">
<td style="text-align: right;">귀무가설 채택</td>
<td style="text-align: center;">옳은 판단</td>
<td style="text-align: center;">2종 오류 <span class="math inline">\(\beta\)</span></td>
</tr>
</tbody>
</table>
<p>가설 검정의 목표는 모든 가능한 기각 영역 중에서 이러한 오류의 확률을 최소화하는 영역을 선택하는 것이지만 일반적으로 이것은 불가능한다. 이러한 오류의 확률은 종종 풍선 효과를 가지고 있는데 이것은 극단적인 경우에 즉시 볼 수 있다.</p>
<p>단순히 <span class="math inline">\(RR = \phi\)</span>라 가정해 보자. 이 기각 영역에서는 결코 귀무가설을 기각하지 않을 것이므로 제1종 오류의 확률은 0이 될 것이지만, 제2종 오류의 확률은 1이다. 종종 우리는 두 오류 중에서 제1종 오류를 더 나쁜 오류로 간주한다. 따라서 우리는 제1종 오류의 확률을 제한하는 기각 영역을 선택한 다음 이러한 기각 영역 중에서 제2종 오류의 확률을 최소화하는 하나를 선택하려고 노력하게 된다. 검정 시 설정한 1종 오류(검정 크기)을 유의수준 significance level이라 한다.</p>
<p>【검정 크기】</p>
<p>만약 <span class="math inline">\(\alpha = \max_{\theta \in \omega_{0}}{P_{\theta}(t\left( X_{1},X_{2},\ldots,X_{n} \right) \in RR)}\)</span> 이면 기각역의 크기 size는 <span class="math inline">\(\alpha\)</span>라 한다. 크기 <span class="math inline">\(\alpha\)</span>의 모든 기각 영역을 고려할 때, 우리는 제2종 오류의 확률이 더 낮은 영역을 고려한다. 또한 제2종 오류의 여집합을 살펴볼 수 있는데 즉 귀무가설이 참일 때 귀무가설을 기각하는 것이며 이것은 옳은 결정이다. 우리는 이후의 결정의 확률을 최대화하려고 하므로 이 확률이 최대한 크도록 하려고 합니다. 즉, <span class="math inline">\(\theta \in \omega_{1}\)</span>인 경우 우리는 다음을 최대화하고자 한다.</p>
<p><span class="math display">\[1 - P_{\theta}(typeIIerror) = P_{\theta}\left( \left( X_{1},X_{2},\ldots,X_{n} \right) \in RR \right)\]</span></p>
<p>【1종 오류】</p>
<p>1종 오류는 유의수준, 검정 크기와 동일하다. 기각역 <span class="math inline">\(C\)</span>에 검정통계량 값이 속할 확률이다. <span class="math inline">\(P_{\theta_{0}}(t\left( X_{1},X_{2},\ldots,X_{n} \right) \in RR)\)</span></p>
<p>【2종 오류 계산】</p>
<p>귀무가설 <span class="math inline">\(H_{0}:\theta = \theta_{0}\)</span>, 대립가설 <span class="math inline">\(H_{1}:\theta = \theta_{1} &lt; \theta_{0}\)</span>의 경우 2종 오류을 계산하는 방법을 살펴 보자. 2종 오류를 계산하려면 대립가설에 속한 모수의 하나의 값이 필요하다. 대립가설의 모수 값은 구간이기 때문이다. 대립가설의 하나의 값을 <span class="math inline">\(\theta_{1}\)</span>라 하자.</p>
<p>2종 오류 : <span class="math inline">\(P_{\theta_{1}}(t\left( X_{1},X_{2},\ldots,X_{n} \right) \in CR)\)</span> 검정 통계량이 기각역(<span class="math inline">\(CR\)</span>)에 속하지 않을 확률</p>
<p>대립가설의 <span class="math inline">\(\theta_{1}\)</span>이 <span class="math inline">\(\theta_{0}\)</span>에 가깝다면 대립가설이 사실임에도 불구하고 귀무가설 받아들일 가능성이 높다. 즉 2종 오류는 커진다.</p>
<p>검정력</p>
<p>【검정력 함수】</p>
<p>다음은 기각역의 검정력 함수 power function로 정의한다. 검정력 함수는 모수 함수이다.</p>
<p><span class="math display">\[\gamma_{C}(\theta) = P_{\theta}(t\left( X_{1},X_{2},\ldots,X_{n} \right) \in RR;\theta \in \omega_{1})\]</span></p>
<p>귀무가설 하의 모수 값에서 검정력은 1 종 오류(유의수준)이다.</p>
<p>【예제】 <span class="math inline">\(f(x;\theta) = \frac{1}{\theta},0 &lt; x &lt; \theta \sim U(0,\theta)\)</span>에서 모수 <span class="math inline">\(\theta\)</span>에 대한 다음 가설을 검정하기 위하여 확률표본을 추출하였다.</p>
<p>귀무가설 : <span class="math inline">\(H_{0}:\theta = \theta_{0}\)</span></p>
<p>대립가설 : <span class="math inline">\(H_{1}:\theta = \theta_{1} &lt; \theta_{0}\)</span> 단측 대립가설</p>
<p>검정통계량 : MVUE의 함수이며 확률밀도함수가 알려진 통계량을 이용한다. *) 모집단 비율의 MVUE는 <span class="math inline">\(\sum X_{i}/n\)</span>이지만 <span class="math inline">\(\sum X_{i} \sim B(n,p)\)</span> 이므로 <span class="math inline">\(T = \sum X_{i}\)</span>을 검정 통계량으로 사용한다.</p>
<p>기각역 및 임계값 : 만약 <span class="math inline">\(RR = \{ t;T \leq k\}\)</span>이면 귀무가설 기각한다. 임계값 <span class="math inline">\(\alpha = P_{\theta_{0}}(T \leq k)\)</span>에 의해 결정된다.</p>
<p>검정력 함수 : <span class="math inline">\(\gamma_{C}(\theta) = P_{\theta}(T \leq k),\theta \leq \theta_{0}\)</span>, 대립가설의 참 모수 값이 귀무가설 <span class="math inline">\(\theta_{0}\)</span>에서 멀어질수록 검정력은 커진다.</p>
<p>【예제】 A 교수는 수리통계학 시험 점수가 평균 70점 수준으로 출제했다고 했다. 수강생이 시험을 보고 나와 어려워 70점 미만이라고 주장했다. 25명 수강생 점수를 확인한 결과 평균 69점, 표준편차 9점이었다. 수강생들의 주장을 유의수준 5%에서 검정하라. 수리통계학 점수는 정규분포를 따른다.</p>
<p>귀무가설 : <span class="math inline">\(H_{0}:\mu_{0} = 70\)</span></p>
<ol type="1">
<li><p>대립가설 : <span class="math inline">\(H_{1}:\mu_{1} &lt; 70\)</span> 단측 대립가설</p></li>
<li><p>검정통계량 : 모집단 평균 MVUE는 <span class="math inline">\(\overline{X}\)</span>이고 <span class="math inline">\(\frac{\overline{X} - \mu_{0}}{\frac{S}{\sqrt{n}}} = \frac{69 - 70}{\frac{9}{\sqrt{25}}} = - 1.67 \sim t(n - 1 = 24)\)</span>이다.</p></li>
<li><p>기각역 및 임계값 : <span class="math inline">\(0.05 = P_{\mu_{0}}(t(24) \leq k)\)</span> 식에서 의해 결정된다. <span class="math inline">\(k = - 1.71\)</span></p></li>
<li><p>검정력 함수 : <span class="math inline">\(\gamma_{C}(\theta) = P_{\mu}\left( \frac{69 - \mu}{\frac{9}{\sqrt{25}}} \leq - 1.71 \right)\)</span></p>
<p>유의확률</p></li>
</ol>
<p>1종 오류, 2종 오류, 검정력을 계산하는 방법에 대해 다루었다. 가설검정 절차를 보면 ① 가설 설정과 유의수준 <span class="math inline">\(\alpha\)</span>을 설정하고 ② 적절한 검정통계량 계산 ③ 기각역(유의수준과 검정통계량의 분포에 따라 계산된다)을 얻고 이에 따라 귀무가설 채택 여부를 결정한다.</p>
<p>설정된 1종 오류를 유의수준 significant level, test level 이라 하고 <span class="math inline">\((1 - \beta)\)</span>을 검정력 power of test, test power 이라 한다. 유의수준은 일반적으로 1%, 5%, 10% (물론 5%을 가장 많이 사용하지만)을 사용하게 되므로 기각역이 달라진다. 만약 어떤 사람이 유의수준 5%에서 귀무가설을 기각하지 못했다고 발표했다. 그럼? 10%일 때는… 우리는 다시 가설 검정을 해야 한다. why? 기각역이 달라지므로…</p>
<p>이런 문제를 해결할 방법이 없을까? p-값 p-value, 유의확률 significant probability 개념을 도입하자. 검정통계량이 계산되면 귀무가설을 더<img src="media/image4.png" style="width:2.92174in;height:1.66237in" alt="도표, 라인, 그래프, 스케치이(가) 표시된 사진 자동 생성된 설명"> 기각할 영역의 확률을 p-값이라 한다. 다음은 대립가설이 <span class="math inline">\(H_{1}:\theta &gt; \theta_{0}\)</span>일 경우 유의확률을 계산 방법이다.</p>
<p>【유의확률】</p>
<p>대립가설은 <span class="math inline">\(H_{1}:\theta = \theta_{1} &gt; \theta_{0}\)</span>이고 확률표본에 의해 계산된 검정통계량 값을 <span class="math inline">\(t^{*}\)</span> 하자.</p>
<p><span class="math inline">\(RR = \{{T &gt; t}^{*}\}\)</span>.</p>
<p>유의확률 : <span class="math inline">\({p - value = P}_{\theta_{0}}(t\left( X_{1},X_{2},\ldots,X_{n} \right) \in RR)\)</span></p>
<p>계산된 검정통계량이 귀무가설이 진실이라는 가정 하에 귀무가설을 기각할 최소의 확률을 유의확률 혹은 p-값이라 한다. 그러므로 유의확률을 계산된 유의수준이다. 계산된 검정통계량이 귀무가설을 기각할 방향(대립가설을 채택할 방향)의 영역 확률을 유의확률이라 한다.</p>
<p>유의확률이 주어지면 귀무가설 채택 여부를 알 수 있다. 유의확률이 유의수준보다 크다면 검정통계량의 값은 기각역에 속한 것이 아니므로 귀무가설이 채택되고 유의확률이 유의수준보다 적다면 검정통계량의 값이 기각역에 속하므로 귀무가설을 기각한다.</p>
<p>【예제】 모집단 <span class="math inline">\(f(x;\theta) \sim N(\mu,\sigma^{2})\)</span>에서 표본 크기 <span class="math inline">\(n\)</span>인 확률표본을 추출하였다. 모분산 <span class="math inline">\(\sigma^{2}\)</span>을 알지 못할 때 nuisance parameter 귀무가설 <span class="math inline">\(H_{0}:\mu = \mu_{0}\)</span>와 대립가설 <span class="math inline">\(H_{1}:\mu = \mu_{1} &gt; \mu_{0}\)</span>을 유의수준 <img src="media/image5.png" style="width:0.15625in;height:0.13889in" alt="image9.pdf">에서 우도비 검정방법은 <span class="math inline">\(T(\overline{x}) = \frac{\sqrt{n}(\overset{¯}{x} - \mu_{0})}{S} \sim t(n - 1)\)</span>이다.(자세한 내용은 다음 2절. 우도비 검정을 참고하기 바란다.)</p>
<blockquote class="blockquote">
<p><span class="math display">\[{p - value = P}_{\theta_{0}}\left( t\left( X_{1},X_{2},\ldots,X_{n} \right) \in RR \right) = P(t(n - 1) \geq T(\overline{x}))\]</span></p>
</blockquote>
<p>만약 대립가설 <span class="math inline">\(H_{1}:\mu = \mu_{1} \neq \mu_{0}\)</span> (양측 대립가설)이면 <span class="math inline">\(p - value = 2P(t(n - 1) \geq |T\left( \overline{x} \right)|)\)</span>.</p>
<p>【유의확률과 대립가설 형태】<img src="media/image6.png" style="width:3.08889in;height:1.89514in" alt="그림 1"></p>
<p>유의확률을 계산할 때 계산된 검정 통계량 값이 귀무가설에 설정한 모수 값(확률밀도함수의 중앙)으로부터 멀어지는 구간에 속할 확률을 구하면 된다. 단측 대립가설이면 구한 유의확률을 그대로 사용하면 되지만 양측 대립가설일 경우에는 계산된 유의확률을 2배 하여 유의확률로 사용해야 한다. 그러므로 양측 대립가설이 채택되면 단측 대립가설도 항상 성립한다.</p>
<p>가설검정 관련 코멘트</p>
<ol type="1">
<li>양측검정이냐? 단측검정이냐? 우리가 무엇에 관심을 갖느냐 하는데 있다. 불량률과 같이 ~값 미만에 관심이 있다면 왼쪽이 단측 검정, 수익과 같이 ~값 이상에 관심이 있다면 우측이 대립가설이 단측 검정을 실시한다. <span dir="rtl">”</span>차이가 없다” 같이 양쪽 모두에 관심이 있다면 양측검정을 실시한다.</li>
</ol>
<!-- -->
<ol start="2" type="1">
<li><p>양측 대립가설이 기각되면 단측 대립가설은 항상 기각된다. 그러므로 “차이가 없다”가 기각되면 “차이가 있다”는 물론 “크다” 혹은 “적다”로 검정 결과를 내려도 된다.</p></li>
<li><p>1종 오류는 기각역이 정해지면 계산 가능하지만 2종 오류는 대립 가설의 값 중 임의의 값이 설정되어야 가능하다. 검정력은 (1-2종 오류) 정의된다. 또한 우리의 관심이 대립가설에 있으므로 1종 오류를 설정하고(이를 유의수준이라 한다) 2종 오류를 최소화 하는 검정 방법을 구하게 된다. (1종, 2종 오류 모두 줄이는 방법은 없다.)</p></li>
<li><p>단측 검정일 때 귀무가설에 대하여 대립가설이 <span class="math inline">\(H_{1}:\theta &lt; \theta_{0}\)</span>라면 귀무가설이 <span class="math inline">\(H_{0}:\theta \geq \theta_{0}\)</span>은 아닌가? 1종 오류는 <span class="math inline">\(\alpha = \max_{\theta \in \omega_{0}}{P_{\theta}(t\left( X_{1},X_{2},\ldots,X_{n} \right) \in CR)}\)</span>에 해당된다. 그러므로 Boundary 값이 <span class="math inline">\(\theta_{0}\)</span>에서 최대화되므로 <span class="math inline">\(H_{0}:\theta = \theta_{0}\)</span>이 적절하다. 그리고 우리의 관심은 귀무가설이 아니므로 귀무가설이 채택된다면 우리는 헛수고 한 것이다.</p>
<p>가설검정과 신뢰수준<img src="media/image7.png" style="width:2.79054in;height:1.88772in" alt="텍스트, 도표, 라인, 폰트이(가) 표시된 사진 자동 생성된 설명"></p></li>
</ol>
<p>유의수준 <span class="math inline">\(\alpha\)</span>의 양측 가설 검정과 <span class="math inline">\(100(1 - \alpha)\%\)</span>신뢰구간은 일대일 대응관계가 있다. 모집단 <span class="math inline">\(f(x;\theta = \mu)\)</span>, 확률표본, 추정량 <span class="math inline">\(\overset{\hat{}}{\theta} = \overset{¯}{X}\)</span>, 표본분산 <span class="math inline">\(S^{2}\)</span>, 귀무가설 <span class="math inline">\(H_{0}:\theta = \theta_{0}\)</span>인 경우 대표본 이론에 의해 <span class="math inline">\(T = \frac{\overset{\hat{}}{\theta} - \theta_{0}}{\frac{S}{\sqrt{n}}}\)</span>는 <span class="math inline">\(N(0,1)\)</span>을 따르므로 다음이 성립한다.</p>
<p><span class="math inline">\(100(1 - \alpha)\%\)</span> 신뢰구간 : <span class="math inline">\(\theta \pm z_{\left( 1 - \frac{\alpha}{2} \right)}\frac{s}{\sqrt{n}}\)</span></p>
<p>유의수준 <span class="math inline">\(\alpha\)</span>인 경우 기각역 : <span class="math inline">\(C = \{|\frac{\overset{\hat{}}{\theta} - \theta}{\frac{s}{\sqrt{n}}}| &gt; z_{\left( 1 - \frac{\alpha}{2} \right)}\}\)</span></p>
<p>유의수준 <span class="math inline">\(\alpha\)</span>인 경우 채택역 : <span class="math inline">\(C^{c} = \{\left| \frac{\overset{\hat{}}{\theta} - \theta}{\frac{s}{\sqrt{n}}} \right| \leq z_{\left( 1 - \frac{\alpha}{2} \right)}\}\)</span><img src="media/image8.png" style="width:2.95753in;height:1.97894in" alt="텍스트, 라인, 도표, 폰트이(가) 표시된 사진 자동 생성된 설명"></p>
<p>즉 신뢰구간과 채택역은 동일함을 알 수 있다. 신뢰구간에 속한 모수 값이 귀무가설에 설정되면 그 귀무가설은 기각되지 않는다. 표본으로부터 통계량이 계산되면 신뢰구간의 식에의해 모수에 대한 구간이 결정된다. 그 부분이 빨간 영역 부분이다.귀무가설에 빨간 영역 안에 있는 모수 값이 설정되면 귀무가설을 기각하지 못한다.</p>
<p>단측 가설 검정과 상한(혹은 하한) 신뢰구간도 일대일 관계가 있다. <span class="math inline">\(100(1 - \alpha)\%\)</span> 하한 신뢰구간은 유의수준 <span class="math inline">\(\alpha\)</span>, 귀무가설 <span class="math inline">\(H_{0}:\theta = \theta_{0}\)</span>, 대립가설: <span class="math inline">\(H_{0}:\theta_{1} &gt; \theta_{0}\)</span>의 채택역과 동일하다. 또한 상한신뢰구간 대립가설 <span class="math inline">\(H_{0}:\theta_{1} &lt; \theta_{0}\)</span>의 채택역과 동일하다.</p>
<p>【예제】 정부는 PC 구입 가격이 900$이라고 발표했다. 이를 알아보기 위하여 소비자 55명을 임의 조사하였더니 평균 885$, 표준편차는 50$이었다.</p>
<p>모집단 평균에 대한 99%(양측)신뢰구간을 구하시오.</p>
<p>(<span class="math inline">\(\overset{¯}{X} \pm Z_{0.995}\frac{S}{\sqrt{n}}) \rightarrow (885 \pm 2.58\frac{50}{\sqrt{25}}) \rightarrow (859.2,910.8)\)</span></p>
<p>정부의 발표가 진실이라고 할 수 있나? 유의수준은 1%</p>
<p>유의수준 1% 검정 통계량 : <span class="math inline">\(\frac{\overset{¯}{X} - \mu_{0}}{\frac{S}{\sqrt{n}}} = \frac{885 - 900}{\frac{50}{\sqrt{25}}} = - 0.5\)</span></p>
<p>기각역 : <span class="math inline">\(C = \{ t;|t| &lt; 2.58\}\)</span> 검정 통계량 값이 기각역에 속하지 않으므로 귀무가설을 채택한다. 유의수준 1%에서 귀무가설 값이 99% 신뢰구간에 속하므로 귀무가설 채택하게 되므로 신뢰구간을 계산한 경우에는 가설검정을 할 필요가 없다.</p>
<p>랜덤화 검정</p>
<p>가설 검정에서 설정한 유의수준에 의해 기각역이 설정되는데 이산형 확률분포의 경우 설정된 유의수준 정확한 값에 대응하는 기각역을 설정하지 못하는 경우가 발생하는 경우 랜덤화 검정을 실시한다. 예제로 이 개념을 설명하기로 한다.</p>
<p>【예제】 <span class="math inline">\(f(x;\theta = \lambda) \sim Poisson(\theta)\)</span>의 모수 <span class="math inline">\(\theta\)</span>에 대한 가설 검정을 위하여 표본크기 <span class="math inline">\(n = 10\)</span>인 확률표본 <span class="math inline">\((X_{1},X_{2},\ldots,X_{10})\)</span>을 추출하였다. 귀무가설 <span class="math inline">\(\theta = 0.1\)</span>, 귀무가설 <span class="math inline">\(\theta &gt; 0.1\)</span>을 유의수준 5%에서 검정하려고 할 때 기각역을 구하라</p>
<p>검정 통계량 : <span class="math inline">\(T = \sum_{i}^{10}X_{i} \sim Poisson(\lambda = 10\theta)\)</span></p>
<p>기각역 : <span class="math inline">\(P_{\theta_{0} = 0.1}(T \geq 3) = 0.08\)</span>, <span class="math inline">\(P_{\theta_{0} = 0.1}(T \geq 4) = 0.019\)</span> 이처럼 유의수준 5%에 해당하는 기각역 얻을 수 없다. 보간법에 의해 <span class="math inline">\(\frac{0.05 - 0.019}{0.08 - 0.019} = \frac{31}{61}\)</span> 이다. 그러므로 유의수준 5% 기각역은 다음과 같다. 만약 <span class="math inline">\((T \geq 4)\)</span> 귀무가설을 기각하고 <span class="math inline">\((T = 3)\)</span>이면 <span class="math inline">\(\frac{31}{61}\)</span> 확률로 기각한다.</p>
<p>2가설검정 방법</p>
<p>최강 검정법</p>
<p>검정방법의 정도 goodness는 1종 오류와 2종 오류로 판단하는데 가설검정 시작 시 1종 오류는 유의수준으로 설정되므로 좋은 검정 방법이란 2종 오류를 최소화 하는 것이다. 즉 (1-2종 오류), 검정력 최대화 하는 것이다. 이를 최강 검정법 most powerful test 이라 한다.</p>
<p>모집단 확률변수 <span class="math inline">\(X \sim f(x;\theta),\theta \in \Omega = \{\omega_{0} \cup \omega_{1}\}\)</span>이고 다음 2개의 단일 귀무가설과 대립가설을 가정하자.</p>
<p>귀무가설 : <span class="math inline">\(H_{0}:\theta \in \omega_{o}\)</span></p>
<p>대립가설 : <span class="math inline">\(H_{1}:\theta \in \omega_{1}\)</span></p>
<p>모집단 확률변수 <span class="math inline">\(X \sim f(x;\theta)\)</span> 에서 확률표본 <span class="math inline">\({\overline{X}}' = (X_{1},X_{2},\ldots,X_{n})\)</span>이라 하고 <span class="math inline">\(\mathcal{S}\)</span>을 확률표본 영역이라 하자.</p>
<p>【유의수준】 확률표본의 영역을 <span class="math inline">\(\mathcal{S}\)</span>, 확률표본 영역의 부분 집합 <span class="math inline">\(RR \in \mathcal{S}\)</span>이라 하자. 다음 <span class="math inline">\(\alpha\)</span>을 1종 오류 type I error, 유의수준 significant level 이라 한다. <span class="math inline">\(\alpha = \max_{\theta \in \omega_{0}}{P_{\theta}\left( T\left( X_{1},X_{2},\ldots,X_{n} \right) \in RR \right)}\)</span>.</p>
<p>정의</p>
<p>【검정력】 다음을 검정력 power function 이라 정의한다.</p>
<p>정의</p>
<p><span class="math display">\[{{P(\theta) = \gamma}_{RR}(\theta) = P}_{\theta}\left( T\left( X_{1},X_{2},\ldots,X_{n} \right) \in RR \right);\theta \in \omega_{1}\]</span></p>
<p>【예제】 표본크기 5인 확률표본 <span class="math inline">\(\left( X_{1},X_{2},\ldots,X_{5} \right) \sim B(p)\)</span>을 이용하여 <span class="math inline">\(H_{0}:p = 0.5vs.H_{1}:p &gt; 0.5\)</span> 가설을 검정한다고 하자.</p>
<p>(1) 기각역을 <span class="math inline">\(RR = \{\sum x_{i} = 5\}\)</span></p>
<ul>
<li><p>1종 오류: <span class="math inline">\(\alpha = P(\sum x_{i} = 5,\sum x_{i} \sim B(5,0.5)) = 0.031\)</span></p></li>
<li><p>2종 오류 : <span class="math inline">\(\beta(p) = P(\sum x_{i} \leq 4,\sum x_{i} \sim B(5,p &gt; 0.5))\)</span></p></li>
<li><p>검정력 : <span class="math inline">\(Power(p) = 1 - \beta(p)\)</span>이므로 <span class="math inline">\(p = 0.5\)</span>에서 멀어질수록 검정력은 커진다. <span class="math inline">\(p = 1\)</span>일 때 검정력은 0이다.</p></li>
</ul>
<p>(2) 기각역을 <span class="math inline">\(RR = \{\sum x_{i} \geq 3\}\)</span></p>
<ul>
<li><p>1종 오류 : <span class="math inline">\(\alpha = P(\sum x_{i} \geq 5,\sum x_{i} \sim B(5,0.5)) = 0.5\)</span></p></li>
<li><p>2종 오류 : <span class="math inline">\(\beta(p) = P(\sum x_{i} \leq 4,\sum x_{i} \sim B(5,p &gt; 0.5))\)</span></p></li>
<li><p><span class="math inline">\(RR = \{\sum x_{i} = 5\}\)</span>에 비해 1종 오류는 늘었으나 2종 오류는 줄었다. 검정력은 커졌다. 즉, 1종 오류와 2종 오류를 동시에 줄이는 검정방법은 존재하지 않는다.</p></li>
</ul>
<p>【최강 검정력】 확률표본의 영역을 <span class="math inline">\(\mathcal{S}\)</span>, 확률표본 영역의 부분 집합 <span class="math inline">\(RR \in \mathcal{S}\)</span>이라 하자. 다음 조건을 만족하는 <span class="math inline">\(RR\)</span>을 검정 크기 <span class="math inline">\(\alpha\)</span>에서 귀무가설 <span class="math inline">\(H_{0}:\theta = \theta_{0}\)</span>, 대립가설 <span class="math inline">\(H_{1}:\theta = \theta_{1}\)</span>을 검정하는 최량 기각역 best critical region이다.</p>
<p>정의</p>
<p><span class="math display">\[\max_{\theta \in \omega_{0}}{P_{\theta}\left( T\left( X_{1},X_{2},\ldots,X_{n} \right) \in RR \right)} = \alpha\]</span></p>
<p>임의의 부분집합 <span class="math inline">\(A \in \mathcal{D}\)</span>에 대하여 다음이 성립한다.</p>
<blockquote class="blockquote">
<p><span class="math display">\[P_{\theta_{0}}\left( T\left( X_{1},X_{2},\ldots,X_{n} \right) \in A \right) = &gt; P_{\theta_{1}}\left( T\left( X_{1},X_{2},\ldots,X_{n} \right) \in RR \right) \geq P_{\theta_{1}}\left( T\left( X_{1},X_{2},\ldots,X_{n} \right) \in A \right)\]</span></p>
</blockquote>
<p>【예제】 모집단 <span class="math inline">\(X \sim B(p = \theta)\)</span> 에서 귀무가설 <span class="math inline">\(H_{0}:p = 0.1\)</span>, 대립가설 <span class="math inline">\(H_{0}:p = 0.2\)</span> 가설을 검정하기 위하여 표본크기3인 확률표본을 추출한 결과는 <span class="math inline">\((1,0,0)\)</span> 이다.</p>
<p>기각역을 <span class="math inline">\(RR = \{ T(\overline{x});\sum X_{i} \geq 1\}\)</span>이라 하자. <span class="math inline">\(\sum X_{i} \sim B(n = 3,p)\)</span>분포를 따른다.</p>
<p>유의수준 : <span class="math inline">\({P_{p = 0.1}\left( T\left( X_{1},X_{2},\ldots,X_{n} \right) \in RR \right)}{= 0.243 + 0.027 + 0.001 = 0.271}\)</span></p>
<p>2종 오류 : <span class="math inline">\({P_{p = 0.2}\left( T\left( X_{1},X_{2},\ldots,X_{n} \right) \in RR^{C} \right)}{= 0.5121}\)</span></p>
<p>검정력 : <span class="math inline">\(1 - 0.5121 = 0.4879\)</span></p>
<table class="caption-top table">
<colgroup>
<col style="width: 40%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
</colgroup>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math display">\[\sum x\]</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">3</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math display">\[f(x;p = 0.1)\]</span></td>
<td style="text-align: center;">0.729</td>
<td style="text-align: center;">0.243</td>
<td style="text-align: center;">0.027</td>
<td style="text-align: center;">0.001</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math display">\[f(x;p = 0.2)\]</span></td>
<td style="text-align: center;">0.512</td>
<td style="text-align: center;">0.384</td>
<td style="text-align: center;">0.096</td>
<td style="text-align: center;">0.008</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math display">\[\frac{f(x;p = 0.1)}{f(x;p = 0.2)}\]</span></td>
<td style="text-align: center;">1.424</td>
<td style="text-align: center;">0.633</td>
<td style="text-align: center;">0.281</td>
<td style="text-align: center;">0.125</td>
</tr>
</tbody>
</table>
<p>만약 대립가설의 모수 하나의 값(대립가설은 귀무가설과는 달리 모수의 영역이다)을 <span class="math inline">\(\theta_{1}\)</span>라 한다면 검정력은 <span class="math inline">\({P(\theta) = P}_{\theta}\left( T\left( X_{1},X_{2},\ldots,X_{n} \right) \in RR^{C}|\theta = \theta_{1} \right)\)</span>이고 2종오류는 <span class="math inline">\(\beta(\theta) = 1 - P(\theta)\)</span> 이다. <span class="math inline">\(H_{0}:\theta = \theta_{0}vs.H_{1}:\theta = \theta_{1} \neq \theta_{0}\)</span> 가설검정의 경우 전형적인 검정력 함수는 다음과 같다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="media/image9.png" style="width:4.49986in;height:1.74073in" class="figure-img"></p>
<figcaption>라인, 도표, 그래프이(가) 표시된 사진 자동 생성된 설명</figcaption>
</figure>
</div>
<p>검정력은 귀무가설 단일 설정 값 <span class="math inline">\(\theta_{0}\)</span>에서 최저였다가 멀어질수록 증가한다. 그러므로 유의수준 <img src="media/image10.png" style="width:0.15625in;height:0.13889in" alt="image14.pdf">을 설정하고 2종 오류를 최소화할 수 있는 검정 방법(기각역 찾음)을 찾는다.</p>
<p>most powerful test 최강력 검정법</p>
<p>가설에 설정된 모수 값이 하나인 경우 이를 단순가설이라 하고 설정된 모수가 영역인 경우 이를 복합가설이라 한다. 단순 귀무가설 <span class="math inline">\(H_{0}:\theta = \theta_{0}\)</span>와 단순 대립가설 <span class="math inline">\(H_{1}:\theta = \theta_{1}\)</span>을 검정한다고 하자. 모수 영역은 <span class="math inline">\(\Omega = \{\theta;\theta_{0},\theta_{1}\}\)</span>이고 <span class="math inline">\(P(\theta) = \alpha\)</span>인 기각역을 설정하고 <span class="math inline">\(\beta(\theta) = 1 - p(\theta)\)</span> 을 최소화 하는 기각역을 구한다. 이는 <span class="math inline">\(P(\theta_{1})\)</span>을 최대화 하는 최강 검정력 검정 most powerful test을 찾는 것과 동일하다.</p>
<p>【Neyman-Pearson Lemma】 단순 귀무가설 <span class="math inline">\(H_{0}:\theta = \theta_{0}\)</span>와 단순 대립가설 <span class="math inline">\(H_{1}:\theta = \theta_{1}\)</span>을 검정한다고 하자. 가설 검정을 확률표본 <span class="math inline">\(\overline{X} = \left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>으로부터 구한 통계량을 이용한다. 이 통계량의 확률밀도함수(샘플링 분포)는 모수 <span class="math inline">\(\theta\)</span>의 함수이며 이를 우도 함수 <span class="math inline">\(L(\overline{x};\theta)\)</span>라 한다. 유의수준 <span class="math inline">\(\alpha\)</span> 하에서 검정력을 최대화 하는 기각역 <span class="math inline">\(RR\)</span>은 다음에 의해 정해진다. 이렇게 얻은 검정 방법(기각역)을 최강력 검정법이라 한다.</p>
<p>정리</p>
<p><span class="math inline">\(\frac{L({\overline{x};\theta}_{0})}{L({\overline{x};\theta}_{1})} \leq k,for\overline{x} \in RR\)</span>.</p>
<p><span class="math inline">\(\frac{L({\overline{x};\theta}_{0})}{L({\overline{x};\theta}_{1})} \geq k,for\overline{x} \in RR^{C}\)</span>.</p>
<p><span class="math display">\[{{\alpha = P}_{H}}_{0}(\overline{x} \in RR)\]</span></p>
<p>【불편 검정방법】 모집단 <span class="math inline">\(X \sim f(x;\theta),\theta \in \Omega\)</span> 에서 확률표본 <span class="math inline">\(\overline{X} = \left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>, 기각역은 <span class="math inline">\({{\alpha = P}_{H}}_{0}(\overline{x} \in RR)\)</span>이라 하면 다음을 불편 unbiased 검정방법이다.</p>
<p>정의</p>
<p><span class="math display">\[P_{\theta}\left( \overline{X} \in RR \right) \geq \alpha,forall\theta \in \omega_{1}\]</span></p>
<p>【예제】 확률표본 <span class="math inline">\(\overline{X} = \left( X_{1},X_{2},\ldots,X_{n} \right) \sim f(x;\theta = \mu)\sim N(\mu,1)\)</span>이고 귀무가설 <span class="math inline">\(H_{0}:\mu = 0\)</span>, 대립가설 <span class="math inline">\(H_{0}:\mu = 1\)</span> 검정하는 최강 기각역을 구하라.</p>
<p>N-P Lemma 의해 최강 기각역 : <span class="math inline">\(\frac{L({\overline{x};\theta}_{0} = 0)}{L({\overline{x};\theta}_{1} = 1)} = \frac{N(0,1)}{N(1,1)} = \exp\left( - \sum x_{i} + \frac{n}{2} \right) \leq k\)</span>.</p>
<p><span class="math display">\[\Leftrightarrow - \sum x_{i} + \frac{n}{2} \leq \ln(k) \Leftrightarrow \sum x_{i} &gt; - \frac{n}{2} - \ln{(k) \Leftrightarrow}\frac{\sum x_{i}}{n} &gt; c\]</span></p>
<p>그러므로 최강 기각역은 <span class="math inline">\(RR = \left\{ \left( x_{1},x_{2},\ldots,x_{n} \right);\overline{x} \geq c \right\},\overline{x} \sim N(0,\frac{1}{n})\)</span>.</p>
<p>유의수준 <span class="math inline">\(\alpha\)</span> 임계값 critical value, <span class="math inline">\(c_{1}\)</span> 결정 : <span class="math inline">\({P_{H}}_{0}\left( \overline{x} \geq c \middle| \mu = 0 \right) = \int_{c}^{\infty}{\frac{1}{\sqrt{2\pi}\sqrt{1/n}}\exp\left( - \frac{\left( \overset{¯}{x} - 0 \right)^{2}}{2(1/n)} \right)d\overset{¯}{x}} = \alpha\)</span>을 만족하는 <span class="math inline">\(c\)</span> 값을 기각역의 시작 값인 임계값 <span class="math inline">\(c_{1}\)</span>이다.</p>
<p>검정력 : <span class="math inline">\({P_{H}}_{1}\left( \overline{x} \geq c_{1} \middle| \mu = 1 \right) = \int_{c_{1}}^{\infty}{\frac{1}{\sqrt{2\pi}\sqrt{1/n}}\exp\left( - \frac{\left( \overset{¯}{x} - 1 \right)^{2}}{2(1/n)} \right)d\overset{¯}{x}}\)</span></p>
<p>【예제】 확률표본 <span class="math inline">\(\overline{X} = \left( X_{1},X_{2},\ldots,X_{n} \right) \sim f(x)\)</span>이고 귀무가설, 대립가설이 확률분포함수인 경우 최강 기각역을 구하라.</p>
<p>귀무가설 : <span class="math inline">\(H_{0}:f_{0}(x) = \frac{e^{- 1}}{x!}\sim Poisson(\lambda = 1),x = 0,1,2,\ldots\)</span></p>
<p>대립가설 : <span class="math inline">\(H_{1}:f_{1}(x) = \left( \frac{1}{2} \right)^{x + 1},x = 0,1,2,\ldots\)</span></p>
<p>우도비 : <span class="math inline">\(\frac{f_{0}(x)}{f_{1}(x)} = \frac{\left( 2e^{- 1} \right)^{n}2^{\sum x_{i}}}{\Pi x_{i}!}\)</span></p>
<p>최강 기각역 : <span class="math inline">\(\frac{\left( 2e^{- 1} \right)^{n}2^{\sum x_{i}}}{\Pi x_{i}!} \leq k \Leftrightarrow \left( \sum x_{i} \right)\ln(2) - \ln\left( \Pi x_{i}! \right) \leq ln)k) - nln(2e^{- 1}) = c\)</span></p>
<p>【예제】 모집단 <span class="math inline">\(f(x;\theta) \sim B(p),x = 0,1\)</span>에서 모수 <span class="math inline">\(\theta = p\)</span>에 대한 가설 검정을 위하여 표본 크기 <span class="math inline">\(n\)</span>인 확률표본 <span class="math inline">\(\overline{X} = \left( X_{1},X_{2},\ldots,X_{n} \right)\)</span> 을 추출하였다. 귀무가설 <span class="math inline">\(H_{0}:p_{0} = 0.5\)</span> 대립가설 <span class="math inline">\(H_{1}:p_{1} = 0.1\)</span>을 유의수준 0.05에서 검정하는 최강 검정방법을 찾아라.</p>
<p>N-P Lemma에 의해 <span class="math inline">\(\frac{L\left( \overline{x}{;\theta}_{0} \right)}{L\left( \overline{x}{;\theta}_{1} \right)} = \frac{{0.5}^{\sum x_{i}}{0.5}^{n - \sum x_{i}}}{{0.2}^{\sum x_{i}}{0.8}^{n - \sum x_{i}}} \leq k \Leftrightarrow \sum x_{i} \leq c\)</span> 이 일양 최강 기각역이다.</p>
<p><span class="math inline">\(\sum x_{i} \sim B(n,p)\)</span>이므로 <span class="math inline">\(0.05 = P(\sum x_{i} \leq c|\sum x_{i} \sim B(n,0.5))\)</span>을 만족하는 정수 <span class="math inline">\(c\)</span>를 찾을 수 없다. 앞에서 살펴본 랜덤화 검정방법을 이용하여 검정하면 된다.</p>
<p>일양 최강 검정</p>
<p>【일양 최강 검정법】 귀무가설 <span class="math inline">\(H_{0}:\theta = \theta_{0}\)</span>, 단순 대립가설 <span class="math inline">\(H_{1}:\theta = \theta_{1} &lt; \theta_{0}\)</span>의 최강 검정 기각역 <span class="math inline">\(RR\)</span>이 모든 복합 대립가설 <span class="math inline">\(H_{1}:\theta = \theta_{1} &lt; \theta_{0}\)</span>의 최강 기각역이면 <span class="math inline">\(RR\)</span>에 의한 검정방법을 일양 최강 검정법 uniformly most powerful test 이라 한다.</p>
<p>정의</p>
<p>【예제】 모집단 <span class="math inline">\(f(x;\theta) = \frac{1}{\theta}e^{- x/\theta},x &gt; 0\)</span>에서 모수 <span class="math inline">\(\theta\)</span>에 대한 가설 검정을 위하여 표본 크기 <span class="math inline">\(n\)</span>인 확률표본 <span class="math inline">\(\overline{X} = \left( X_{1},X_{2},\ldots,X_{n} \right)\)</span> 을 추출하였다. 귀무가설 <span class="math inline">\(H_{0}:{\theta = \theta}_{0}\)</span> 대립가설 <span class="math inline">\(H_{1}:{\theta = \theta}_{1} &lt; \theta_{0}\)</span>을 유의수준 <span class="math inline">\(\alpha\)</span>에서 검정하는 일양 최강 검정방법을 찾아라.</p>
<p>N-P Lemma에 의해 <span class="math inline">\(\frac{L\left( \overline{x}{;\theta}_{0} \right)}{L\left( \overline{x}{;\theta}_{1} \right)} = \frac{\frac{1}{\theta_{0}^{n}}e^{- \frac{\sum x}{\theta_{0}}}}{\frac{1}{\theta_{1}^{n}}e^{- \frac{\sum x}{\theta_{1}}}} \leq k \Leftrightarrow \sum x_{i} \leq c\)</span> 이 일양 최강 기각역이다. <span class="math inline">\(RR = \{\sum x_{i} \leq c\}\)</span> 이 UMPT 기각역이다. 항상 기각역에 사용되는 통계량의 분포는 알려져 있어야 가능하다. <span class="math inline">\(\sum x_{i} \sim Gamma(n,\theta)\)</span>. 임계값은 <span class="math inline">\(0.05 = P(\sum x_{i} \geq c|\sum x_{i} \sim Gamma(n,\theta_{0}))\)</span>을 만족하는 <span class="math inline">\(c\)</span>값이다.</p>
<p>동일한 방법으로 귀무가설 <span class="math inline">\(H_{0}:{\theta = \theta}_{0}\)</span> 대립가설 <span class="math inline">\(H_{1}:{\theta = \theta}_{1} &gt; \theta_{0}\)</span>을 유의수준 <span class="math inline">\(\alpha\)</span>에서 검정하는 일양 최강 검정력은 <span class="math inline">\(RR = \{\sum x_{i} \geq c|\sum x_{i} \sim Gamma(n,\theta)\}\)</span>.</p>
<p>그러나 대립가설 <span class="math inline">\(H_{0}:{\theta = \theta}_{1} \neq \theta_{0}\)</span>이면 Uniformly Most Powerful Test는 존재하지 않는다.</p>
<p>【예제】 모집단 <span class="math inline">\(f(x;\theta) \sim N(0,\theta)\)</span>에서 모수 <span class="math inline">\(\theta\)</span>(분산)에 대한 가설 검정을 위하여 표본 크기 <span class="math inline">\(n\)</span>인 확률표본 <span class="math inline">\(\overline{X} = \left( X_{1},X_{2},\ldots,X_{n} \right)\)</span> 을 추출하였다. 귀무가설 <span class="math inline">\(H_{0}:{\theta = \theta}_{0}\)</span> 대립가설 <span class="math inline">\(H_{1}:{\theta = \theta}_{1} &gt; \theta_{0}\)</span>을 유의수준 <span class="math inline">\(\alpha\)</span>에서 검정하는 일양 최강 검정방법을 찾아라.</p>
<p>N-P Lemma에 의해 <span class="math inline">\(\frac{L\left( \overline{x}{;\theta}_{0} \right)}{L\left( \overline{x}{;\theta}_{1} \right)} = \frac{\left( \frac{1}{2\pi\theta_{0}} \right)^{\frac{n}{2}}exp( - \frac{1}{2\theta_{0}}\sum x_{i}^{2})}{\left( \frac{1}{2\pi\theta_{1}} \right)^{\frac{n}{2}}exp( - \frac{1}{2\theta_{1}}\sum x_{i}^{2})} \leq k \Leftrightarrow \sum x_{i}^{2} \geq c\)</span>이 일양 최강 기각역이다.</p>
<p>그러나 <span class="math inline">\(\sum x_{i}^{2}\)</span>의 확률밀도함수는 알 수 없으므로 기각역에 사용되는 검정 통계량은 <span class="math inline">\(\frac{\sum x_{i}^{2}}{\theta_{0}} \sim \chi^{2}(n - 1)\)</span> 분포를 따르므로 <span class="math inline">\(\frac{\sum x_{i}^{2}}{\theta_{0}}\)</span>을 이용하는데 이 통계량을 주축 pivotal 검정 통계량이라 한다.</p>
<p>【단조우도비】 만약 우도비 <span class="math inline">\(\frac{L\left( \overline{x}{;\theta}_{0} \right)}{L\left( \overline{x}{;\theta}_{1} \right)},for\theta_{0} &lt; \theta_{1}\)</span>가 <span class="math inline">\(y = u(x)\)</span>의 단조 함수이면 우도함수 <span class="math inline">\(L\left( \overline{x};\theta \right)\)</span>은 통계량 <span class="math inline">\(y = u(x)\)</span>의 단조 우도비 monotone likelihood ratio(mlr)을 갖는다.</p>
<p>정의</p>
<p><span class="math inline">\(\frac{L\left( \overline{x}{;\theta}_{0} \right)}{L\left( \overline{x}{;\theta}_{1} \right)} \leq k \Leftrightarrow t\left( x_{1},x_{2},\ldots,x_{n} \right) \in RR\)</span>. <span class="math inline">\(\alpha = P_{\theta_{0}}(t\left( x_{1},x_{2},\ldots,x_{n} \right) \in RR)\)</span>을 만족하는 <span class="math inline">\(k\)</span>가 임계값이다.</p>
<p><span class="math inline">\(\frac{L\left( \overline{x}{;\theta}_{0} \right)}{L\left( \overline{x}{;\theta}_{1} \right)} = g(Y) \leq k \Leftrightarrow Y \geq g^{- 1}(k)\)</span>. <span class="math inline">\(g^{- 1}(k)\)</span>는 <span class="math inline">\(\alpha = P_{\theta_{0}}(Y \geq g^{- 1}(k))\)</span>을 만족한다.</p>
<p>【예제】 모집단 <span class="math inline">\(f(x;\theta) \sim B(\theta = p),0 &lt; \theta &lt; 1\)</span>에서 모수 <span class="math inline">\(\theta\)</span>에 대한 가설 검정을 위하여 표본 크기 <span class="math inline">\(n\)</span>인 확률표본 <span class="math inline">\(\overline{X} = \left( X_{1},X_{2},\ldots,X_{n} \right)\)</span> 을 추출하였다. 귀무가설 <span class="math inline">\(H_{0}:{\theta = \theta}_{0}\)</span> 대립가설 <span class="math inline">\(H_{1}:{\theta = \theta}_{1} &gt; \theta_{0}\)</span>을 유의수준 <span class="math inline">\(\alpha\)</span>에서 검정하는 일양 최강 검정방법을 찾아라.</p>
<p><span class="math inline">\(\frac{L\left( \overline{x}{;\theta}_{0} \right)}{L\left( \overline{x}{;\theta}_{1} \right)} = \frac{{\theta_{0}}^{\sum x_{i}}{\theta_{0}}^{n - \sum x_{i}}}{{\theta_{1}}^{\sum x_{i}}{\theta_{1}}^{n - \sum x_{i}}} = \left( \frac{\theta_{0}(1 - \theta_{1})}{\theta_{1}(1 - \theta_{0})} \right)^{\sum x_{i}}\left( \frac{1 - \theta_{0}}{1 - \theta_{1}} \right)^{n}\)</span>이므로 우도비는<span class="math inline">\(y = \sum x_{i}\)</span>의 단조 함수이다. 그러므로 UMPT 기각역은 <span class="math inline">\(RR = \{\sum x_{i} \geq c\}\)</span>이다.</p>
<p>【지수족 UMPT】</p>
<p>모집단 확률밀도함수가 지수족이면 다음 가설의 일양 최강 검정 기각역은 <span class="math inline">\(RR = \{ y = \sum K\left( x_{i} \right) \geq c\}\)</span>이다.</p>
<p>귀무가설 : <span class="math inline">\(H_{0}:\theta = \theta_{0}\)</span> vs.&nbsp;대립가설 : <span class="math inline">\(H_{1}:\theta = \theta_{1} &gt; \theta_{0}\)</span></p>
<p>만약 대립가설 : <span class="math inline">\(H_{1}:\theta = \theta_{1} &lt; \theta_{0}\)</span> 이면 일양 최강 검정 기각역은 <span class="math inline">\(RR = \{ y = \sum K\left( x_{i} \right) \leq c\}\)</span>이다.</p>
<ol type="1">
<li>우도비 검정</li>
</ol>
<p>단순 귀무가설과 단순 대립가설에 대한 Most powerful test을 얻으려면 Neyman-Pearson 정리를 이용하면 된다. 물론 대립가설이 단측 가설(한 쪽 방향)에 Most powerful 검정을 얻을 수 있지만… 양측 검정이나 Nuisance parameter가 있는 경우에는 N-P 정리를 사용할 수 없다.</p>
<p>모수 θ 영역을 <span class="math inline">\(\Omega\)</span>라 하자. 귀무가설에 설정된 모수 값은 단일 값으로 <span class="math inline">\(\Omega_{0} = \{\theta_{0}\}\)</span>이고 대립가설의 모수 공간은 <span class="math inline">\(\Omega_{1} = \Omega_{0}^{C}\)</span>이다. 전체 모수 공간 <span class="math inline">\(\Omega\)</span>에서 우도함수를 <span class="math inline">\(L\left( \overline{x};\Omega \right)\)</span>라 정의하고 모수에 대한 MLE(최대우도추정량)을 추정치로 사용한 우도함수를 <span class="math inline">\(L\left( \overline{x};\overset{\hat{}}{\Omega} \right)\)</span>라 하자.</p>
<p>【우도비 검정】 귀무가설 <span class="math inline">\(H_{0}:\theta \in \Omega_{0}\)</span>, 대립가설 <span class="math inline">\(H_{1}:\theta \in \Omega_{0}^{C}\)</span> 검정하는 우도 통계량은 <span class="math inline">\(\lambda\left( \overline{x} \right) = \frac{\max_{\Omega_{0}}{L\left( \overline{x};\Omega_{0} \right)}}{\max_{\Omega}{L\left( \overline{x};\Omega \right)}}\)</span>이다. 우도비 검정 likelihood ratio test 기각역은 <span class="math inline">\(\left\{ \lambda\left( \overline{x} \right) \leq c \right\}\)</span>이다. <span class="math inline">\(c\)</span>는 <span class="math inline">\(0 &lt; c &lt; 1\)</span>의 값을 갖는다.</p>
<p>정의</p>
<p>만약 <span class="math inline">\(\lambda \rightarrow 0\)</span>이면 귀무가설 하의 우도함수 값이 매우 작다는 것을 의미하므로 대립가설에 비해 귀무가설을 기각하는 것이 적절하다. 만약 <span class="math inline">\(\lambda \rightarrow 1\)</span>이면 귀무가설이 진실일 가능성이 높다. 그러므로 기각역이 <span class="math inline">\(\lambda \leq c\)</span> 이다.</p>
<p>【예제】 모집단 <span class="math inline">\(f(x;\theta) \sim N(\mu,\sigma^{2})\)</span>에서 표본 크기 <span class="math inline">\(n\)</span>인 확률표본 <span class="math inline">\(\overline{X} = \left( X_{1},X_{2},\ldots,X_{n} \right)\)</span> 을 추출하였다. 모분산 <span class="math inline">\(\sigma^{2}\)</span>을 알지 못할 때 nuisance parameter 귀무가설 <span class="math inline">\(H_{0}:\mu = \mu_{0}\)</span>와 대립가설 <span class="math inline">\(H_{1}:\mu = \mu_{1} &gt; \mu_{0}\)</span>을 유의수준 <img src="media/image11.png" style="width:0.15625in;height:0.13889in" alt="image9.pdf">에서 우도비 검정방법을 찾으시오.</p>
<p>귀무가설 하 모수 공간은 <span class="math inline">\(\Omega_{0} = \{\mu,\sigma_{0};\mu = \mu_{0},\sigma^{2} &gt; 0\}\)</span>, 대립가설 하에서 모수 공간은 <span class="math inline">\(\Omega_{1} = \{\mu,\sigma_{1};\mu &gt; \mu_{0},\sigma_{1}^{2} &gt; 0\}\)</span>이므로 모수 전체 공간은 <span class="math inline">\(\Omega = \{\mu,\sigma;\mu \geq \mu_{0},\sigma^{2} &gt; 0\}\)</span>이다.</p>
<p><span class="math inline">\(L\left( \overline{x};\Omega_{0} \right) = \Pi\frac{1}{\sqrt{2\pi}\sigma}exp( - \frac{\left( x_{i} - \mu_{0} \right)^{2}}{2\sigma^{2}})\)</span>이고 귀무가설 모평균은 <span class="math inline">\(\mu_{0}\)</span>로 주어져 있으니 모분산에 대한 MLE 추정치를 구하면 <span class="math inline">\(\overset{\hat{}}{\sigma_{0}^{2}} = \frac{1}{n}\sum\left( x_{i} - \mu_{0} \right)^{2}\)</span>이다.</p>
<p><span class="math inline">\(L\left( \overline{x};\Omega \right)\)</span>에서 <span class="math inline">\(\mu\)</span>의 MLE는 <span class="math inline">\(\overset{\hat{}}{\mu} = max(\overset{¯}{x},\mu_{0})\)</span>이다. 왜냐하면 모수 공간 <span class="math inline">\(\Omega\)</span>의 <span class="math inline">\(\mu \geq \mu_{0}\)</span>이기 때문이다. 모분산에 대한 MLE 추정치는 <span class="math inline">\(\overset{\hat{}}{\sigma} = \frac{1}{n}\sum\left( x_{i} - \overset{\hat{}}{\mu} \right)^{2}\)</span>이다.</p>
<p><span class="math inline">\(\lambda = \frac{L(\overset{\hat{}}{\Omega_{0}})}{L(\overset{\hat{}}{\Omega})} = \left( \frac{\overset{\hat{}}{\sigma_{0}^{2}}}{\overset{\hat{}}{\sigma^{2}}} \right)^{\frac{n}{2}} = \left\{ \begin{array}{r}
\left( \frac{\sum\left( x_{i} - \overset{¯}{x} \right)^{2}}{\sum\left( x_{i} - \mu_{0} \right)^{2}} \right)^{\frac{n}{2}} \\
1,if\overline{x} \leq \mu_{0}
\end{array},if\overline{x} &gt; \mu_{0} \right.\ \)</span> .</p>
<p><span class="math inline">\(\sum\left( x_{i} - \mu_{0} \right)^{2} = \sum\left( x_{i} - \overset{¯}{x} \right)^{2} + \sum\left( \overset{¯}{x} - \mu_{0} \right)^{2}\)</span> 이므로 정리하면</p>
<p><span class="math display">\[\lambda = \left( \frac{\sum\left( x_{i} - \overset{¯}{x} \right)^{2}}{\sum\left( x_{i} - \mu_{0} \right)^{2}} \right)^{\frac{n}{2}} \leq k \Leftrightarrow \frac{\sum\left( x_{i} - \overset{¯}{x} \right)^{2}}{\sum\left( x_{i} - \mu_{0} \right)^{2}} \leq k^{\frac{2}{n}} \Leftrightarrow \frac{\sum\left( x_{i} - \overset{¯}{x} \right)^{2}}{\sum\left( x_{i} - \overset{¯}{x} \right)^{2} + \sum\left( \overset{¯}{x} - \mu_{0} \right)^{2}} \leq k^{\frac{2}{n}}\]</span></p>
<p><span class="math display">\[\Rightarrow \frac{\sqrt{n}(\overset{¯}{x} - \mu_{0})}{S} &gt; c,whereS^{2} = \sum\left( x_{i} - \overset{¯}{x} \right)^{2}/(n - 1)\]</span></p>
<p><span class="math inline">\(\frac{\sqrt{n}(\overset{¯}{x} - \mu_{0})}{S}\)</span>은 t-분포를 따르므로 우도비 검정은 t-검정과 일치한다.</p>
<p>【예제】 모집단 <span class="math inline">\(f(x;\theta) = e^{- (x - \theta)},x \geq 0\)</span>에서 표본 크기 <span class="math inline">\(n\)</span>인 확률표본 <span class="math inline">\(\overline{X} = \left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>을 추출하였다. 귀무가설 <span class="math inline">\(H_{0}:\theta = \theta_{0}\)</span>와 대립가설 <span class="math inline">\(H_{1}:\theta &gt; \theta_{0}\)</span>을 유의수준 <img src="media/image11.png" style="width:0.15625in;height:0.13889in" alt="image9.pdf">에서 우도비 검정방법을 찾으시오.</p>
<p>우도 함수는 <span class="math inline">\(L\left( \overline{x};\theta \right) = \Pi e^{- (x - \theta)} = e^{- \sum(x_{i} - \theta)},\theta \leq x_{(1)}\)</span>이므로 우도 함수는 모수 <span class="math inline">\(\theta\)</span>의 증가함수이다.</p>
<p><span class="math inline">\(\lambda = \frac{L(\overset{\hat{}}{\Omega_{0}})}{L(\overset{\hat{}}{\Omega})} = \frac{e^{- \sum(x_{i} - \theta_{0})}}{e^{- \sum(x_{i} - x_{(1)})}} = \left\{ \begin{array}{r}
e^{- n\left( x_{(1)} - \theta_{0} \right)},ifx_{(1)} &gt; \theta_{0} \\
1,ifx_{(1)} \leq \theta_{0}
\end{array} \right.\ \)</span></p>
<p>기각역 <span class="math inline">\(\{\lambda \leq k\} \Leftrightarrow \{\overline{x};x_{(1)} \geq \theta_{0} - \frac{ln(c)}{n}\}\)</span></p>
<p>일반적으로 우도비 검정의 경우 검정통계량의 분포를 아는 것은 쉽지 않다. 이런 경우 다음 정리를 이용하여 검정하게 된다.</p>
<p><span class="math inline">\(\lambda = \frac{L(\overset{\hat{}}{\Omega_{0}})}{L(\overset{\hat{}}{\Omega})}\)</span>라 정의하자. 표본의 크기 <span class="math inline">\(n\)</span>이 충분히 크다면 귀무가설 <span class="math inline">\(H_{0}:\theta \in \Omega_{0}\)</span>, 대립가설 <span class="math inline">\(H_{1}:\theta \in \Omega_{1}\)</span>에 대한 우도비(LTR) 검정은 검정통계량 <span class="math inline">\(\lambda\)</span>에 대해 다음이 성립한다.</p>
<p>정리</p>
<p><span class="math inline">\(- 2\ln(\lambda) \sim (app)\chi^{2}(r_{0} - r)\)</span>, <span class="math inline">\(r\)</span>은 모수 공간 <span class="math inline">\(\Omega\)</span>하에서 설정된 모수의 개수이고 <span class="math inline">\(r_{0}\)</span>은 모수 공간 <span class="math inline">\(\Omega_{0}\)</span> 하에서 설정된 모수의 개수이다.</p>
<p>【예제】 작업 라인이 2개 있다. 각 작업을 일주일 단위로 생산된 제품에 대한 불량 개수를 조사하였더니 작업라인1은 평균 20, 작업라인 2는 22이다(표본의 개수는 각각 100이다). 불량 개수는 포아송 분포를 따르고 작업 라인 1의 평균을 <span class="math inline">\(\lambda_{1}\)</span>, 작업 라인 2의 평균을 <span class="math inline">\(\lambda_{2}\)</span>라 하자. 귀무가설 <span class="math inline">\(H_{0}:\lambda_{1} = \lambda_{2}\)</span>와 대립가설 <span class="math inline">\(H_{0}:\lambda_{1} \neq \lambda_{2}\)</span>을 검정하는 우도비 검정을 유의수준 0.01에서 실시하자.</p>
<p>작업라인 1의 확률표본을 <span class="math inline">\((X_{1},X_{2},...,X_{n})\)</span>, 작업라인 2의 확률표본을 <span class="math inline">\((Y_{1},Y_{2},...,y_{n})\)</span>라 하자.</p>
<p>귀무가설 모수 공간은 <span class="math inline">\(\Omega_{0} = \{\lambda_{1} = \lambda_{2} = \lambda\}\)</span>이고 전체 모수 공간은 <span class="math inline">\(\Omega = \{\lambda_{1} = \lambda_{2} &gt; 0\}\)</span>이다.</p>
<p>전체 모수 공간 결합 우도비는 <img src="media/image12.png" style="width:3.99742in;height:0.56017in" alt="image23.pdf">이고</p>
<p>귀무가설 모수 공간 결합 우도비는 <img src="media/image13.png" style="width:3.75116in;height:0.61148in" alt="image24.pdf">이다.</p>
<p><img src="media/image14.png" style="width:4.30301in;height:0.49981in" alt="image25.pdf">➔ MLE는 <span class="math inline">\({\widehat{\lambda}}_{1} = \overline{X} = 20,{\widehat{\lambda}}_{2} = \overline{Y} = 22\)</span>이다.</p>
<p><img src="media/image15.png" style="width:4.30301in;height:0.51433in" alt="image28.pdf">➔ MLE는 <span class="math inline">\(\widehat{\lambda} = \frac{\overline{X} + \overline{Y}}{2} = 21\)</span>이다.</p>
<p><img src="media/image16.png" style="width:2.1146in;height:0.70422in" alt="image30.pdf">이므로 <span class="math inline">\(- 2ln\lambda = 9.53\)</span>이다.</p>
<p>귀무가설에서 설정된 귀무가설의 수는 1이고 전체 모수의 수는 2이다. 그러므로 <span class="math inline">\(- 2ln\lambda \sim \chi^{2}(df = 2 - 1 = 1)\)</span>이 성립한다. 자유도 1이고 유의수준이 0.01인 경우 기각치(임계치)는 <span class="math inline">\(\chi^{2}\)</span>-분포표에 의해 6.635이다. 9.53이 기각역에 속하므로 귀무가설은 기각된다.</p>
<p>Chapter 4. 구간 추정</p>
<p>앞에서는 모수 <span class="math inline">\(\theta\)</span>의 점 추정에 대해 논의했는데 <span class="math inline">\(\theta\)</span>의 값을 하나의 추정치로 추측하는 것입니다. 여기서는 구간 추정 및 더 일반적으로 집합 추정에 대해 논의한다. 집합 추정 문제에서의 추론은 <span class="math inline">\(\theta\)</span>이 구간 <span class="math inline">\(C(\overline{x})\)</span>에 속한다."라는 추정됩니다. 즉, <span class="math inline">\(P\left( \overset{\hat{}}{\theta} = \theta \right) = 0\)</span>(점 추정차와 모수가 같을 확률은 0이지만 <span class="math inline">\(P(\theta \in C(\overline{x}))\)</span>는 0보다 큰 확률을 가지게 되는데 이를 신뢰수준이라 한다.</p>
<p>1구간추정</p>
<p>【구간 추정량】</p>
<p>모집단 <span class="math inline">\(f(x;\theta),\overline{x} \in \mathcal{S}\)</span>에서 모수 <span class="math inline">\(\theta\)</span> 추론을 위하여 표본 크기 <span class="math inline">\(n\)</span>인 확률표본 <span class="math inline">\(\overline{X} = \left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>을 추출하였다. 확률표본의 함수, 통계량 <span class="math inline">\(L\left( \overline{x} \right) \leq U\left( \overline{x} \right)\)</span>을 정의하자. <span class="math inline">\((L\left( \overline{x} \right),U\left( \overline{x} \right))\)</span>을 모수 <span class="math inline">\(\theta\)</span> 구간 추정량 interval estimator 이라 한다.</p>
<p>그리고 <span class="math inline">\(\min_{\theta}{P_{\theta}(\theta \in (L\left( \overline{x} \right),U\left( \overline{x} \right)))}\)</span>을 신뢰수준이라 한다. 좌우 대칭인 분포의 경우에는 양쪽 꼬리 부분에 동일한 확률 값을 배분해야 동일 신뢰수준 하에서 신뢰구간 폭이 가장 작아진다(정도는 높아짐).</p>
<p>【예제】 모집단 <span class="math inline">\(f(x;\theta) \sim N(\mu,1)\)</span>에서 모수 <span class="math inline">\(\theta\)</span> 추론을 위하여 표본 크기 2인 확률표본 <span class="math inline">\(\overline{X} = \left( X_{1},X_{2} \right)\)</span> 추출하였다. 모수 <span class="math inline">\(\theta\)</span>에 대한 신뢰구간을 구하라.</p>
<p>모수 <span class="math inline">\(\theta\)</span>의 MVUE가 <span class="math inline">\(\overset{¯}{X}\)</span>이므로 <span class="math inline">\((\overset{¯}{X} - 1,\overset{¯}{X} + 2)\)</span> 신뢰구간 중 하나이다. 신뢰수준 : 91.9% <span class="math inline">\(P\left( \overset{¯}{X} - 1 \leq \mu \leq \overset{¯}{X} + 2 \middle| \overset{¯}{X} \sim N\left( \mu,\frac{1}{2} \right) \right) = P\left( - \frac{2}{\sqrt{1/2}} \leq z = \frac{\overset{¯}{X} - \mu}{\sqrt{1/2}} \leq \frac{1}{\sqrt{1/2}} \right) = P\left( - 2\sqrt{2} \leq z \leq \sqrt{2} \right) = 0.921 - 0.002 = 0.919\)</span></p>
<p>【comment】</p>
<ol type="1">
<li><p>유의수준 <span class="math inline">\(\alpha\)</span>의 양측 대립가설 검정방법과 신뢰수준 <span class="math inline">\(100(1 - \alpha)\%\)</span> 구간 추정은 동일하다.</p></li>
<li><p>앞에서 설명하였듯이 신뢰수준 <span class="math inline">\(100(1 - \alpha)\%\)</span> 구간의 의미는 신뢰수준 <span class="math inline">\(100(1 - \alpha)\%\)</span> 구간 내에 모수 <span class="math inline">\(\theta\)</span>가 있을 확률이 <span class="math inline">\(100(1 - \alpha)\%\)</span>이 아니라 100번의 신뢰구간을 구했을 때 <span class="math inline">\(100(1 - \alpha)\%\)</span>개 신뢰구간이 모수를 포함하고 있다는 것으로 신뢰구간의 모수 커버리지 coverage 확률이다.</p></li>
</ol>
<p>【예제】 모집단 <span class="math inline">\(f(x;\theta) \sim U(0,\theta)\)</span>에서 표본 크기 <span class="math inline">\(n\)</span>인 확률표본 <span class="math inline">\(\overline{X} = \left( X_{1},X_{2},\ldots,X_{n} \right)\)</span> 추출하였다. 모수 <span class="math inline">\(\theta\)</span>에 대한 신뢰구간으로 다음 2개를 생각해 보자. 모수 <span class="math inline">\(\theta\)</span>의 MLE는 <span class="math inline">\(Y = x_{(n)}\)</span> 이다.</p>
<p><span class="math inline">\(Y = x_{(n)}\)</span> 확률밀도함수는 <span class="math inline">\(f(y) = ny^{n - 1}\left( \frac{1}{\theta} \right)^{n},0 &lt; y &lt; \theta\)</span> 이므로 변수변환 <span class="math inline">\(T = \frac{Y}{\theta}\)</span> 확률밀도함수는 <span class="math inline">\(f(t) = nt^{n - 1},0 &lt; y &lt; 1\)</span> 이다.</p>
<p>(1) 신뢰구간 <span class="math inline">\((aY,bY)\)</span>의 신뢰수준 : <span class="math inline">\(P_{\theta}(aY \leq \theta \leq bY) = P_{\theta}\left( \frac{1}{a} \leq T = \frac{Y}{\theta} \leq \frac{1}{b} \right) = \int_{\frac{1}{a}}^{\frac{1}{b}}{nt^{n - 1}dt} = \left( \frac{1}{a} \right)^{n} - \left( \frac{1}{b} \right)^{n}\)</span> – 신뢰구간은 모수에 의존하지 않는다.</p>
<p>(2) 신뢰구간 <span class="math inline">\((Y + c,Y + d)\)</span>의 신뢰수준 : <span class="math inline">\(P_{\theta}(Y + c \leq \theta \leq Y + d) = P_{\theta}\left( 1 - \frac{d}{\theta} \leq T = \frac{Y}{\theta} \leq 1 - \frac{c}{\theta} \right) = \left( 1 - \frac{c}{\theta} \right)^{n} - \left( 1 - \frac{d}{\theta} \right)^{n}\)</span> – 신뢰구간은 모수에 의존한다.</p>
<p>【유의수준 <span class="math inline">\(\alpha\)</span> 가설검정과 <span class="math inline">\(100(1 - \alpha)\%\)</span> 신뢰구간은 동일하다.】</p>
<p>모집단 <span class="math inline">\(f(x;\theta) \sim N(\mu,\sigma^{2})\)</span>에서 표본 크기 <span class="math inline">\(n\)</span>인 확률표본 <span class="math inline">\(\overline{X} = \left( X_{1},X_{2},\ldots,X_{n} \right)\)</span> 추출하였다. 귀무가설 <span class="math inline">\(H_{0}:\mu = \mu_{0}\)</span>, 대립가설 <span class="math inline">\(H_{0}:\mu \neq \mu_{0}\)</span> UMPT 기각역은 <span class="math inline">\(RR = \{\overline{x};\left| \overline{x} - \mu_{0} \right| &gt; z_{1 - \frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}}\}\)</span>(유의수준 <span class="math inline">\(\alpha\)</span>)이다. 그러므로 채택역은 <span class="math inline">\(\left| \overline{x} - \mu_{0} \right| \leq z_{1 - \alpha/2}\frac{\sigma}{\sqrt{n}}\)</span>이다. 이것은 모수 <span class="math inline">\(\theta\)</span>에 대한 <span class="math inline">\(100(1 - \alpha)\%\)</span> 신뢰구간과 동일하다.</p>
<p><span class="math display">\[P\left( \overline{x} - z_{1 - \frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}} \leq \mu \leq \overline{x} + z_{1 - \frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}} \right) = 1 - \alpha\]</span></p>
<p>결론적으로 <span class="math inline">\(100(1 - \alpha)\%\)</span> 신뢰구간 포함된 모수 값을 (유의수준 <span class="math inline">\(\alpha\)</span>) 설정한 귀무가설은 채택하게 된다. 신뢰구간 밖의 모수를 설정한 귀무가설은 기각된다.</p>
<p>【신뢰구간】</p>
<p>귀무가설 <span class="math inline">\(H_{0}:\theta = \theta_{0}\)</span>에 대한 유의수준 <span class="math inline">\(\alpha\)</span>의 검정의 채택역을 <span class="math inline">\(A(\theta_{0})\)</span> 이라 하자. 모수 공간 <span class="math inline">\(C\left( \overline{x} \right) = \{\theta_{0}:\overline{x} \in A(\theta_{0})\}\)</span>은 <span class="math inline">\((1 - \alpha)\)</span> 신뢰구간이다.</p>
<p>【예제】 모집단 <span class="math inline">\(f(x;\theta) \sim exponetial(\theta = \lambda)\)</span>에서 표본 크기 <span class="math inline">\(n\)</span>인 확률표본 <span class="math inline">\(\overline{X} = \left( X_{1},X_{2},\ldots,X_{n} \right)\)</span> 추출하였다. 모수 <span class="math inline">\(\lambda\)</span>(평균)에 대한 <span class="math inline">\(100(1 - \alpha)\%\)</span> 신뢰구간을 구하라.</p>
<p>귀무가설 : <span class="math inline">\(H_{0}:\lambda = \lambda_{0}\)</span> vs.&nbsp;대립가설 : <span class="math inline">\(H_{0}:\lambda \neq \lambda_{0}\)</span></p>
<p>우도함수 : <span class="math inline">\(L\left( \overline{x};\Omega \right) = \Pi\frac{1}{\lambda}\exp\left( - \frac{x_{i}}{\lambda} \right) = \frac{1}{\lambda^{n}}exp( - \frac{\sum x_{i}}{\lambda})\)</span></p>
<p>우도비 : <span class="math inline">\(\lambda = \frac{L(\overset{\hat{}}{\Omega_{0}})}{L(\overset{\hat{}}{\Omega})} = \frac{\frac{1}{\lambda_{0}^{n}}exp( - \frac{\sum x_{i}}{\lambda_{0}})}{\frac{1}{(\sum x_{i}/n)^{n}}exp( - n)} = \left( \frac{\sum x_{i}}{n\lambda_{0}} \right)^{n}e^{n}e^{- \sum x_{i}/\lambda_{0}}\)</span> (모수 <span class="math inline">\(\lambda\)</span>의 MLE는 <span class="math inline">\(\overset{¯}{x}\)</span> 이기 때문이다)</p>
<p>기각역 : <span class="math inline">\({\lambda = \left( \frac{\sum x_{i}}{n\lambda_{0}} \right)}^{n}e^{n}e^{- \sum x_{i}/\lambda_{0}} \leq k \Leftrightarrow {\lambda = \left( \frac{\sum x_{i}}{\lambda_{0}} \right)}^{n}e^{- \frac{\sum x_{i}}{\lambda_{0}}} \leq k^{*}\)</span>, <span class="math inline">\(RR(\overline{x}) = \{\overline{x};\left( \frac{\sum x_{i}}{\lambda_{0}} \right)^{n}e^{- \frac{\sum x_{i}}{\lambda_{0}}} \leq c\}\)</span></p>
<p>그러므로 채택역은 <span class="math inline">\(A(\theta) = \{\overline{x};\left( \frac{\sum x_{i}}{\lambda} \right)^{n}e^{- \frac{\sum x_{i}}{\lambda}} \geq c\}\)</span> 이고 충분통계량 <span class="math inline">\(\sum x_{i}\)</span>의 함수이므로 신뢰구간은 다음과 같다. <span class="math inline">\(C\left( \sum x_{i} \right) = \{\lambda;L\left( \sum x_{i} \right) &lt; \lambda &lt; U\left( \sum x_{i} \right)\}\)</span></p>
<p><span class="math inline">\(\left( \frac{\sum x_{i}}{L\left( \sum x_{i} \right)} \right)^{n}e^{- \frac{\sum x_{i}}{L\left( \sum x_{i} \right)}}\)</span>, <span class="math inline">\(\left( \frac{\sum x_{i}}{U\left( \sum x_{i} \right)} \right)^{n}e^{- \frac{\sum x_{i}}{U\left( \sum x_{i} \right)}}\)</span> =&gt; 만약 <span class="math inline">\(a = \frac{\sum x_{i}}{L\left( \sum x_{i} \right)},b = \frac{\sum x_{i}}{U\left( \sum x_{i} \right)}\)</span>라 놓으면 <span class="math inline">\(a^{n}e^{- a}\)</span>, <span class="math inline">\(be^{- b}\)</span></p>
<p><span class="math inline">\(\sum x_{i} \sim Gamma(n,\lambda)\)</span> 이므로 <span class="math inline">\(\frac{\sum x_{i}}{\lambda} \sim Gamma(n,1)\)</span> 다음을 만족하는 <span class="math inline">\((a,b)\)</span>를 찾으면 <span class="math inline">\(100(1 - \alpha)\%\)</span> 신뢰구간이다.</p>
<p><span class="math display">\[P_{\lambda}\left( \frac{\sum x_{i}}{a} \leq \lambda \leq \frac{\sum x_{i}}{b} \right) = P_{\lambda}\left( b \leq \frac{\sum x_{i}}{\lambda} \leq a \right) = 1 - \alpha\]</span></p>
<p>【주축통계량】</p>
<p>통계량 <span class="math inline">\(Q\left( \overline{x},\theta \right)\)</span>의 분포가 모수와 독립이면 이를 주축 pivotal 통계량이라 한다. 즉, <span class="math inline">\(X \sim F(x)\)</span>이면 <span class="math inline">\(Q\left( \overline{x},\theta \right)\)</span> 확률밀도함수는 모수 <span class="math inline">\(\theta\)</span>에 상관없이 동일하다. 일반적으로 주축 통계량은 충분 통계량의 함수이다.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 44%">
<col style="width: 21%">
<col style="width: 32%">
</colgroup>
<tbody>
<tr class="odd">
<td style="text-align: center;">확률분포 형식</td>
<td style="text-align: center;">타입</td>
<td style="text-align: center;">주축 통계량</td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math display">\[f(x - \mu)\]</span></td>
<td style="text-align: center;">위치</td>
<td style="text-align: center;"><span class="math display">\[\overline{x} - \mu\]</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math display">\[\frac{1}{\sigma}f(\frac{x}{\sigma})\]</span></td>
<td style="text-align: center;">크기</td>
<td style="text-align: center;"><span class="math display">\[\frac{\overline{x}}{S}\]</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math display">\[\frac{1}{\sigma}f(\frac{x - \mu}{\sigma})\]</span></td>
<td style="text-align: center;">위치-크기</td>
<td style="text-align: center;"><span class="math display">\[\frac{\overline{x} - \mu}{S}\]</span></td>
</tr>
</tbody>
</table>
<p>【예제】 모집단 <span class="math inline">\(f(x;\theta) \sim exponetial(\theta = \lambda)\)</span>에서 표본 크기 <span class="math inline">\(n\)</span>인 확률표본 <span class="math inline">\(\overline{X} = \left( X_{1},X_{2},\ldots,X_{n} \right)\)</span> 추출하였다. 모수 <span class="math inline">\(\lambda\)</span>(평균)에 대한 <span class="math inline">\(100(1 - \alpha)\%\)</span> 신뢰구간을 구하라.</p>
<p>지수분포는 지수족이므로 <span class="math inline">\(T = \sum x_{i}\)</span>는 충분 통계량이고 <span class="math inline">\(T = \sum x_{i} \sim Gamma(n,\lambda))\)</span>이다.<span class="math inline">\(\sum x_{i}/\lambda \sim Gamma(1,\lambda))\)</span>이 주축 통계량이다. 그러므로 <span class="math inline">\(100(1 - \alpha)\%\)</span> 신뢰구간은 다음을 만족하는 <span class="math inline">\((a,b)\)</span>이다. <span class="math inline">\(P_{\lambda}\left( a \leq \frac{\sum x_{i}}{\lambda} \leq b \right) = 1 - \alpha\)</span>.</p>
<p>【예제】 <span class="math inline">\(f(x;\theta) \sim N\left( \theta = \mu,\sigma^{2} \right),where\sigma^{2}isknown\)</span>에서 표본 크기 <span class="math inline">\(n\)</span>인 확률표본 <span class="math inline">\(\left( X_{1},X_{2},\ldots,X_{n} \right)\)</span> 추출하였다. 모수 <span class="math inline">\(\mu\)</span>(평균)에 대한 <span class="math inline">\(100(1 - \alpha)\%\)</span> 신뢰구간을 구하라.</p>
<p>정규분포는 위치-크기 모수 타입이므로 주축 통계량은 <span class="math inline">\(\frac{\overline{x} - \mu}{S}\)</span> 형태이다. 만약 분산 <span class="math inline">\(\sigma^{2}\)</span>을 알고 있다면 <span class="math inline">\(P\left( a \leq \frac{\overline{x} - \mu}{\frac{\sigma}{\sqrt{n}}} \sim N(0,1) \leq b \right) = 1 - \alpha\)</span> =&gt; <span class="math inline">\((\overline{x} - z_{1 - \frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}},\overline{x} + z_{1 - \frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}})\)</span></p>
<p>만약 분산 <span class="math inline">\(\sigma^{2}\)</span>을 모른다면 <span class="math inline">\(P\left( a \leq \frac{\overline{x} - \mu}{\frac{s}{\sqrt{n}}} \sim t(n - 1) \leq b \right) = 1 - \alpha\)</span></p>
<p>=&gt; <span class="math inline">\((\overline{x} - t_{1 - \frac{\alpha}{2},n - 1}\frac{s}{\sqrt{n}},\overline{x} + t_{1 - \frac{\alpha}{2},n - 1}\frac{s}{\sqrt{n}})\)</span></p>
<p>2정규분포 가정 모형</p>
<p>모집단 <span class="math inline">\(f(x;\theta)\)</span>에서 확률표본 <span class="math inline">\(\overline{X} = \left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>의 제곱 변환 <span class="math inline">\(X_{i}^{2}\)</span>의 확률분포함수에 대하여 살펴보자. 모집단 <span class="math inline">\(f(x;\theta) \sim N(0,1)\)</span>이면 <span class="math inline">\(X^{2}\)</span>의 분포는 <span class="math inline">\(\chi^{2}(1)\)</span>을 따른다.</p>
<p>【cochran theorem】</p>
<p>모집단 <span class="math inline">\(f(x;\theta) \sim N(\mu,\sigma^{2})\)</span>에서의 확률표본 <span class="math inline">\(\overline{X} = \left( X_{1},X_{2},\ldots,X_{n} \right)\)</span> 의 제곱 형태 (이차형식, quadratic form) <span class="math inline">\(Q_{i}^{2},fori = 1,2,\ldots,k\)</span> 확률변수와 <span class="math inline">\({Q = \sum Q}_{i}^{2}\)</span> 확률변수에 대하여 다음이 성립한다.</p>
<ol type="1">
<li><span class="math inline">\(Q_{1},Q_{2},\ldots,Q_{k}\)</span>는 서로 독립이다.</li>
</ol>
<!-- -->
<ol start="5" type="1">
<li><p><span class="math inline">\(\frac{Q_{k}}{\sigma^{2}} \sim \chi^{2}(r_{k})\)</span>을 갖는다.</p></li>
<li><p><span class="math inline">\(\frac{Q}{\sigma^{2}} \sim \chi^{2}(\sum r_{i})\)</span>을 갖는다.</p></li>
</ol>
<p>【예제】 모집단 <span class="math inline">\(f(x;\theta) \sim N\left( \mu,\sigma^{2} \right)\)</span>에서 확률표본 <span class="math inline">\(\left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>의 분산 <span class="math inline">\(\sigma^{2}\)</span>의 MVUE 표본 분산 <span class="math inline">\(S^{2} = \frac{\sum\left( x_{i} - \overset{¯}{x} \right)^{2}}{n - 1}\)</span> 은 이차형식이다. <span class="math inline">\((n - 1)S^{2} = \sum\left( x_{i} - \overset{¯}{x} \right)^{2} \Leftrightarrow \frac{(n - 1)S^{2}}{\sigma^{2}} = \frac{\sum\left( x_{i} - \overset{¯}{x} \right)^{2}}{\sigma^{2}} = \frac{\sum\left( x_{i} - \mu \right)^{2}}{\sigma^{2}} - \frac{\sum\left( \overset{¯}{x} - \mu \right)^{2}}{\sigma^{2}}\)</span></p>
<p><span class="math inline">\(X_{i} \sim N\left( \mu,\sigma^{2} \right)\)</span> 이므로 <span class="math inline">\(Q_{i} = \frac{\left( X_{i} - \mu \right)^{2}}{\sigma^{2}} \sim \chi^{2}(1) = &gt; \sum Q_{i} = \frac{\sum\left( X_{i} - \mu \right)^{2}}{\sigma^{2}} \sim \chi^{2}(n)\)</span> 이다.</p>
<p><span class="math inline">\(\overset{¯}{X} \sim N\left( \mu,\frac{\sigma^{2}}{n} \right)\)</span> 이므로<img src="media/image17.png" style="width:2.66944in;height:2.58264in" alt="그림 1"> <span class="math inline">\(Q_{1} = \frac{{n\left( \overset{¯}{X} - \mu \right)}^{2}}{\sigma^{2}} \sim \chi^{2}(1\)</span>) 이다. 그러므로 코크란 정리에 의해 <span class="math inline">\(\frac{(n - 1)S^{2}}{\sigma^{2}} \sim \chi^{2}(n - 1)\)</span>이다.</p>
<p>분산분석</p>
<p>모델 : <span class="math inline">\(X_{ij} = \mu_{i} + e_{ij};i = 1,2,\ldots,a,j = 1,2,\ldots,n\)</span></p>
<p>가정 : <span class="math inline">\(e_{ij} \sim (iid)N(0,\sigma^{2})\)</span></p>
<p>모수 : <span class="math inline">\(\Omega = \{\left( \mu_{1},\mu_{2},\ldots,\mu_{k},\sigma^{2} \right); - \infty &lt; \mu_{j} &lt; \infty,0 &lt; \sigma^{2} &lt; \infty\)</span></p>
<p>귀무가설 <span class="math inline">\(H_{0}:\mu_{1} = \mu_{2} = \ldots = \mu_{k} = \mu\)</span></p>
<p>귀무가설 모수 : <span class="math inline">\(\Omega_{0} = \{\left( \mu_{1},\mu_{2},\ldots,\mu_{k},\sigma^{2} \right); - \infty &lt; \mu_{1} = \mu_{2} = \ldots = \mu_{k} = \mu &lt; \infty,0 &lt; \sigma^{2} &lt; \infty\)</span></p>
<p>【표본분산 분할】</p>
<p>분산분석 모형에서 표본분산 <span class="math inline">\(S^{2} = \frac{1}{(an - 1)}\sum_{i}^{}{\sum_{j}^{}\left( x_{ij} - {\overset{¯}{x}}_{..} \right)^{2}}\)</span>을 이차형식으로 분할하라. 단, <span class="math inline">\({\overset{¯}{x}}_{..} = \frac{\sum_{i}^{}{\sum_{j}^{}x_{ij}}}{an},{\overset{¯}{x}}_{i.} = \frac{\sum_{j}^{}x_{ij}}{n}\)</span>, <span class="math inline">\({\overset{¯}{x}}_{.j} = \frac{\sum_{i}^{}x_{ij}}{a}\)</span>이다.</p>
<p><span class="math inline">\({(an - 1)S}^{2} = \sum_{i}^{}{\sum_{j}^{}\left( x_{ij} - {\overset{¯}{x}}_{..} \right)^{2}} = \sum_{i}^{}{\sum_{j}^{}\left( x_{ij} - {\overset{¯}{x}}_{i.} \right)^{2}} + \sum_{i}^{}{\sum_{j}^{}\left( {\overset{¯}{x}}_{i.} - {\overset{¯}{x}}_{..} \right)^{2}}\)</span></p>
<p><span class="math inline">\(= \sum_{i}^{}{\sum_{j}^{}\left( x_{ij} - {\overset{¯}{x}}_{i.} \right)^{2}} + n\sum_{i}^{}{\left( {\overset{¯}{x}}_{i.} - {\overset{¯}{x}}_{..} \right)^{2} = Q_{1} + Q_{2}}\)</span></p>
<p><span class="math inline">\({(an - 1)S}^{2} = \sum_{i}^{}{\sum_{j}^{}\left( x_{ij} - {\overset{¯}{x}}_{..} \right)^{2}} = \sum_{i}^{}{\sum_{j}^{}\left( x_{ij} - {\overset{¯}{x}}_{.j} \right)^{2}} + \sum_{i}^{}{\sum_{j}^{}\left( {\overset{¯}{x}}_{.j} - {\overset{¯}{x}}_{..} \right)^{2}}\)</span></p>
<p><span class="math inline">\(= \sum_{i}^{}{\sum_{j}^{}\left( x_{ij} - {\overset{¯}{x}}_{.j} \right)^{2}} + a\sum_{j}^{}{\left( {\overset{¯}{x}}_{.j} - {\overset{¯}{x}}_{..} \right)^{2} = Q_{3} + Q_{4}}\)</span></p>
<p><span class="math display">\[{(an - 1)S}^{2} = a\sum_{j}^{}{\left( {\overset{¯}{x}}_{.j} - {\overset{¯}{x}}_{..} \right)^{2} +}n\sum_{i}^{}{\left( {\overset{¯}{x}}_{i.} - {\overset{¯}{x}}_{..} \right)^{2} +}\sum_{i}^{}{\sum_{j}^{}\left( x_{ij} - {\overset{¯}{x}}_{i.} - {\overset{¯}{x}}_{.j} + {\overset{¯}{x}}_{..} \right)^{2}} = Q_{2} + Q_{3} + Q_{4}\]</span></p>
<p>【우도비 검정】</p>
<p>분자 우도함수 : <span class="math inline">\(L\left( \Omega_{0} \right) = \left( \frac{1}{2\pi\sigma} \right)^{an/2}exp( - \frac{1}{2\sigma^{2}}\sum_{i}^{}{\sum_{j}^{}\left( x_{ij} - \mu \right)^{2}})\)</span></p>
<p><span class="math inline">\(\mu\)</span> &nbsp;MLE : <span class="math inline">\(\frac{\partial L\left( \Omega_{0} \right)}{\partial\mu} = 0 \Rightarrow \overset{\hat{}}{\mu} = \frac{1}{an}\sum_{i}^{}{\sum_{j}^{}x_{ij} = {\overset{¯}{x}}_{..}}\)</span></p>
<p><span class="math inline">\(\sigma^{2}\)</span> &nbsp;MLE : <span class="math inline">\(\frac{\partial L\left( \Omega_{0} \right)}{\partial\sigma^{2}} = 0 \Rightarrow \overset{\hat{}}{\sigma^{2}} = \frac{1}{an}\sum_{i}^{}{\sum_{j}^{}{{(x}_{ij} - {\overset{¯}{x}}_{..})^{2}} = v}\)</span></p>
<p>분모 우도함수 : <span class="math inline">\(L(\Omega) = \left( \frac{1}{2\pi\sigma} \right)^{an/2}exp( - \frac{1}{2\sigma^{2}}\sum_{i}^{}{\sum_{j}^{}\left( x_{ij} - \mu_{i} \right)^{2}})\)</span></p>
<p><span class="math inline">\(\mu_{i}\)</span> &nbsp;MLE : <span class="math inline">\(\frac{\partial L(\Omega)}{\partial\mu_{i}} = 0 \Rightarrow \overset{\hat{}}{\mu_{i}} = \frac{1}{n}\sum_{j}^{}{x_{ij} = {\overset{¯}{x}}_{i.}}\)</span></p>
<p><span class="math inline">\(\sigma^{2}\)</span> &nbsp;MLE : <span class="math inline">\(\frac{\partial L(\Omega)}{\partial\sigma^{2}} = 0 \Rightarrow \overset{\hat{}}{\sigma^{2}} = \frac{1}{an}\sum_{i}^{}{\sum_{j}^{}{{(x}_{ij} - {\overset{¯}{x}}_{..})^{2}} = w}\)</span></p>
<p>우도비 : <span class="math inline">\(\lambda = \frac{L\left( {\overset{\hat{}}{\Omega}}_{0} \right)}{L\left( \overset{\hat{}}{\Omega} \right)} = \left( \frac{\sum_{i}^{}{\sum_{j}^{}\left( x_{ij} - {\overset{¯}{x}}_{i.} \right)^{2}}}{\sum_{i}^{}{\sum_{j}^{}\left( x_{ij} - {\overset{¯}{x}}_{..} \right)^{2}}} \right)^{an/2}\)</span>.</p>
<p>가정 <span class="math inline">\(e_{ij} \sim (iid)N(0,\sigma^{2})\)</span>에 의해 <span class="math inline">\(X_{ij} \sim (iid)N(\mu_{i},\sigma^{2})\)</span> 이다.</p>
<p>그러므로 <span class="math inline">\(V = \frac{1}{an}\sum_{i}^{}{\sum_{j}^{}{{(x}_{ij} - {\overset{¯}{x}}_{..})^{2}} = \frac{Q}{an}}\)</span> 이고 <span class="math inline">\(W = \frac{1}{an}\sum_{i}^{}{\sum_{j}^{}{{(x}_{ij} - {\overset{¯}{x}}_{i.})^{2}} = \frac{Q_{3}}{an}}\)</span> 이다.</p>
<p>우도비 : <span class="math inline">\(\lambda^{2/an} = \frac{Q_{3}}{Q_{3} + Q_{4}} = \frac{1}{1 + Q_{4}/Q_{3}}\)</span></p>
<p>귀무가설 검정 유의수준 <span class="math inline">\(\alpha\)</span> : <span class="math inline">\(\alpha = P_{H_{0}}\left( \frac{1}{1 + \frac{Q_{4}}{Q_{3}}} \leq \lambda^{\frac{2}{an}} \right) = P_{H_{0}}\left( \frac{Q_{4}/(a - 1)}{Q_{3}/a(n - 1)} \leq c \right)\)</span></p>
<p><span class="math inline">\(\frac{Q_{4}/(\sigma^{2}(a - 1))}{Q_{3}/(\sigma^{2}a(n - 1))} \sim F(a - 1,a(n - 1))\)</span>이다.</p>
<p>【ANOVA table】</p>
<table class="caption-top table">
<colgroup>
<col style="width: 5%">
<col style="width: 52%">
<col style="width: 8%">
<col style="width: 17%">
<col style="width: 13%">
</colgroup>
<tbody>
<tr class="odd">
<td style="text-align: center;">변동</td>
<td style="text-align: center;">제곱합</td>
<td style="text-align: center;">자유도</td>
<td style="text-align: center;">평균제곱합</td>
<td style="text-align: center;">F-통계량</td>
</tr>
<tr class="even">
<td style="text-align: center;">집단간 변동</td>
<td style="text-align: center;"><span class="math display">\[SSB = \sum_{i}^{}{\sum_{j}^{}\left( {\overline{x}}_{i} - {\overset{¯}{x}}_{..} \right)^{2}}\]</span></td>
<td style="text-align: center;"><span class="math display">\[a - 1\]</span></td>
<td style="text-align: center;"><span class="math display">\[MSB = \frac{SSB}{a - 1}\]</span></td>
<td rowspan="2" style="text-align: center;"><span class="math display">\[F = \frac{MSB}{MSE}\]</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;">오차변동</td>
<td style="text-align: center;"><span class="math display">\[SSE = \sum_{i}^{}{\sum_{j}^{}\left( x_{ij} - {\overline{x}}_{i} \right)^{2}}\]</span></td>
<td style="text-align: center;"><span class="math display">\[a(n - 1)\]</span></td>
<td style="text-align: center;"><span class="math display">\[MSE = \frac{SSE}{a(n - 1)}\]</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">총변동</td>
<td style="text-align: center;"><span class="math display">\[SST = \sum_{i}^{}{\sum_{j}^{}\left( x_{ij} - {\overset{¯}{x}}_{..} \right)^{2}}\]</span></td>
<td style="text-align: center;"><span class="math display">\[an - 1\]</span></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>회귀분석</p>
<p>모델 : <span class="math inline">\(Y_{i} = a + bx_{i} + e_{i};i = 1,2,\ldots,n\)</span></p>
<p>가정 : <span class="math inline">\(e_{i} \sim (iid)N(0,\sigma^{2})\)</span></p>
<p>귀무가설 <span class="math inline">\(H_{0}:\alpha = \beta = 0\)</span><img src="media/image18.png" style="width:2.77504in;height:2.03386in" alt="텍스트, 라인, 폰트, 스크린샷이(가) 표시된 사진 자동 생성된 설명"></p>
<p>【OLS 최소자승추정법】</p>
<p>관측점들을 가장 대표하는 직선 (best fit)을 어떻게 구할 것인가? 데이터 <span class="math inline">\((x_{i},y_{i})\)</span>를 활용하여 점들에 가장 적합한 직선의 회귀계수 <span class="math inline">\((a,b)\)</span>를 추정하고 이를 이용하여 목표변수 추정값을 <span class="math inline">\(\overset{\hat{}}{y_{i}} = \overset{\hat{}}{a} + \overset{\hat{}}{b}x_{i}\)</span> fitted value 구한다. 오차항에 대한 추정값으로 &nbsp;<span class="math inline">\({\overset{\hat{}}{e}}_{i} = y_{i} - \overset{\hat{}}{y_{i}}\)</span>을 사용하여 직선의 유의성을 검증한다.</p>
<p><span class="math display">\[\min_{(a,b)}{Q = \sum_{i}^{}\left( y_{i} - a - bx_{i} \right)}^{2}\]</span><span class="math display">\[\frac{\partial Q}{\partial a} = - 2\sum\left( y_{i} - a - bx_{i} \right) = 0,\frac{\partial Q}{\partial b} = - 2\sum x_{i}\left( y_{i} - a - bx_{i} \right) = 0\]</span></p>
<p><span class="math inline">\(\overset{\hat{}}{b} = \frac{\sum\left( x_{i} - \overset{¯}{x} \right)\left( y_{i} - \overset{¯}{y} \right)}{\sum\left( x_{i} - \overset{¯}{x} \right)^{2}} = \frac{S_{XY}}{S_{XX}}\)</span>, <span class="math inline">\(\overset{\hat{}}{a} = \overset{¯}{y} - \overset{\hat{}}{b}\overset{¯}{x}\)</span></p>
<p>【MLE】</p>
<p><span class="math inline">\(e_{i} \sim (iid)N(0,\sigma^{2})\)</span> 이므로 <span class="math inline">\(y_{i} \sim (iid)N(a + bx_{i},\sigma^{2})\)</span> 이다.</p>
<p>우도함수 : <span class="math inline">\(L\left( \overline{x};a,b \right) = \left( \frac{1}{2\pi\sigma} \right)^{\frac{n}{2}}exp( - \frac{{\sum_{i}^{}\left( y_{i} - a - bx_{i} \right)}^{2}}{2\sigma^{2}}) \propto {\sum_{i}^{}\left( y_{i} - a - bx_{i} \right)}^{2}\)</span>우도함수를 최대화 하는 것이나 <span class="math inline">\({\sum_{i}^{}\left( y_{i} - a - bx_{i} \right)}^{2}\)</span>을 최소화 하는 OLS와 동일하다.</p>
<p>【 OLS is blue 】 markov theorem</p>
<p>회귀계수에 대한 OLS 추정치는 BLUE(Best Linear Unbiased Estimator)이다. 즉 모든 선형, 불편 추정량 중 최소 분산(minimum variance)를 갖는다. 분포함수가 지수족이므로 MLE는 CSS이고 불편추정량이므로 Rao-Blackwell 정리에 의해 MVUE이다.</p>
<p>【 오차 분산 MVUE 추정량 】</p>
<p><span class="math inline">\(\overset{\hat{}}{\sigma^{2}} = \frac{1}{n - 2}\sum\left( y_{i} - \overset{\hat{}}{a} - \overset{\hat{}}{b}x_{i} \right)^{2} = MSE\)</span>.</p>
<p>【 <span class="math inline">\(\overset{\hat{}}{b}\)</span> 샘플링 분포 】</p>
<p><span class="math inline">\(\overset{\hat{}}{b} = \frac{\sum\left( x_{i} - \overset{¯}{x} \right)\left( y_{i} - \overset{¯}{y} \right)}{\sum\left( x_{i} - \overset{¯}{x} \right)^{2}}\)</span> 이므로 <span class="math inline">\(k_{i} = \frac{\left( y_{i} - \overset{¯}{y} \right)}{\sum\left( x_{i} - \overset{¯}{x} \right)^{2}}\)</span> 이라 하면 <span class="math inline">\(\overset{\hat{}}{b} = \sum k_{i}y_{i}\)</span> 이다. 그리고 <span class="math inline">\(\sum k_{i} = 0,\sum k_{i}x_{i} = 1,\sum k_{i}^{2} = \frac{1}{\sum\left( x_{i} - \overset{¯}{x} \right)^{2}}\)</span>이다.</p>
<p><span class="math inline">\(y_{i} \sim (iid)N(a + bx_{i},\sigma^{2})\)</span> 이므로 선형 결합 <span class="math inline">\(\overset{\hat{}}{b} = \sum k_{i}y_{i}\)</span>도 정규분포를 따른다.</p>
<p><span class="math display">\[E\left( \overset{\hat{}}{b} \right) = E\left( \sum k_{i}y_{i} \right) = \sum k_{i}{E(y}_{i}) = \sum k_{i}(a + bx_{i}) = b\]</span></p>
<p><span class="math display">\[V\left( \overset{\hat{}}{b} \right) = V\left( \sum k_{i}y_{i} \right) = \sum k_{i}^{2}{V(y}_{i}) = \sum k_{i}^{2}(\sigma^{2}) = \frac{\sigma^{2}}{\sum\left( x_{i} - \overset{¯}{x} \right)^{2}}\]</span></p>
<p><span class="math inline">\(\overset{\hat{}}{b} \sim N(b,\frac{\sigma^{2}}{\sum\left( x_{i} - \overset{¯}{x} \right)^{2}})\)</span>. 만약 <span class="math inline">\(\sigma^{2}\)</span>을 MVUE 추정량 <span class="math inline">\(\frac{(n - 2)\overset{\hat{}}{\sigma^{2}}}{\sigma^{2}} = \frac{\sum\left( y_{i} - \overset{\hat{}}{a} - \overset{\hat{}}{b}x_{i} \right)^{2}}{\sigma^{2}} \sim \chi^{2}(n - 2)\)</span> 성립한다.</p>
<p>그러므로 <span class="math inline">\(\frac{\overset{\hat{}}{b} - b}{s\left( \overset{\hat{}}{b} \right)} \sim t(n - 2)\)</span>, <span class="math inline">\(s^{2}\left( \overset{\hat{}}{b} \right) = \frac{MSE}{\sum\left( x_{i} - \overset{¯}{x} \right)^{2}}\)</span>이다.</p>
<p>【기울기 <span class="math inline">\(b\)</span>&nbsp;에 대한 <span class="math inline">\(100(1 - \alpha)\%\)</span> 신뢰구간 】</p>
<p><span class="math inline">\((\overset{\hat{}}{b} - t_{1 - \frac{\alpha}{2},(n - 1)}s\left( \overset{\hat{}}{b} \right),\overset{\hat{}}{b} + t_{1 - \frac{\alpha}{2},(n - 1)}s\left( \overset{\hat{}}{b} \right)\)</span>, <span class="math inline">\(s^{2}\left( \overset{\hat{}}{b} \right) = \frac{MSE}{\sum\left( x_{i} - \overset{¯}{x} \right)^{2}}\)</span>.</p>
<p>【 절편 <span class="math inline">\(a\)</span>&nbsp;에 대한 <span class="math inline">\(100(1 - \alpha)\%\)</span> 신뢰구간 】</p>
<p><span class="math inline">\((\overset{\hat{}}{a} - t_{1 - \frac{\alpha}{2},(n - 1)}s\left( \overset{\hat{}}{a} \right),\overset{\hat{}}{a} + t_{1 - \frac{\alpha}{2},(n - 1)}s\left( \overset{\hat{}}{a} \right)\)</span>, <span class="math inline">\(s^{2}\left( \overset{\hat{}}{a} \right) = MSE(\frac{1}{n} + \frac{{\overset{¯}{x}}^{2}}{\sum\left( x_{i} - \overset{¯}{x} \right)^{2}}\)</span>)</p>
<p>저자 정보</p>
<p>1982. 성균관대학교 통계학 학사</p>
<p>1985. 성균관대학교 통계학 석사</p>
<p>1992. 미국 North Carolina State University 통계학 박사</p>
<p>1993-1995. 전자통신연구원 선임연구원</p>
<p>1995-2026. 한남대학교 통계학과 교수</p>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>