<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="ko" xml:lang="ko"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>수리 통계 5. 확률 표본 – 세상 모든 통계 이야기</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-1b3e43c72e8be34557c75123b0b69e0d.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-302e6895c9654fb97c48ad8f826d3f42.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "일치 없음",
    "search-matching-documents-text": "일치된 문서",
    "search-copy-link-title": "검색 링크 복사",
    "search-hide-matches-text": "추가 검색 결과 숨기기",
    "search-more-match-text": "추가 검색결과",
    "search-more-matches-text": "추가 검색결과",
    "search-clear-button-title": "제거",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "취소",
    "search-submit-button-title": "검색",
    "search-label": "검색"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="floating nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">세상 모든 통계 이야기</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="검색"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="탐색 전환" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">기초수학</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-">    
        <li>
    <a class="dropdown-item" href="../../notes/math/function.html">
 <span class="dropdown-text">함수</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/math/derivate_integral.html">
 <span class="dropdown-text">미분적분</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/math/vector.html">
 <span class="dropdown-text">벡터</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/math/matrix.html">
 <span class="dropdown-text">행렬</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu--1" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">수리통계</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu--1">    
        <li>
    <a class="dropdown-item" href="../../notes/math_stat/probability.html">
 <span class="dropdown-text">확률</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/math_stat/random_variable.html">
 <span class="dropdown-text">확률변수</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/math_stat/famous_distribution.html">
 <span class="dropdown-text">유명한분포</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/math_stat/multi_variate.html">
 <span class="dropdown-text">다변량확률변수</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/math_stat/random_sample.html">
 <span class="dropdown-text">확률표본_난수생성</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/math_stat/estimation.html">
 <span class="dropdown-text">추정</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/math_stat/hypothesis_testing.html">
 <span class="dropdown-text">가설검정_신뢰구간</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu--2" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">일변량분석</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu--2">    
        <li>
    <a class="dropdown-item" href="../../notes/intro_stat/concept_of_stat.html">
 <span class="dropdown-text">일변량분석 개념</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/intro_stat/data.html">
 <span class="dropdown-text">데이터와 통계</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/intro_stat/univariate.html">
 <span class="dropdown-text">일변량분석</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/intro_stat/crosstab.html">
 <span class="dropdown-text">교차표분석</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/intro_stat/goodness_of_fits.html">
 <span class="dropdown-text">적합성검정</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/intro_stat/normality.html">
 <span class="dropdown-text">정규변환</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/intro_stat/correlation.html">
 <span class="dropdown-text">상관분석</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/intro_stat/anova.html">
 <span class="dropdown-text">실험설계 분산분석</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/intro_stat/time_series.html">
 <span class="dropdown-text">시계열분석</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu--3" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">조사방법론</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu--3">    
        <li>
    <a class="dropdown-item" href="../../notes/survey/survey_intro.html">
 <span class="dropdown-text">조사방법 기초</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/survey/sample_design.html">
 <span class="dropdown-text">표본설계</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/survey/questionnaire.html">
 <span class="dropdown-text">설문지</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/survey/nonresponse.html">
 <span class="dropdown-text">무응답 대체</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/survey/data_process.html">
 <span class="dropdown-text">데이터 처리</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/survey/survey_scale.html">
 <span class="dropdown-text">조사지 척도</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/survey/delphi_ahp_conjoint.html">
 <span class="dropdown-text">델파이_AHP_컨조인트</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/survey/psm.html">
 <span class="dropdown-text">PSM 성향점수매칭</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu--4" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">회귀분석</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu--4">    
        <li>
    <a class="dropdown-item" href="../../notes/linear_model/lm_concept.html">
 <span class="dropdown-text">회귀분석 개념&amp;추정</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/linear_model/lm_selection.html">
 <span class="dropdown-text">변수선택</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/linear_model/lm_multicolin.html">
 <span class="dropdown-text">다중공선성</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/linear_model/lm_diagnosis.html">
 <span class="dropdown-text">회귀진단</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/linear_model/lm_logistic.html">
 <span class="dropdown-text">로지스틱회귀</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu--5" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">다변량분석</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu--5">    
        <li>
    <a class="dropdown-item" href="../../notes/mda/mda_concepts.html">
 <span class="dropdown-text">다변량분석 개념</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://by-sekwon.github.io/notes/intro_stat/correlation.html#chapter-3.-%EB%8B%A4%EB%B3%80%EB%9F%89-%EC%83%81%EA%B4%80%EA%B3%84%EC%88%98">
 <span class="dropdown-text">다변량 상관계수</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/mda/mda_pca.html">
 <span class="dropdown-text">주성분분석 svd</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/mda/mda_factor.html">
 <span class="dropdown-text">요인분석 구조방정식</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/mda/mda_discriminant.html">
 <span class="dropdown-text">판별분석 Fisher|Logistic</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/mda/mda_cluster.html">
 <span class="dropdown-text">군집분석 계층적|비계층적방법</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/mda/mda_mds_ca.html">
 <span class="dropdown-text">다차원척도법|대응분석</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/mda/mda_cancorr_manova.html">
 <span class="dropdown-text">정준상관분석|다변량분산분석</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-wgpt" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">머신러닝딥러닝 개념 w/GPT</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-wgpt">    
        <li>
    <a class="dropdown-item" href="../../notes/mldl/mldl_concepts01.html">
 <span class="dropdown-text">MLDL AI 통계 01</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/mldl/mldl_concepts02.html">
 <span class="dropdown-text">MLDL AI 통계 02</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../notes/mldl/mldl_concepts.html">
 <span class="dropdown-text">머신러닝 통계적사고</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../cardnews/index.html"> 
<span class="menu-text">카드뉴스</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../consult.html"> 
<span class="menu-text">통계상담</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu--6" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">📡스트리밍</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu--6">    
        <li>
    <a class="dropdown-item" href="https://by-sekwonappio-esqshnv7wueapp4da6jrizn.streamlit.app" target="_blank">
 <span class="dropdown-text">실시간주가[5대종목]</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://by-sekwonappio-k5e5n7wasvj3kveyqbwmgc.streamlit.app/" target="_blank">
 <span class="dropdown-text">대전유성구 일기예보</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">목차</h2>
   
  <ul>
  <li><a href="#chapter-1.-데이터와-확률표본" id="toc-chapter-1.-데이터와-확률표본" class="nav-link active" data-scroll-target="#chapter-1.-데이터와-확률표본">chapter 1. 데이터와 확률표본</a>
  <ul>
  <li><a href="#데이터" id="toc-데이터" class="nav-link" data-scroll-target="#데이터">1. 데이터</a></li>
  <li><a href="#데이터-수집-및-모형" id="toc-데이터-수집-및-모형" class="nav-link" data-scroll-target="#데이터-수집-및-모형">2. 데이터 수집 및 모형</a></li>
  <li><a href="#데이터와-모집단" id="toc-데이터와-모집단" class="nav-link" data-scroll-target="#데이터와-모집단">3. 데이터와 모집단</a></li>
  </ul></li>
  <li><a href="#chapter-2.-확률표본-개념" id="toc-chapter-2.-확률표본-개념" class="nav-link" data-scroll-target="#chapter-2.-확률표본-개념">chapter 2. 확률표본 개념</a>
  <ul>
  <li><a href="#확률표본-정의-및-활용" id="toc-확률표본-정의-및-활용" class="nav-link" data-scroll-target="#확률표본-정의-및-활용">1. 확률표본 정의 및 활용</a></li>
  <li><a href="#복원추출과-비복원추출" id="toc-복원추출과-비복원추출" class="nav-link" data-scroll-target="#복원추출과-비복원추출">2. 복원추출과 비복원추출</a></li>
  </ul></li>
  <li><a href="#chapter-3.-확률표본의-함수" id="toc-chapter-3.-확률표본의-함수" class="nav-link" data-scroll-target="#chapter-3.-확률표본의-함수">chapter 3. 확률표본의 함수</a>
  <ul>
  <li><a href="#통계량" id="toc-통계량" class="nav-link" data-scroll-target="#통계량">1. 통계량</a></li>
  <li><a href="#확률표본의-평균과-분산" id="toc-확률표본의-평균과-분산" class="nav-link" data-scroll-target="#확률표본의-평균과-분산">2. 확률표본의 평균과 분산</a></li>
  <li><a href="#샘플링-분포" id="toc-샘플링-분포" class="nav-link" data-scroll-target="#샘플링-분포">3. 샘플링 분포</a></li>
  </ul></li>
  <li><a href="#chapter-4.-정규분포로부터의-확률표본" id="toc-chapter-4.-정규분포로부터의-확률표본" class="nav-link" data-scroll-target="#chapter-4.-정규분포로부터의-확률표본">chapter 4. 정규분포로부터의 확률표본</a>
  <ul>
  <li><a href="#표본평균과-표본분산의-샘플링-분포" id="toc-표본평균과-표본분산의-샘플링-분포" class="nav-link" data-scroll-target="#표본평균과-표본분산의-샘플링-분포">1. 표본평균과 표본분산의 샘플링 분포</a></li>
  <li><a href="#카이제곱-확률변수에-대한-성질" id="toc-카이제곱-확률변수에-대한-성질" class="nav-link" data-scroll-target="#카이제곱-확률변수에-대한-성질">2. 카이제곱 확률변수에 대한 성질</a></li>
  <li><a href="#정규-변수들의-선형결합-간의-독립성-판별" id="toc-정규-변수들의-선형결합-간의-독립성-판별" class="nav-link" data-scroll-target="#정규-변수들의-선형결합-간의-독립성-판별">3. 정규 변수들의 선형결합 간의 독립성 판별</a></li>
  <li><a href="#정규분포로부터-유도된-분포" id="toc-정규분포로부터-유도된-분포" class="nav-link" data-scroll-target="#정규분포로부터-유도된-분포">4. 정규분포로부터 유도된 분포</a></li>
  </ul></li>
  <li><a href="#chapter-5.-순서통계량" id="toc-chapter-5.-순서통계량" class="nav-link" data-scroll-target="#chapter-5.-순서통계량">chapter 5. 순서통계량</a>
  <ul>
  <li><a href="#순서통계량-정의" id="toc-순서통계량-정의" class="nav-link" data-scroll-target="#순서통계량-정의">1. 순서통계량 정의</a></li>
  <li><a href="#순서-통계량-결합-주변-확률밀도함수" id="toc-순서-통계량-결합-주변-확률밀도함수" class="nav-link" data-scroll-target="#순서-통계량-결합-주변-확률밀도함수">2. 순서 통계량 결합, 주변 확률밀도함수</a></li>
  <li><a href="#상자수염그림" id="toc-상자수염그림" class="nav-link" data-scroll-target="#상자수염그림">3. 상자수염그림</a></li>
  </ul></li>
  <li><a href="#chapter-6.-수렴개념" id="toc-chapter-6.-수렴개념" class="nav-link" data-scroll-target="#chapter-6.-수렴개념">chapter 6. 수렴개념</a>
  <ul>
  <li><a href="#확률수렴" id="toc-확률수렴" class="nav-link" data-scroll-target="#확률수렴">1. 확률수렴</a></li>
  <li><a href="#거의-확실한-수렴-all-sure-convergence" id="toc-거의-확실한-수렴-all-sure-convergence" class="nav-link" data-scroll-target="#거의-확실한-수렴-all-sure-convergence">2. 거의 확실한 수렴 ALL sure convergence</a></li>
  <li><a href="#분포-수렴-convergence-in-distribution" id="toc-분포-수렴-convergence-in-distribution" class="nav-link" data-scroll-target="#분포-수렴-convergence-in-distribution">3. 분포 수렴 convergence in distribution</a></li>
  </ul></li>
  <li><a href="#chapter-7.-확률표본-생성-시뮬레이션" id="toc-chapter-7.-확률표본-생성-시뮬레이션" class="nav-link" data-scroll-target="#chapter-7.-확률표본-생성-시뮬레이션">chapter 7. 확률표본 생성 : 시뮬레이션</a>
  <ul>
  <li><a href="#개념" id="toc-개념" class="nav-link" data-scroll-target="#개념">1. 개념</a></li>
  <li><a href="#난수생성-방법" id="toc-난수생성-방법" class="nav-link" data-scroll-target="#난수생성-방법">2. 난수생성 방법</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">수리 통계 5. 확률 표본</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="chapter-1.-데이터와-확률표본" class="level3">
<h3 class="anchored" data-anchor-id="chapter-1.-데이터와-확률표본">chapter 1. 데이터와 확률표본</h3>
<section id="데이터" class="level4">
<h4 class="anchored" data-anchor-id="데이터">1. 데이터</h4>
<p>실험을 통해 수집된 자료는 일반적으로 어떤 하나의 변수에 대한 여러 관측값으로 구성되며, 이러한 자료를 우리는 데이터(data)라고 한다. 데이터는 자연현상이나 사회현상에 대한 체계적 이해를 가능하게 해주는 가장 기초적인 재료이며, 과학적 탐구의 출발점이라 할 수 있다.</p>
<p>과학 이론은 때때로 아인슈타인의 상대성 이론처럼 탁월한 이론적 통찰이나, 케플러의 행성 궤도 법칙처럼 새로운 자연현상의 관찰, 또는 Student의 t-분포처럼 실험과 경험에서 비롯된 혁신적인 아이디어를 통해 탄생하기도 한다. 그러나 대부분의 경우 과학 이론은 관찰, 실험, 그리고 분석의 반복을 통해 점진적으로 정립된다. 이러한 과정에서 수집되고 해석되는 데이터는 과학적 주장과 이론의 정당성을 뒷받침하는 핵심적인 증거가 된다.</p>
<p>예를 들어, 벼 품종의 수량성을 높이기 위한 품종 개량 연구, 신약의 효과와 부작용을 평가하기 위한 임상시험, 혹은 산업 현장에서의 공정 개선 실험 등은 모두 체계적인 실험 설계에 따라 데이터를 수집하고 분석함으로써 유의미한 결론에 도달하게 된다. 이러한 연구들은 데이터의 수집과 활용이 단순한 관찰을 넘어서, 실질적인 과학적·기술적 진보를 이끌어낸다는 점을 잘 보여준다.</p>
<p>요약하면, 데이터란 실험이나 관찰을 통해 얻은 정량적 또는 정성적 측정값의 집합이며, 이는 과학적 이론을 정립하고 검증하는 데 필수적인 도구이다. 따라서 데이터에 대한 명확한 이해와 올바른 수집·분석 방법의 습득은 과학 연구 및 통계학 학습의 핵심이라 할 수 있다.</p>
<p>데이터(data)란 추론, 토론, 계산 등의 목적을 위해 활용되는 실제 정보의 집합으로, 일반적으로 측정값 또는 통계적 수치의 형태를 갖는 숫자들의 모임을 의미한다. 이러한 데이터는 관찰이나 실험을 통해 수집되며, 연구 가설의 검정이나 현상의 이해를 위한 객관적 근거로 기능한다. 즉, 데이터란 변수의 값을 수치 또는 범주 형태로 표현한 관측값들의 집합으로, 이는 모집단에 대한 추론이나 가설 검정 등의 통계적 분석의 기초 자료가 된다.</p>
<p><strong>【정의】</strong> 통계학에서 분석의 대상이 되는 데이터는 일반적으로 행과 열로 구성된 숫자 행렬의 형태를 가진다. 이때 각 행은 하나의 개체 또는 관측 단위를 나타내며, 각 열은 해당 개체에 대해 측정된 변수(확률변수) 또는 특성을 의미한다. 이러한 데이터 행렬에서 행의 첨자는 서로 다른 개체를 구분하는 데 사용되며, 열의 첨자는 어떤 변수를 나타내는지를 구별하는 역할을 한다. 따라서 행렬의 각 원소는 특정 개체에 대해 특정 변수의 값을 의미하며, 분석은 이 구조를 기반으로 이루어진다.</p>
<p><span class="math display">\[\mathbf{X}n \times p = \begin{bmatrix}
x11 &amp; x_{12} &amp; \cdots &amp; x_{1p} \\
x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np}
\end{bmatrix}\]</span></p>
<ul>
<li><p><span class="math inline">\(n\)</span>: 관측값의 수 (또는 개체 수)</p></li>
<li><p><span class="math inline">\(p\)</span>: 변수의 수 (측정된 특성의 수)</p></li>
<li><p><span class="math inline">\(x_{ij}\)</span>: i번째 개체의 j번째 변수에 대한 관측값</p></li>
</ul>
</section>
<section id="데이터-수집-및-모형" class="level4">
<h4 class="anchored" data-anchor-id="데이터-수집-및-모형">2. 데이터 수집 및 모형</h4>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/빅데이터3v.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
<p>Veracity(데이터 정확성) + Value(데이터 가치) = 5V of Big Data</p>
<p>데이터는 객관적인가? NO &lt;- 수집되는 데이터는 목적이 있다. even 빅데이터 - 분석자의 의도없이 매초 단위로 엄청난 자동 저장되는 데이터도 일단 분석 대상이 되는 순간 그 데이터는 목적을 가지게 되므로 객관성을 상실한다.</p>
<p>데이터는 관심을 갖는 모집단 개체로부터 분석 대상 특성을 관측, 측정 등을 통하여 얻어지는 숫자(고전적 데이터), 문자(텍스트 마이닝), 음성, 이미지(빅데이터) 형식이다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/탐색적 확증적.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
<p>(전통적인 통계방법) 과학에서 이론이 제안되고 데이터 분석이 이루어지는 경우보다는 (빅데이터 통계방법)데이터로부터 새로운 이론이나 모형을 도출하는 경우가 많고 탐색적 자료 분석에 의해 제안된 이론이나 모형은 다시 확증적 방법에 의해 유의성이 (연구가설이 적합하다) 검증되므로 모형과 데이터는 순환 사이클을 갖는다.</p>
<p>통계적 모형은 과학적 진실이기 보다는 분석 대상이 되는 사실(현황)의 대표적 모형이다. 예를 들어, 회귀모형에서는 선형함수(모형)이 설명하지 못하는 오차항(e)이존재하고 이 오차항은 평균 0, 분산 <span class="math inline">\(\sigma^{2}\)</span>인 정규분포를 따른다고 가정한다.</p>
</section>
<section id="데이터와-모집단" class="level4">
<h4 class="anchored" data-anchor-id="데이터와-모집단">3. 데이터와 모집단</h4>
<section id="모집단과-확률변수" class="level5">
<h5 class="anchored" data-anchor-id="모집단과-확률변수">(1) 모집단과 확률변수</h5>
<p>관심의 대상이 되는 개체 전체를 모집단이라 한다. 예를 들어 코스피 지수와 등록된 기업의 주가에 관심이 있다면 코스피 등록된 기업들이 모집단이 된다. 전국 대학생들의 흡연율, 일주일 공부시간, 폰에 저장된 친구 전화번호 개수에 관심이 있다면 조사시점 기준 대학에 등록한 대학생이 모집단이 된다.</p>
<p>모집단을 구성하는 개체의 관심 특성을 (확률)변수라 한다. 코스피 예제에서 확률변수는 주가(시작가, 최고가, 최저가, 종가)이고 관측은 일별(주 중 5일)로 관측된다. 주가는 연속형 확률변수이고 측정형이다. 시간적 측면에서는 시계열 데이터이다. 대학생 예제의 확률변수는 흡연여부, 일주일 공부시간이다. 흡연여부와 친구번호 개수는 이산형 확률변수, 공부시간은 연속형 확률변수이다.</p>
</section>
<section id="모집단-관심-정보" class="level5">
<h5 class="anchored" data-anchor-id="모집단-관심-정보">(2) 모집단 관심 정보</h5>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/확률표본.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%"></p>
</figure>
</div>
<p>모집단 관심 특성 확률변수의 모든 정보는 <span class="math inline">\(f(x;\theta)\)</span>, 확률분포함수와 모수로 요약된다. <span class="math inline">\(f(x)\)</span>에 대하여 모르는 상황은 다음 2가지 중 하나이다.</p>
<ol type="1">
<li><p>모집단 확률분포함수 <span class="math inline">\(f(x)\)</span>는 알려져 있지 않다.</p></li>
<li><p><span class="math inline">\(f(x)\)</span>의 형태는 모수 <span class="math inline">\(\theta\)</span>까지는 알려져 있다.</p></li>
</ol>
<p>일반적으로 <span class="math inline">\(f(x)\)</span>에 대한 관심이보다는 요약값인 <span class="math inline">\(\theta\)</span>에 관심을 가지므로 위의 (2) 상황에서 추론을 한다. (예) 가구소득은 로그정규분포를 따른다고 가정하고 평균과 표준편차에 대한 추론을 하게 된다.</p>
<p><strong>모집단 확률분포함수 <span class="math inline">\(f(x)\)</span></strong></p>
<p>모집단 확률변수에 대한 모든 정보는 확률분포함수를 얻으면 얻을 수 있다. 이산형 확률변수의 모집단 확률밀도함수는 베르누이 시행 가정 하에 구할 수 있지만 연속형 모집단 확률분포함수는 이론적으로 가정하거나 수집된 데이터(확률표본)로부터 얻을 수 있는데 이를 실증적 확률분포함수라 한다.</p>
<p><strong>모수 <span class="math inline">\(f(x;\theta)\)</span></strong></p>
<p>확률분포함수의 모든 개체의 관측값의 정보를 가지고 있으므로 모집단의 확률분포함수를 구할 수 있다면 모집단에 대한 원하는 정보를 얻을수 있다. 일반적으로 이산형 데이터 모집단에 대한 확률분포함수를 얻는 것은 가능하나 연속형인 경우에는 불가능하다. 그러므로 일반적으로 모집단 확률분포함수에 대하여는 가정하게 된다.</p>
<p>통계학은 모집단 개체 하나 하나의 정보에 관심을 갖기보다는 확률변수의 요약 특성(예를 들면 중앙위치, 흩어진 정도 등) 값에 관심을 갖는다. 이를 모수라 하고 <span class="math inline">\(\theta\)</span>라 표현한다.</p>
</section>
</section>
</section>
<section id="chapter-2.-확률표본-개념" class="level3">
<h3 class="anchored" data-anchor-id="chapter-2.-확률표본-개념">chapter 2. 확률표본 개념</h3>
<section id="확률표본-정의-및-활용" class="level4">
<h4 class="anchored" data-anchor-id="확률표본-정의-및-활용">1. 확률표본 정의 및 활용</h4>
<section id="확률표본-정의" class="level5">
<h5 class="anchored" data-anchor-id="확률표본-정의">(1) 확률표본 정의</h5>
<p>확률변수 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>이 다음 조건을 만족할 때, 이들을 모집단 <span class="math inline">\(f(x)\)</span>로부터의 크기 n인 확률표본 random sample 이라 한다.</p>
<ol type="1">
<li><p><span class="math inline">\(X_{1},\ldots,X_{n}\)</span>은 서로 독립이며</p></li>
<li><p>각각의 <span class="math inline">\(X_{i}\)</span>는 동일한 확률밀도함수 또는 확률질량함수를 갖는다.</p></li>
</ol>
<p>이러한 확률변수들을 우리는 독립이고 동일한 분포(iid: independent and identically distributed)를 따르는 변수들이라고 하고 다음과 같이 표기한다. <span class="math inline">\(X_{1},\ldots,X_{n} \sim \text{iid}f(x)\)</span></p>
<p>모집단의 확률함수 <span class="math inline">\(f(x)\)</span>가 어떤 모수 모형에 속한다고 가정할 수 있다면, 확률밀도함수는 <span class="math inline">\(f(x \mid \theta)\)</span>의 형태로 표현될 수 있다. 이 경우 결합 확률함수는 다음과 같다. 여기서 동일한 모수 <span class="math inline">\(\theta\)</span>가 모든 항에서 동일하게 사용된다.</p>
<p><span class="math display">\[f(x_{1},\ldots,x_{n} \mid \theta) = \overset{n}{\prod_{i = 1}}f(x_{i} \mid \theta)\]</span></p>
<p>통계적 분석에서는 모집단이 어떤 특정한 모수 모형에 속한다고 가정하되, 실제 모수 값 <span class="math inline">\(\theta\)</span>는 미지수로 취급한다. 이러한 상황에서 임의표본은 위와 같은 형태의 결합 확률함수를 가지며, <span class="math inline">\(\theta\)</span>는 모르는 상태로 남는다. 따라서 다양한 가능한 <span class="math inline">\(\theta\)</span> 값을 고려함으로써, 서로 다른 모집단들로부터 추출된 임의표본이 어떻게 행동할지를 연구할 수 있다.</p>
</section>
<section id="확률표본-활용" class="level5">
<h5 class="anchored" data-anchor-id="확률표본-활용">(2) 확률표본 활용</h5>
<p>통계학에서는 확률변수, 확률변수의 관측치를 데이터(열, 변수x행, 관측치)라 하고 데이터가 가진 모든 정보는 확률밀도함수 <span class="math inline">\(f(x;\theta)\)</span>에 의해 요약된다. 통계추론에서는 확률밀도함수를 요약하는 값을 모수(<span class="math inline">\(\theta\)</span>)라 하며 추론 관심 대상이 되는 값으로 모집단 평균, 분산, 비율 등이 대표적인 예이다. 확률밀도함수의 모수는 확률밀도함수의 형태를 결정한다.</p>
<p>예들 들어 이항분포의 모수는 실험 회수(<span class="math inline">\(n\)</span>)와 성공확률((<span class="math inline">\(p\)</span>)이고, 감마분포의 모수는 형태모수, <span class="math inline">\(\alpha\)</span>와 비율모수, <span class="math inline">\(\beta\)</span>이다. 모집단 모수는 <span class="math inline">\(\theta\)</span>로 표현되고 <span class="math inline">\(\theta\)</span> 값을 추정 estimation하거나 가설검정 hypothesis testing을 통계적 추론이라 하고 이를 위하여 모집단으로부터 확률표본(이를 데이터라 함)을 추출하게 된다.</p>
<p>확률표본으로부터 모수에 <span dir="rtl">”</span>가장” 적절한 값, 통계량(확률표본의 함수, <span class="math inline">\(T = T(X_{1},X_{2},\ldots,X_{n})\)</span>)을 계산하고 이를 이용하여 추론 을 하게 된다. 통계적 추론에서 모집단의 확률밀도함수를 <span class="math inline">\(f(x;\theta),p(x;\theta)\)</span>로 하여 모수 포함하여 표현한다.</p>
<p><span class="math inline">\(f(x),p(x)\)</span>의 형태는 알려져 있지 않다.</p>
<p>모수 <span class="math inline">\(\theta\)</span>는 고정된 값이나 모른다. 베이지안 추론에서는 모수 <span class="math inline">\(\theta\)</span>을 확률변수 하여 추론한다.</p>
<p>데이터_확률표본</p>
<p><span class="math display">\[(x_{1},x_{2},...,x_{n})\]</span></p>
<p>모집단</p>
<p><span class="math display">\[f(x;\theta)\]</span></p>
<p>통계량</p>
<p><span class="math display">\[\widehat{\theta} = h(x_{1},x_{2},...,x_{n})\]</span></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/모집단 통계량.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:60.0%"></p>
</figure>
</div>
</section>
<section id="확률표본-성질" class="level5">
<h5 class="anchored" data-anchor-id="확률표본-성질">(3) 확률표본 성질</h5>
<p>확률표본의 확률분포함수는 모집단 확률분포함수와 동일하다.</p>
<p>i-번째 관측치 <span class="math inline">\(x_{i}\)</span> 의 확률분포함수는 모집단의 확률분포 <span class="math inline">\(f(x;\theta)\)</span> 와 동일하고 다른 관측치와 서로 독립이다.</p>
<p><strong>확률표본 결합확률밀도함수 <span class="math inline">\(f(x_{1},x_{2},...,x_{n})\)</span></strong></p>
<p>확률표본이 갖는 정보인 확률분포함수는 다음과 같이 구해지며 이를 확률표본 결합밀도함수라 한다.</p>
<p><span class="math display">\[f(x_{1},x_{2},...,x_{n}) = (independent)f(x_{1})f(x_{2})...f(x_{n})\]</span></p>
<p><span class="math display">\[= (identical)f(x;\theta)f(x;\theta)...f(x;\theta) = \lbrack f(x;\theta)\rbrack^{n}\]</span></p>
<ul>
<li><p>모집단 확률분포함수 <span class="math inline">\(f(x)\)</span>를 알지 못하므로 결합확률밀도함수도 알수 없다.</p></li>
<li><p>확률표본 결합확률밀도함수가 추정해야 하는 모수를 포함하고 있는 경우 이를 우도함수 likelihood function 라 한다.</p></li>
</ul>
<p><strong>【예제 ①】</strong> 확률변수 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>이 평균이 <span class="math inline">\(\beta\)</span>인 지수분포로부터 추출된 크기 n의 확률표본이라고 하자. 결합확률밀도함수는 다음과 같다.</p>
<p><span class="math display">\[f(x_{1},\ldots,x_{n} \mid \beta) = \overset{n}{\prod_{i = 1}}f(x_{i} \mid \beta) = \overset{n}{\prod_{i = 1}}\frac{1}{\beta}e^{- x_{i}/\beta} = \frac{1}{\beta^{n}}e^{- (x_{1} + \cdots + x_{n})/\beta}\]</span></p>
<p>만약 모든 <span class="math inline">\(X_{i}\)</span>가 1 이상 값을 가질 확률은</p>
<p><span class="math display">\[P(X_{1} &gt; 1,\ldots,X_{n} &gt; 1) = \int_{1}^{\infty}\cdots\int_{1}^{\infty}\overset{n}{\prod_{i = 1}}\frac{1}{\beta}e^{- x_{i}/\beta}dx_{1}\cdots dx_{n}\]</span></p>
<p><span class="math display">\[= \left( \int_{1}^{\infty}\frac{1}{\beta}e^{- x/\beta}dx \right)^{n} = \left( e^{- 1/\beta} \right)^{n} = e^{- n/\beta}\]</span></p>
</section>
</section>
<section id="복원추출과-비복원추출" class="level4">
<h4 class="anchored" data-anchor-id="복원추출과-비복원추출">2. 복원추출과 비복원추출</h4>
<p><strong>무한 모집단</strong></p>
<p>앞에서 정의된 확률표본 모형은 때때로 무한 모집단으로부터의 표본추출로 간주된다. 예를 들어, <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>의 값을 순차적으로 얻는 과정을 생각해 보자. 먼저 실험을 수행하여 <span class="math inline">\(X_{1} = x_{1}\)</span>이 관측되고, 다음으로 실험을 반복하여 <span class="math inline">\(X_{2} = x_{2}\)</span>가 관측된다.</p>
<p>이때 무작위 표본추출에서의 독립성 가정은 <span class="math inline">\(X_{1} = x_{1}\)</span>이 먼저 관측되었더라도 <span class="math inline">\(X_{2}\)</span>의 확률분포에는 아무런 영향을 주지 않는다는 것을 의미한다. 다시 말해, <span class="math inline">\(x_{1}\)</span>을 무한 모집단에서 <span dir="rtl">”</span>제거”하더라도 모집단의 성질은 바뀌지 않기 때문에, <span class="math inline">\(X_{2} = x_{2}\)</span> 역시 여전히 동일한 모집단에서의 무작위 추출로 간주된다.</p>
<p><strong>유한모집단 복원추출</strong></p>
<p>반면, 유한 모집단으로부터 표본을 추출하는 경우에는 실제 자료가 어떻게 수집되었는지에 따라 달라진다. 모집단의 크기가 유한한 <span class="math inline">\(N\)</span>개일 때, 각 값이 동일한 확률 <span class="math inline">\(\frac{1}{N}\)</span>로 선택되는 방식으로 표본을 추출한다고 하자. 선택된 첫 번째 값은 <span class="math inline">\(X_{1} = x_{1}\)</span>로 기록된다. 그 다음 동일한 과정을 반복하여 <span class="math inline">\(X_{2} = x_{2}\)</span>를 선택한다. 만약 동일한 값이 다시 선택된다면 <span class="math inline">\(x_{1} = x_{2}\)</span>가 될 수도 있다. 이러한 표본추출 방식은 각 단계에서 선택된 값을 다시 모집단에 되돌려 놓는다는 의미에서 복원추출이라 부른다. 추출 선택 과정이 서로 영향을 미치지 않기 때문에<span class="math inline">\(X_{1},\ldots,X_{n}\)</span>은 상호 독립이다.</p>
<p><strong>유한모집단 비복원추출</strong></p>
<p>비복원추출은 한 번 선택된 값은 이후의 선택에서 제외되는 방식이다. 처음에는 모집단 <span class="math inline">\(\{ x_{1},\ldots,x_{N}\}\)</span>중 하나를 확률 <span class="math inline">\(\frac{1}{N}\)</span>로 선택하여 <span class="math inline">\(X_{1} = x_{1}\)</span> 로 기록한다. 그 다음 두 번째 값은 나머지 <span class="math inline">\(N - 1\)</span>개의 값 중에서 선택되며, 각 값은 <span class="math inline">\(1/(N - 1)\)</span>의 확률로 선택된다. 이런 방식으로 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>까지 계속 선택해나간다. 하지만 한 번 선택된 값은 다시 선택되지 않으므로 중복은 허용되지 않으므로 <span class="math inline">\(P(X_{2} = y \mid X_{1} = y) = 0\)</span> 상호 독립이 아니다.</p>
<p>하지만 흥미로운 점은, 이러한 경우에도 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>은 여전히 동일한 분포를 따른다. 즉, 각각의 주변분포는 같다.</p>
<p><span class="math inline">\(X_{1}\)</span>의 경우, <span class="math inline">\(P(X_{1} = x) = \frac{1}{N}\)</span>이다.</p>
<p><span class="math inline">\(X_{2}\)</span>의 주변확률분포: <span class="math inline">\(P(X_{2} = x) = \overset{N}{\sum_{i = 1}}P(X_{2} = x \mid X_{1} = x_{i}) \cdot P(X_{1} = x_{i})\)</span></p>
<p>이때 <span class="math inline">\(x_{i} = x\)</span>인 경우, <span class="math inline">\(P(X_{2} = x \mid X_{1} = x) = 0\)</span></p>
<p>나머지 <span class="math inline">\(j \neq k\)</span>일 때는 <span class="math inline">\(P(X_{2} = x \mid X_{1} = x_{j}) = \frac{1}{N - 1}\)</span>.</p>
<p><span class="math inline">\(P(X_{2} = x) = (N - 1)\left( \frac{1}{N - 1} \cdot \frac{1}{N} \right) = \frac{1}{N}\)</span> (동일분포)</p>
<p>다음 예제는 유한 모집단에서의 복잡한 정확 확률 계산을, 독립성이라는 가정 하에 단순한 곱셈식으로 근사할 수 있음을 보여주는 유용한 사례이다.</p>
<p><strong>【예제 ②】</strong> 유한 모집단 <span class="math inline">\(\{ 1,2,\ldots,1000\}\)</span>에서 표본을 추출한다고 하자. 이 모집단에서 크기 n = 10인 표본을 비복원 추출로 선택한다고 가정하고 <span class="math inline">\(P(X_{1} &gt; 200,\ldots,X_{10} &gt; 200)\)</span>을 구해보자.</p>
<p>(독립성 가정) <span class="math inline">\(\left( P(X &gt; 200) \right)^{10} = \left( \frac{800}{1000} \right)^{10} = 0.107374\)</span></p>
<p>(초기하분포) <span class="math inline">\(P(Y = 10) = \frac{\binom{800}{10} \cdot \binom{200}{0}}{\binom{1000}{10}} = 0.106164\)</span></p>
</section>
</section>
<section id="chapter-3.-확률표본의-함수" class="level3">
<h3 class="anchored" data-anchor-id="chapter-3.-확률표본의-함수">chapter 3. 확률표본의 함수</h3>
<p>확률표본 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>이 주어졌을 때, 일반적으로 이 값들에 대한 어떤 요약값을 계산하게 된다. <span class="math inline">\(T(x_{1},\ldots,x_{n})\)</span></p>
<p>여기서 함수 <span class="math inline">\(T\)</span>의 정의역은 확률벡터(<span class="math inline">\(X_{1},\ldots,X_{n}\)</span>)의 표본공간 전체를 포함한다. 함수 <span class="math inline">\(T\)</span>는 확률변수의 함수이므로 확률변수가 된다.</p>
<p>표본 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>이 독립이고 동일한 분포를 따른다는 구조적 단순성 덕분에, 이로부터 유도되는 확률변수 <span class="math inline">\(Y = T(X_{1},\ldots,X_{n})\)</span>의 분포는 비교적 다루기 쉬운 편이다. 이러한 분포는 일반적으로 표본 안의 변수들의 분포로부터 유도되므로, 이를 샘플링 sampling 분포라 부른다. 여기서는 확률변수의 합(<span class="math inline">\(Y = \sum X_{i}\)</span>) 형태로 정의되는 함수를 중심으로, 샘플링분포의 성질에 대해 논의할 것이다.</p>
<section id="통계량" class="level4">
<h4 class="anchored" data-anchor-id="통계량">1. 통계량</h4>
<p><strong>【정의】</strong> <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>이 어떤 모집단으로부터 크기 n인 임의표본이라고 하자. 또한 <span class="math inline">\(T(x_{1},\ldots,x_{n})\)</span>이 표본공간 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>을 정의역으로 갖는 실수값 또는 벡터값 함수라고 하자. <span class="math inline">\(Y = T(X_{1},\ldots,X_{n})\)</span>으로 정의되는 확률변수 또는 확률벡터 <span class="math inline">\(Y\)</span>를 통계량 statistic 이라 한다. 이 통계량 <span class="math inline">\(Y\)</span>의 확률분포를 샘플링 분포라 한다.</p>
<p>통계량의 정의는 매우 폭넓지만, 단 하나의 제한 조건은 통계량은 모수의 함수가 될 수 없다는 점이다. 즉, 통계량은 오직 표본 데이터만을 기반으로 정의되어야 한다.</p>
<p>확률표본인 데이터로부터 실제 값이 계산되면 소문자 <span class="math inline">\(t\)</span>로 표시하며 이를 모수 <span class="math inline">\(\theta \subseteq \Omega\)</span>에 대한 점 추정량 point estimator 으로 사용한다.</p>
<p>통계량을 추정에 사용하면 추정량 , 가설 검정에 사용하면 검정통계량 이라 한다.</p>
<p>확률표본의 함수인 통계량도 확률변수의 함수이므로 확률변수이다. 그러므로 확률분포함수를 갖게 되므로 이를 샘플링분포라 한다.</p>
<p><strong>확률변수의 선형함수의 평균과 분산</strong></p>
<p><span class="math inline">\((X_1, \ldots, X_n)\)</span> 이 어떤 확률실험에서 얻어진 확률벡터(random vector)라고 하자. 우리는 종종 <span class="math inline">\(T = T(X_1, \ldots, X_n)=\sum_{i=1}^{n} a_i X_i,\)</span> 과 같은 선형결합(linear combinations)에 관심을 갖는다.</p>
<p><strong>【정리】</strong> <span class="math inline">\(T = \sum_{i=1}^{n} a_i X_i\)</span> 라고 하자. 또한 모든 <span class="math inline">\(i = 1, \ldots, n에 대해 E[|X_i|] &lt; \infty\)</span> 라고 하자. 그러면, <span class="math inline">\(E(T) = \sum_{i=1}^{n} a_i E(X_i)\)</span>.</p>
<p><strong>【정리】</strong> <span class="math inline">\(T = \sum_{i=1}^{n} a_i X_i\)</span> 이고, <span class="math inline">\(W = \sum_{j=1}^{m} b_j Y_j\)</span> 라고 하자. 만약 모든 <span class="math inline">\(i = 1, \ldots, n\)</span> 에 대해 <span class="math inline">\(E[X_i^2] &lt; \infty\)</span>, 그리고 모든 <span class="math inline">\(j = 1, \ldots, m\)</span> 에 대해 <span class="math inline">\(E[Y_j^2] &lt; \infty\)</span> 라면,</p>
<p><span class="math inline">\(\operatorname{Cov}(T, W)
= \sum_{i=1}^{n} \sum_{j=1}^{m} a_i b_j \operatorname{Cov}(X_i, Y_j)\)</span>.</p>
<p><strong>【따름정리】</strong> <span class="math inline">\(T = \sum_{i=1}^{n} a_i X_i\)</span> 라고 하자. 또한 모든 <span class="math inline">\(i = 1, \ldots, n에 대해 E[X_i^2] &lt; \infty\)</span> 라고 하자. 그러면, <span class="math inline">\(\operatorname{Var}(T)
= \operatorname{Cov}(T, T)
= \sum_{i=1}^{n} a_i^{2}\,\operatorname{Var}(X_i)
\;+\; 2 \sum_{i&lt;j} a_i a_j\, \operatorname{Cov}(X_i, X_j)\)</span>.</p>
<p><strong>【따름정리】</strong> 만약 <span class="math inline">\(X_1, \ldots, X_n\)</span> 이 서로 독립이며 유한한 분산을 가진 확률변수들이라면, <span class="math inline">\(\operatorname{Var}(T)
= \sum_{i=1}^{n} a_i^{2}\, \operatorname{Var}(X_i)\)</span>.</p>
</section>
<section id="확률표본의-평균과-분산" class="level4">
<h4 class="anchored" data-anchor-id="확률표본의-평균과-분산">2. 확률표본의 평균과 분산</h4>
<p><strong>【정의】</strong> 확률표본 <span class="math inline">\(\left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>의 함수 <span class="math inline">\(\overset{¯}{X} = \frac{1}{n}\sum_{i}^{n}X_{i}\)</span>통계량을 표본평균이라 한다.</p>
<p><strong>【정의】</strong> 확률표본 <span class="math inline">\(\left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>의 함수 <span class="math inline">\(S^{2} = \frac{1}{n - 1}\sum_{i}^{n}\left( X_{i} - \overset{¯}{X} \right)^{2}\)</span>통계량을 표본분산이라 한다. <span class="math inline">\(\sum_{i}^{n}\left( x_{i} - \overset{¯}{x} \right)^{2} = \sum_{1}^{n}{x_{i}^{2} - n\overset{¯}{x}}\)</span></p>
<p><strong>【정리】</strong>표본분산을 최소화 하는 <span class="math inline">\(a = \overset{¯}{x}\)</span> 이다.</p>
<p><strong>【정리】</strong> 평균 <span class="math inline">\(\mu\)</span>, 분산 <span class="math inline">\(\sigma^{2}\)</span>인 모집단으로부터 확률표본 <span class="math inline">\(\left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>의 표본평균, 표본분산에 대하여 다음이 성립한다.</p>
<p><span class="math display">\[E\left( \overline{X} \right) = E\left( \frac{1}{n}\sum_{1}^{n}X_{i} \right) = \frac{1}{n}\sum_{i}^{n}{E\left( X_{i} \right) =}\frac{1}{n}\sum_{i}^{n}{\mu =}\mu\]</span></p>
<p><span class="math display">\[V\left( \overline{X} \right) = V\left( \frac{1}{n}\sum x_{i} \right) = (ind)\frac{1}{n^{2}}\sum V\left( X_{i} \right) = \frac{1}{n^{2}}\sum\sigma^{2} = \frac{\sigma^{2}}{n}\]</span></p>
<p><span class="math display">\[ES^{2} = \mathbb{E}\left( \frac{1}{n - 1}\left\lbrack \overset{n}{\sum_{i = 1}}X_{i}^{2} - n{\overline{X}}^{2} \right\rbrack \right) = \frac{1}{n - 1}\left( n\mathbb{E}\lbrack X_{1}^{2}\rbrack - n\mathbb{E}\lbrack{\overline{X}}^{2}\rbrack \right)\]</span></p>
<p><span class="math display">\[ES^{2} = \frac{1}{n - 1}\left( n(\sigma^{2} + \mu^{2}) - n\left( \frac{\sigma^{2}}{n} + \mu^{2} \right) \right) = \sigma^{2}\]</span></p>
<p>표본분산은 모집단 분산의 불편 추정량이다.</p>
</section>
<section id="샘플링-분포" class="level4">
<h4 class="anchored" data-anchor-id="샘플링-분포">3. 샘플링 분포</h4>
<p>확률표본 함수인 통계량 <span class="math inline">\(T = T\left( X_{1},X_{2},\ldots,X_{n} \right)\)</span>확률밀도함수를 샘플링 분포라 한다.</p>
<p>통계량을 활용하여 가설검정하거나 신뢰구간 추정을 하려면 통계량의 확률분포함수를 알아야 한다. 통계량의 확률분포함수 <span class="math inline">\(f(x)\)</span>의 샘플링 확률분포함수라 한다.</p>
<p>모집단의 확률분포=표본확률분포이나 샘플링 확률분포함수는 상이하다. 모집단의 확률분포함수는 몰라도 샘플링 확률분포함수는 알 수 있어, 이를 이용하여 추정과 검정을 한다.</p>
<p>(중심극한정리) 모집단의 확률분포함수와 무관하게 표본평균, 표본합의 확률분포함수는 정규분포에 근사한다.</p>
<p><strong>【정리】</strong> 확률표본 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>이 모멘트생성함수 <span class="math inline">\(M_{X}(t)\)</span>를 갖는 모집단으로부터 추출되었다고 하자. 그렇다면, 표본평균 <span class="math inline">\(\overline{X} = \frac{1}{n}\overset{n}{\sum_{i = 1}}X_{i}\)</span>의 모멘트생성함수는 <span class="math inline">\(M_{\overline{X}}(t) = \left\lbrack M_{X}\left( \frac{t}{n} \right) \right\rbrack^{n}\)</span>이다.</p>
<p><strong>【예제 ①】</strong> 확률표본 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>이 <span class="math inline">\(\mathcal{N}(\mu,\sigma^{2})\)</span> 분포를 따르는 모집단으로부터 추출되었다고 하자. 이때, 표본평균 <span class="math inline">\(\overline{X}\)</span>의 모멘트생성함수는 다음과 같다.</p>
<p><span class="math display">\[M_{\overline{X}}(t) = \left\lbrack \exp\left( \mu \cdot \frac{t}{n} + \frac{\sigma^{2}(t/n)^{2}}{2} \right) \right\rbrack^{n} = \exp\left( n\left( \mu \cdot \frac{t}{n} + \frac{\sigma^{2}(t/n)^{2}}{2} \right) \right) = \exp\left( \mu t + \frac{\sigma^{2}}{2n}t^{2} \right)\]</span></p>
<p>이로부터, <span class="math inline">\(\overline{X} \sim \mathcal{N}\left( \mu,\frac{\sigma^{2}}{n} \right)\)</span>.</p>
<p><strong>【예제 ②】</strong> 확률표본 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>이 감마분포 <span class="math inline">\(\text{Gamma}(\alpha,\beta)\)</span>를 따른다고 하자. 표본평균 <span class="math inline">\(\overline{X}\)</span>의 모멘트생성함수는 다음과 같으므로 표본평균의 샘플링분포는 <span class="math inline">\(\overline{X} \sim \text{Gamma}(n\alpha,\beta/n)\)</span> 또한 감마분포이다.</p>
<p><span class="math display">\[M_{\overline{X}}(t) = \left\lbrack \left( \frac{1}{1 - \beta(t/n)} \right)^{\alpha} \right\rbrack^{n} = \left( \frac{1}{1 - (\beta/n)t} \right)^{n\alpha}\]</span></p>
<p><strong>【정리】</strong> 만약 <span class="math inline">\((X,Y)\)</span>가 서로 독립이며 연속형 확률변수이고, 각각의 확률밀도함수가 <span class="math inline">\(f_{X}(x),f_{Y}(y)\)</span>라고 하자. 그러면 이들의 합 <span class="math inline">\(Z = X + Y\)</span>의 확률밀도함수는 다음과 같은 컨볼루션 convolution으로 주어진다. <span class="math inline">\(f_{Z}(z) = \int_{- \infty}^{\infty}f_{X}(w)f_{Y}(z - w)dw\)</span></p>
<p><strong>【예제 ③】</strong> 독립인 코쉬 확률변수 <span class="math inline">\(U \sim \text{Cauchy}(0,\sigma),V \sim \text{Cauchy}(0,\tau)\)</span>가 있을 때 <span class="math inline">\(U + V\)</span>의 확률밀도함수는 <span class="math inline">\(\text{Cauchy}(0,\sigma + \tau)\)</span>이다.</p>
<p><span class="math display">\[f_{U}(u) = \frac{1}{\pi\sigma} \cdot \frac{1}{1 + (u/\sigma)^{2}},f_{V}(v) = \frac{1}{\pi\tau} \cdot \frac{1}{1 + (v/\tau)^{2}}, - \infty &lt; u,v &lt; \infty\]</span></p>
<p><span class="math display">\[f_{Z}(z) = \int_{- \infty}^{\infty}\frac{1}{\pi\sigma} \cdot \frac{1}{1 + (w/\sigma)^{2}} \cdot \frac{1}{\pi\tau} \cdot \frac{1}{1 + \left( \frac{z - w}{\tau} \right)^{2}}dw\]</span></p>
<p><span class="math display">\[f_{Z}(z) = \frac{1}{\pi(\sigma + \tau)} \cdot \frac{1}{1 + \left( \frac{z}{\sigma + \tau} \right)^{2}}, - \infty &lt; z &lt; \infty\]</span></p>
<p>위치-척도 분포 <span class="math inline">\(X_{i} \sim \frac{1}{\sigma}f\left( \frac{x - \mu}{\sigma} \right)\)</span> 가족으로부터 추출된 확률표본 합의 샘플링 분포는 동일 확률밀도함수를 가지며 위치 파라미터는 유지되고, 척도 파라미터는 단순히 더해진다. 코쉬분포의 합, 정규분포의 합, 감바분포의 합이 대표적인 예이다.</p>
<p><strong>【정리】</strong> 확률표본 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>가 다음의 지수족 모집단에서 추출되었다고 하자. <span class="math inline">\(f(x \mid \theta) = h(x)c(\theta)\exp\left( \overset{k}{\sum_{i = 1}}w_{i}(\theta)t_{i}(x) \right)\)</span>, 이때, 통계량 <span class="math inline">\(T_{1},\ldots,T_{k}\)</span>를 <span class="math inline">\(T_{i}(X_{1},\ldots,X_{n}) = \overset{n}{\sum_{j = 1}}t_{i}(X_{j}),i = 1,\ldots,k\)</span>와 같이 정의한다면, 이 통계량들의 결합분포는 다음과 같은 형태의 지수족이 된다.<span class="math inline">\(f_{T}(u_{1},\ldots,u_{k} \mid \theta) = H(u_{1},\ldots,u_{k})\lbrack c(\theta)\rbrack^{n}\exp\left( \overset{k}{\sum_{i = 1}}w_{i}(\theta)u_{i} \right)\)</span></p>
<p>이 정리는, 지수족으로부터 추출된 표본의 충분통계량 역시 지수족의 형태를 갖는 분포를 따른다는 중요한 결과를 제시한다.</p>
<p>【예제 ④】 확률표본 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>이 <span class="math inline">\(Bernoulli(p)\)</span>분포에서 추출되었다고 하자. <span class="math inline">\(T_{1}(X_{1},\ldots,X_{n}) = \overset{n}{\sum_{i = 1}}X_{i}\)</span>는 충분통계량이다.<span class="math inline">\(k = 1,c(p) = 1 - p,w_{1}(p) = \log\left( \frac{p}{1 - p} \right),t_{1}(x) = x\)</span></p>
</section>
</section>
<section id="chapter-4.-정규분포로부터의-확률표본" class="level3">
<h3 class="anchored" data-anchor-id="chapter-4.-정규분포로부터의-확률표본">chapter 4. 정규분포로부터의 확률표본</h3>
<p>정규분포를 따르는 모집단은 여전히 가장 널리 사용되는 통계 모형 중 하나이며, 이로부터 표본을 추출하면 표본 통계량의 유용한 성질뿐 아니라, 잘 알려진 여러 셈플링 분포도 함께 유도된다. 통계 모형에 대한 추론은 정규분포를 가정하여 발전한 것과 무관하지 않다.</p>
<section id="표본평균과-표본분산의-샘플링-분포" class="level4">
<h4 class="anchored" data-anchor-id="표본평균과-표본분산의-샘플링-분포">1. 표본평균과 표본분산의 샘플링 분포</h4>
<p><strong>【정리】</strong> 확률표본 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>이 <span class="math inline">\(\mathcal{N}(\mu,\sigma^{2})\)</span>분포에서 추출되었다고 하자. 표본평균 <span class="math inline">\(\overline{X} = \frac{1}{n}\overset{n}{\sum_{i = 1}}X_{i}\)</span>, 표본분산 <span class="math inline">\(S^{2} = \frac{1}{n - 1}\overset{n}{\sum_{i = 1}}(X_{i} - \overline{X})^{2}\)</span>에 대하여 다음이 성립한다.</p>
<ol type="1">
<li><p><span class="math inline">\(\overline{X}\)</span>와 <span class="math inline">\(S^{2}\)</span>는 서로 독립인 확률변수이다.</p></li>
<li><p><span class="math inline">\(\overline{X} \sim \mathcal{N}(\mu,\sigma^{2}/n)\)</span></p></li>
<li><p><span class="math inline">\((n - 1)S^{2}/\sigma^{2} \sim \chi^{2}(n - 1)\)</span></p></li>
</ol>
</section>
<section id="카이제곱-확률변수에-대한-성질" class="level4">
<h4 class="anchored" data-anchor-id="카이제곱-확률변수에-대한-성질">2. 카이제곱 확률변수에 대한 성질</h4>
<p><strong>【보조정리】</strong></p>
<ol type="1">
<li><p>만약 <span class="math inline">\(Z\)</span>가 표준정규분포 <span class="math inline">\(\mathcal{N}(0,1)\)</span>를 따른다면, <span class="math inline">\(Z^{2}\)</span>는 자유도 1인 카이제곱 분포를 따른다. <span class="math inline">\(Z^{2} \sim \chi_{1}^{2}\)</span></p></li>
<li><p>독립인 카이제곱 확률변수 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>가 각각 자유도 <span class="math inline">\(p_{1},\ldots,p_{n}\)</span>을 갖는다고 하자. 확률표본의 합은 <span class="math inline">\(X_{1} + \cdots + X_{n} \sim \chi_{p_{1} + \cdots + p_{n}}^{2}\)</span>을 따른다.</p></li>
</ol>
</section>
<section id="정규-변수들의-선형결합-간의-독립성-판별" class="level4">
<h4 class="anchored" data-anchor-id="정규-변수들의-선형결합-간의-독립성-판별">3. 정규 변수들의 선형결합 간의 독립성 판별</h4>
<p><strong>【보조정리】</strong> <span class="math inline">\(X_{j} \sim \mathcal{N}(\mu_{j},\sigma_{j}^{2}),j = 1,\ldots,n\)</span>이 서로 독립이라고 하자. 상수 <span class="math inline">\(a_{ij},b_{rj}\)</span>에 대해 <span class="math inline">\(i = 1,\ldots,k,r = 1,\ldots,m,j = 1,\ldots,n\)</span>, 단 <span class="math inline">\(k + m \leq n\)</span>이라 하자. 다음과 같이 선형결합을 정의한다.</p>
<p><span class="math inline">\(U_{i} = \overset{n}{\sum_{j = 1}}a_{ij}X_{j},i = 1,\ldots,k\)</span>, <span class="math inline">\(V_{r} = \overset{n}{\sum_{j = 1}}b_{rj}X_{j},r = 1,\ldots,m\)</span></p>
<ul>
<li>두 확률변수 <span class="math inline">\(U_{i}\)</span>와 <span class="math inline">\(V_{r}\)</span>는 독립일 필요충분조건은 공분산이 0일 때이다. <span class="math inline">\(U_{i}\bot V_{r} \Longleftrightarrow \text{Cov}(U_{i},V_{r}) = 0\)</span>. 공분산은 다음과 같이 계산된다. <span class="math inline">\(\text{Cov}(U_{i},V_{r}) = \overset{n}{\sum_{j = 1}}a_{ij}b_{rj}\sigma_{j}^{2}\)</span></li>
<li>벡터 <span class="math inline">\((U_{1},\ldots,U_{k})\)</span>와 <span class="math inline">\((V_{1},\ldots,V_{m})\)</span>이 상호 독립이기 위한 필요충분조건은 모든 <span class="math inline">\(i = 1,\ldots k,\)</span>와 <span class="math inline">\(r = 1,\ldots,m\)</span>에 대하여 <span class="math inline">\(U_{i}\bot V_{r}\)</span>이다. 즉, 각 쌍의 선형결합이 모두 독립일 때, 전체 벡터도 독립이다.</li>
</ul>
<ol type="1">
<li><p>표본평균 <span class="math inline">\(\overline{X}\)</span>와 표본분산 <span class="math inline">\(S^{2}\)</span>의 독립성 증명</p></li>
<li><p>분산분석(ANOVA)에서 독립성 증명: 집단 간 제곱합(SSB)과 집단 내 제곱합(SSW)이 독립임을 보일 때 유용하다. 즉, F-분포의 분자와 분모가 독립이라는 성질을 확인할 때 자주 등장한다.</p></li>
<li><p>회귀분석에서 잔차(residual)와 추정량의 독립성: 예측값과 오차항이 독립이라는 성질을 정규 가정하에서 보장할 때 사용된다.</p></li>
<li><p>고급 통계 이론 및 추정량의 분산 계산: 선형 추정량의 분산 공식을 도출하거나, 선형 회귀에서 BLUE(최선선형불편추정량) 조건을 분석할 때도 활용된다.</p></li>
<li><p>다변량 정규분포의 성질 분석: 독립성 조건을 갖는 여러 선형변환 결과들이 서로 독립이 되는지 판단할 때.</p></li>
</ol>
</section>
<section id="정규분포로부터-유도된-분포" class="level4">
<h4 class="anchored" data-anchor-id="정규분포로부터-유도된-분포">4. 정규분포로부터 유도된 분포</h4>
<section id="t-분포" class="level5">
<h5 class="anchored" data-anchor-id="t-분포">(1) t-분포</h5>
<p>위에서 유도한 분포들은, 정규성을 가정한 통계 분석의 출발점으로 매우 중요하다. 실제로, 대부분의 실제 통계 분석 상황에서는 모분산 <span class="math inline">\(\sigma^{2}\)</span>의 값을 알지 못한다. 따라서, 모평균 <span class="math inline">\(\mu\)</span>에 대한 추론을 위해 <span class="math inline">\(\overline{X}\)</span>의 변동성을 이해하려면 우선 <span class="math inline">\(\sigma^{2}\)</span>를 추정해야 한다. 이 주제는 1900년대 초, W. S. Gosset에 의해 처음으로 연구되었으며, 그는 Student라는 필명으로 논문을 발표하였다. Student의 업적은 오늘날 우리가 t 분포라 부르는 Student의 t 분포로 이어졌다.</p>
<p>정규분포 <span class="math inline">\(N(\mu,\sigma^{2})\)</span>로부터의 확률표본 평균 <span class="math inline">\(\overline{X}\)</span>에 대하여 다음이 성립한다. <span class="math inline">\(\frac{\overline{X} - \mu}{\frac{\sigma}{\sqrt{n}}} \sim N(0,1)\)</span>. 여기서 모집단 표준편차 <span class="math inline">\(\sigma\)</span> 값을 안다면 모평균 <span class="math inline">\(\mu\)</span>에 대한 추론이 가능하다. 그러나 만약 <span class="math inline">\(\sigma\)</span> 값을 모른다면 가정하에 t-분포가 유도되었다.</p>
<p><span class="math display">\[\frac{\overline{X} - \mu}{\frac{S}{\sqrt{n}}} = \frac{\left( \overline{X} - \mu \right)/(\sigma/\sqrt{n})}{\sqrt{S^{2}/\sigma^{2}}} = \frac{N(0,1)}{\sqrt{\chi_{n - 1}^{2}/(n - 1)}} \sim t(n - 1)\]</span></p>
</section>
<section id="f-분포" class="level5">
<h5 class="anchored" data-anchor-id="f-분포">(2) F-분포</h5>
<p>통계적 추론에서 우리는 종종 두 개 이상의 모집단을 비교해야 하는 상황에 놓이게 된다. 특히, 여러 집단 간 평균이 서로 동일한지 검정하고자 할 때, 단순히 두 집단만을 비교하는 t-검정만으로는 충분하지 않다. 예를 들어, 세 가지 종류의 약물이 혈압에 미치는 영향을 비교하고자 한다면, 각 약물 그룹의 평균 혈압을 비교해야 하고, 이를 위해 분산분석(ANOVA)이 사용된다.</p>
<p>F-분포는 영국의 통계학자 Ronald A. Fisher에 의해 도입되었다. 그는 1920년대 농업 실험을 설계하면서, 여러 가지 비료의 효과를 비교하는 문제에 직면하였고, 이를 해결하기 위해 집단 간 변동과 집단 내 변동의 비율을 비교하는 통계량이 필요했다. 이렇게 하여 F-검정과 분산분석 기법이 탄생하게 되었고, 그 기반이 되는 확률분포가 F-분포이다. 분산분석의 핵심은 전체 변동(총제곱합)을 집단 간 변동(처리 제곱합)과 집단 내 변동(오차 제곱합)으로 분해하고, 이들 제곱합을 자유도로 나눈 평균제곱(mean square)의 비율을 통해 유의성을 검정하는 데 있다. 이때 사용되는 검정통계량이 바로 F-분포를 따르는 통계량이다.</p>
<p><strong>【정의】</strong> 두 독립적인 정규 모집단에서 각각 다음과 같은 표본을 추출한다고 하자.</p>
<p><span class="math inline">\(X_{1},\ldots,X_{n} \sim \mathcal{N}(\mu_{X},\sigma_{X}^{2})\)</span>, <span class="math inline">\(Y_{1},\ldots,Y_{m} \sim \mathcal{N}(\mu_{Y},\sigma_{Y}^{2})\)</span></p>
<p>이때, 표본분산들 <span class="math inline">\(S_{X}^{2},S_{Y}^{2}\)</span>를 사용하여 다음과 같은 통계량을 정의한다.</p>
<p><span class="math inline">\(F = \frac{(S_{X}^{2}/\sigma_{X}^{2})}{(S_{Y}^{2}/\sigma_{Y}^{2})}\)</span>. 이때 이 <span class="math inline">\(F\)</span>는 자유도 <span class="math inline">\(n - 1\)</span>과 <span class="math inline">\(m - 1\)</span>을 갖는 Snedecor의 <span class="math inline">\(F\)</span>-분포를 따른다.</p>
<p><strong>【정리】</strong></p>
<ul>
<li><p>만약 <span class="math inline">\(X \sim F_{p,q}\)</span> 라면, 그 역수인 <span class="math inline">\(1/X \sim F_{q,p}\)</span>를 따른다.</p></li>
<li><p>만약 <span class="math inline">\(X \sim t_{q}\)</span>이면, <span class="math inline">\(X^{2} \sim F_{1,q}\)</span>이다.</p></li>
<li><p>만약 <span class="math inline">\(X \sim F_{p,q}\)</span>이면, <span class="math inline">\(\frac{(p/q)X}{1 + (p/q)X} \sim \text{Beta}\left( \frac{p}{2},\frac{q}{2} \right)\)</span>이다.</p></li>
</ul>
</section>
</section>
</section>
<section id="chapter-5.-순서통계량" class="level3">
<h3 class="anchored" data-anchor-id="chapter-5.-순서통계량">chapter 5. 순서통계량</h3>
<p>확률표본에서 가장 작거나 큰 값, 또는 중앙값과 같은 관측값들은 단순한 평균이나 분산 외에도 중요한 요약 정보를 제공할 수 있다. 예를 들어, 지난 50년간 기록된 최대 홍수 수위나 최저 기온은 향후 재난 예방과 대비에 유용한 기준이 될 수 있으며, 지난달 주택의 중위 가격은 생활비나 주거비용을 추정하는 데 실질적인 참고 자료가 된다.</p>
<p>평균과 중앙값은 서로 관련되어 있지만, 측정하는 특성과 해석의 관점에서는 분명한 차이가 있다. 이를 이해하기 위해 서울 아파트 가격을 예로 들어보자.</p>
<p>일부 부동산 정책 입안자들은 “서울 아파트의 평균 매매 가격이 14억 원이므로 현재의 금융 조건이나 세금 정책은 타당하다”고 주장한다. 그러나 많은 실수요자들은 “실제로는 절반 이상의 거래가 9억 원 이하에서 이뤄지고 있으며, 15억 원 이상의 고가 아파트는 강남권 등 특정 지역에만 집중되어 있다”고 말한다. 실제로 몇 채의 초고가 아파트만으로도 전체 평균 가격이 크게 상승할 수 있다.</p>
<p>이처럼 평균은 극단값(outliers)에 민감하게 반응하여 대표값으로서 왜곡될 수 있으며, 중앙값은 보다 전형적인 거래 수준을 반영해 실생활과 정책 판단에 더 유용한 지표가 될 수 있다.</p>
<section id="순서통계량-정의" class="level4">
<h4 class="anchored" data-anchor-id="순서통계량-정의">1. 순서통계량 정의</h4>
<p><strong>【정의】</strong> 이러한 값들은 모두 순서통계량 order statistics 이라 불리며, 자료의 크기 순서에 따라 결정되는 통계량이다. 모집단 <span class="math inline">\(f(x),x \in S = \left\{ x;a &lt; x &lt; b \right\}\)</span>으로부터의 확률표본 <span class="math inline">\((X_{1},X_{2},\ldots,X_{n})\)</span> 크기 순으로 정렬하고 <span class="math inline">\(X_{(1)} \leq X_{(2)} \leq \ldots \leq X_{(n)}\)</span> 이를 순서 통계량이라 한다.</p>
<ul>
<li><p>최소값 minimum value : <span class="math inline">\(X_{(1)} = \min_{i}{(x_{1},x_{2},\ldots,x_{n})}\)</span></p></li>
<li><p>최대값 maximum value : <span class="math inline">\(X_{(n)} = \max_{i}{(x_{1},x_{2},\ldots,x_{n})}\)</span></p></li>
<li><p>범위 range : <span class="math inline">\(R = X_{(n)} - X_{(1)}\)</span></p></li>
<li><p>중앙값 median : <span class="math inline">\(P(X \leq {\overset{˜}{x}}_{m}) = \frac{1}{2}\)</span>을 만족하는 <span class="math inline">\({\overset{˜}{x}}_{m}\)</span>이다.</p></li>
<li><p>표본 데이터 중앙값 : <span class="math inline">\(M = \{\begin{matrix}
X_{((n + 1)/2)} &amp; \text{if}n\text{is odd} \\
&amp; \\
\frac{1}{2}\left( X_{(n/2)} + X_{(n/2 + 1)} \right) &amp; \text{if}n\text{is even}
\end{matrix}\)</span></p></li>
</ul>
<p><strong>【정의】</strong> 백분위값 percentile은 주어진 값보다 작은 관측값의 비율을 나타내는 중요한 지표이다. 0과 1 사이의 어떤 수 <span class="math inline">\(p\)</span>에 대해, 샘플에서의 <span class="math inline">\((100p)\%\)</span>백분위는 전체 표본 중 약 <span class="math inline">\(np\)</span>개의 관측값이 그 값보다 작고, 약 <span class="math inline">\(n(1 - p)\)</span>개의 관측값이 그 값보다 큰 위치에 있는 값으로 정의된다. <span class="math inline">\(Q_{p} = F^{- 1}(p)\)</span></p>
<p>샘플에서의 <span class="math inline">\(100p\)</span>번째 백분위는 다음 관측값으로 정의된다.</p>
<p><span class="math inline">\(p\)</span>가 <span class="math inline">\(\frac{1}{2n} &lt; p &lt; 0.5\)</span> 범위: <span class="math inline">\(X_{(np)}\)</span></p>
<ul>
<li><span class="math inline">\(0.5 &lt; p &lt; 1 - \frac{1}{2n}\)</span> 범위 : <span class="math inline">\(X_{(n + 1 - n(1 - p))}\)</span></li>
</ul>
<p><strong>표본 백분위</strong></p>
<p>표본 데이터의 <span class="math inline">\(p\)</span>th백분위수는 <span class="math inline">\(k = (n + 1)p\)</span>가 정수이면 <span class="math inline">\(X_{(k)}\)</span>이나 실수인 경우에는 다음 방법으로 구한다. <span class="math inline">\((n + 1)p = k + r,0 &lt; r &lt; 1\)</span>, <span class="math inline">\(r\)</span>은 소수 부분으로 가중치로 사용된다. <span class="math inline">\(p\)</span>th백분위수 : <span class="math inline">\((1 - r)X_{(k)} + rX_{(k + 1)}\)</span></p>
</section>
<section id="순서-통계량-결합-주변-확률밀도함수" class="level4">
<h4 class="anchored" data-anchor-id="순서-통계량-결합-주변-확률밀도함수">2. 순서 통계량 결합, 주변 확률밀도함수</h4>
<p>순서통계량 <span class="math inline">\(X_{(1)},X_{(2)},\ldots,X_{(n)}\)</span>의 결합 확률밀도함수는 다음과 같다.</p>
<p><strong>【정리】</strong> <span class="math display">\[f_{X_{(1)},\ldots,X_{(n)}}(x_{1},\ldots,x_{n}) = \{\begin{matrix}
n! \cdot f_{X}(x_{1})\cdots f_{X}(x_{n}), &amp; \text{if} - \infty &lt; x_{1} &lt; \cdots &lt; x_{n} &lt; \infty \\
0, &amp; \text{otherwise}
\end{matrix}\]</span></p>
<p><strong>【정리】</strong> <span class="math inline">\(X_{(1)},\ldots,X_{(n)}\)</span>을 확률표본 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>의 순위통계량이라 하자. 이 확률표본은 누적분포함수<span class="math inline">\(F_{X}(x)\)</span>, 확률밀도함수 <span class="math inline">\(f_{X}(x)\)</span>를 갖는 연속 분포에서 추출된 것이다. 이때, <span class="math inline">\(X_{(j)}\)</span>의 확률밀도함수는 다음과 같다.</p>
<p><span class="math display">\[f_{X_{(j)}}(x) = \frac{n!}{(j - 1)!(n - j)!}f_{X}(x)\lbrack F_{X}(x)\rbrack^{j - 1}\lbrack 1 - F_{X}(x)\rbrack^{n - j}\]</span></p>
<ul>
<li><p>최대값 확률밀도함수 : <span class="math inline">\(f_{X_{(n)}}(x) = nF(x)^{n - 1}f(x)\)</span></p></li>
<li><p>최소값 확률밀도함수 : <span class="math inline">\(f_{X_{(1)}}(x) = n(1 - F{(x))}^{n - 1}f(x)\)</span></p></li>
</ul>
<p><span class="math inline">\(1 \leq i &lt; j \leq n\)</span>일 때, 순위통계량 <span class="math inline">\(X_{(i)},X_{(j)}\)</span>의 결합 확률밀도함수는 다음과 같다.</p>
<p><span class="math display">\[f_{X_{(i)},X_{(j)}}(u,v) = \frac{n!}{(i - 1)!(j - 1 - i)!(n - j)!}f_{X}(u)f_{X}(v)\lbrack F_{X}(u)\rbrack^{i - 1}\lbrack F_{X}(v) - F_{X}(u)\rbrack^{j - 1 - i}\lbrack 1 - F_{X}(v)\rbrack^{n - j}\]</span></p>
</section>
<section id="상자수염그림" class="level4">
<h4 class="anchored" data-anchor-id="상자수염그림">3. 상자수염그림</h4>
<p><strong>사분위 quartile</strong></p>
<p>표본 데이터의 <span class="math inline">\(p = 25,50,75\)</span>인 순서 통계량을 1사분위수 first quartile(<span class="math inline">\(Q_{1}\)</span>), 2사분위수 second quartile(<span class="math inline">\(Q_{2}\)</span>), 3사분위수 third quartile(<span class="math inline">\(Q_{13}\)</span>)이라 한다. 2사분위수를 중앙값 median이라 한다.</p>
<ul>
<li>사분위 범위 inter-quartile range : <span class="math inline">\({IQR = Q}_{3} - Q_{1}\)</span></li>
</ul>
<p><strong>상자 수염 그림 box whisker plot</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/상자수염그림.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:40.0%"></p>
</figure>
</div>
<ul>
<li><p>5개 요약 통계량 표현 : (최소값, 1사분위, 중앙값, 3사분위, 최대값)</p></li>
<li><p>하한 펜스 lower fence : <span class="math inline">\(Q_{1} - 1.5IQR\)</span></p></li>
<li><p>상한 펜스 upper fence : <span class="math inline">\(Q_{3} + 1.5IQR\)</span></p></li>
<li><p>상한, 하한 펜스를 벗어나는 값들을 이상치 outlier 라 한다. 1.5 대신 3을 사용하면 극심한 severe 이상치라 진단한다.</p></li>
</ul>
</section>
</section>
<section id="chapter-6.-수렴개념" class="level3">
<h3 class="anchored" data-anchor-id="chapter-6.-수렴개념">chapter 6. 수렴개념</h3>
<section id="확률수렴" class="level4">
<h4 class="anchored" data-anchor-id="확률수렴">1. 확률수렴</h4>
<p>표본크기가 무한대(이론적이고 가상적인 개념)로 접근하는 경우 표본 통계량의 변화에 대한 내용을 다룬다.</p>
<p><strong>【확률수렴】 </strong><span class="math inline">\(X_{n}\overset{P}{\rightarrow}X\)</span></p>
<p><span class="math inline">\(\{ X_{n}\}\)</span> 확률변수 시퀀스, <span class="math inline">\(X\)</span> 확률변수일 때 다음을 만족하면 <span class="math inline">\(X_{n}\)</span>은 <span class="math inline">\(X\)</span>에 확률 수렴한다고(<span class="math inline">\(X_{n}\)</span> convergence in probability) 정의한다.</p>
<p><span class="math inline">\(\lim_{n \rightarrow \infty}{P\left( \left| X_{n} - X \right| \geq \epsilon \right) = 0forall\epsilon &gt; 0}\)</span> ⬄</p>
<p><span class="math inline">\(\lim_{n \rightarrow \infty}{P\left( \left| X_{n} - X \right| &lt; \epsilon \right) = 1forall\epsilon &gt; 0}\)</span></p>
<p><strong>(WLLN weak law of large numbers)</strong> <span class="math inline">\(\{ X_{n}\}\)</span>은 평균 <span class="math inline">\(\mu\)</span>, 분산 <span class="math inline">\(\sigma^{2} &lt; \infty\)</span>을 갖는iid 확률변수 시퀀스라 하면 표본평균(<span class="math inline">\({\overset{¯}{X}}_{n}\)</span>)은 평균(<span class="math inline">\(\mu\)</span>)에 확률 수렴한다. <span class="math inline">\({\overset{¯}{X}}_{n}\overset{P}{\rightarrow}\mu\)</span></p>
<p><span class="math inline">\(E\left( {\overset{¯}{X}}_{n} \right) = \mu,V\left( {\overset{¯}{X}}_{n} \right) = \frac{\sigma^{2}}{n}\)</span>이므로 Chebyshev inequality 정리 <span class="math inline">\(P\left( |X - \mu| &gt; k\sigma \right) \leq \frac{1}{k^{2}}\)</span>에 의해 다음이 성립한다.</p>
<p><span class="math inline">\(P\left( \left| {\overset{¯}{X}}_{n} - \mu \right| \geq \epsilon \right) = P\left( \left| \overset{¯}{X_{n}} - \mu \right| \geq (\epsilon\sqrt{n}/\sigma)(\sigma/\sqrt{}n) \right) \leq \frac{\sigma^{2}}{n\epsilon^{2}} \rightarrow 0\)</span></p>
<p><strong>【정리】</strong> <span class="math inline">\(X_{1},X_{2},\ldots\)</span>이 확률변수 <span class="math inline">\(X\)</span>에 확률 수렴 하면 연속함수 <span class="math inline">\(g\)</span>에 대하여 <span class="math inline">\({g(X}_{1}),g(X_{2}),\ldots\)</span>은 <span class="math inline">\(g(X)\)</span>에 확률 수렴한다. <span class="math inline">\(X_{n}\overset{P}{\rightarrow}X\)</span> 이면 <span class="math inline">\({g(X}_{n})\overset{P}{\rightarrow}g(X)wheregiscontinuousfunction\)</span>.</p>
<p><strong>【정리】</strong> <span class="math inline">\(X_{n}\overset{P}{\rightarrow}X,Y_{n}\overset{P}{\rightarrow}Y\)</span> 이면 <span class="math inline">\({X_{n}Y}_{n}\overset{P}{\rightarrow}XY\)</span></p>
<p><strong>【정의】</strong> 확률분포함수 <span class="math inline">\(F(x;\theta)\)</span>를 갖는 모집단으로부터 확률표본 <span class="math inline">\(X_{1},X_{2},\ldots,X_{n}\)</span>의 통계량 <span class="math inline">\(T_{n} = t(x_{1},x_{2},\ldots,x_{n})\)</span>이 다음을 만족하면 모수 <span class="math inline">\(\theta\)</span>의 일치 추정량이라 한다.</p>
<p><span class="math inline">\(T_{n}\overset{P}{\rightarrow}\theta\)</span> ⬄ 표본평균은 모평균의 일치 추정량이다.</p>
<p>【예제 ①】 <span class="math inline">\(\{ X_{n}\}\)</span>은 평균 <span class="math inline">\(\mu\)</span>, 분산 <span class="math inline">\(\sigma^{2} &lt; \infty\)</span>을 갖는 확률표본 시퀀스라 하자. 표본분산 <span class="math inline">\(S_{n}^{2} = \frac{1}{n - 1}\sum_{i}^{n}{(X_{i} - {\overset{¯}{X}}_{n})}\)</span>은 모집단 분산 <span class="math inline">\(\sigma^{2}\)</span>의 일치 추정량 이다. <span class="math inline">\(S_{n}^{2}\overset{P}{\rightarrow}\sigma^{2}\)</span></p>
<p><span class="math inline">\(S_{n}^{2} = \frac{1}{n - 1}\sum_{i}^{n}{\left( X_{i} - {\overset{¯}{X}}_{n} \right)^{2} = \frac{n}{n - 1}(\frac{1}{n}\sum_{i}^{n}{X_{i}^{2} - {\overset{¯}{X}}_{n}^{2}})\overset{P}{\rightarrow}1\left( E\left( X^{2} \right) - \mu^{2} \right) = \sigma^{2}}\)</span> 표본분산은 모분산 일치 추정량 이다.</p>
</section>
<section id="거의-확실한-수렴-all-sure-convergence" class="level4">
<h4 class="anchored" data-anchor-id="거의-확실한-수렴-all-sure-convergence">2. 거의 확실한 수렴 ALL sure convergence</h4>
<p><strong>【정의】</strong> <span class="math inline">\(\{ X_{n}\}\)</span> 확률변수 시퀀스, <span class="math inline">\(X\)</span> 확률변수일 때 다음을 만족하면 <span class="math inline">\(X_{n}\)</span>은 <span class="math inline">\(X\)</span>에 거의 확실한 수렴을 한다고 정의한다. <span class="math inline">\(P\left( \underset{n \rightarrow \infty}{lim}\left| X_{n} - X \right| &lt; \epsilon \right) = 1forall\epsilon &gt; 0\)</span></p>
<p><strong>【정의】</strong> 평균 <span class="math inline">\(\mu\)</span>, 분산 <span class="math inline">\(\sigma^{2} &lt; \infty\)</span>을 갖는 확률표본 평균 <span class="math inline">\({\overset{¯}{X}}_{n}\)</span>은 평균에 거의 확실히 수렴한다. (강한 대수의 법칙)</p>
<p><span class="math inline">\(P\left( \underset{n \rightarrow \infty}{lim}\left| {\overset{¯}{X}}_{n} - \mu \right| &lt; \epsilon \right) = 1forall\epsilon &gt; 0\)</span></p>
</section>
<section id="분포-수렴-convergence-in-distribution" class="level4">
<h4 class="anchored" data-anchor-id="분포-수렴-convergence-in-distribution">3. 분포 수렴 convergence in distribution</h4>
<p><strong>【정의】</strong> <span class="math inline">\(\{ X_{n}\}\)</span> 확률변수 시퀀스, <span class="math inline">\(X\)</span> 확률변수이고 <span class="math inline">\(F_{X_{n}},F_{X}\)</span> 각각 <span class="math inline">\(X_{n},X\)</span> 확률분포함수일 때 다음을 만족하면 <span class="math inline">\(X_{n}\)</span>은 <span class="math inline">\(X\)</span>에 분포 수렴한다고 정의한다. <span class="math inline">\(X_{n}\overset{D}{\rightarrow}X\)</span></p>
<p><span class="math inline">\(\lim_{n \rightarrow \infty}{F_{X}}_{n}(x) = F_{X}(x)forallx \in C(F_{X})\)</span>.</p>
<p>확률변수 <span class="math inline">\(X\)</span>의 분포를 <span class="math inline">\(X_{n}\)</span>의 한계 limiting asymptotic 분포라 한다.</p>
<p><strong>【정리】</strong> <span class="math inline">\(X_{n}\)</span> 확률변수 시퀀스가 <span class="math inline">\(X\)</span> 확률변수에 확률 수렴하면 <span class="math inline">\(X_{n}\)</span>은 <span class="math inline">\(X\)</span>에 분포 수렴한다. <span class="math inline">\(ifX_{n}\overset{P}{\rightarrow}X,thenX_{n}\overset{D}{\rightarrow}X\)</span>.</p>
<p><strong>【예제】</strong> <span class="math inline">\(X_{1},X_{2},\ldots\)</span>은 <span class="math inline">\(U(0,1)\)</span>으로부터 확률표본이다. 최대값 <span class="math inline">\(X_{(n)}\)</span>의 극한 분포를 구하라.</p>
<p><span class="math inline">\(U(0,1)\)</span> 로부터 확률표본 이므로 <span class="math inline">\(n \rightarrow \infty\)</span>로 가면 <span class="math inline">\(X_{(n)}\)</span>은 1에 근사해야 한다.</p>
<p><span class="math display">\[P\left( \left| X_{(n)} - 1 \right| \geq \epsilon \right) = P\left( X_{(n)} \geq 1 + \epsilon \right) + P\left( X_{(n)} \leq 1 - \epsilon \right) = P\left( X_{(n)} \leq 1 - \epsilon \right)\]</span></p>
<p>확률표본 이므로 <span class="math inline">\(P\left( X_{(n)} \leq 1 - \epsilon \right) = \Pi_{i}^{n}P\left( X_{i} \leq 1 - \epsilon \right) = (1 - \epsilon)^{n}\)</span></p>
<p>만약 <span class="math inline">\(\epsilon = \frac{t}{n}\)</span>라 놓으면 <span class="math inline">\(P\left( X_{(n)} \leq 1 - \frac{t}{n} \right) = \left( 1 - \frac{t}{n} \right)^{n} \rightarrow e^{- t}\)</span> 이다.</p>
<p><span class="math inline">\(P\left( {n(1 - X}_{(n)}) \leq t \right) \rightarrow e^{- t}\)</span> 이므로 <span class="math inline">\({n(1 - X}_{(n)})\)</span> 극한 분포는 <span class="math inline">\(\beta = 1\)</span>인 지수분포이다.</p>
<p><strong>【극한 확률분포함수】</strong></p>
<p><span class="math inline">\(X_{n}\)</span> 의 확률밀도함수를 이용하여 극한 확률분포함수를 구하는 것은 쉽지 않아 누적 확률분포함수를 이용하는 것이 편리하다.</p>
<p><span class="math inline">\(X_{n}\)</span> 확률밀도함수를 <span class="math inline">\(p_{n}(x) = \left\{ \begin{array}{r}
1,x = 2 + \frac{1}{n} \\
0,otherwise
\end{array} \right.\ \)</span>이라 하자.</p>
<p>극한 확률밀도함수는 <span class="math inline">\(\lim_{n \rightarrow \infty}{p_{n}(x) = 0}forallx\)</span>, 즉 극한 확률밀도함수가 존재하지 않는다. <span class="math inline">\(X_{n}\)</span> 누적 확률분포함수는 <span class="math inline">\(F_{n}(x) = \left\{ \begin{array}{r}
0,x &lt; 2 + \frac{1}{n} \\
1,x \leq 2 + \frac{1}{n}
\end{array} \right.\ \)</span>이므로 극한 확률분포함수는 <span class="math inline">\(F(x) = \left\{ \begin{array}{r}
0,x &lt; 2 \\
1,x \leq 2
\end{array} \right.\ \)</span> 이다.</p>
<p><strong>【중심극한정리 central limit theorem】</strong></p>
<p><span class="math inline">\(X_{1},X_{2},\ldots\)</span>은 평균, 분산이 <span class="math inline">\(E\left( X_{i} \right) = \mu &lt; \infty,V\left( X_{i} \right) = \sigma^{2} &lt; \infty\)</span> 로부터 확률표본이다. <span class="math inline">\(\frac{\sqrt{n}({\overset{¯}{X}}_{n} - \mu)}{\sigma}\)</span>의 극한분포는 표준정규분포이다.</p>
<p><strong>【예제】</strong> <span class="math inline">\(X_{1},X_{2},\ldots\)</span>은 평균, 분산이 <span class="math inline">\(E\left( X_{i} \right) = p,V\left( X_{i} \right) = p(1 - p)\)</span>인 베르누이분포 로부터 확률표본이다. 표본비율 <span class="math inline">\(\overset{\hat{}}{p} = \frac{\sum x_{i}}{n}\)</span>의 극한 분포는 중심극한 정리에 의해 <span class="math inline">\(\frac{\sqrt{n}\left( \overset{\hat{}}{p} - p \right)}{p(1 - p)}\overset{D}{\rightarrow}N(0,1)\)</span> 이다.</p>
<p><strong>【예제】</strong> <span class="math inline">\(X_{1},X_{2},\ldots,X_{n}\)</span>은 <span class="math inline">\(NB(r,p)\)</span>의 확률표본이라 하면 <span class="math inline">\(E\left( X_{i} \right) = \frac{r(1 - p)}{p},V\left( X_{i} \right) = \frac{r(1 - p)}{p^{2}}\)</span> 이므로</p>
<p>중심극한정리에 의해 <span class="math inline">\(\frac{\sqrt{n}({\overset{¯}{X}}_{n} - r(1 - p)/p)}{\sqrt{r(1 - p)/p^{2}}}\)</span> 극한분포는 정규분포에 근사한다.</p>
<p><strong>【<span class="math inline">\(\Delta\)</span>-method theorem】</strong></p>
<p><span class="math inline">\(X_{n}\)</span> 시퀀스에 대하여 <span class="math inline">\(\sqrt{n}\left( X_{n} - \theta \right)\overset{D}{\rightarrow}N(0,\sigma^{2})\)</span> 이며 <span class="math inline">\(g(x)\)</span>가 미분 가능한 연속형 함수이면 <span class="math inline">\(g(X_{n})\)</span> 시퀀스에 대하여 <span class="math inline">\(\sqrt{n}\left( {g(X}_{n}) - g(\theta) \right)\overset{D}{\rightarrow}N(0,\sigma^{2}\left( g'(\theta) \right)^{2})\)</span>이 성립한다.</p>
<p>【예제】 <span class="math inline">\(X_{n}\)</span>은 평균, 분산이 <span class="math inline">\(E\left( X_{i} \right) = p,V\left( X_{i} \right) = p(1 - p)\)</span>인 베르누이분포로부터 확률표본이다.</p>
<p><span class="math inline">\(X_{n} = \overset{\hat{}}{p} = \frac{\sum x_{i}}{n}\)</span>이므로 <span class="math inline">\(\frac{\sqrt{n}\left( \overset{\hat{}}{p} - p \right)}{p(1 - p)}\overset{D}{\rightarrow}N(0,1)\)</span></p>
<p>오즈비 <span class="math inline">\(\frac{p}{1 - p}\)</span> 추정한다고 하자. <span class="math inline">\(X_{n} = \frac{\overset{\hat{}}{p}}{1 - \overset{\hat{}}{p}}\)</span>이고 <span class="math inline">\(g(p) = \frac{p}{1 - p}\)</span>이다. <span class="math inline">\({E(X}_{n}) = \frac{p}{1 - p}\)</span>, <span class="math inline">\(V\left( \frac{\overset{\hat{}}{p}}{1 - \overset{\hat{}}{p}} \right) \approx \left\lbrack g'(p) \right\rbrack^{2}V\left( \overset{\hat{}}{p} \right) = \left\lbrack \frac{1}{(1 - p)^{2}} \right\rbrack^{2}\frac{p(1 - p)}{n} = \frac{p}{n(1 - p)^{3}}\)</span></p>
<p><span class="math inline">\(\sqrt{n}\left( X_{n} = \frac{\overset{\hat{}}{p}}{1 - \overset{\hat{}}{p}} - g(p) \right)\overset{D}{\rightarrow}N(0,\frac{p}{n(1 - p)^{3}})\)</span>.</p>
</section>
</section>
<section id="chapter-7.-확률표본-생성-시뮬레이션" class="level3">
<h3 class="anchored" data-anchor-id="chapter-7.-확률표본-생성-시뮬레이션">chapter 7. 확률표본 생성 : 시뮬레이션</h3>
<p>확률변수의 특성을 설명하기 위한 다양한 방법들—변환, 분포, 적률 계산, 극한 정리를 다루었다.이러한 확률변수들은 실제 현상을 설명하고 모형화하는 데 사용되며, 이 변수들에 대한 관측값이 우리가 수집하는 데이터가 된다.</p>
<section id="개념" class="level4">
<h4 class="anchored" data-anchor-id="개념">1. 개념</h4>
<p><strong>정의</strong></p>
<p>관심 대상인 사회현상이나 자연현상에 대한 통찰력을 얻기 위한 시스템 모델링, 실체적 혹은 추상적인 시스템(프로세스)의 주요 특성을 정형화하여 임의 공간에서 모방 실현하는 것을 의미한다.</p>
<p><strong>필요성</strong></p>
<p>수학 모형의 해를 대수적 처리 불가능, 근사 해, 현실에서 실행이 불가능할 때, 새로운 정책 효과 측정, 우주 비행 시 발생 문제 예측, 효율성: 비용과 시간 측면, 모의 비행, 교통 신호 체계 변환, 콜 센터/은행 창구 적정 서비스 직원 수</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/시뮬레이션.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:60.0%"></p>
</figure>
</div>
<p><strong>난수생성과 시뮬레이션</strong></p>
<p>난수 생성과 시뮬레이션은 매우 밀접한 관계를 가지고 있다. 시뮬레이션을 수행할 때 현실 세계의 복잡한 현상을 모델링하고 예측하기 위해 무작위한 요소를 포함하는 것이 중요한데 이것이 바로 난수 생성이 시뮬레이션에 사용되는 주된 이유 중 하나이다.</p>
<ol type="1">
<li><p>불확실성 모델링: 현실 세계의 많은 요소들은 불확실성을 내포하고 있는데 이러한 불확실성을 모델링하기 위해 난수가 사용될 수 있다. 날씨 예보 시뮬레이션에서는 다양한 요인들에 따라 다른 결과가 발생할 수 있으며 이를 모델링하기 위해 난수를 사용할 수 있다.</p></li>
<li><p>테스트 및 검증: 복잡한 모델이나 알고리즘을 시뮬레이션하고 검증할 때, 난수는 다양한 상황을 시뮬레이션하는 데 사용될 수 있다. 자율 주행 자동차의 시뮬레이션에서는 다양한 운전 상황을 난수를 사용하여 시험할 수 있다.</p></li>
<li><p>결과의 변동성 도입: 난수를 사용하여 모델의 결과에 변동성을 도입할 수 있는데 재무 모델링에서는 주식 시장의 랜덤한 움직임을 모델링하기 위해 난수를 사용할 수 있다.</p></li>
<li><p>몬테카를로 시뮬레이션: 몬테카를로 시뮬레이션은 무작위 샘플링을 사용하여 복잡한 문제의 근사해를 찾는 데 사용하는데 시뮬레이션에서는 난수가 필수적으로 사용된다.</p></li>
</ol>
<p>난수 생성은 이러한 시뮬레이션 과정에서 중요한 요소입니다. 올바른 난수 생성은 시뮬레이션 결과의 정확성과 신뢰성을 보장하는 데 도움이 되므로 신뢰할 수 있는 난수 생성 알고리즘과 적절한 난수 분포 선택이 필요하다.</p>
<p><strong>시뮬레이션을 통한 근사 계산 (법칙을 활용한 검증)</strong></p>
<p>통계 추론은 우리는 모집단 분포 <span class="math inline">\(f(x|\theta)\)</span>로부터 확률변수 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>을 관측하고 그 분포의 특성을 이용하여 이 변수들의 행동을 설명하고자 한다. 여기서는 그와 반대로, 주어진 분포 <span class="math inline">\(f(x|\theta)\)</span>로부터 무작위 확률표본 <span class="math inline">\(X_{1},\ldots,X_{n}\)</span>을 생성하는 방법에 초점을 둔다.</p>
<p><strong>【예제】</strong> 전구 수명이 지수분포 <span class="math inline">\(\text{Exponential}(\lambda)\)</span>를 따르는다고 하자. 생산된 전구 <span class="math inline">\(c\)</span>개의 부품 중 적어도 <span class="math inline">\(t\)</span>개 이상이 <span class="math inline">\(h\)</span>시간 이상 작동할 확률을 구한다고 하자.</p>
<p><span class="math display">\[\begin{matrix}
p_{1} &amp; = P(\text{부품이}h\text{시간 이상 작동}) \\
&amp; = P(X \geq h \mid \lambda)
\end{matrix}\]</span></p>
<p><span class="math display">\[\begin{matrix}
p_{2} &amp; = P(\text{적어도}t\text{개 이상의 부품이}h\text{시간 이상 작동}) \\
&amp; = \overset{c}{\sum_{k = t}}\binom{c}{k}p_{1}^{k}(1 - p_{1})^{c - k}
\end{matrix}\]</span></p>
<p><span class="math inline">\(p_{1} = \int_{h}^{\infty}\frac{1}{\lambda}e^{- x/\lambda}dx = e^{- h/\lambda}\)</span>이 계산 가능하다면 <span class="math inline">\(p_{2}\)</span> 확률 계산도 용이하다.</p>
<p>위의 예제에서 <span class="math inline">\(p_{2}\)</span> 계산이 불가능한 경우 원하는 분포를 따르는 확률변수들을 시뮬레이션을 통해 생성한 후, 대수의 법칙을 이용하여 그 시뮬레이션의 타당성을 검증하는 것이다.</p>
<ul>
<li><p>어떤 확률 변수 <span class="math inline">\(X\)</span>에 대해 함수 <span class="math inline">\(h(Y)\)</span>의 기대값을 알고 싶은데,이론적으로 직접 계산하기 어렵다면</p></li>
<li><p>동일한 분포를 따르는 <span class="math inline">\(Y_{1},\ldots,Y_{n}\)</span> 을 컴퓨터로 많이 만들어서 (시뮬레이션)</p></li>
<li><p>이들의 평균 <span class="math inline">\(\frac{1}{n}\overset{n}{\sum_{i = 1}}h(Y_{i})\)</span>를 구하면, 이 평균은 <span class="math inline">\(E\lbrack h(Y)\rbrack\)</span>에 수렴한다는 것이다. 바로 이것이 대수의 법칙의 핵심입니다.</p></li>
</ul>
<p><span class="math inline">\(Y_{i},i = 1,\ldots,n\)</span>이 서로 독립이고 동일한 분포를 따른다고 가정하면(가정이 충족된다는 전제 하에) <span class="math inline">\(\frac{1}{n}\overset{n}{\sum_{i = 1}}h(Y_{i})\overset{P}{\rightarrow}E\lbrack h(Y)\)</span>이다.</p>
<p><strong>【예제】</strong> 확률 <span class="math inline">\(p_{2}\)</span>는 다음 절차를 통해 시뮬레이션으로 근사할 수 있다.</p>
<p><span class="math inline">\(j = 1,\ldots,n\)</span>에 대해 다음 단계를 수행한다.</p>
<ol type="1">
<li><p><span class="math inline">\(X_{1},\ldots,X_{c}\)</span>를 서로 독립적으로 생성하되, 각각은 지수분포 <span class="math inline">\(\text{Exponential}(\lambda)\)</span>를 따른다.</p></li>
<li><p><span class="math inline">\(X_{i}\)</span> 중에서 <span class="math inline">\(h\)</span>시간 이상 작동하는 부품이 <span class="math inline">\(t\)</span>개 이상이면<span class="math inline">\(Y_{j} = 1\)</span>, 그렇지 않으면 <span class="math inline">\(Y_{j} = 0\)</span>으로 설정한다.</p></li>
<li><p>이렇게 정의된 <span class="math inline">\(Y_{j}\)</span>는 베르누이분포 <span class="math inline">\(\text{Bernoulli}(p_{2})\)</span>를 따르고, 기대값은 <span class="math inline">\(\mathbb{E}\lbrack Y_{j}\rbrack = p_{2}\)</span>이므로 대수의 법칙에 따라 다음이 성립한다.</p></li>
</ol>
<p><span class="math display">\[\frac{1}{n}\overset{n}{\sum_{j = 1}}Y_{j}\overset{P}{\rightarrow}p_{2}\text{(as}n \rightarrow \infty)\]</span></p>
<p><strong>난수 생성 시작</strong></p>
<p>첫째, 필요한 확률변수를 어떻게 생성할 것인가에 대한 문제이고, 둘째, 그 생성값을 바탕으로 한 근사 결과가 타당한지를 확인하기 위해 대수의 법칙의 한 형태를 사용하는 것이다. 우리는 일단 어딘가에서 출발해야 하므로 독립적이고 동일한 분포(iid)를 따르는 균등분포 난수 <span class="math inline">\(U_{1},\ldots,U_{m}\)</span>를 생성할 수 있다고 가정한다.</p>
<p>이러한 균등분포 난수 생성 문제는 컴퓨터 과학자들에 의해 이미 성공적으로 다루어져 왔고 대부분의 통계 소프트웨어 패키지에 우수한 유사 pseudo 난수 생성 알고리즘이 포함되어 있다.</p>
<p>우리는 이미 균등분포 난수를 생성할 수 있다고 가정하고 있으므로 목표 확률변수를 직접 생성하는 것이 아니라, 균등난수를 원하는 분포로 변환 하는 것이다.</p>
</section>
<section id="난수생성-방법" class="level4">
<h4 class="anchored" data-anchor-id="난수생성-방법">2. 난수생성 방법</h4>
<section id="선형합동생성기" class="level5">
<h5 class="anchored" data-anchor-id="선형합동생성기">(1) 선형합동생성기</h5>
<p>연속형 일양분포를 생성하는 이론적인 방법은 기본적으로 균등하게 분포된 확률을 갖는 숫자를 생성하는 것이다. 예를 들어, [0, 1] 범위 내에서의 연속형 일양분포를 생성한다면, 0과 1 사이의 어떤 숫자든 균등하게 선택되어야 한다.</p>
<p>선형합동생성기는 재귀적 관계를 이용하여 난수를 생성한다.</p>
<p><span class="math display">\[X_{n} = (aX_{n - 1} + c)modm\]</span></p>
<ul>
<li><p><span class="math inline">\(X_{n - 1}\)</span> : 이전 값, <span class="math inline">\(X_{n}\)</span> : 새로운 값</p></li>
<li><p><span class="math inline">\(m\)</span> : 모듈러 연산에 사용되는 상수, 선형 합동 생성기는 주기적으로 난수를 반복한다. 하여, m은 주기의 길이를 결정하며 충분히 긴 주기를 가져야 하므로 큰 소수를 사용한다.</p></li>
<li><p><span class="math inline">\(a\)</span> : 곱셈 상수, 이 값은 주기의 길이와 난수의 분포에 영향을 줍니다. 보통은 m과 서로소인 값으로 선택하는 것이 좋습니다. 또한 m의 약수가 아닌 소수를 선택하는 것이 바람직하다.</p></li>
<li><p><span class="math inline">\(c\)</span> : 덧셈 상수, 덧셈 상수는 순환 주기를 변화시키는 역할을 합니다. 적절한 값은 일반적으로 작은 수로 선택되며, m과 서로소이면서 <span class="math inline">\((c - 1)\)</span>의 배수이어야 합니다.</p></li>
</ul>
</section>
<section id="역변환-방법" class="level5">
<h5 class="anchored" data-anchor-id="역변환-방법">(2) 역변환 방법</h5>
<p>이론적 확률분포함수 <span class="math inline">\(f(x)\)</span>의 누적확률밀도함수 <span class="math inline">\(F(x)\)</span>가 알려진 경우 사용하는 방법이다.</p>
<ol type="1">
<li><span class="math inline">\(F(x) = U(0,1)\)</span> : 누적확률밀도함수와 난수생성 일양균일분포 같다고 한다.</li>
<li><span class="math inline">\(x = F^{- 1}(u)\)</span> 선형합동생성기에 의하여 생성한 난수(<span class="math inline">\((0,1)\)</span> 균일분포)를 이용하여 <span class="math inline">\(x \sim f(x)\)</span>을 생성한다.</li>
</ol>
<p><strong>【예제】</strong> 지수분포(<span class="math inline">\(\beta\)</span>)을 따르는 확률변수를 생성하시오.</p>
<ol type="1">
<li><span class="math inline">\(X \sim exponential(\lambda)\)</span> 이므로 <span class="math inline">\(F_{X}(x) = \int_{0}^{x}{\frac{1}{\beta}e^{- \frac{x}{\beta}}dx = 1 - e^{- \frac{x}{\beta}}}\)</span></li>
<li><span class="math inline">\(U = 1 - e^{- x/\beta}\)</span> 변환을 하자. <span class="math inline">\(U\)</span>의 영역은 <span class="math inline">\(0 \leq U \leq 1\)</span>이고 <span class="math inline">\(X = - \beta ln(1 - U)\)</span></li>
<li><span class="math inline">\(F_{X}^{- 1}(U) = - \beta ln(1 - U)\)</span>는 지수분포 <span class="math inline">\((\beta)\)</span>을 갖는다.</li>
</ol>
<p><strong>【지수분포와 함수관계】</strong></p>
<p>카이제곱분포는 지수분포를 이용하여 생성한다.</p>
<p><span class="math inline">\(- 2ln(U) \sim \chi^{2}(df = 1)\)</span>을 따른다.</p>
</section>
<section id="convolution-방법" class="level5">
<h5 class="anchored" data-anchor-id="convolution-방법">(3) convolution 방법</h5>
<p>확률표본의 합(가법성)의 분포를 알 수 있을 때 사용한다.</p>
<ol type="1">
<li>지수분포의 합은 감마분포를 따른다.</li>
<li>감마분포(<span class="math inline">\(\alpha = 1,\beta = 2\)</span>) ⬄ 자유도 1인 카이제곱이고 자유도 1인 카이제곱은 표준정규분포(<span class="math inline">\(X\)</span>)를 따른다. <span class="math inline">\(\mu + \sigma X\)</span>는 평균이 <span class="math inline">\(\mu\)</span>, 표준편차 <span class="math inline">\(\sigma\)</span>인 정규분포를 따른다.</li>
</ol>
<p><strong>【예제】</strong> 형상모수 <span class="math inline">\(\alpha\)</span>, 척도모수 <span class="math inline">\(\beta\)</span>인 감마분포를 따르는 확률변수(데이터)를 생성하시오.</p>
<ol type="1">
<li><p>일양분포로부터 지수분포(<span class="math inline">\(\beta\)</span>)을 따르는 확률변수를 생성한다.</p></li>
<li><p>생성된 확률변수들의 <span class="math inline">\(\alpha\)</span>개 합을 구하면 이 확률변수가 감마분포를 따른다.</p></li>
</ol>
</section>
<section id="기각-채택방법" class="level5">
<h5 class="anchored" data-anchor-id="기각-채택방법">(4) 기각 채택방법</h5>
<p><strong>이산형인 경우</strong></p>
<p>이항분포(<span class="math inline">\(n = 3,p = 0.75\)</span>)을 따르는 확률변수를 생성하자.<span class="math inline">\(P(X = 0|X \sim B(3,0.75)) = 0.016,P(X = 1) = 0.141,P(X = 2) = P(X = 3) = 0.422\)</span><span class="math inline">\(U \sim U(0,1)\)</span>을 생성하고 <span class="math inline">\(X = \left\{ \begin{array}{r}
0,0 &lt; U \leq 0.016 \\
1,0.016 &lt; U \leq 0.156 \\
2,0.156 &lt; U \leq 0.578 \\
3,0.578 &lt; U \leq 1.
\end{array} \right.\ \)</span></p>
<p><strong>연속형인 경우</strong></p>
<p><span class="math inline">\(F(x)\)</span>을 구할 수 없는 경우 생성하기 쉬운 확률변수를 이용하여 사용하는 방법이다. 이 방법의 핵심은 상위 경계함수를 설정하는 것이다.</p>
<ol type="1">
<li><p>상위 경계함수(majorant functon) <span class="math inline">\(e(x)\)</span> : 확률변수 모든 영역 <span class="math inline">\(x\)</span>에 대하여 <span class="math inline">\(e(x) \geq f(x)\)</span> 만족하는 함수 <span class="math inline">\(e(x)\)</span>가 존재한다고 하자.</p></li>
<li><p>다음 조건을 만족하는 함수 <span class="math inline">\(e(x)\)</span>는 효율적이다. ① <span class="math inline">\(e(x)\)</span>와 <span class="math inline">\(f(x)\)</span>는 확률변수 <span class="math inline">\(X\)</span>의 영역에서 유사하다. ② 생성하기 쉬운 확률밀도함수 <span class="math inline">\(g(x)\)</span>에 대하여 <span class="math inline">\(e(x) = ag(x)\)</span>이다.</p></li>
<li><p><span class="math inline">\(ag(x)\)</span>을 생성하여 <span class="math inline">\(f(x)\)</span>보다 작으면 채택, 크면 기각하여 <span class="math inline">\(f(x)\)</span>을 따르는 확률변수를 생성하게 된다.</p></li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/기각채택 변수생성.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:60.0%"></p>
</figure>
</div>
<p><strong>【예제】</strong> 감마분포(<span class="math inline">\(\alpha,\beta\)</span>)을 생성하자.</p>
<p><span class="math display">\[f(x) = \frac{1}{\Gamma(\alpha)}x^{\alpha - 1}\beta^{- \alpha}e^{- x/\beta},0 &lt; x &lt; - \infty\]</span></p>
<ol type="1">
<li><p>지수분포를 베이스 분포로 하자. <span class="math inline">\(g(x) = \frac{1}{\beta}e^{- x/\beta}\)</span></p></li>
<li><p>상위 경계함수 <span class="math inline">\(e(x) = \frac{a}{\alpha}e^{- x/\alpha}\)</span>, <span class="math inline">\(a = \frac{\alpha^{\alpha}e^{1 - \alpha}}{\Gamma(\alpha)}\)</span>이면, <span class="math inline">\(e(x) \geq f(x)foreveryx\)</span> 만족한다.</p></li>
</ol>
<p><strong>【예제】</strong> 베타분포(<span class="math inline">\(\alpha = 2,\beta = 4\)</span>)을 생성하자.</p>
<p><span class="math display">\[f(x) = 20x(1 - x)^{3},0 &lt; x &lt; 1\]</span></p>
<ol type="1">
<li><p><span class="math inline">\(U(0,1)\)</span>을 베이스 분포로 하자. <span class="math inline">\(g(x) = 1,0 &lt; x &lt; 1\)</span></p></li>
<li><p><span class="math inline">\(\frac{f(x)}{g(x)} \leq a\)</span>을 만족하는 <span class="math inline">\(a\)</span>을 구하자. <span class="math inline">\(\frac{f(x)}{g(x)} = 20x(1 - x)^{3}\)</span>는 <span class="math inline">\(x = 1/4\)</span>에서 최대값을 가지므로 <span class="math inline">\(a = 20(1/4)(1 - 1/4)^{3} = 135/64\)</span></p></li>
<li><p>그러므로 <span class="math inline">\(\frac{f(x)}{ag(x)} = \frac{256}{27}x(1 - x)^{3}\)</span>이다.</p></li>
<li><p>균일분포를 따르는 <span class="math inline">\(U(0,1)_{1},U(0,1)_{2}\)</span>을 생성하고 만약 <span class="math inline">\(U_{2} \leq \frac{256}{27}U_{1}(1 - U_{1})^{3}\)</span>이면 <span class="math inline">\(X = U_{1}\)</span>을 채택한다.</p></li>
</ol>
<p><strong>【예제】</strong> 부품 수명이 지수분포(<span class="math inline">\(\beta\)</span>)을 따른다고 하자. 품질 관리자는 <span class="math inline">\(c\)</span>개의 부품 중 적어도 <span class="math inline">\(t\)</span>개가 <span class="math inline">\(h\)</span> 시간 이상일 확률을 구하고 싶다고 하자.</p>
<p>1개 부품 수명이 <span class="math inline">\(h\)</span> 이상일 확률 : <span class="math inline">\(p_{1} = P\left( X \geq h \middle| X \sim exponential(\beta) \right) = \int_{h}^{\infty}{\frac{1}{\beta}e^{- h/\beta}dx = e^{- h/\beta}}\)</span>【방법】 모수 <span class="math inline">\(\beta\)</span>인 지수분포 확률변수 <span class="math inline">\(X_{1},X_{2},\ldots,X_{c}\)</span> 데이터를 생성한다(역변환 방법).</p>
<p><span class="math inline">\(c\)</span>개 중 수명이 <span class="math inline">\(h\)</span> 이상인 부품 개수가 적어도 <span class="math inline">\(t\)</span>개 일 확률 :</p>
<p><span class="math display">\[p_{2} = \overset{c}{\sum_{k = t}}\binom{c}{k}p_{1}^{k}(1 - p_{1})^{c - k}\]</span></p>
<p>【계산】 만약 생성한 <span class="math inline">\(c\)</span> 개 데이터 중 <span class="math inline">\(h\)</span> 이상인 데이터가 적어도 <span class="math inline">\(t\)</span>개 이면 <span class="math inline">\(Y_{j} = 1\)</span> 그렇지 않으면 <span class="math inline">\(Y_{j} = 0\)</span>이라 놓는다. 이 과정을 무한 반복하여 <span class="math inline">\(Y_{j}\)</span>의 평균을 구하면 <span class="math inline">\(c\)</span>개의 부품 중 적어도 <span class="math inline">\(t\)</span>개가 <span class="math inline">\(h\)</span> 시간 이상일 확률이다.</p>
</section>
<section id="metropolis-algorithm" class="level5">
<h5 class="anchored" data-anchor-id="metropolis-algorithm">(5) Metropolis Algorithm</h5>
<p>목표 확률밀도함수가 두꺼운 꼬리를 가질 경우, 유한한 M 값을 갖는 후보 확률밀도함수를 찾는 것이 어려울 수 있다. 이러한 경우에는 수용/기각 알고리즘을 적용할 수 없으며, 대신 마코프 연쇄 몬테카를로 Markov Chain Monte Carlo 방법이라는 또 다른 범주의 기법을 사용하게 된다. 대표적인 특수 사례로는 깁스 샘플링(Gibbs Sampler) 과 메트로폴리스 알고리즘(Metropolis Algorithm)이 있다.</p>
<p>메트로폴리스 알고리즘 (Metropolis Algorithm)</p>
<p>확률변수 <span class="math inline">\(Y \sim f_{Y}(y),V \sim f_{V}(v)\)</span>라 하자. 이때 <span class="math inline">\(f_{Y}\)</span>와 <span class="math inline">\(f_{V}\)</span>는 공통 정의역을 가진다고 가정한다. <span class="math inline">\(Y \sim f_{Y}\)</span>를 생성하기 위한 절차는 다음과 같다.</p>
<ol type="1">
<li>초기화: <span class="math inline">\(V \sim f_{V}\)</span>에서 생성하고, <span class="math inline">\(Z_{0} = V\)</span>로 설정한다.</li>
<li>반복 <span class="math inline">\(fori = 1,2,\ldots\)</span> :</li>
</ol>
<p>다음을 생성한다: <span class="math inline">\(U_{i} \sim \text{Uniform}(0,1)\)</span>, <span class="math inline">\(V_{i} \sim f_{V}\)</span></p>
<p>그리고 다음을 계산한다:</p>
<p><span class="math inline">\(\rho_{i} = \min\left\{ \frac{f_{Y}(V_{i})}{f_{V}(V_{i})} \cdot \frac{f_{V}(Z_{i - 1})}{f_{Y}(Z_{i - 1})},1 \right\}\)</span></p>
<ol start="3" type="1">
<li>다음과 같이 <span class="math inline">\(Z_{i}\)</span>를 결정한다.</li>
</ol>
<p><span class="math inline">\(Z_{i} = \{\begin{matrix}
V_{i} &amp; \text{if}U_{i} \leq \rho_{i} \\
Z_{i - 1} &amp; \text{if}U_{i} &gt; \rho_{i}
\end{matrix}\)</span></p>
<ol start="4" type="1">
<li>반복이 충분히 커지면(<span class="math inline">\(i \rightarrow \infty\)</span>), <span class="math inline">\(Z_{i}\overset{d}{\rightarrow}Y\)</span>.</li>
</ol>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Metropolis Algorithm</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 목표 분포: 표준 정규분포</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> target_density(x):</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> norm.pdf(x, loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>)  <span class="co"># f_Y(x)</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Metropolis 알고리즘</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> metropolis(n_samples, proposal_std<span class="op">=</span><span class="fl">1.0</span>):</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    samples <span class="op">=</span> np.zeros(n_samples)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    current <span class="op">=</span> <span class="dv">0</span>  <span class="co"># 초기값</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_samples):</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>        proposal <span class="op">=</span> np.random.normal(current, proposal_std)  <span class="co"># f_V</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>        acceptance_ratio <span class="op">=</span> target_density(proposal) <span class="op">/</span> target_density(current)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>        rho <span class="op">=</span> <span class="bu">min</span>(<span class="dv">1</span>, acceptance_ratio)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> np.random.rand() <span class="op">&lt;</span> rho:</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>            samples[i] <span class="op">=</span> proposal</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>            current <span class="op">=</span> proposal</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>            samples[i] <span class="op">=</span> current</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> samples</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="co"># 샘플 생성</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">0</span>)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> metropolis(<span class="dv">10000</span>)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="co"># 결과 시각화</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">1000</span>)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>plt.hist(samples, bins<span class="op">=</span><span class="dv">50</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, label<span class="op">=</span><span class="st">'Metropolis samples'</span>)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>plt.plot(x, norm.pdf(x), <span class="st">'r--'</span>, label<span class="op">=</span><span class="st">'Target N(0,1)'</span>)</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Metropolis Algorithm: Sampling from N(0,1)"</span>)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/표준정규분포 생성.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:60.0%"></p>
</figure>
</div>
<p><strong>Gibbs Sampler 알고리즘</strong></p>
<p>결합분포 <span class="math inline">\(f(x,y)\)</span>에서 직접 샘플링하기 어려울 때, 조건부 분포 <span class="math inline">\(f(x|y),f(y|x)\)</span>를 통해 순차적으로 샘플을 생성하여 <span class="math inline">\((x,y) \sim f(x,y)\)</span>를 근사적으로 얻는다.</p>
<ol type="1">
<li>초기값 선택: <span class="math inline">\(x^{(0)},y^{(0)}\)</span>을 초기값으로 설정한다.</li>
<li>반복 <span class="math inline">\(fort = 1,2,\ldots,N\)</span>: <span class="math inline">\(\begin{matrix}
x^{(t)} &amp; \sim f(x \mid y^{(t - 1)}) \\
y^{(t)} &amp; \sim f(y \mid x^{(t)})
\end{matrix}\)</span></li>
</ol>
<p>즉, 이전 단계에서의 <span class="math inline">\(y\)</span>를 고정하고 <span class="math inline">\(x\)</span>를 샘플링한 다음, 새로 얻은 <span class="math inline">\(x\)</span>를 고정하고 <span class="math inline">\(y\)</span>를 샘플링한다.</p>
<ol start="3" type="1">
<li>충분히 반복하면, <span class="math inline">\((x^{(t)},y^{(t)})\overset{d}{\rightarrow}f(x,y)\)</span></li>
</ol>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Gibbs Sampler Algorithm</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 설정: 평균, 표준편차, 상관계수</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>mu_x, mu_y <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>sigma_x, sigma_y <span class="op">=</span> <span class="dv">1</span>, <span class="dv">1</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>rho <span class="op">=</span> <span class="fl">0.8</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 조건부 분포의 파라미터</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sample_y_given_x(x):</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> mu_y <span class="op">+</span> rho <span class="op">*</span> (sigma_y <span class="op">/</span> sigma_x) <span class="op">*</span> (x <span class="op">-</span> mu_x)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> np.sqrt(<span class="dv">1</span> <span class="op">-</span> rho<span class="op">**</span><span class="dv">2</span>) <span class="op">*</span> sigma_y</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.random.normal(mu, std)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sample_x_given_y(y):</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> mu_x <span class="op">+</span> rho <span class="op">*</span> (sigma_x <span class="op">/</span> sigma_y) <span class="op">*</span> (y <span class="op">-</span> mu_y)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> np.sqrt(<span class="dv">1</span> <span class="op">-</span> rho<span class="op">**</span><span class="dv">2</span>) <span class="op">*</span> sigma_x</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.random.normal(mu, std)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="co"># 깁스 샘플링</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>x_samples <span class="op">=</span> np.zeros(n_samples)</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>y_samples <span class="op">=</span> np.zeros(n_samples)</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>x, y <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span>  <span class="co"># 초기값</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_samples):</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> sample_x_given_y(y)</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> sample_y_given_x(x)</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>    x_samples[i] <span class="op">=</span> x</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>    y_samples[i] <span class="op">=</span> y</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a><span class="co"># 시각화</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>plt.plot(x_samples, y_samples, <span class="st">'o'</span>, alpha<span class="op">=</span><span class="fl">0.2</span>, markersize<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Gibbs Sampler: Bivariate Normal"</span>)</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"X"</span>)</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Y"</span>)</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">'equal'</span>)</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/이변량정규분포 생성.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:60.0%"></p>
</figure>
</div>
</section>
<section id="box-muller-algorithm" class="level5">
<h5 class="anchored" data-anchor-id="box-muller-algorithm">(6) BOX-Muller algorithm</h5>
<p><span class="math inline">\(U(0,1)\)</span>에서 서로 독립인 <span class="math inline">\(U_{1},U_{2}\)</span>을 생성하고 <span class="math inline">\(Z_{1},Z_{2}\)</span>을 다음과 같이 정의하면 서로 독립이고 <span class="math inline">\(N(0,1)\)</span>을 따른다.</p>
<p><span class="math inline">\(Z_{1} = \sqrt{- 2lnU_{1}}cos(2\pi U_{2})\)</span> <span class="math inline">\(Z_{2} = \sqrt{- 2lnU_{1}}sin(2\pi U_{2})\)</span></p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> box_muller_bivariate(n, mu, Sigma):</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 1: Generate standard normal samples using Box-Muller</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    u1 <span class="op">=</span> np.random.rand(n)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    u2 <span class="op">=</span> np.random.rand(n)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    z1 <span class="op">=</span> np.sqrt(<span class="op">-</span><span class="dv">2</span> <span class="op">*</span> np.log(u1)) <span class="op">*</span> np.cos(<span class="dv">2</span> <span class="op">*</span> np.pi <span class="op">*</span> u2)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    z2 <span class="op">=</span> np.sqrt(<span class="op">-</span><span class="dv">2</span> <span class="op">*</span> np.log(u1)) <span class="op">*</span> np.sin(<span class="dv">2</span> <span class="op">*</span> np.pi <span class="op">*</span> u2)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> np.vstack((z1, z2))  <span class="co"># Shape: (2, n)</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 2: Cholesky decomposition of Sigma</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    L <span class="op">=</span> np.linalg.cholesky(Sigma)  <span class="co"># Shape: (2, 2)</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 3: Transform standard normals to bivariate normal</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> (L <span class="op">@</span> Z).T <span class="op">+</span> mu  <span class="co"># Shape: (n, 2)</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameters</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>mu <span class="op">=</span> np.array([<span class="dv">3</span>, <span class="dv">5</span>])  <span class="co"># Mean vector</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>Sigma <span class="op">=</span> np.array([[<span class="dv">4</span>, <span class="dv">2</span>], [<span class="dv">2</span>, <span class="dv">3</span>]])  <span class="co"># Covariance matrix</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate samples</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> box_muller_bivariate(<span class="dv">5000</span>, mu, Sigma)</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">6</span>))</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>plt.scatter(samples[:,<span class="dv">0</span>], samples[:,<span class="dv">1</span>], s<span class="op">=</span><span class="dv">5</span>, alpha<span class="op">=</span><span class="fl">0.4</span>)</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Bivariate Normal Distribution via Box-Muller"</span>)</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"X"</span>)</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Y"</span>)</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">'equal'</span>)</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/박스뮬러 이변량 난수생성.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:60.0%"></p>
</figure>
</div>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "복사완료!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "복사완료!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© 2025 Kwon</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>Built with Quarto</p>
</div>
  </div>
</footer>




</body></html>