[
  {
    "objectID": "cardnews/index.html",
    "href": "cardnews/index.html",
    "title": "📰 카드뉴스 모음",
    "section": "",
    "text": "통계를 주제로 한 다양한 카드뉴스를 주제별로 모았습니다.\n클릭하면 자세한 내용을 보실 수 있어요 😊\n\n\n\n\n\n #### 고령화 속도 65세 이상 비율이 역대 최고!\n자세히 보기 ▶\n\n\n #### 출산율 감소 합계출산율 0.72명의 의미는?\n자세히 보기 ▶\n\n\n\n\n\n\n\n\n #### 청년 고용률 청년 고용의 구조적 문제\n자세히 보기 ▶\n\n\n #### 전공별 격차 전공 따라 취업률이 이렇게나!\n자세히 보기 ▶"
  },
  {
    "objectID": "cardnews/index.html#인구와-사회",
    "href": "cardnews/index.html#인구와-사회",
    "title": "📰 카드뉴스 모음",
    "section": "",
    "text": "#### 고령화 속도 65세 이상 비율이 역대 최고!\n자세히 보기 ▶\n\n\n #### 출산율 감소 합계출산율 0.72명의 의미는?\n자세히 보기 ▶"
  },
  {
    "objectID": "cardnews/index.html#청년과-고용",
    "href": "cardnews/index.html#청년과-고용",
    "title": "📰 카드뉴스 모음",
    "section": "",
    "text": "#### 청년 고용률 청년 고용의 구조적 문제\n자세히 보기 ▶\n\n\n #### 전공별 격차 전공 따라 취업률이 이렇게나!\n자세히 보기 ▶"
  },
  {
    "objectID": "cardnews/news001.html",
    "href": "cardnews/news001.html",
    "title": "고령화 속도",
    "section": "",
    "text": "👵 고령화 속도, 세계 최고\n\n\n\n고령화\n\n\n\n2024년 한국 65세 이상 인구: 18.4%\n고령사회(14%) 기준 이미 초과\n초고령사회(20%) 진입도 눈앞\n\n\n📌 정책은 얼마나 따라가고 있을까?"
  },
  {
    "objectID": "cardnews/news003.html",
    "href": "cardnews/news003.html",
    "title": "청년 고용률",
    "section": "",
    "text": "청년 고용률\n\n\n2023년 기준, 15~29세 청년 고용률은 45.4%\n코로나 이후 회복 중이지만 여전히 회복세는 느림.\n\n\n\n\n청년층 일자리 중 단기 계약직, 인턴 비중이 높음\n\n정규직 진입률은 10년 전보다 낮아진 상태\n\n\n🔍 “취업했다”는 통계 뒤에 숨은 고용의 질 문제를 들여다봐야 합니다.\n\n\n\n\n\n\n일자리 찾기 → 계약직 → 재취업 준비 → 불안정 반복\n이직까지 평균 1.5년 소요\n\n\n\n\n\n\n\nNote\n\n\n\n📌 통계청 자료 기준: 2023 경제활동인구조사 청년 부문\n\n\n\n\n\n\n\n청년 고용률 수치만 보는 게 아니라\n고용의 질, 지속성, 업종 다양성을 함께 살펴야 합니다."
  },
  {
    "objectID": "cardnews/news003.html#정규직-비중은-여전히-낮아",
    "href": "cardnews/news003.html#정규직-비중은-여전히-낮아",
    "title": "청년 고용률",
    "section": "",
    "text": "청년층 일자리 중 단기 계약직, 인턴 비중이 높음\n\n정규직 진입률은 10년 전보다 낮아진 상태\n\n\n🔍 “취업했다”는 통계 뒤에 숨은 고용의 질 문제를 들여다봐야 합니다."
  },
  {
    "objectID": "cardnews/news003.html#반복되는-패턴",
    "href": "cardnews/news003.html#반복되는-패턴",
    "title": "청년 고용률",
    "section": "",
    "text": "일자리 찾기 → 계약직 → 재취업 준비 → 불안정 반복\n이직까지 평균 1.5년 소요\n\n\n\n\n\n\n\nNote\n\n\n\n📌 통계청 자료 기준: 2023 경제활동인구조사 청년 부문"
  },
  {
    "objectID": "cardnews/news003.html#정책이-나아가야-할-방향은",
    "href": "cardnews/news003.html#정책이-나아가야-할-방향은",
    "title": "청년 고용률",
    "section": "",
    "text": "청년 고용률 수치만 보는 게 아니라\n고용의 질, 지속성, 업종 다양성을 함께 살펴야 합니다."
  },
  {
    "objectID": "notes/survey/delphi_ahp_conjoint.html",
    "href": "notes/survey/delphi_ahp_conjoint.html",
    "title": "조사방법론. 7. 델파이, AHP, 컨조인트분석",
    "section": "",
    "text": "chapter 1. 델파이 조사\n\n1. 개념\n델파이 방법(Delphi Method)은 의사결정과 미래 예측을 위해 전문가의 의견을 체계적이고 신뢰할 수 있는 방식으로 수렴하는 방법이다. 이 방법은 다양한 분야에 걸쳐 활용되며, 특히 불확실한 미래 상황을 전망하는 데 있어 중요한 도구로 자리 잡고 있다. 델파이 방법은 전문가들의 의견을 익명으로 수집하고, 반복적인 피드백 과정을 거쳐 점진적으로 의견의 합의를 도출하는 방식으로 이루어진다.\n델파이 방법은 1948년 미국 RAND 연구소에서 처음 개발되었다. 제2차 세계대전 이후 급변하는 기술 환경과 군사 전략 수립의 필요성에 대응하기 위해, 미래의 전쟁 양상과 기술 발전 방향을 예측할 목적으로 고안된 것이다. 초기에는 핵전쟁 가능성, 무기 체계 개발, 군사 전략 등의 국방 관련 주제가 주로 다루어졌지만, 1960년대 이후에는 정보기술, 연구개발(R&D), 교육, 사회과학 등 다양한 분야로 적용 영역이 확대되었다.\n델파이 방법은 종종 브레인스토밍 회의나 일반 설문 조사와 혼동되지만, 이들과는 중요한 차이를 지닌다. 브레인스토밍은 참가자 간의 자유로운 의견 개진을 장점으로 하지만, 발언권이 강한 소수의 의견에 전체 논의가 왜곡될 위험이 존재한다. 반면, 델파이 방법은 응답자의 익명성을 보장함으로써 이러한 영향을 최소화하고, 개별 전문가의 독립적인 판단을 유지한 채 집단적인 통찰을 이끌어낸다.\n일반 설문 조사와도 구별된다. 설문 조사는 대체로 현재 상황이나 개인의 만족도를 파악하는 데 초점이 맞춰져 있다. 이에 반해, 델파이 방법은 전문가의 미래 예측 능력을 활용하여 향후 변화 가능성과 대응 방안을 도출하는 데 중점을 둔다. 예를 들어, 단순히 “현재 서비스에 대한 만족도”를 묻는 질문은 델파이 방식에 부적절하다. 대신, “향후 10년 내 이 산업에서 핵심적인 변화 요인은 무엇인가?”와 같은 전망 중심의 질문이 보다 적합하다.\n결국 델파이 방법은 단순한 의견 수렴이나 자료 조사 이상의 성격을 가진다. 반복적이고 구조화된 피드백 과정을 통해 전문가들의 견해를 정제하고, 특정 개인의 영향력에서 벗어난 객관적 합의를 도출함으로써 미래를 예측하는 데 효과적인 수단이 된다. 이는 브레인스토밍이나 일반 설문과는 본질적으로 다른 방식이며, 특히 전략 수립과 정책 기획, 기술 예측 등 고차원의 의사결정 상황에서 그 진가를 발휘한다.\n\n\n2. 델파이 방법의 핵심 개념\n전문가 의견 탐색 및 수렴\n델파이 방법은 특정 주제에 대해 전문가들의 의견을 체계적으로 탐색하고 반복적으로 수렴하는 과정을 통해 최적의 결론을 도출하는 기법이다. 이 과정은 단순히 여러 사람의 의견을 모으는 것이 아니라, 각 전문가의 독립적인 판단을 익명으로 수집하고, 피드백을 제공하며, 반복적으로 의견을 조정해 나가는 구조를 가진다.\n이 방법은 “다수의 전문가 의견이 단일 전문가보다 더 신뢰할 수 있다”는 가정에 기반하고 있으며, 특히 개별 의견 간의 편향이나 극단적 견해를 완화하고 집단 지성을 활용함으로써 보다 객관적이고 실현 가능성 높은 결론을 도출하는 데 유리하다. 따라서 델파이 방법은 정답이 명확하지 않거나 예측이 어려운 문제 상황에서 합리적 집단 합의에 도달하는 데 매우 효과적인 도구로 활용된다.\n설문지를 통한 의견 수렴\n델파이 방법에서는 전문가들이 일련의 설문지를 통해 반복적으로 의견을 제시하고 조정한다. 이 설문은 한 번으로 끝나는 것이 아니라, 2차, 3차에 걸쳐 반복적으로 시행되며, 각 라운드 후에는 집단의 응답 경향이 요약된 피드백이 제공된다. 이를 통해 전문가들은 다른 이들의 응답을 참고하면서 자신의 견해를 수정하거나 유지할 수 있는 기회를 갖게 된다.\n이 과정은 익명으로 진행되어, 특정 개인의 사회적 지위나 영향력이 결과에 영향을 미치는 것을 방지한다. 결과적으로, 개인의 주관적 판단보다는 집단적이고 합리적인 판단에 기반한 의견 수렴이 이루어지며, 이는 보다 신뢰성 높은 합의에 도달하도록 돕는다.\n통제된 피드백 과정\n델파이 방법의 핵심 중 하나는 통제된 피드백이다. 각 라운드가 끝난 후, 연구자는 참여 전문가들에게 다른 응답자들의 응답 분포나 평균, 중앙값 등 요약된 통계 정보를 제공한다. 이를 통해 전문가들은 자신의 견해가 전체 집단의 의견과 어느 정도 일치하거나 차이가 나는지를 확인할 수 있다.\n이러한 피드백은 단순한 정보 제공이 아니라, 의견의 수정과 재조정을 유도하는 통제된 메커니즘이다. 특히 극단적이거나 소수의견은 다수의 경향을 참고하면서 점차 조율되고, 집단 전체가 보다 합리적이고 신뢰할 수 있는 합의점으로 수렴하게 된다. 이 과정은 무작위적인 토론이 아닌, 체계적이고 점진적인 의견 정제의 역할을 한다.\n익명성 보장\n델파이 방법은 모든 응답 과정을 익명으로 진행하여, 특정 개인의 의견이 다른 전문가들의 판단에 직·간접적으로 영향을 미치는 것을 차단한다. 이는 집단 토론에서 흔히 발생할 수 있는 편승 효과(Bandwagon Effect)나 후광 효과(Halo Effect)와 같은 심리적 편향을 줄이는 데 중요한 역할을 한다.\n예를 들어, 명망 있는 전문가의 발언이 다른 참여자들에게 과도한 영향을 미치는 것을 방지함으로써, 각 전문가가 자신의 전문성과 판단에 근거한 독립적인 응답을 할 수 있도록 돕는다. 이러한 익명성은 델파이 방법의 객관성과 신뢰성을 높이는 핵심 요소 중 하나다.\n반복적 절차\n델파이 방법은 단회성 조사에 그치지 않고, 여러 차례 반복되는 의견 수렴 과정을 통해 전문가들의 판단을 점진적으로 정제해 나가는 특징을 갖는다. 각 회차에서는 이전 라운드의 요약 결과와 통계적 피드백이 제공되며, 전문가들은 이를 참고하여 자신의 응답을 유지하거나 수정할 수 있다.\n이러한 반복적 절차를 통해 극단적인 의견은 완화되고, 전문가 집단 내 합의에 가까운 결론에 도달하게 된다. 이 과정은 보통 2~4회 정도 반복되며, 응답의 변화 폭이 줄어들고 의견이 수렴되면 종료된다. 즉, 반복적 피드백과 응답 조정을 통해 보다 신중하고 타당한 합의된 전망이나 판단을 얻을 수 있다.\n\n\n3. 델파이 방법 절차\n\n(1) 문제 정의\n델파이 방법의 첫 단계는 연구 주제를 명확히 설정하고, 그 목적을 구체화하는 것이다. 이는 전체 조사 과정의 방향을 결정짓는 핵심 단계로, 무엇을 예측하고자 하는지, 어떤 결론을 도출하려는지를 명확히 해야 한다.\n예를 들어, “향후 10년간 인공지능이 고등교육에 미치는 영향”이라는 주제를 설정할 경우, 단순한 기술 동향을 넘어 교육 제도, 교사 역할 변화, 학습 방식의 진화 등 다양한 측면을 고려할 필요가 있다.\n문제 정의가 불명확하거나 포괄적이면, 전문가들이 일관된 방향으로 의견을 제시하기 어려워지고, 의견 수렴도 분산될 수 있다. 따라서 명확하고 구체적인 조사 목적과 기대 성과를 설정하는 것이 성공적인 델파이 조사의 출발점이다.\n\n\n(2) 응답 패널 구성\n델파이 방법에서 응답 패널의 구성은 조사 결과의 질을 좌우하는 핵심 요소이다. 패널은 보통 15~35명 규모로 구성되며, 최소 4명의 전문가는 반드시 포함되어야 한다. 이는 다양한 관점을 반영함과 동시에 의견의 신뢰성을 확보하기 위함이다.\n패널 구성을 위해서는 예상 응답률(일반적으로 60~80%)을 고려하여 여유 있는 인원을 사전에 확보해야 한다. 예를 들어, 25명의 유효 응답을 목표로 할 경우, 최소 30~40명의 잠재 패널 명단을 준비하는 것이 바람직하다.\n또한 패널 참여자는 조사 목적을 정확히 이해하고 있어야 하며, 해당 분야에서의 전문성과 경험을 갖춘 인물이어야 한다. 이는 단순한 의견이 아닌, 전문적 통찰이 반영된 정제된 응답을 유도하기 위해서다.\n패널 구성 시 연구자는 다음 기준을 고려해야 한다.\n\n다양한 하위 분야 또는 시각을 대표할 수 있는 구성\n이질성과 동질성 간의 균형 유지\n반복적 참여가 가능한 일정 여유\n\n적절하게 구성된 패널은 의견 수렴 과정의 신뢰성을 높이고, 보다 정확한 미래 예측과 정책 제언을 가능하게 한다.\n\n\n(3) 설문지 구성 및 문항 검증\n델파이 방법에서 설문지는 전문가의 의견을 체계적이고 명확하게 수렴하기 위한 핵심 도구이다. 따라서 설문지는 문제 정의에 부합하면서도 응답자의 이해를 돕고 부담을 줄이는 방향으로 설계되어야 한다.\n문항 구성 시 다음의 원칙을 따른다.\n\n개방형 문항: 선택 보기 구성이 어려운 탐색적 질문이나 주관적인 의견을 수렴할 때는 개방형 문항을 사용한다. 이는 전문가의 자유로운 사고를 유도하고, 다양한 아이디어를 수집하는 데 유리하다.\n선택형 문항: 선택지가 명확한 경우, 객관식 문항을 사용하여 응답자의 부담을 줄이고 응답 일관성을 높인다. 반복 회차에서는 초기 응답을 바탕으로 선택지를 구성할 수 있다.\n\n설문지는 사전 검토 및 문항 검증 절차를 반드시 거쳐야 한다. 이를 위해 보통 5인 이내의 관련 분야 전문가를 대상으로 사전 조사(pilot test)를 실시하고, 다음과 같은 사항을 점검한다.\n\n문항이 모호하거나 중복되지는 않는지\n질문의 의도와 어휘가 명확한지\n문항 순서가 논리적이며 응답 흐름에 적절한지\n불필요한 문항은 없는지 또는 중요한 문항이 누락되지 않았는지\n\n이 과정을 통해 설문지의 타당성(validity)과 명확성(clarity)을 확보할 수 있으며, 응답자의 이해도와 응답률을 높이는 데 기여한다. 궁극적으로 정제된 설문지는 반복 회차마다 신뢰도 높은 의견 수렴을 가능하게 하고, 델파이 연구의 질을 결정짓는 핵심 요소가 된다.\n\n\n\n\n\n\n\n\n\n\n\n\n(4) 1차 설문조사 실시 및 분석\n1차 설문조사는 전문가 패널에게 최종적으로 확정된 설문지를 송부함으로써 시작된다. 이때 조사의 목적, 회차 구성, 응답 방식, 일정(예: 2주 이내 회신 요청) 등이 명확하게 안내되어야 하며, 전자메일, 우편, 또는 온라인 플랫폼을 통해 진행될 수 있다.\n1. 설문 실시 방법\n\n설문 참여에 대한 동의를 얻고, 응답의 익명성과 기밀성을 보장한다.\n설문 기간과 회신 방법을 구체적으로 안내한다.\n온라인 설문 시스템(예: Google Forms, LimeSurvey 등)을 활용하면 관리가 용이하다.\n\n2. 응답 자료 분석\n\n빈도분석을 통해 각 문항의 응답 분포를 확인하고, 중복되거나 비효율적인 문항 제거를 고려한다.\n개방형 문항의 응답은 내용분석(content analysis)을 통해 핵심 키워드와 공통된 의견을 도출하고, 이를 선택형 보기로 재구성하여 다음 회차 설문에 반영한다.\n\n3. 응답 일치도 분석 기준\n델파이 방법은 의견 수렴의 정도(합의 정도)를 확인하는 데 중점을 둔다. 이를 위해 다음과 같은 통계 지표를 활용하여 응답의 일치도를 판단한다: 응답 일치도\n\n리커트 척도 : IQR 1이하, 변동계수 (=표준편차/평균) 0.5 이하\n비율 척도 : 변동계수 0.5 이하\n객관식 선택 문항 : 50%~75% 이상\n\nIQR(Interquartile Range)는 중앙 집중성을 확인하는 지표로, 값이 작을수록 의견이 모여 있음을 의미한다. 변동계수(CV)는 상대적 분산 정도를 나타내며, 평균에 대한 표준편차의 비율로 계산된다. 객관식 선택 문항은 특정 선택지에 응답이 집중되어 있는지를 통해 합의 여부를 판단할 수 있다.\n\n\n\n\n\n\n\n\n\n\n\n\n(5) 2차 설문지 구성\n2차 설문지는 1차 조사 결과를 바탕으로 정교하게 구성된다. 이 과정에서는 응답 일치도가 낮은 문항을 중심으로 표현 방식이나 선택지를 조정하여 응답자의 이해를 돕는다. 특히 개방형 문항에서 도출된 주요 응답을 기반으로 객관식 보기 항목을 구성함으로써, 명확하고 구조화된 응답을 유도할 수 있다.\n또한 1차 설문 결과 요약을 함께 제공하여, 전문가들이 다른 응답자들의 평균적 견해를 참고한 뒤 자신의 응답을 조정할 수 있도록 한다. 이를 통해 응답 간의 극단적 편차를 줄이고, 보다 높은 합의 수준에 도달할 수 있다. 2차 설문은 단순한 반복이 아니라, 의견 수렴을 위한 정제와 피드백 조정의 핵심 단계로 작용한다.\n\n\n\n\n\n\n\n\n\n\n\n\n(6) 2차 설문조사 실시\n2차 설문은 수정된 문항을 반영하여 전문가 패널에게 재송부하는 단계로, 설문은 전자메일이나 우편 등의 방식으로 배포되며, 조사 목적과 일정이 명확하게 안내된다. 이 단계에서는 전문가들이 1차 조사 결과를 바탕으로 자신의 의견을 재검토하고 조정할 기회를 갖는다.\n회수된 응답은 통계적으로 분석되어 응답 일치도를 다시 평가하며, 의견의 수렴 정도를 확인한다. 특히, 의견 분산이 줄어들었는지, 특정 문항에 대한 합의가 형성되었는지를 중점적으로 파악한다. 필요에 따라 추가적인 반복 조사를 고려할 수 있다.\n\n\n(7) 최종 결과 보고서 작성\n파이 조사의 마지막 단계는 전체 조사 과정을 정리하고, 응답 분석 결과 및 전문가 의견의 수렴 과정을 체계적으로 요약한 최종 보고서를 작성하는 것이다. 이 보고서에는 설문 설계 및 조사 절차, 각 라운드에서 수집된 응답의 통계적 분석 결과, 의견 변화의 양상, 최종적으로 도출된 합의 내용을 포함해야 한다.\n작성된 결과 보고서는 정책 결정, 전략 수립, 연구 기획, 기술 예측 등 다양한 분야에서 의사결정의 근거 자료로 활용될 수 있다. 델파이 결과 제시방법은 다음과 같다.\n\n중요도 척도 : 최빈값 &gt; 중위값과 IQR (Inter Quartile Range)\n비율척도 : 중위값 &gt; 평균, IQR (Inter Quartile Range)\n선택 보기문항의 경우 빈도 백분율 (%) 표시\n\n\n\n\n\n\n\n\n\n4. 한계\n첫째, 미래에 대한 평가 절하 현상이 자주 발생한다. 인간의 사고방식은 현재의 상황을 과도하게 중요하게 여기고, 미래의 변화 가능성을 충분히 반영하지 못하는 경향이 있다. 전문가들조차도 현재를 기준으로 미래를 바라보기 때문에 혁신적이거나 급격한 변화보다는 점진적인 변화를 예상하는 경우가 많다. 따라서 델파이 방법을 사용할 때는 미래를 단순한 연장선으로만 평가하지 않도록 유도할 필요가 있다.\n둘째, 단순화 경향이 나타난다. 전문가들은 복잡한 사회·경제적 요인을 충분히 반영하기보다 특정 변수나 트렌드만을 독립적으로 분석하는 경향이 있다. 이는 예측의 실용성을 높이는 장점도 있지만, 실제로 상호작용하는 다양한 요소들을 간과하게 만들어 예측의 정확성을 떨어뜨릴 수 있다. 특히, 시스템적인 사고 없이 개별 요소만 고려하면 현실과 동떨어진 결과가 나올 가능성이 높다.\n셋째, 전문성의 한계와 비현실적인 전망도 문제로 작용할 수 있다. 델파이 방법이 전문가의 집단 지성을 활용하는 방식이긴 하지만, 모든 전문가가 동일한 수준의 통찰력을 갖고 있는 것은 아니다. 일부 전문가들은 자신의 경험과 직관에 의존하여 근거가 부족한 예측을 제시하기도 하고, 반대로 지나치게 이상적인 전망을 내놓기도 한다. 이러한 의견이 전체 결과에 영향을 미칠 경우, 실질적으로 활용하기 어려운 예측이 도출될 위험이 있다. 따라서 전문가 선정 과정에서 균형 잡힌 시각과 충분한 경험을 갖춘 인물을 포함하는 것이 중요하다.\n마지막으로, 질문 형식의 명확성과 목적성이 핵심적인 역할을 한다. 델파이 방법에서 활용되는 질문은 예측의 방향성을 결정하는 중요한 요소이므로, 모호한 표현을 피하고 하나의 질문이 하나의 명확한 주제를 다루도록 구성해야 한다. 질문이 불명확하면 전문가들의 응답이 일관성을 잃거나 지나치게 광범위해질 수 있으며, 이로 인해 최종적인 합의 도출이 어려워질 수 있다.\n결론적으로, 델파이 방법이 효과적인 예측 도구가 되기 위해서는 미래의 변화 가능성을 충분히 고려하고, 단순화를 경계하며, 전문가 의견의 신뢰성을 검토하고, 질문 설계를 체계적으로 진행해야 한다. 이를 보완할 수 있다면 델파이 방법은 보다 정교하고 신뢰도 높은 미래 예측을 가능하게 할 것이다.\n\n\n\nchapter 2. AHP 방법\nAHP(Analytic Hierarchy Process)는 Thomas Saaty(1980)가 제안한 계량적 의사결정 기법으로, 가치 평가 및 복잡한 의사결정 문제 해결을 위한 방법론이다. 이 기법은 계층구조 원리, 우선순위 결정 원리, 일관성 원리를 기반으로 의사결정 대안을 평가하며, 다양한 대안을 다수의 목표와 비교하여 최적의 선택을 도출하는 데 활용된다. AHP는 두 가지 핵심 과정을 통해 문제를 분석한다.\n첫째, 정성적 혹은 무형적 특성을 상대적 비율 척도를 이용해 수량화하여 평가할 수 있도록 한다.\n둘째, 복잡한 문제를 점차 작은 요소로 분해하여 이원 비교를 수행함으로써 보다 단순한 형태로 의사결정을 진행한다.\n이를 위해 의사결정 대안을 평가할 수 있는 요소들을 계층 구조로 구성하며, 각 계층의 요소들은 평가자의 지식, 경험, 직관을 바탕으로 상대적으로 비교된다. 이러한 비교 과정을 통해 의사결정 대안을 수량화하여 최적의 대안을 선택할 수 있도록 지원하는 것이 AHP의 핵심 원리이다.\n\n1. AHP 주요 특징\nAHP는 복잡한 의사결정 문제를 체계적으로 분석하고 해결하기 위한 방법론으로, 여러 대안 중에서 최적의 선택을 도출하기 위해 다음과 같은 절차적 특징을 갖는다.\n우선, AHP는 문제를 구조화하기 위해 계층적 구조를 구성한다. 이는 가장 상위 수준의 의사결정 목표에서 출발하여, 그 아래 기준(criteria), 하위기준(sub-criteria), 그리고 최종적으로 대안(alternatives)으로 이어지는 방식이다. 이러한 계층 구조는 문제를 명확하게 시각화하고, 각 구성 요소 간의 관계를 체계적으로 분석할 수 있도록 한다.\n다음으로, AHP는 쌍대비교(pairwise comparison)를 통해 각 요소의 상대적 중요도를 평가한다. 이때 Saaty가 제안한 1~9의 정수 척도를 사용하여 두 요소 간 우선순위를 수치화하며, 이를 통해 각 요소의 가중치(weight)를 산출한다. 이 과정은 정성적 판단을 정량적으로 변환하는 데 핵심적인 역할을 한다.\n이렇게 도출된 비교 결과는 판단 행렬(judgment matrix)로 구성되며, 이에 대해 고유값 분석(eigenvalue analysis)을 실시하여 일관성을 검토한다. 특히 일관성 지수(Consistency Index, CI)와 일관성 비율(Consistency Ratio, CR)을 계산하여 응답의 논리적 일관성이 유지되고 있는지를 평가하고, 수용 가능한 범위(CR &lt; 0.1)를 넘을 경우 재검토가 요구된다.\n마지막으로, 계층 구조의 각 수준에서 산출된 가중치를 종합하여 각 대안의 종합 점수를 계산한다. 이 점수를 바탕으로 가장 높은 평가를 받은 대안을 최적의 선택으로 결정하게 된다. 이를 통해 AHP는 복수의 기준과 복잡한 평가 요소를 고려한 합리적 의사결정을 가능하게 한다.\n\n\n2. AHP 기본 전제\nAHP는 의사결정 과정에서 계층 구조 원리, 우선순위 결정 원리, 일관성 원리를 기본 전제로 한다.\n먼저, 계층 구조 원리는 복잡한 의사결정 문제를 보다 작은 요소로 분해하여 구조화하는 개념이다. 이를 통해 목표, 평가 기준, 하위 기준, 대안 등을 체계적으로 정리할 수 있다.\n둘째, 우선순위 결정 원리는 평가 요소 간 상대적인 중요도를 비교하여 가중치를 산출하는 과정이다. 이를 위해 이원 비교를 수행하며, 각 요소의 중요도를 수량화하여 최적의 의사결정을 도출할 수 있도록 한다.\n셋째, 일관성 원리는 의사결정 과정에서 논리적 일관성을 유지하도록 검증하는 절차이다. AHP는 일관성 비율을 활용하여 평가자의 판단이 논리적으로 타당한지 확인하고, 신뢰할 수 있는 결과를 도출할 수 있도록 한다.\n이러한 원리를 기반으로 AHP 방법을 적용하면, 정성적 평가 요소에 대한 가중치를 산정할 수 있으며, 이를 통해 평가 요소들의 우선순위를 체계적으로 결정할 수 있다.\n\n\n3. AHP 절차\nAHP는 의사결정 문제를 체계적으로 분석하고 최적의 대안을 도출하기 위해 다음과 같은 절차를 따른다.\n① 먼저, 의사결정 문제를 계층화하는 과정이 이루어진다. 이를 위해 의사결정과 관련된 평가 요소들을 목표, 기준, 하위 기준, 대안 등으로 구조화하여 계층적 모델을 구축한다. 이를 통해 복잡한 문제를 보다 명확하게 정리하고 분석할 수 있는 기반을 마련한다.\n② 다음 단계에서는 전문가 설문조사를 통해 평가 요소 간의 상대 비교 데이터를 수집한다. 평가자는 계층 내 각 요소들을 쌍(pair)으로 비교하여 상대적 중요도를 판단하며, 이 데이터를 바탕으로 상대 비교 행렬이 생성된다.\n③ 이후, 상대 비교 행렬을 이용하여 평가자의 응답 일관성을 검토하고 상대적 가중치를 계산한다. 이를 위해 일관성 지수(Consistency Index, CI)와 일관성 비율(Consistency Ratio, CR)을 활용하여 응답의 논리적 일관성을 평가한다. 평가자가 2인 이상인 경우, 일관성을 갖춘 응답자들의 상대 비교 행렬을 종합하여 단일 상대 비교 행렬을 도출하는 과정이 추가로 수행된다.\n④ 마지막으로, 평가 대상이 되는 여러 대안들에 대한 우선순위를 산정한다. 이를 위해 각 의사결정 요소의 상대적 가중치를 종합하여 최종적으로 가장 적합한 대안을 선정할 수 있도록 한다.\n\n\n4. 계층화\nAHP 방법에서 가장 중요한 단계는 의사결정과 관련된 요소들을 계층화하는 과정이다. 계층화란 시스템을 구성하는 각 특성이나 속성을 기준으로 분할된 집단을 형성하는 과정으로, 하나의 집단이 특정한 하위 집단에만 영향을 주고, 동시에 상위 집단으로부터만 영향을 받는 구조를 의미한다.\n계층 구조의 최상층에는 가장 포괄적인 의사결정 목표가 위치하며, 그 아래에는 목표 달성에 영향을 미치는 다양한 기준과 요소들이 하위 계층으로 배치된다. 계층이 낮아질수록 요소들은 보다 구체적인 특성을 가지게 되며, 각 계층 내 요소들 간에는 상호 비교가 가능해야 한다.\n계층 설정 시 고려해야 할 사항\n첫째, 계층의 완전성과 비완전성을 고려해야 한다. 하위 계층의 모든 요소가 직계 상위 계층의 모든 항목과 관련될 경우 완전한 계층이라 하며, 그렇지 않을 경우 비완전한 계층이라고 한다. Ramanujam과 Saaty(1981)는 AHP를 활용할 때 모든 계층을 반드시 완전하게 구조화할 필요는 없다고 주장하였으며, 일부 계층이 비완전하더라도 의사결정 과정에 큰 영향을 미치지 않는다고 보았다.\n둘째, 계층 내 평가 요소의 개수가 적절하게 설정되어야 한다. 인간은 동시에 9개의 대상을 비교할 수 있는 인지적 한계를 가지며, 비교 항목의 개수가 10개 이상이 되면 응답의 일관성을 유지하기 어려워진다. 따라서 Saaty(1980)는 계층 내 요소의 개수를 5개~9개 정도로 유지하는 것이 적절하며, 평가 요소 간 상대적 중요도를 비교할 때는 9점 척도를 사용하는 것이 바람직하다고 제안하였다.\n계층화의 기본 원칙과 단계\n최상위 계층에는 의사결정의 목표를 설정한다.\n\n중간 계층에는 목표 달성에 영향을 미치는 주요 평가 요소(기준 및 하위 기준)를 배치한다.\n최하위 계층에는 최종적으로 평가할 여러 대안을 포함한다.\n계층이 낮을수록 요소들은 보다 구체적이어야 하며, 계층 내 요소들 간에는 비교가 가능해야 한다.\n각 계층의 요소들은 직계 하위 집단에만 영향을 미치며, 동시에 상위 계층으로부터만 영향을 받는다.\n\n이러한 계층화 과정을 통해 복잡한 의사결정 문제를 구조적으로 정리할 수 있으며, 이를 기반으로 AHP를 활용한 체계적인 평가와 의사결정이 가능해진다.\n\n\n5. 상대비교 행렬 및 일관성 비율\nAHP에서 계층 구조가 완성되면, 각 계층 내 평가 요소들의 상대적 중요도를 평가하기 위해 상대 비교 행렬을 작성한다. 상대 비교 행렬은 대칭 행렬의 형태를 가지며, 행렬의 차수는 평가 요소의 개수를 의미한다.\n절차\n\n상대 비교 행렬을 구성하여 평가 요소 간 상대적 중요도를 비교한다.\n상대 비교 행렬의 대각 원소는 1이며, 상·하 대칭 원소는 역수 관계를 가진다.\n응답자의 판단 일관성을 검토하기 위해 일관성 지수(CI)를 계산한다.\n난수 지수(RI)를 활용하여 일관성 비율(CR)을 구하고, CR이 10% 미만이면 일관성이 확보된 것으로 판단한다.\n\n상대비교 행렬\n평가 요소를 \\(i,j\\)쌍으로 비교할 때, 평가 요소 \\(i\\)의 상대적 중요도를 \\(w_{i}\\), 평가 요소 \\(j\\)의 상대적 중요도를 \\(w_{j}\\)라 하면, 상대 비교 행렬의 원소는 \\(a_{ij} = \\frac{w_{i}}{w_{j}}\\)로 정의된다. 이때, 상대 비교 행렬은 다음과 같은 형태를 가진다.\n\\[A = \\begin{bmatrix}\na_{11} & a_{12} & \\cdots & a_{1p} \\\\\na_{21} & a_{22} & \\cdots & a_{2p} \\\\\na_{31} & a_{32} & \\cdots & a_{3p} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{p1} & a_{p2} & \\cdots & a_{pp}\n\\end{bmatrix}\\]\n대각 행렬 원소: \\(a_{ii} = 1\\) (자기 자신과의 비교는 항상 1)\n상대 비교 값: \\(a_{ij}(i \\neq j)\\)는 기준 평가 요소 \\(i\\)가 평가 요소 \\(j\\)에 비해 중요하다고 판단되는 정도를 의미하며, Saaty(1980)가 제안한 1~9 척도를 사용하여 값을 입력한다. (예: 1/9, 1/8, …, 1, 2, …, 9)\n대응 원소 관계: \\(a_{ji} = \\frac{1}{a_{ij}}\\)\n일관성 지수\n상대 비교를 통한 평가에서 응답자의 판단에는 다소간의 논리적 오류가 발생할 수 있다. 이를 보완하기 위해 일관성 지수를 활용하여 응답의 일관성을 검토한다.\n상대 비교 행렬이 완전히 일관성을 가지려면 \\(a_{ij} \\cdot a_{jk} = a_{ik}\\) 관계가 성립해야 하며, 상대 비교 행렬의 최대 고유치(\\(\\lambda_{\\max}\\))는 평가 요소의 개수 \\(n\\)과 동일하게 된다. 이를 활용하여 Saaty(1980)는 일관성 지수를 다음과 같이 정의하였다.\n\\(CI = \\frac{\\lambda_{\\max} - n}{n - 1}\\).\n일관성이 높은 경우: 응답자의 판단이 논리적으로 일관됨을 의미하며, 결과의 신뢰도가 높다.\n일관성이 낮은 경우: 응답자의 판단 과정에서 일관성이 유지되지 않았음을 의미하며, 결과의 신뢰도가 낮아진다.\n일관성 비율 (Consistency Ratio, CR)\nSaaty(1980)는 상대 비교를 9점 척도로 수행할 경우, 평가 요소의 개수에 따라 사용할 수 있는 난수 지수를 제시하였다. 이를 활용하여 일관성 비율을 계산할 수 있다.\n\\(CR = \\frac{CI}{RI}\\): CR 값이 10% 미만이면 일관성이 확보된 응답으로 간주한다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n차수 (n)\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nRI\n0\n0\n0.58\n0.9\n1.12\n1.24\n1.32\n1.41\n1.45\n\n\n\n\n\n6. 상대 중요도 계산\n상대 비교 행렬을 통해 계층 내 평가 요소들의 상대적 중요도를 평가하고 일관성을 검증한 후, 최종적으로 상대적 중요도(가중치)를 산출하는 과정이 진행된다.\n먼저, 상대 비교 행렬로부터 최대 고유치(\\(\\lambda_{\\max}\\))를 구하고, 이에 대응하는 고유 벡터를 도출한다. 고유 벡터의 각 원소는 평가 요소의 상대적 중요도를 나타내며, 모든 원소의 합이 1이 되도록 정규화하여 최종 가중치를 산출한다. 이를 위해 고유 벡터의 각 원소를 원소 합으로 나누어 정규화된 중요도 값을 얻는다.\n계층이 2개 이상인 경우\n의사결정 과정에서 일반적으로 계층은 2개 이상으로 구성된다. 이 경우, 각 계층별로 동일한 방법을 반복하여 평가 요소들의 가중치를 산출한다. 최하위 계층의 평가 요소에 대한 최종 가중치는 자신이 속한 계층의 가중치와 상위 계층의 평가 요소 가중치를 곱하여 계산된다. 즉, 상위 계층의 가중치는 하위 계층으로 전달되며, 이러한 과정이 반복되어 최종적으로 평가 요소들의 가중치가 결정된다. 이를 활용하여 의사결정의 대안들을 평가하고 최적의 선택을 도출할 수 있다.\n다수의 평가자가 존재하는 경우\n의사결정 과정에서 평가자가 2명 이상인 경우, 개별적으로 도출된 상대 비교 행렬을 종합하여 단일 그룹 상대 비교 행렬을 생성하는 과정이 필요하다. 이때 사용되는 대표적인 방법은 다음과 같다.\n1. 그룹 평가 방법(Delphi 방법)\n평가자들의 의견을 종합하여 하나의 상대 비교 행렬을 직접 작성하는 방법이다.\n전문가 의견을 반복적으로 조정하여 합의된 평가 결과를 도출하는 것이 특징이다.\n2. 개별 평가 후 그룹 전체 상대 비교 행렬 산출 방법\n각 평가자의 상대 비교 행렬을 개별적으로 작성한 후, 이를 바탕으로 그룹 전체의 단일 상대 비교 행렬을 생성하는 방식이다.\nSaaty(1980)는 이 방법에서 각 평가자의 상대 비교 행렬의 원소에 대해 기하 평균(geometric mean)을 적용하여 단일 비교 행렬을 생성하는 방법을 제안하였다.\nSaaty(1980)의 기하 평균 방법은 계산이 간편하며, 행렬의 역수성을 유지할 수 있다는 장점이 있어 가장 널리 사용된다. 이후 개별 상대 비교 행렬로부터 그룹 전체 상대 비교 행렬을 얻는 다양한 방법이 연구되었지만, Saaty(1995)는 각 방법 간 결과 차이가 거의 없음을 주장하였다.\n결론적으로, AHP를 통한 상대 중요도 산출 과정에서는 일관성 검증을 거쳐 신뢰성을 확보한 후, 고유 벡터를 이용하여 가중치를 계산하며, 다수 평가자의 의견을 반영할 경우 기하 평균을 활용하는 방법이 가장 효과적으로 평가된다.\n\n\n7. AHP 활용 사례\n네트워크 환경에서 발생하는 사이버 위협의 위협 수준을 정량적으로 산정하기 위해 계층 분석 기법을 적용할 수 있다. 사이버 위협 평가는 주로 정성적 요소를 기반으로 이루어지며, 주요 평가 항목으로는 감염 대상 획득, 감염 경로, 감염 시 증상, 방어 조치 난이도, 피해 자산 유형 등이 포함될 수 있다. 이러한 평가 요소들은 객관적인 정량화가 어려운 특성을 지니므로, AHP를 활용하여 계층적 구조를 설정하고 상대적 가중치를 산출함으로써 체계적인 위협도 평가가 가능하다.\n최상위 계층: 사이버 위협도 산정을 위한 핵심 평가 요소(감염 대상 획득, 감염 경로, 감염 시 증상, 방어 조치 난이도, 피해 자산 유형)\n중간 계층: 각 5개 평가 요소별 하위 평가 기준\n최하위 계층: 사이버 위협의 개별 사례(대안), 즉 위협 발생 사례별 위협도 점수\n여기서는 최상위 계층의 평가 요소 5개에 대한 상대적 가중치를 부여하는 방법을 설명한다. 동일한 방법을 적용하여 하위 계층에서도 각 항목의 가중치를 산정할 수 있다.\n\n\n\n\n\n사이버 위협 관련 전문가 3명을 대상으로 설문 조사를 실시하여 상대비교 행렬을 얻었다. ID 1번, 2번 응답자의 일관성 비율이 10% 미만이었으므로, 이들만 응답의 일관성을 유지하였음을 알 수 있다.\n\n\n\n\n\n평가 일관성을 유지한 ID 1번, 2번 응답자의 상대비교 행렬을 이용하여 단일 상대비교 행렬을 구하면 아래와 같다. 단일 상대비교 행렬은 Saaty(1980)가 제안한 기하평균 방법을 이용하여 구해졌다.\n\n\n\n\n\n단일 상대비교 행렬의 최대 고유치는 5.127이므로 일관성 지수 CI=0.032이고, 일관성 비율 CR=2.8%이다. 상대비교 행렬의 최대 고유치에 대응하는 고유벡터는 다음과 같다. 각 평가요소의 가중치는 고유벡터의 합을 구하고, 대응하는 평가요소의 고유벡터 값을 합으로 나눈 값이다. 결과를 해석해 보면, 네트워크상에서 사이버 위협이 발생했을 때 피해예상자산이 감염경로에 비해 2배 더 위협적이라는 할 수 있다.\n\n\n\n\n\n\n\n\nchapter 3. 컨조인트 분석\n컨조인트 분석(Conjoint Analysis)은 소비자의 선호를 평가하고 예측하기 위해 설계된 다변량 통계 기법이다. 이는 제품 또는 서비스의 속성과 각 속성의 수준에 대한 소비자의 선호도를 분석하는 방법으로, 특히 마케팅, 제품 기획, 가격 결정 등의 분야에서 널리 활용된다.\n컨조인트 분석의 기본 개념은 소비자가 제품을 개별 속성 단위가 아니라, 속성들의 조합(conjoint)으로 인식하고 평가한다는 점에 있다. 따라서 이 기법은 소비자의 실제 선택 과정과 유사한 환경을 모형화하여, 개별 속성이 소비자의 선택에 미치는 영향을 분해하고 추정하는 데 초점을 맞춘다.\n\n1. 컨조인트 분석 개념\n\n(1) 목적\n컨조인트 분석은 제품 및 서비스 기획에서 중요한 의사결정을 내리는 데 활용되며, 주요 목적은 다음과 같다.\n\n독립변수(속성)의 상대적 중요도를 분석하여 특정 제품이나 서비스의 평가 요소를 도출한다.\n종속변수(소비자 선호도)에 미치는 영향을 정량적으로 측정하여 소비자가 무엇을 중요하게 여기는지를 파악한다.\n최적의 속성 조합을 찾아 기업의 제품 기획 및 마케팅 전략에 반영하여 경쟁력을 강화한다.\n\n\n\n(2) 개념\n컨조인트 분석은 소비자가 제품의 다양한 속성을 어떻게 평가하고 선택하는지를 분석하기 위한 방법이다. 이 기법은 평가자들이 제시된 대안에 대해 응답한 결과를 바탕으로 각 속성 수준의 효용(utility)을 추정할 수 있도록, 요인 설계(factorial design)를 기반으로 분석을 수행한다.\n실제 조사에서는 제품이나 서비스의 대안을 여러 속성의 조합으로 구성하여 제시하고, 소비자가 이들 조합 중 어떤 방식을 선호하는지를 평가하게 한다. 이를 통해 최적의 속성 조합을 도출하고, 제품 개발이나 마케팅 전략 수립에 활용할 수 있다.\n’컨조인트(Conjoint)’라는 용어는 ’Consider’와 ’Jointly’의 합성어로, 소비자가 여러 속성을 함께 고려하여 평가한다는 개념을 반영하고 있다.\n컨조인트 분석과 다차원척도법(Multidimensional Scaling) 비교\n컨조인트 분석과 다차원척도법은 모두 소비자의 심리적 판단을 정량적으로 측정하기 위한 기법이라는 공통점을 가진다. 그러나 두 방법은 평가 대상을 제시하는 방식과 분석 초점에서 차이를 보인다.\n\n컨조인트 분석은 제품이나 서비스의 속성을 요인 설계 방식으로 조합한 후, 응답자가 어떤 조합을 선호하는지 평가하게 함으로써 속성별 효용(utility)을 추정한다. 즉, 사전에 정의된 속성 조합을 바탕으로 선호 구조를 분석하는 데 중점을 둔다.\n다차원척도법(MDS)은 소비자가 느끼는 제품이나 브랜드 간의 유사성 또는 선호도 차이를 바탕으로, 그 관계를 저차원의 공간에 시각화하는 방법이다. 평가자는 구체적인 속성보다는 전체적 인상이나 거리감을 기준으로 판단하게 되며, 분석 결과는 점 간의 거리로 나타난다.\n\n요약하면, 컨조인트 분석은 속성 기반의 선택 분석에, MDS는 심리적 거리 기반의 포지셔닝 분석에 적합한 방법이다.\n\n\n(3) 고려 사항\n\n종속변수 측정상의 문제: 응답자의 선호나 선택을 어떻게 정량화할 것인지 명확히 설정해야 한다. 예를 들어, 순위(rank), 평점(rating), 선택(choice) 방식 중 어떤 방식을 택할지에 따라 분석 기법이 달라지고, 결과 해석에도 영향을 미친다.\n독립변수 결합상의 문제: 독립변수(속성)들을 어떤 방식으로 조합해 제시할 것인지가 분석의 핵심이다. 전수조합(full-profile design)은 정보가 많지만 부담이 크고, 부분요인 설계(fractional factorial design)는 효율적이지만 정보 손실 위험이 있다. 따라서 연구 목적과 응답자의 인지 부담을 균형 있게 고려해 설계해야 한다.\n\n\n\n(4) 기본원리\n제품이나 서비스는 여러 속성의 조합으로 구성되며, 각 속성은 여러 수준을 가질 수 있다. 예를 들어, 스마트폰을 고려할 경우 다음과 같은 속성과 수준이 존재할 수 있다.\n\n\n\n\n\n\n\n속성(Attribute)\n수준(Levels)\n\n\n화면 크기\n5인치, 6인치, 7인치\n\n\n배터리 용량\n3000mAh, 4000mAh, 5000mAh\n\n\n가격\n50만원, 70만원, 90만원\n\n\n\n\n\n\n2. 컨조인트 분석 관련 용어 정리\n1. Attribute (속성)와 Level (수준)\n속성: 제품이나 서비스가 가지는 독립변수로, 소비자가 고려하는 주요 특성이다.\n수준: 각 속성이 취할 수 있는 값. 컨조인트 분석에서는 최소 두 개 이상의 수준을 가져야 하며, 일반적으로 4~5개 이내로 설정하는 것이 적절하다.\n예제: 휴대폰의 속성이 3개(화면크기, 배터리 용량, 가격)이고, 각 속성이 3 개의 수준을 가진다면, 가능한 제품 조합 수는 \\(3 \\times 3 \\times 3 = 27\\)개이다.\n2. 종속변수 dependent variable\n응답자의 선호도: 소비자가 특정 속성 조합을 선호하는 정도를 나타내는 값으로, 컨조인트 분석에서 최적의 제품 설계를 위한 핵심 정보가 된다.\n3. 주효과 main effects\n독립변수(속성)가 종속변수에 미치는 직접적인 영향을 의미한다. 특정 속성이 전체 선호도에 어느 정도 기여하는지 평가할 수 있다.\n\n\n3. 컨조인트 분석 모형\n\n(1) 이론적 배경\n컨조인트 분석의 이론적 기초는 효용 이론과 선택 모델에 기반을 둔다. 주요한 이론적 요소는 다음과 같다.\n(1) 효용 이론(Utility Theory)\n컨조인트 분석은 선택 대안의 속성이 개인의 효용에 미치는 영향을 분석하는데, 이는 경제학과 행동과학에서 널리 연구된 효용 이론을 바탕으로 한다. 효용 이론에서 소비자는 주어진 대안 중 최대 효용을 제공하는 대안을 선택한다고 가정한다. 즉, 제품이나 서비스의 속성이 소비자에게 부여하는 효용 값을 평가하고, 이를 통해 소비자의 선호도를 모델링 한다.\n(2) 분해적 접근(Decompositional Approach)\n컨조인트 분석은 전체적인 선택을 기반으로 개별 속성이 미치는 영향을 역추정 하는 분해적 접근을 따른다. 즉, 소비자가 직접적으로 속성의 중요도를 평가하는 것이 아니라, 속성이 조합된 여러 대안을 비교하면서 나타나는 선택 행태를 분석하여 속성별 중요도를 추론한다.\n(3) 다속성 효용 모형(Multi-Attribute Utility Model)\n컨조인트 분석에서는 다속성 효용 모형을 사용하여 개별 속성이 전체 효용에 미치는 기여도를 평가한다. 가장 일반적인 효용 함수는 선형 가법적 형태로 표현된다.\n\n\n(2) 전통적 컨조인트 분석\n전통적 컨조인트 분석은 다속성 효용 모형을 기반으로 하며, 소비자가 제품을 선택할 때 각 속성이 독립적으로 효용을 제공한다고 가정한다.\n(1) 가법적 효용 모형(Additive Utility Model)\n\\[U(X) = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\ldots + \\beta_{k}X_{k} + \\varepsilon\\]\n\\(U(X)\\): 소비자가 선택한 대안 \\(X\\)의 총 효용값\n\\(X_{1},X_{2},\\ldots,X_{k}\\): 제품의 속성들\n\\(\\beta_{0}\\): 상수항\n\\(\\beta_{1},\\beta_{2},\\ldots,\\beta_{k}\\): 각 속성의 가중치(효용 값)\n\\(\\varepsilon\\): 오차항(random error)\n위 모형은 각 속성이 독립적으로 효용을 제공하며, 그 합이 전체 제품의 효용을 결정한다는 가정을 따른다.\n(2) 수행 절차\n① 속성 및 수준 선정\n연구자가 제품의 주요 속성과 각 속성의 수준을 결정한다. 예를 들어, 스마트폰의 속성을 다음과 같이 설정할 수 있다.\n\n\n\n\n\n\n\n속성(Attribute)\n수준(Levels)\n\n\n가격\n100만원, 120만원, 140만원\n\n\n배터리 용량\n3000mAh, 4000mAh, 5000mAh\n\n\n브랜드\n삼성, 애플, 샤오미\n\n\n\n② 실험 설계\n총 조합 개수는 27개가 되어 가능한 모든 조합을 평가하는 것은 비효율적이므로, 부분(1/3) 요인 설계를 사용하여 9개의 대표적인 제품 프로필을 선정한다.\n\n\n\n\n\n\n\n\n가격\n배터리 용량\n브랜드\n\n\n100만원\n3000mAh\n삼성\n\n\n100만원\n4000mAh\n애플\n\n\n100만원\n5000mAh\n샤오미\n\n\n120만원\n3000mAh\n샤오미\n\n\n120만원\n4000mAh\n삼성\n\n\n120만원\n5000mAh\n애플\n\n\n140만원\n3000mAh\n애플\n\n\n140만원\n4000mAh\n샤오미\n\n\n140만원\n5000mAh\n삼성\n\n\n\n③ 데이터 수집\n적정 응답자 수: \\(n \\geq \\frac{1000 \\times c}{a \\times t}\\) Johnson & Orme (1996)의 경험적 공식 (예제) \\(n \\geq \\frac{1000 \\times 3}{3 \\times 9} = \\frac{3000}{27} = 111.1 \\approx 112\\)\n\\(c\\): 각 속성의 최대 수준 개수\n\\(a\\): 하나의 제품 프로필에 포함된 속성 개수\n\\(t\\): 한 명의 응답자가 평가하는 제품 프로필 수\n종속변수: 응답자는 10점 척도나 선호여부(0, 1)로 응답한다.\n독립변수: \\(X_{1} = \\text{가격 120만원},X_{2} = \\text{가격 140만원},\\)\\(X_{3} = \\text{배터리 4000mAh},X_{4} = \\text{배터리 5000mAh},\\)\\(X_{5} = \\text{브랜드 애플},X_{6} = \\text{브랜드 샤오미}\\).\n④ 모형 추정 및 해석\n10점 척도는 OLS 추정, 선호 여부는 로짓회귀로 추정한다. 추정 결과가 다음과 같다면 소비자가 제품의 어떤 속성을 가장 중요하게 생각하는지 정량적으로 헤석할 수 있다.\n\n\n\n\n\n\n\n\n속성\n수준\n효용 값 (추정)\n\n\n가격\n120만원\n0.3333\n\n\n가격\n140만원\n-1.3333\n\n\n배터리\n4000mAh\n2\n\n\n배터리\n5000mAh\n2.5\n\n\n브랜드\n애플\n-1.3333\n\n\n브랜드\n샤오미\n-0.6667\n\n\n\n\n가격이 높아질수록 선호도가 감소 (120만원까지만 소폭 증가)\n배터리 용량이 커질수록 선호도 증가\n삼성 브랜드가 가장 선호됨\n최적의 제품 조합: 120만원 X 5000mAh X 삼성 브랜드\n\n\n\n(3) 적응형 컨조인트 분석(Adaptive Conjoint Analysis, ACA)\n적응형 컨조인트 분석은 응답자의 선택에 따라 설문이 동적으로 조정되는 방식의 컨조인트 분석 기법으로 전통적 컨조인트 분석과 달리, 모든 응답자에게 동일한 제품 프로필을 제시하는 것이 아니라, 응답자의 초기 선호도를 기반으로 이후 질문이 맞춤형으로 제시되는 방식을 사용한다.\n응답자의 피로도를 줄일 수 있음 (불필요한 속성 조합을 제외)\n높은 차원의 속성을 포함할 수 있음 (속성이 많아도 설문이 복잡해지지 않음)\n개인 맞춤형 분석이 가능 (응답자마다 다른 질문을 받을 수 있음)\n따라서 제품의 속성 개수가 많거나, 개인별 선호도 차이가 클 경우 적응형 컨조인트 분석이 더욱 효과적이다.\n① 이론적 모형\n전통적 컨조인트 분석과 동일한 가법적 효용 모형을 사용한다.\n\\[U(X) = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\ldots + \\beta_{k}X_{k} + \\varepsilon\\]\n전통적 컨조인트 분석에서는 모든 응답자가 동일한 속성 조합을 평가하는 반면, 적응형 컨조인트 분석에서는 응답자의 이전 응답을 반영하여, 이후 질문이 동적으로 조정한다. 각 응답자에게 가장 의미 있는 질문을 집중적으로 제시하여 보다 효율적인 데이터를 수집할 수 있다.\n② 설문방식\n1. 속성별 중요도 평가\nQ1. 가격이 얼마나 중요한가요? 5점 척도\nQ2. 배터리 용량이 중요한가요? 5점 척도\nQ3. 브랜드 선호도가 있는가요? 브랜드 3개\n2. 속성 수준 비교 질문: 응답자의 답변을 바탕으로 맞춤형 제품 조합을 생성하여 비교 질문을 제시한다.\nQ. 다음 두 가격 수준 중 어느 것이 더 선호됩니까?\nA: 100만원 B: 120만원\nQ. 배터리 용량 중 어느 수준을 선호합니까?\nA: 4000mAh B: 5000mAh\n3. 제품 프로필 비교: 이전 응답을 바탕으로, 응답자가 비교하기 쉬운 2개의 제품 프로필을 생성하여 선택하도록 한다.\n예: ”다음 두 제품 중 하나를 선택하세요.”\nA 제품: 120만원, 5000mAh, 삼성\nB 제품: 100만원, 3000mAh, 애플\n개별 응답자의 선호도에 따라 불필요한 속성 조합은 제거되므로 응답 피로도가 낮고 개별 응답자의 선호도를 정밀하게 측정할 수 있어 개인 맞춤형 마케팅이 가능하나 설문 설계가 복잡하고, 분석이 어렵다.\n③ 추정방법\n(방법1) 전통적 컨조인트 분석 OLS(최소 자승법) 동일\n(방법2) 계층적 베이지안 추정 (Hierarchical Bayesian, HB)\n개별 응답자의 효용 값을 베이지안 추론을 이용하여 추정하고 모집단 평균과 개별 차이를 반영하여 신뢰성 높은 효용 값을 도출한다.\n\n\n(4) 선택기반 컨조인트 분석(Choice-Based Conjoint, CBC)\n선택기반 컨조인트 분석은 소비자가 여러 개의 제품 옵션 중 하나를 선택하는 방식으로 데이터를 수집하는 컨조인트 분석 기법이다. 이는 소비자의 실제 구매 행동과 가장 유사한 방법으로 설계되었으며, 시장 점유율 예측, 최적의 제품 조합 분석, 가격 민감도 측정 등 다양한 마케팅 전략 수립에 활용된다.\nCBC의 가장 큰 특징은 응답자가 단순히 제품의 속성에 점수를 부여하거나 순위를 매기는 것이 아니라, 실제 구매 결정을 내리는 것처럼 여러 제품 중 하나를 선택하는 방식으로 응답한다는 점이다. 따라서 CBC는 소비자의 실질적인 선택 행동을 반영하는 데 유리하며, 보다 현실적인 소비자 선호 데이터를 제공할 수 있다.\n추정은 이산 선택 모델을 기반으로 하며, 소비자가 특정 제품을 선택할 확률을 예측하는 방식으로 이루어진다. 이를 위해 다항 로짓 모형 또는 혼합 로짓 모형과 같은 확률적 선택 모델이 적용될 수 있다. 이러한 모델들은 응답자의 선택 데이터를 바탕으로 개별 속성들이 소비자의 최종 선택에 미치는 영향을 분석하며, 제품의 가격, 기능, 브랜드 등의 속성 간 상대적인 중요도를 정량적으로 평가할 수 있도록 한다.\n① 이론적 배경\n이산 선택 모형을 기반으로 하며, 소비자가 여러 개의 대안 중 하나를 선택하는 방식을 따른다. 이는 경제학에서 사용하는 랜덤 효용 모형을 적용하여, 소비자가 가장 높은 효용(Utility)을 제공하는 제품을 선택한다고 가정합니다.\n효용 함수: 소비자가 제품 \\(i\\) 를 선택할 확률은 효용 함수를 통해 결정됩니다.\n\\(U_{i} = V_{i} + \\varepsilon_{i}\\), 여기서 \\(U_{i}\\): 제품 \\(i\\) 의 총 효용, \\(V_{i}\\): 관측 가능한 속성들의 가중 합, \\(\\varepsilon_{i}\\): 오차항 ~ (정규 분포 또는 로지스틱 분포 가정)\n특히, 효용 값 \\(V_{i}\\) 는 제품의 속성 값과 해당 속성의 가중치의 선형 조합으로 표현됩니다.\n\\(V_{i} = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\ldots + \\beta_{k}X_{k}\\), 여기서\n\\(X_{1},X_{2},\\ldots,X_{k}\\): 제품 속성 값\n\\(\\beta_{1},\\beta_{2},\\ldots,\\beta_{k}\\): 속성별 효용 계수\n② 설문방식\n사례에서 27개 조건 혹은 9개 조건 중 3개를 임의로 선정하여 응답자에게 보여주고 선호하는 제품을 선택한다.\n③ 추정방법: 다항 로짓 모형(Multinomial Logit Model, MNL)\n이 모형은 소비자가 특정 제품을 선택할 확률을 예측하는 방식으로 동작한다.\n\\(P(i) = \\frac{e^{V_{i}}}{\\sum_{j}^{}e^{V_{j}}}\\), 여기서 \\(P(i)\\): 소비자가 제품 i 를 선택할 확률, \\(e^{V_{i}}\\): 제품 \\(i\\) 의 효용 값을 지수 함수로 변환한 값, \\(\\sum_{j}^{}e^{V_{j}}\\): 모든 제품의 효용 값의 합이다."
  },
  {
    "objectID": "notes/survey/nonresponse.html",
    "href": "notes/survey/nonresponse.html",
    "title": "조사방법론. 3. 무응답과 대체",
    "section": "",
    "text": "chapter 1. 무응답 개요\n설문조사에서 무응답(nonresponse)은 표본으로 선정된 일부 응답자가 질문에 답하지 않는 현상을 의미한다. 이러한 무응답이 발생하면, 추정값이 편향될 수 있으며 표본이 모집단을 제대로 대표하지 못하게 되어 분석 결과의 신뢰성이 떨어질 가능성이 높다.\n무응답자가 응답자와 다른 특성을 가진다면, 응답자만을 대상으로 계산한 추정값은 모집단 전체의 실제 값과 차이를 보일 수 있다. 특히 무응답이 일정한 방향이나 경향성을 가지는 경우, 이는 단순한 오류를 넘어서 설계 전체에 체계적인 편향을 초래할 수 있으며, 이를 무응답 편향(nonresponse bias)이라고 한다.\n무응답이 특정 집단에 집중될 경우, 표본이 모집단의 다양한 특성을 충분히 반영하지 못하게 된다. 예를 들어, 소득이 높은 사람이나 바쁜 직장인처럼 일정한 특성을 가진 집단의 응답률이 낮다면, 이들의 의견은 과소 대표되거나 완전히 누락될 수 있다. 그 결과 표본의 대표성이 손상된다.\n또한 무응답이 무작위로 발생한다면 통계적으로 큰 문제가 되지 않을 수 있지만, 현실에서는 특정 문항이나 주제에 따라 일관된 응답 회피가 발생하는 경우가 많다. 예를 들어 정치적 성향에 대한 질문에서 특정 지지층이 응답을 회피한다면, 결과는 특정 방향으로 왜곡될 수 있다.\n무응답으로 인해 유효한 응답 수가 줄어들면, 전체 표본의 크기가 감소하게 되어 통계 추정의 분산이 커지고 표본 오차가 증가한다. 이는 결과의 정확성을 떨어뜨리고, 신뢰구간을 넓혀 결과 해석에 불확실성을 더하게 된다.\n결과적으로 무응답이 많을수록 조사 결과를 일반화하기 어려워지고, 정책 결정이나 연구 활용 시 신뢰할 수 없는 정보를 제공하게 될 가능성이 커진다. 따라서 설문조사에서 무응답을 최소화하고, 발생한 무응답을 적절히 보정하는 절차가 중요하다.\n단위 무응답 unit nonresponse\n무응답이 발생하는 방식 중 하나는 단위 무응답(unit nonresponse)으로, 이는 표본으로 선정된 사람이 조사에 전혀 응답하지 않는 경우를 의미한다. 이 경우, 조사 대상자는 모든 질문에 답하지 않기 때문에 해당 응답자는 전체적으로 누락된다. 예를 들어 어떤 조사 대상자가 전화를 받자마자 “나는 설문조사에 절대 참여하지 않는다. 다시 전화하지 말라”고 말하며 응답을 거부하는 경우, 이는 전형적인 단위 무응답에 해당한다.\n항목 무응답 item nonresponse\n무응답이 전체 문항이 아닌 일부 질문에서만 발생하는 경우를 항목 무응답(item nonresponse)이라고 한다. 이는 응답자가 특정 질문에 대해서만 답변을 하지 않거나 회피하는 상황을 말한다.\n예를 들어 조사자가 “작년 총 가구 소득이 얼마였습니까?”라고 묻자, 응답자가 “모르겠다. 아내가 그런 기록을 관리한다”고 답하며 해당 항목에 대한 응답을 유보하는 경우, 이는 항목 무응답에 해당한다.\n\n\nchapter 2. 단위 무응답 유형\n무응답은 여러 가지 이유로 발생할 수 있으며, 크게 세 가지 유형으로 구분할 수 있다.\n첫째, 조사 요청 전달 실패는 조사자가 표본으로 선정된 대상자에게 조사 요청을 전달하지 못하는 경우를 의미한다. 이는 조사 대상자를 물리적으로 찾지 못하거나, 우편으로 보낸 설문지가 반송되는 상황 등이 포함된다. 이러한 경우에는 조사 자체가 이루어지지 않으므로 단위 무응답으로 처리된다.\n둘째, 응답 거부는 조사 대상자가 조사 요청을 인지했음에도 불구하고 설문 참여를 명확히 거절하는 경우에 해당한다. 전화나 방문을 통해 접촉이 이루어졌지만, 개인적인 이유, 조사에 대한 불신, 시간 부족 등의 이유로 응답을 거부하는 경우가 여기에 포함된다.\n셋째, 응답 불가능은 조사 대상자가 설문 문항을 이해하지 못하거나, 인지적 또는 신체적인 이유로 응답할 수 없는 경우를 의미한다. 예를 들어 고령자나 언어적 장벽이 있는 사람이 질문의 의미를 제대로 파악하지 못해 답변을 제공하지 못하는 상황이 해당된다.\n\n1. 조사 요청 전달 실패로 인한 단위 무응답\n비접촉 또는 조사 요청 전달 실패로 인한 무응답은 조사 대상자가 특정한 데이터 수집 방식으로는 접근이 어려운 경우에 발생한다. 이와 같은 상황에서 중요한 개념은 접근 가능성이며, 이는 조사자가 표본으로 선정된 대상자에게 실제로 연락하거나 조사를 수행할 수 있는지를 의미한다. 조사 대상자의 연락처 정보가 부정확하거나, 반복적인 접촉 시도에도 불구하고 연결되지 않는 경우, 설문 참여 여부와 무관하게 조사가 이루어지지 않게 된다.\n가구 설문조사에서 접근 가능성 문제\n조사자가 응답자가 집에 머무는 시간을 알고 있다면, 단 한 번의 시도로도 성공적으로 접촉할 수 있다. 그러나 실제 조사에서는 표본 대상자의 접근 가능한 시간이 사전에 알려져 있는 경우가 드물다. 이로 인해 조사자는 동일한 대상자에게 여러 차례 연락을 시도해야 하며, 이는 조사 비용과 시간이 증가하는 원인이 되기도 한다.\n접근이 어려운 사례\n조사 요청 전달이 실패하는 주요 원인 중 하나는 물리적인 접근의 제한이다. 이는 외부인의 접촉을 차단하는 환경에서 자주 발생하며, 예를 들어 출입이 통제된 아파트 건물이나 자동 응답 전화 시스템이 설치된 경우 조사자가 대상자에게 직접 접근하기 어렵다.\n우편을 통한 설문조사에서는 설문지가 대상자에게 도달하더라도, 발신자를 알 수 없는 우편물을 열어보지 않고 폐기하는 사람들은 응답에서 자연스럽게 누락될 가능성이 높다.\n전화 조사에서도 비슷한 문제가 발생한다. 예를 들어 집에 머무는 시간이 거의 없는 사람들은 조사자가 여러 차례 전화를 시도하더라도 연결되지 않을 가능성이 크다. 또한 발신자 번호를 차단하거나 필터링하는 서비스를 이용하는 경우, 조사원의 연락 시도 자체가 인지되지 않아 응답으로 이어지지 않을 수 있다.\n첫번 째 시도에서 조사 성공률이 가장 높다.\n성공적인 연락률은 통화 시도 횟수가 늘어날수록 점차 감소하는 경향이 있으며, 이러한 감소는 종종 지수적인 형태를 따른다. 특히 가구를 대상으로 한 설문조사에서는 첫 번째 접촉을 성사시키기 위해 몇 차례의 전화 시도가 필요한지를 결정하는 데 다음과 같은 두 가지 요인이 주요하게 작용한다.\n첫째, 통화가 이루어지는 시간대는 응답률에 영향을 미친다. 일반적으로 저녁 시간이나 주말에 걸려온 전화는 평일 낮 시간에 비해 응답률이 더 높은 것으로 나타난다. 이는 많은 사람들이 해당 시간대에 집에 머물 가능성이 높기 때문이다.\n둘째, 모집단의 특성에 따라 접근 가능성이 다르게 나타날 수 있다. 예를 들어 직업, 생활 패턴, 주거 형태 등에 따라 어떤 모집단은 조사자와의 연락이 상대적으로 더 용이한 반면, 또 다른 모집단은 접근이 더 어려울 수 있다. 이러한 차이는 조사 설계와 연락 전략에 반영될 필요가 있다.\n우편, 이메일, 웹 설문조사\n인터뷰어가 직접 접촉하지 않는 방식의 조사는, 조사 요청이 표본 대상자에게 지속적으로 노출될 수 있도록 설계되어야 한다. 예를 들어 우편 설문조사의 경우, 설문지가 일단 가구에 도착하면 응답 여부와 관계없이 일정 기간 동안 가구 내에 그대로 남아 있게 된다. 이로 인해 가구 구성원은 자신이 원하는 요일이나 시간대에 설문에 응답할 수 있다.\n이러한 방식에서는 전화나 방문 조사와 달리, 조사자가 능동적으로 접촉을 시도하지 않더라도 응답이 이루어질 가능성이 생긴다. 따라서 직접적인 접촉을 필요로 하는 조사 방식과는 달리, 표본 단위가 첫 접촉에 이르기까지 필요한 시도 횟수나 시간의 분포가 서로 다른 양상을 보인다.\n\n\n2. 응답거부로 인한 단위 무응답\n설문조사의 성공 여부는 응답자가 낯선 조사자의 요청에 자발적으로 응할 의사가 있는지에 크게 좌우된다. 응답자가 설문에 참여하기 위해서는 몇 가지 심리적 조건이 충족되어야 한다.\n우선, 조사자로부터 신체적 또는 경제적 피해를 입을 것이라는 두려움이 없어야 한다. 응답자는 자신에게 어떠한 해도 가해지지 않을 것이라는 확신을 가져야 한다.\n또한, 응답 과정에서 자신의 평판이 손상될 가능성을 걱정하지 않아야 하며, 조사 참여가 사회적 이미지에 부정적인 영향을 미치지 않을 것이라고 느껴야 한다.\n설문 참여로 인해 심리적 스트레스를 겪을 수 있다는 불안도 응답을 가로막는 요인이 될 수 있다. 따라서 조사는 응답자에게 부담을 주지 않는 방식으로 진행되어야 한다.\n기밀 보장에 대한 신뢰 역시 중요한 요소이다. 응답자는 조사자가 제공한 정보 보호 약속을 믿을 수 있어야 하며, 자신의 응답 내용이 외부로 유출되지 않을 것이라는 확신을 가져야 한다.\n마지막으로, 응답자는 자신의 의견을 자유롭게 표현할 수 있으며, 솔직한 정보를 제공하더라도 불이익을 받거나 위험에 처하지 않을 것이라고 믿을 때 비로소 진정한 응답이 이루어진다. 이러한 심리적 안정이 확보되어야만 응답자는 설문조사에 적극적으로 참여하게 된다.\n\n(1) 설문조사와 타 조사의 차이\n설문조사 요청은 사람들이 일상생활에서 경험하는 다양한 외부 요청들과 비교해볼 수 있으며, 이러한 비교는 설문 응답 행태를 이해하는 데 중요한 시사점을 제공한다. 대중이 낯선 사람으로부터 받는 요청은 일반적으로 판매 전화, 업무 또는 서비스 관련 연락, 기부 요청, 정치 활동, 그리고 설문조사 등으로 나눌 수 있다. 이들은 여러 측면에서 서로 다른 특성을 보인다.\n첫째, 사람들의 경험 빈도는 접촉 방식에 따라 달라진다. 과거에는 방문 판매가 흔했으나, 최근에는 텔레마케팅이 그 자리를 대신하고 있다. 이로 인해 낯선 사람으로부터 걸려오는 전화나 우편, 이메일 메시지는 설문조사보다는 상품이나 서비스 판매를 목적으로 하는 경우가 훨씬 더 많다. 이러한 경험의 불균형은 응답자가 설문조사 요청을 다른 상업적 요청과 혼동할 가능성을 높인다.\n둘째, 대중의 인식 수준에서도 차이가 나타난다. 기업이나 널리 알려진 자선단체, 정치 단체의 경우 많은 사람들이 해당 조직의 이름에 익숙할 수 있다. 반면, 설문조사를 실시하는 주체가 대학이나 정부 기관인 경우에도 일부 응답자는 사전에 해당 기관을 인식하고 있을 수 있지만, 그렇지 않은 경우에는 요청자가 낯설게 느껴질 수 있다.\n셋째, 인센티브의 제공 여부도 다르다. 설문조사는 응답에 대한 감사의 표시로 소정의 금전적 보상이나 선물을 제공하는 경우가 있으나, 판매나 서비스 요청에서는 일반적으로 이러한 유인책이 제공되지 않는다. 이는 설문 응답 동기를 유도하는 중요한 차별점이 될 수 있다.\n넷째, 연락의 지속성 측면에서 판매 및 모금 요청은 대체로 반복적인 시도를 하지 않는 경향이 있다. 망설이는 대상자를 설득하기보다는 새로운 대상을 찾는 것이 더 효율적이기 때문이다. 이에 반해, 설문조사 특히 확률 표본조사는 표본의 대표성을 확보해야 하므로 동일 가구에 대해 여러 차례 연락을 시도하는 경우가 많다.\n다섯째, 요청의 성격에서도 차이가 있다. 판매는 일반적으로 상품이나 서비스에 대한 금전적 지불을 요구하지만, 설문조사는 응답자의 시간과 정보를 제공받는 것이 목적이다. 설문은 응답자의 자발적인 참여가 아닌 조사자의 접근으로 시작되기 때문에, 응답자는 설문 참여보다는 자신의 원래 활동으로 돌아가는 것을 더 중요하게 여길 수 있다.\n이러한 반복적인 경험은 사람들로 하여금 설문 요청에 대해 일정한 반응을 형성하게 만든다. 즉, 응답자의 반응은 과거의 유사한 경험에서 비롯된 습관적인 대응일 수 있다. 설문 요청이 상업적 전화와 혼동되어 거절되는 경우도 자주 발생하는데, 이를 해결하기 위해서는 반복적인 연락을 통해 조사 목적을 명확히 설명하는 것이 중요하다. 또한 신뢰할 수 있는 기관이 주관하는 조사라면, 조사원이 해당 기관의 이름을 강조함으로써 상업적 목적이 아님을 분명히 할 수 있다.\n\n\n(2) 응답거절 단위 무응답 발생 요인\n설문조사에서 응답률을 높이고 무응답 편향을 줄이기 위해서는 응답 거절로 인한 단위 무응답 발생 요인을 이해하는 것이 중요하다. 이러한 요인은 조사자가 통제할 수 없는 요인과 조정 가능한 요인으로 나눌 수 있다.\n먼저, 조사자가 조정하기 어려운 요인으로는 사회적 환경과 개인 수준의 특성이 있다. 예를 들어, 대도시 지역에서는 가구 단위 설문에서 응답 거절 비율이 상대적으로 높게 나타난다. 이는 도시 생활의 익명성, 바쁜 생활 패턴, 낯선 사람에 대한 경계심 등이 영향을 줄 수 있다. 또한, 가구 구성원이 여러 명인 가정은 1인 가구보다 응답에 협조할 가능성이 높으며, 이는 집단 내의 의견 조율이나 설문 참여에 대한 심리적 부담이 분산되기 때문이다. 개인 수준에서는 남성이 여성보다 설문에 응하지 않을 가능성이 더 높은 경향이 관찰된다.\n한편, 조사자가 조정할 수 있는 요인도 있다. 대표적인 예로는 조사원 개인의 능력과 설문 설계 방식이 있다. 경험이 풍부한 조사원은 응답자의 반응에 능숙하게 대응하고 신뢰를 구축하는 데 유리하므로, 경험이 적은 조사원보다 더 높은 응답 협조율을 이끌어낼 수 있다. 또한, 응답자에게 소정의 인센티브를 제공하는 것은 응답률을 높이는 데 효과적이며, 이는 설문 참여에 대한 긍정적인 동기를 부여하는 역할을 한다.\n이와 같은 요인들을 종합적으로 고려하여 설문조사를 설계하고 실행한다면, 단위 무응답을 줄이고 보다 신뢰성 있는 결과를 얻을 수 있다.\n\n\n(3) 응답거절 관련 이론적 가설\n응답 거절을 설명하는 데 활용되는 이론적 가설은 설문조사의 응답률과 무응답 편향을 이해하는 데 중요한 통찰을 제공한다. 다음의 네 가지 가설은 응답자의 행동을 설명하는 대표적인 이론적 틀로 제시된다.\n첫째는 기회비용 가설이다. 이 가설에 따르면 바쁜 사람일수록 인터뷰나 설문조사 참여를 거부할 가능성이 높다. 이들은 일상에서 다른 활동에 할애할 시간이 부족하므로, 설문 참여를 시간 낭비로 인식하거나 부담스럽게 느낀다.\n둘째는 사회적 고립 개념이다. 이는 사회경제적 계층의 양극단에 위치한 사람들이 설문 요청에 응하지 않을 가능성이 높다는 주장이다. 지나치게 부유하거나 매우 빈곤한 계층의 경우, 사회적 제도나 기관과의 관계가 약해 설문 요청 자체를 거부하거나 무관심하게 대할 수 있다.\n셋째는 주제 관심 가설이다. 이 가설은 특정 주제에 대해 관심이 있는 사람들만이 설문에 적극적으로 응하면서, 표본이 해당 주제에 편향된 집단으로 구성될 가능성이 있다는 점을 지적한다. 이러한 경우 통계적 결과에 무응답 오류가 발생할 수 있으며, 이는 전체 모집단을 반영하지 못하는 왜곡된 결과로 이어질 수 있다.\n넷째는 과도한 설문조사 개념이다. 반복적이고 빈번한 설문 요청은 응답자의 피로도를 높이고, 결과적으로 설문 참여를 꺼리게 만드는 요인이 될 수 있다. 이는 특히 동일한 대상자에게 유사한 설문이 반복적으로 도달하는 상황에서 더욱 두드러진다.\n이러한 가설들은 설문조사 과정에서 나타나는 응답 거절 현상을 보다 정교하게 이해하고, 이를 줄이기 위한 설계 전략을 수립하는 데 유용하게 활용될 수 있다.\n\n\n(4) 레버리지-현저성 이론 leverage-salience theory\n레버리지-현저성 이론(leverage-salience theory)은 사람들이 설문 요청의 여러 속성을 서로 다르게 중요하게 여긴다는 점에 주목한다. 설문 주제, 인터뷰에 소요되는 시간, 후원 기관, 수집된 데이터의 활용 목적 등이 이에 해당하며, 응답자는 각 속성을 긍정적으로 평가할 수도 있고 부정적으로 받아들일 수도 있다.\n조사자는 사전에 어떤 속성이 응답자에게 중요한지를 알기 어렵지만, 설문이 진행되는 과정에서 특정 속성이 강조되면 응답자의 응답 여부에 영향을 미칠 수 있다. 즉, 강조된 요소가 응답자의 가치관이나 관심과 부합하면 설문에 응할 가능성이 높아지며, 반대로 불편함이나 거부감을 유발하는 경우에는 응답을 거절할 가능성이 높아진다.\n예를 들어, 첫 번째 응답자는 설문 주제에 높은 관심을 가지지만 시간이 많이 걸리는 점을 부담스럽게 느낄 수 있고, 두 번째 응답자는 주제에는 관심이 없지만 제공되는 인센티브에 긍정적인 반응을 보일 수 있다. 이때 조사자가 설문의 후원 기관이나 보상에 대해 강조한다면, 각 응답자에게 해당 요소가 설문 참여 여부를 결정짓는 기준으로 작용할 수 있다. 이러한 상황에서는 주제에 긍정적인 첫 번째 응답자가 설문에 응할 가능성이 더 높아질 수 있다.\n이 이론이 주는 주요 시사점은 설문조사에서 응답자의 다양성을 고려한 맞춤형 접근이 필요하다는 것이다. 응답자가 설문 요청을 수락하거나 거절하는 이유는 사람마다 다르고, 조사자는 이러한 이유를 조사 초기에는 파악하기 어렵다. 따라서 단일한 접근 방식만으로는 다양한 응답자의 요구와 우려를 효과적으로 해결하기 어렵다. 대신, 응답자가 긍정적으로 인식할 수 있는 속성을 파악하고 이를 적절히 강조하는 전략을 통해 응답률을 높이는 것이 효과적이다.\n\n\n\n3. 요청된 데이터를 제공할 수 없는 경우의 단위 무응답\n단위 무응답은 응답자가 설문에 응할 의사가 있음에도 불구하고, 요청된 데이터를 제공할 수 없는 경우에도 발생할 수 있다. 이러한 상황은 표본 대상자와의 접촉이 성공적으로 이루어졌더라도, 다양한 제약으로 인해 응답이 불가능한 경우를 포함한다.\n예를 들어, 일부 응답자는 설문이 제공되는 언어를 전혀 이해하지 못하거나, 질문의 내용을 이해하거나 기억에서 필요한 정보를 불러오는 것이 어려울 수 있다. 정신적인 부담이나 인지적 제약이 있는 경우도 여기에 해당된다. 또한, 건강 문제로 인해 응답이 어려운 경우도 있으며, 문해력에 제한이 있어 설문지를 읽거나 해석하는 데 어려움을 겪는 경우도 무응답으로 이어질 수 있다. 기업을 대상으로 한 조사에서는 조사 형식이 적절하지 않거나 조사에 할애할 시간이 부족하여 필요한 정보를 제공하지 못하는 경우가 발생하기도 한다.\n이와 같이 응답 불가능의 원인이 다양하기 때문에, 단위 무응답이 통계 분석에 미치는 영향도 상황에 따라 달라진다. 예를 들어, 인구의 건강 상태를 조사하는 설문에서는 건강상의 이유로 응답이 이루어지지 않는 경우가 무응답 편향을 유발할 수 있다. 건강이 좋지 않은 사람들이 조사에서 빠지게 되면, 전체 인구의 건강 수준이 실제보다 더 양호하게 추정될 가능성이 있다. 반면, 동일한 조사에서 정치적 태도나 사회적 인식을 측정하는 경우에는 같은 무응답이 결과에 미치는 영향이 상대적으로 작을 수 있다.\n따라서 이러한 유형의 무응답은 단순한 데이터 누락 이상의 의미를 가지며, 조사 주제와 분석 목적에 따라 그 영향을 면밀히 평가하고 보정할 필요가 있다.\n\n\n\nchapter 3. 응답률 계산\n\n1. 무응답이 통계 품질에 미치는 영향\n무응답으로 인해 발생하는 편향은 무응답의 원인이 조사 대상이 되는 통계적 특성과 연관될 때 더욱 심각해진다. 예를 들어, 혼자 사는 가구의 비율을 조사하는 경우를 생각해보면, 1인 가구는 집에 머무는 시간이 상대적으로 짧아 조사자가 연락을 시도했을 때 접촉이 어려울 수 있다. 이 경우 단 한 번의 연락 시도만으로는 해당 가구가 표본에서 누락될 가능성이 높으며, 결과적으로 혼자 사는 사람의 비율이 실제보다 낮게 추정될 수 있다. 반면, 반복적인 연락 시도를 통해 이러한 가구를 조사에 포함시키면 오히려 과도하게 반영되어 실제보다 높은 추정값이 나올 수도 있다. 이는 무응답이 가구의 거주 시간과 밀접하게 관련되어 있기 때문이다.\n이와 달리, 정치적 관심도와 같은 주제를 조사하는 경우에는 무응답이 통계에 미치는 영향이 상대적으로 작을 수 있다. 따라서 무응답이 초래하는 통계적 편향은 조사 주제와 무응답의 원인 간의 관련성에 따라 달라질 수 있다.\n거절 무응답 오류는 응답자가 설문에 응하지 않는 이유가 해당 통계와 관련이 있을 때 발생한다. 예를 들어, 어떤 설문조사에서 특정 인센티브가 특정 집단의 응답률을 높이는 데는 효과적일 수 있으나, 동시에 응답자의 구성이나 특성에 영향을 주어 조사 결과 자체에 변화를 일으킬 가능성도 있다.\n무응답 편향이 발생하는지를 판단하기 위해서는 응답 여부에 영향을 미치는 인과 메커니즘을 고려해야 한다. 어떤 경우에는 무응답의 원인이 조사 대상과 직접적인 관련이 없어 통계적으로 큰 문제가 되지 않기도 한다. 예를 들어, 가구의 전기 사용량을 조사할 때 집에 머무는 시간이 응답 성향에는 영향을 줄 수 있지만, 이 성향이 전기 사용량과 직접적인 관련을 가지지 않는다면 무응답은 비교적 무해한 것으로 간주할 수 있다.\n반면, 무시할 수 없는 인과 메커니즘이 작용하는 경우도 있다. HIV 유병률 조사에서는 응답자의 감염 여부 자체가 설문 참여 여부에 영향을 줄 수 있다. 이러한 경우 무응답은 단순한 비응답이 아닌 통계의 과소추정을 초래하는 심각한 편향 요인이 될 수 있다. 실제로 미국에서 HIV 유행 초기 공중보건 당국은 혈액 채취를 포함한 전국적 유병률 조사를 실시하고 금전적 보상까지 제공했으나, HIV 감염자들의 응답률은 여전히 낮았다. 기록 대조 연구에 따르면 이는 사회적 낙인으로 인해 감염자들이 설문 참여를 기피했기 때문이며, 그 결과 조사된 HIV 감염률이 실제보다 낮게 추정되는 과소추정이 발생한 것으로 나타났다.\n무응답의 영향은 조사 주제와 맥락에 따라 다르게 나타난다. 어떤 조사에서는 무응답률이 높든 낮든 결과에 큰 차이를 주지 않는 경우도 있으며, 이로 인해 일부 연구자들은 무응답률을 중요하지 않다고 간주하기도 한다. 이는 무응답률이 반드시 조사 결과의 질을 저해한다는 가정이 항상 성립하지는 않는다는 점을 보여준다.\n그러나 무응답의 원인이 조사 대상 속성과 밀접하게 연관된 경우에는 통계적 추정에 심각한 왜곡을 초래할 수 있다. 문제는 대부분의 경우 연구자가 무응답이 어떤 특성과 연관되어 발생하는지를 명확히 파악하기 어렵다는 데 있다. 이러한 불확실성 속에서 무응답의 영향을 정확히 측정하거나, 최적의 응답률을 판단하는 것은 현실적으로 쉽지 않다. 따라서 대부분의 연구에서는 조사 예산이 허용하는 범위 내에서 가능한 한 높은 응답률을 확보하려는 전략이 일반적으로 사용된다.\n\n\n2. 응답률 계산\n\n(1) 무응답 편향 계산 공식\n무응답 편향nonresponse bias 계산식: \\({\\overline{y}}_{r} - {\\overline{y}}_{s} = \\frac{m_{s}}{n_{s}}({\\overline{y}}_{r} - {\\overline{y}}_{m})\\)\n\n\\({\\overline{y}}_{s}\\): 특정 표본에서 선택된 전체 응답의 평균\n\\({\\overline{y}}_{r}\\): 해당 표본 내 응답자의 평균\n\\({\\overline{y}}_{m}\\): 해당 표본 내 무응답자의 평균\n\\(n_{s}\\): 해당 표본의 총 표본 수\n\\(r_{s}\\): 해당 표본 내 응답자의 수\n\\(m_{s}\\): 해당 표본 내 무응답자의 수\n\n무응답자의 평균, \\({\\overline{y}}_{m}\\)을 알 수 없으나 확률적인 특성을 가질 수 있으므로 이를 반영한 보다 일반적인 편향 공식은 다음과 같다.\n\\[bias({\\overline{y}}_{r}) = \\text{Cov}(r_{i},Y_{i}) + E\\left\\lbrack \\left( \\frac{m_{s}}{n_{s}} \\right)({\\overline{y}}_{r} - \\overline{Y}) \\right\\rbrack\\]\n응답 확률(\\(r_{i}\\))과 관심 변수(\\(Y_{i}\\)) 간의 공분산: 이는 응답자가 될 확률과 조사 대상 변수 간의 상관관계를 의미하며, 응답자가 될 가능성이 높은 사람이 특정한 특성을 가질 경우 편향이 발생할 수 있다.\n기대 무응답률과 전체 평균의 차이: 두 번째 항은 기대 무응답률 \\(\\frac{m_{s}}{n_{s}}\\)과 응답자 평균(\\({\\overline{y}}_{r})\\) 과 모집단 평균(\\(\\overline{Y}\\))의 차이의 곱이다. 이는 무응답자의 특성이 전체 모집단과 다를 경우 발생하는 편향을 나타낸다.\n무응답자의 특성이 더욱 뚜렷해지고 무응답률이 낮아지더라도, 무응답 오류가 반드시 감소하는 것은 아니다. 이는 무응답자의 특성이 전체 모집단과 크게 다를 경우, 단순히 응답률을 높이는 것만으로는 통계적 편향을 효과적으로 줄이기 어렵다는 점을 시사한다. 다시 말해, 응답률이 개선되었다고 하더라도 응답하지 않은 집단의 특성이 여전히 표본에서 제대로 반영되지 않는다면, 결과적으로 무응답 편향은 여전히 존재하거나 오히려 심화될 수도 있다. 따라서 단순한 응답률 향상보다는, 무응답자의 특성과 응답자의 차이를 파악하고 적절한 보정 방법을 병행하는 노력이 필요하다.\n\n\n(2) 응답율 계산 주요 이슈\n무응답률을 단순히 \\(\\frac{m_s}{n_s}\\) 의 비율로 계산하는 방식은 그 계산에 내포된 복잡성을 감추는 결과를 낳을 수 있다. 무응답률은 무응답 오류를 구성하는 주요 요소 중 하나이며, 때로는 조사 결과의 신뢰도를 높여 보이기 위해 의도적으로 무응답률을 낮게 산정하려는 경향도 나타난다. 하지만 무응답률의 정확한 계산에는 여러 가지 실질적인 문제가 존재한다.\n첫째, 표본 프레임에는 조사 대상이 아닌 단위가 포함될 수 있기 때문에, 조사 대상자의 적격성을 사전에 선별하는 과정이 필요하다. 예를 들어, 가구를 대상으로 하는 전화 조사에서 표본 프레임에 업무용 전화번호가 포함되어 있는 경우, 해당 번호의 수신자가 조사 대상에 해당하는지를 확인하기 어렵다. 이로 인해 응답률 계산 시 분모에 어떤 대상을 포함할 것인지에 대한 기준이 불확실해질 수 있다.\n둘째, 일부 표본은 클러스터 단위로 구성되어 있어, 표본 추출 단계에서 개별 조사 대상자의 수를 알기 어려운 경우가 있다. 예를 들어, 학교를 표본 단위로 설정한 후 그 안에서 학생을 조사하는 경우, 전체 클러스터가 무응답으로 분류될 때 실제 몇 명이 응답하지 않은 것인지 명확히 알기 어렵다. 이는 무응답률 산정 시 분자의 해석에 불확실성을 더한다.\n셋째, 표본 프레임에 포함된 요소들이 동일한 선택 확률을 갖지 않는 경우, 응답률 계산에 가중치를 반영해야 하는지 여부에 대한 고민이 필요하다. 예를 들어, 특정 소수 민족 집단을 초과 표집한 경우, 응답률 산정 시 이들의 과대표집 비율을 그대로 반영할 것인지 아니면 가중치를 조정할 것인지에 대한 기준이 모호할 수 있다.\n이러한 이유로 인해 응답률은 단순한 비율 수치 이상의 의미를 가지며, 무응답률의 해석과 활용에 있어 보다 세심한 접근이 요구된다.\n\n\n(3) 응답률 계산\n첫 번째와 두 번째 이슈를 해결하는 방법 중 하나는 분모의 값을 추정하는 것이다. 이때 외부 정보 또는 다른 사례에서 얻은 정보를 활용할 수 있으므로 응답률은 다음과 같이 계산될 수 있다.\n\\(\\frac{I}{I + R + NC + O + e(UH + UO)}\\), 여기서 \\(I\\)은 조사 완료자 수, \\(R\\)은 거절 및 중단, \\(NC\\)은 미접촉, \\(O\\)은 기타 적격 사례, \\(UH\\)은 조사대상자 여부가 불분명한 사례, \\(UO\\)은 기타 적격 여부가 불분명한 사례, \\(e\\)은 적격 여부가 불분명한 사례 중 적격으로 추정되는 비율이다. 변수 \\(e\\)의 추정치는 현재 진행 중인 설문조사에서 얻을 수 있다.\n\\[e = \\frac{I + R + NC + O}{I + R + NC + O + \\text{샘플에 포함된 부적격 사례}}\\]\n만약 \\(e\\)에 대한 신뢰할 수 있는 추정치를 얻을 수 없다면 \\((UH + UO)\\)을 계수 없이 분모를 사용하거나 분모에서 이를 제외하는 방식이다.\n응답률을 추정할 때 선택 확률이 불균등한 경우, 단순한 계산 방식만으로는 정확한 응답률을 산정하기 어렵다. 예를 들어, 행정 서비스에 대한 사회조사를 실시하면서 저소득층 거주 지역을 다른 지역에 비해 두 배 높은 비율로 표본추출한 경우를 생각해보자. 이와 같은 설계에서는 응답률과 관련해 다음과 같은 두 가지 주요 문제가 발생할 수 있다.\n첫째는 층별 응답률 비교이다. 저소득층 지역과 비저소득층 지역 간의 응답률을 각각 구해 비교하는 것은 일반적인 접근 방식이며, 두 집단 간의 평균 차이를 분석하는 데 유용하다. 이 경우에는 각 층 내에서의 응답률을 별도로 계산하고, 단순 비교를 통해 응답 특성을 이해할 수 있다. 이러한 분석에서는 앞서 설명한 표준적인 응답률 계산 방식이 적용 가능하다.\n둘째는 전체 표본의 응답률을 계산하는 경우이다. 만약 분석의 초점이 전체 모집단의 평균에 있다면, 응답률을 계산할 때 표본 추출 시의 불균등한 선택 확률을 반영해야 한다. 즉, 각 표본 요소의 선택 확률에 따라 가중치(\\(w_i\\))를 부여한 후 이를 활용하여 전체 응답률을 산정해야 한다. 이러한 가중 응답률 계산은 전체 표본이 모집단을 얼마나 잘 대표하는지를 보다 정확히 평가할 수 있도록 도와준다.\n이처럼 불균등 표집 설계에서는 응답률 계산 시 분석 목적에 따라 적절한 방법을 선택해야 하며, 층별 비교와 전체 평균 추정에서 서로 다른 계산 방식이 요구된다.\n다양한 응답률 지표의 활용\n응답률을 해석하고 활용할 때는 조사 목적과 구조에 따라 적절한 지표를 선택하는 것이 중요하다. 단순한 전체 응답률 외에도 다양한 유형의 응답률 지표가 존재하며, 이는 조사 설계와 분석 목적에 따라 다르게 적용될 수 있다.\n우선, 거절률은 설문 요청을 받은 대상자 중에서 응답을 거부한 비율을 의미하며, 일반적으로 \\(R / (I + R)\\) 의 공식으로 계산된다. 여기서 \\(R\\) 은 거절 수, \\(I\\)는 실제 응답 수를 나타낸다. 또한, 처음에는 응답을 거절했지만 이후에 설문에 참여한 경우를 반영하는 거절 변환율도 함께 고려할 수 있다. 이러한 지표는 조사 접근 방식의 효과성을 평가하는 데 유용하다.\n다음으로, 포괄률은 특히 기업을 대상으로 한 조사에서 사용되며, 전체 조사 대상 집단 중 실제 응답한 단위가 차지하는 비율을 의미한다. 이는 예를 들어 생산량이나 고용 규모와 같은 정보를 추정할 때 중요하게 고려된다. 이때 대형 유통업체인 이마트가 응답하지 않는 것과, 소규모 동네 편의점이 빠지는 경우는 조사 결과에 미치는 영향이 다르기 때문에 단순한 개수 기준의 응답률보다 포괄률이 더 적절한 지표가 될 수 있다.\n또한, 복합 응답률은 수행평가조사와 같이 다단계 표본추출이 이루어지는 구조에서 활용된다. 예를 들어, 학교와 학생이라는 두 수준에서 각각 무응답이 발생하는 경우, 이들 각 수준의 응답률을 결합하여 전체 응답률을 계산하는 방식이다. 이는 조사 참여가 여러 단계를 거치는 설계에서 보다 정확한 응답 수준을 반영할 수 있도록 한다.\n결론적으로, 응답률은 단일한 개념으로 이해하기보다는, 조사 대상, 설계 구조, 분석 목적에 따라 다양한 형태로 정의되고 활용될 수 있으며, 상황에 맞는 지표를 적절히 선택하는 것이 중요하다.\n\n\n\n\nchapter 4. 항목 무응답\n\n1. 항목 무응답 정의\n항목 무응답은 설문조사에서 응답자가 전체 설문에 참여하였음에도 불구하고 특정 질문에 대해서만 응답하지 않는 경우를 의미한다. 예를 들어, 소비자 조사의 응답자가 대부분의 문항에 성실히 응답하였더라도, 조사자가 지난 1년간의 가족 소득을 묻는 질문에 대해서는 답변을 거부할 수 있다. 항목 무응답은 단위 무응답과 마찬가지로 통계에 편향을 일으킬 수 있으나, 그 영향은 해당 항목의 데이터를 활용한 통계에만 국한된다.\n항목 무응답이 발생하는 원인은 단위 무응답과는 성격이 다를 수 있다. 단위 무응답은 설문 참여 여부를 결정하는 초기 단계에서 발생하는 반면, 항목 무응답은 설문이 진행되는 도중 개별 문항에 대한 응답 결정 과정에서 나타난다.\n항목 무응답의 주요 원인에는 다음과 같은 요인이 포함된다. 첫째, 응답자가 질문의 의도를 충분히 이해하지 못할 경우 답변을 생략할 수 있다. 둘째, 질문에 대한 정보를 기억해내기 어렵거나, 정확한 수치를 제공하기 어려운 상황도 무응답으로 이어질 수 있다. 셋째, 응답자가 질문 내용이 민감하다고 느끼거나, 정보를 공개할 동기나 의지가 부족한 경우에도 응답을 거부할 가능성이 있다.\n또한, 일부 응답자는 자신이 제공할 수 있는 답변이 정확하지 않다고 판단할 때 해당 항목을 생략하기도 한다. 이러한 상황에서는 질문의 형식을 조정하여 응답률을 개선할 수 있다. 예를 들어, 소득을 구체적인 금액이 아니라 범위로 제시하면, 응답자가 보다 부담 없이 응답할 수 있어 항목 무응답을 줄이는 데 도움이 될 수 있다.\nBeatty-Herrmann 모델\nBeatty-Herrmann 모델은 항목 무응답이 발생하는 과정을 인지적 측면과 응답 경로의 차이에 따라 설명하는 이론적 틀이다. 이 모델은 응답자가 필요한 정보를 얼마나 쉽게 접근할 수 있는지를 기준으로 네 가지 인지 상태를 제시하며, 각 상태에서 응답이 이루어질 가능성과 오류 발생 가능성을 함께 설명한다.\n첫 번째는 가용한 정보 상태이다. 이는 응답자가 질문에 필요한 정보를 쉽게 회상할 수 있는 경우를 의미한다. 이 상태에서는 대부분 정확한 응답이 이루어지며, 응답 오류가 발생할 가능성도 매우 낮다.\n두 번째는 접근 가능한 정보 상태이다. 이 경우, 응답자가 정보를 즉시 기억해내지는 못하지만, 약간의 인지적 노력이나 조사원의 유도에 의해 기억을 떠올릴 수 있다. 이러한 상황에서도 응답은 대체로 이루어지며, 정확성도 비교적 높은 편이지만, 일부 오류가 포함될 수 있다.\n세 번째는 추정 가능한 정보 상태이다. 응답자가 직접적인 기억은 없지만, 유사한 경험이나 논리적 추론을 통해 정보를 생성할 수 있는 경우에 해당한다. 이때 제공되는 응답은 어느 정도 일관성을 가질 수 있지만, 오류가 발생할 가능성이 높으며, 응답자가 스스로 신뢰하지 못해 응답을 포기할 경우 무응답으로 이어질 수 있다.\n마지막으로, 추정 불가능한 정보 상태는 응답자가 해당 질문에 대한 정보를 전혀 기억하지 못하고, 이를 유추할 수 있는 근거조차 없는 경우를 말한다. 이 상태에서는 대부분 응답이 이루어지지 않으며, 항목 무응답으로 직접 연결된다.\n이 모델은 항목 무응답을 단순한 의사결정 결과가 아니라, 응답자의 인지적 정보 처리 과정의 산물로 이해할 수 있도록 도와주며, 질문 설계와 조사 전략 수립에 유용한 시사점을 제공한다.\n\n\n2. 항목 무응답 줄이기 위한 설계적 요소\n\n(1) 응답 과정\n응답 과정은 설문조사에서 응답이 이루어지기까지의 일련의 단계로 구성되며, 일반적으로 접촉 단계, 초기 결정 단계, 그리고 최종 결정 단계의 세 단계로 구분된다. 각 단계는 응답률과 조사 품질에 중요한 영향을 미치며, 단계별로 다양한 요인이 작용한다.\n접촉 단계에서는 응답자와의 접촉이 가능한지를 판단하며, 이는 조사 성공의 첫 번째 조건이 된다. 이 단계에서는 다음과 같은 요소들이 고려된다. 우선, 자료 수집 기간이 길수록 응답자가 설문 요청을 인지하고 응답할 기회를 가질 가능성이 높다. 또한, 면접자에게 과도한 업무량이 배정되면 개별 응답자와 충분히 접촉하기 어려워져 응답률이 낮아질 수 있다. 면접자의 관찰 능력도 중요한데, 가구의 특성을 빠르게 파악하고 응답 가능성을 예측하는 능력은 조사 효율을 높이는 데 기여한다. 아울러, 통화 시도 횟수와 시점 역시 응답자와의 연결 가능성에 영향을 미치므로, 적절한 시간대에 여러 차례 연락하는 전략이 효과적이다.\n초기 결정 단계는 응답자가 설문 참여 여부를 판단하는 시점으로, 다양한 심리적·환경적 요인이 영향을 미친다. 먼저, 사전 통지는 응답자가 조사에 대한 신뢰를 갖고 사전에 준비할 수 있도록 하여 응답률을 높이는 데 도움을 준다. 금전적 보상이나 선물 등의 인센티브는 설문 참여에 대한 동기를 부여하며, 설문이 지나치게 길거나 인지적 부담이 큰 경우에는 오히려 응답률이 낮아질 수 있다. 가구 내 응답자 선택 규칙이 유연할수록 무응답 가능성이 줄어들며, 면접자가 응답자와 신뢰 관계를 형성할 수 있을 경우 응답률이 높아질 가능성이 크다. 조사 주관 기관이 정부나 공신력 있는 기관인 경우에도 설문에 대한 수용도가 높아지는 경향이 있다. 아울러, 면접자가 응답자의 관심사나 상황에 맞게 대화를 조정하는 능력 역시 긍정적인 영향을 미친다.\n최종 결정 단계는 초기 판단 이후에도 응답을 유도하기 위한 추가 조치들이 이루어지는 시점이다. 예를 들어, 응답자의 선호에 따라 조사 방식을 전화에서 대면으로 전환하는 모드 전환 전략이 있으며, 응답을 얻기 어려운 경우 면접자를 교체하는 방법도 있다. 또한, 설문 참여를 거절한 응답자에게 설득 편지를 보내 다시 참여를 유도하거나, 무응답자를 대상으로 별도의 모집단을 구성하여 이중 단계 표본 추출을 실시하는 방식도 활용된다. 마지막으로, 조사 후 분석 단계에서 무응답으로 인한 통계적 편향을 보정하기 위해 가중치를 조정하는 보정 기법이 적용될 수 있다.\n이와 같이 응답 과정은 단일한 선택의 결과가 아니라, 여러 단계와 다양한 요인이 상호작용한 결과이며, 각 단계에서의 전략적 개입은 전체 조사 품질을 높이는 데 중요한 역할을 한다.\n\n\n(2) 항목 무응답 출이기 단계\n설문 대상자와의 접촉 시도 횟수와 시기는 응답률에 중요한 영향을 미친다. 자기기입식 설문과 조사원이 보조하는 설문 모두에서, 설문 요청을 반복적으로 전달할수록 응답자와 성공적으로 접촉할 가능성이 높아진다.\n전화나 대면 조사의 경우, 응답자와의 접촉 가능성이 높은 시간대는 일반적으로 일요일부터 목요일까지의 저녁 시간대와 주말 낮 시간대이다. 반면, 평일 낮 시간에는 대부분의 가구가 부재 중이므로 연락이 어려운 경우가 많다.\n데이터 수집 기간 역시 응답률에 영향을 준다. 수집 기간이 길수록 응답자가 조사 요청을 인지할 가능성이 높아진다. 예를 들어, 미국 인구 센서스는 약 10일간 진행되며 거의 모든 가구와의 접촉에 성공한다. 이는 적절한 조사원 배치만으로도 비교적 짧은 시간 내에 대부분의 초기 접촉이 가능함을 시사한다.\n조사원의 업무량 또한 중요한 요소이다. 조사원에게 할당된 표본 사례당 충분한 시간이 주어져야 응답자와의 접촉과 설득이 가능하다. 예를 들어, 첫 번째 전화 연락 시도에서 접촉이 성공할 확률은 약 50%에 불과하며, 충분한 시간이 확보되지 않거나 과도한 업무량이 주어진 경우 비접촉이나 설득 부족으로 인한 무응답이 증가할 수 있다.\n조사 후원 기관도 응답 협력률에 영향을 미친다. 대부분의 국가에서 정부 기관이 주관하는 조사에 대한 응답률이 대학이나 민간기관보다 높은 경향을 보인다. 특히 조사 후원 기관이 응답자의 소속 집단이나 가치와 관련이 있을 경우 응답률은 더욱 높아진다. 예를 들어, 회원제로 운영되는 단체가 후원하는 조사에서는 소속 응답자들의 참여 의향이 더 높게 나타난다.\n대면 조사는 조사원이 직접 표본 가구를 관찰할 수 있다는 점에서 강점을 가진다. 예를 들어, 마당에 놓인 장난감을 통해 어린이의 존재를 유추하거나, 이웃을 통해 가구 구성에 대한 정보를 얻을 수 있다. 이러한 관찰 정보는 조사 진행과 관리에 유용하게 활용될 수 있으며, 응답자가 설문에 대한 질문을 하는 경우에는 오히려 응답 의향이 있다는 신호로 해석될 수 있다.\n사전 통지도 응답률에 긍정적인 영향을 준다. 응답자에게 우편이나 이메일로 조사 계획을 미리 안내하면 설문 요청의 신뢰도가 높아지고, 실제로 많은 조사에서 응답률이 향상되는 것으로 나타났다. 특히 대학이나 공공기관이 주관하는 경우 그 효과가 더 크게 나타나며, 반대로 시장 조사기관의 경우 사전 통지가 오히려 응답률을 낮추는 결과를 보이기도 한다.\n인센티브는 응답 동기를 높이는 또 다른 요인이다. 현금 보상이 물품 보상보다 더 효과적인 것으로 나타났으며, 설문 완료 이후보다 요청 이전에 인센티브를 제공할 경우 응답률이 더 높게 나타나는 경향이 있다.\n응답자가 느끼는 부담도 응답률에 영향을 미친다. 설문이 너무 길거나 내용이 복잡하면 참여를 꺼리는 경향이 있으며, 실제로 자기기입식 설문지의 페이지 수가 한 장 늘어날 때마다 응답률이 평균 0.4%포인트 감소한다는 연구 결과도 있다.\n가구 내에서 응답자를 선택하는 방식 또한 응답률에 영향을 미친다. 가능한 모든 성인이 응답할 수 있도록 허용하는 방식은 무작위로 성인을 선정하는 방식보다 응답 협력률이 높다. 또한 대리 응답을 허용하는 경우, 직접 응답만 허용하는 방식보다 높은 응답률을 기록하는 경우가 많다.\n특히 전화 조사에서는 인터뷰어의 초기 소개 방식이 중요하다. 억양이나 말하는 속도 등 미묘한 언어적 특징이 응답자의 협조 의사에 영향을 줄 수 있으며, 조사원이 지나치게 정형화된 소개 문구를 읽는 경우 응답 거부율이 높아진다는 연구 결과도 존재한다.\n응답자와 조사자 간의 신뢰 형성을 위한 적절한 매칭도 응답률을 높이는 전략으로 활용될 수 있다. 예를 들어, 혼자 사는 고령 여성 응답자에게는 보다 연령이 높은 여성 조사자를 배정하는 것이 응답 가능성을 높이는 데 도움이 될 수 있다.\n조사 방식의 변경도 응답률 향상에 기여할 수 있다. 예를 들어, 초기에는 비용 효율성이 높은 우편 설문을 사용하고, 이후 무응답자에게는 대면 조사를 적용하는 혼합 설계가 자주 활용된다. 일반적으로 대면 조사는 전화나 우편 방식보다 응답률이 높은 경향이 있다.\n설문 참여를 처음에 거절한 대상자에게 설문 목적과 중요성을 설명하는 설득 편지를 보내는 방법도 있다. 이 편지는 조사원이 다시 방문하여 질문이나 우려 사항에 답변하겠다는 내용을 포함하며, 응답자의 태도 변화와 협조 가능성을 높이기 위한 전략으로 활용된다.\n\n\n(3) 통계적 기법 활용\n무응답 문제를 해결하기 위해 통계적 분석 기법을 활용한 다양한 방법이 개발되어 왔으며, 특히 무응답자에 대해 새로운 접근 방식을 적용하는 시도들이 주목받고 있다.\n먼저, 이중 단계 표본 추출은 무응답자 중 일부를 확률적으로 다시 추출하여 새로운 방식으로 접촉을 시도하고 응답을 유도하는 방법이다. 이 과정에서 얻은 응답 데이터를 활용하면 전체 무응답자의 특성을 추정할 수 있으며, 이는 무응답 편향을 줄이는 데 효과적으로 활용될 수 있다.\n또한, 조사 후 보정은 기존 응답자의 데이터를 바탕으로 무응답자의 특성을 보정하는 방식이다. 예를 들어, 도시 지역에서 응답률이 낮을 경우, 응답한 도시 지역 표본에 더 높은 가중치를 부여하여 전체 결과의 대표성을 확보하고 편향을 줄이는 방식이 여기에 해당한다.\n이와 같은 통계적 기법들은 무응답에 의한 왜곡을 줄이는 데 중요한 역할을 하지만, 여전히 해결되지 않은 여러 연구 과제가 존재한다.\n예를 들어, 응답을 꺼리는 대상자와의 인터뷰가 성공했을 경우, 이들이 제공하는 응답은 다른 응답자보다 측정 오류가 더 클 가능성이 있는지에 대한 의문이 제기된다. 단순히 응답을 확보하는 것이 아니라, 그 응답의 품질 또한 함께 고려해야 한다는 문제의식이다.\n또한, 응답률을 높이기 위한 노력이 항상 무응답 편향 감소로 이어지는지, 또는 특정 조건에서만 효과적인지에 대한 검토도 필요하다. 응답률 자체가 개선되더라도, 응답자 구성의 대표성이 여전히 확보되지 않는다면 무응답 편향은 여전히 존재할 수 있다.\n비접촉 무응답과 거절 무응답을 줄이기 위한 전략 간의 균형도 중요한 과제이다. 예를 들어, 접촉 가능성을 높이기 위해 여러 차례 시도하는 것은 비접촉 무응답을 줄일 수 있지만, 지나치게 빈번한 연락은 오히려 거절 무응답을 증가시킬 위험이 있다. 두 가지 유형의 무응답 간에 어떻게 자원을 배분할지에 대한 전략적 판단이 필요하다.\n마지막으로, 표본 오차와 무응답 오차를 동시에 고려할 때, 제한된 예산 내에서 응답률을 무조건 극대화하지 않아도 되는 조건은 무엇인지에 대한 논의도 중요하다. 예를 들어, 응답률을 약간 희생하더라도 더 넓은 표본을 확보하거나 다른 품질 보정 기법을 적용하는 것이 전체적으로 더 나은 결과를 낳을 수 있다. 이러한 판단은 조사 설계의 목적, 예산, 대상 모집단의 특성 등을 종합적으로 고려하여 이루어져야 한다.\n\n\n\n\nchapter 5. 항목 무응답 대체\n항목 무응답은 조사 대상자가 전체 설문에는 응답했지만, 일부 질문에만 응답하지 않아 특정 항목의 데이터가 결측되는 경우를 의미한다. 이러한 무응답은 소득이나 건강 상태와 같은 민감한 질문에 대한 기피, 질문 내용을 정확히 이해하지 못한 경우, 응답 과정에서의 실수, 또는 조사자의 착오 등 다양한 이유로 발생할 수 있다.\n항목 무응답은 전체 응답률에는 영향을 미치지 않지만, 특정 변수에 대한 응답이 충분하지 않을 경우 해당 변수에 대한 분석이 제한된다. 특히, 항목 무응답이 많아지면 분석 가능한 표본 수가 줄어들고, 결측된 응답이 특정 집단에 집중될 경우 해당 변수와 관련된 분석 결과에 편향이 발생할 수 있다. 이는 결과의 신뢰성을 저하시킬 수 있으며, 모집단을 대표하는 정확한 추정을 어렵게 만든다. 따라서 항목 무응답의 발생 원인을 이해하고, 적절한 보정이나 결측 처리 방법을 적용하는 것이 중요하다.\n\n1. 가중치 조정\n가중치 조정은 단위 무응답으로 인해 발생하는 대표성 문제를 완화하기 위한 방법 중 하나이다. 이 방법은 응답하지 않은 표본의 특성을 고려하여, 응답자에게 부여된 가중치를 조정함으로써 전체 모집단의 분포를 보다 정확하게 반영하고자 한다.\n조정의 핵심 목적은 응답자 표본이 실제 모집단을 대표할 수 있도록 하는 것이다. 예를 들어, 특정 연령대나 지역의 응답률이 낮은 경우, 해당 집단에 속한 응답자에게 더 높은 가중치를 부여함으로써 전체 분석에서 그 집단의 영향력을 보정할 수 있다. 이를 통해 무응답으로 인한 편향을 줄이고, 통계 결과의 신뢰성과 대표성을 높이는 데 기여할 수 있다.\n\n(1) 후보정 가중치(Post-Stratification Weighting)\n후보정 가중치는 모집단의 이미 알려진 특성을 바탕으로 응답자의 가중치를 조정하는 방법이다. 이 방식은 표본과 모집단 간의 불균형을 수정하여, 분석 결과에 포함될 수 있는 편향을 줄이는 데 목적이 있다.\n후보정에서는 성별, 연령, 지역, 교육 수준 등과 같이 모집단의 분포가 사전에 알려진 보조 변수를 활용한다. 응답자 집단이 특정 보조 변수에서 모집단과 다르게 구성되어 있을 경우, 해당 변수의 분포를 기준으로 가중치를 재조정함으로써 전체 표본이 모집단을 보다 잘 대표하도록 보완할 수 있다. 이 과정은 조사 결과의 신뢰성과 정확성을 높이는 데 중요한 역할을 한다.\n\\(w_{i} = \\frac{N_{g}}{n_{g}}\\) 여기서, \\(w_{i}\\)은 응답자 i 의 새로운 가중치, \\(N_{g}\\)은 모집단 내 해당 그룹 \\(g\\)의 크기, \\(n_{g}\\)은 표본 내 해당 그룹 \\(g\\)의 응답자 수\n즉, 후보정 가중치는 각 그룹의 모집단 비율을 반영하여 응답자의 가중치를 조정하는 방식이다. 이를 통해 표본이 모집단의 구조를 보다 정확하게 반영하도록 한다.\n예를 들어, 모집단에서 성별 비율이 남성 60%, 여성 40%인 상황에서 실제 조사에서는 남성과 여성이 각각 50명씩 조사되었다고 가정하자. 이 경우 표본에서는 남성이 과소표집된 상태이며, 모집단의 실제 분포와 불일치가 발생한다. 이를 보정하기 위해 남성 응답자의 가중치를 증가시키고, 여성 응답자의 가중치를 상대적으로 낮춤으로써 분석 결과가 모집단의 구조에 맞도록 조정할 수 있다. 이와 같은 방식은 무응답이나 표본 추출상의 불균형으로 인한 편향을 줄이는 데 유효한 방법이다.\n\\(w_{\\text{남성}} = \\frac{N_{\\text{남성}}}{n_{\\text{남성}}} = \\frac{60}{50} = 1.2\\), \\(w_{\\text{여성}} = \\frac{N_{\\text{여성}}}{n_{\\text{여성}}} = \\frac{40}{50} = 0.8\\)\n즉, 남성 응답의 영향을 증가시키고 여성 응답의 영향을 감소시켜 모집단의 성별 비율을 반영합니다.\n\n\n(2) 무응답 가중치 조정(Nonresponse Weighting Adjustment)\n무응답 가중치 조정은 응답자의 특성을 기준으로 유사한 무응답자 그룹을 식별한 후, 해당 응답자의 가중치를 조정하여 무응답으로 인한 편향을 보정하는 방법이다. 이 기법은 응답자와 무응답자가 유사한 특성(예: 성별, 연령, 지역 등)을 가진 집단 내에 속해 있다고 가정하고, 그 집단(Strata) 내 응답자의 비율을 활용하여 가중치를 조정한다.\n특히 무응답이 특정 집단에 집중되는 경향이 있을 때 이 방법은 효과적으로 작동한다. 예를 들어, 특정 연령대나 지역에서 응답률이 낮은 경우, 그 집단의 응답자에게 더 높은 가중치를 부여함으로써 전체 표본의 대표성을 회복할 수 있다.\n통계적으로는, 응답자가 설문에 응할 확률인 응답 확률 \\(p_i\\) 를 고려하여 각 응답자의 가중치를 \\(1 / p_i\\) 의 형태로 조정할 수 있다. 이러한 방식은 무응답으로 인한 왜곡을 줄이고, 조사 결과의 정확성과 신뢰성을 높이는 데 기여한다.\n\\(w_{i} = \\frac{1}{p_{i}}\\) 여기서, \\(w_{i}\\)은 응답자 \\(i\\)의 가중치, \\(p_{i}\\) 은 응답 확률 (응답자가 해당 조사에 응답할 확률) 또는, 그룹 \\(g\\) 별 응답률을 고려하여 다음과 같이 가중치를 조정할 수 있다.\n\\(w_{i} = w_{i}^{\\text{기존}} \\times \\frac{1}{{\\widehat{p}}_{g}}\\), 여기서, \\({\\widehat{p}}_{g} = \\frac{n_{g}}{m_{g}}\\) (해당 그룹의 응답률), \\(n_{g}\\) 은 해당 그룹 내 응답자 수, \\(m_{g}\\) 은 해당 그룹 내 전체 표본 수이다.\n예를 들어, 특정 연령대(20대)의 응답률이 낮다고 가정해 보겠습니다. 모집단에서 20대는 1,000명이고, 표본에서는 100명을 선정했지만, 그중 50명만 응답했다면 20대의 응답률은 \\({\\widehat{p}}_{20\\text{대}} = \\frac{50}{100} = 0.5\\) 따라서, 응답자의 가중치는 \\(w_{\\text{20대}} = \\frac{1}{0.5} = 2.0\\)이다. 즉, 20대 응답자의 가중치를 2배 증가시켜 모집단의 특성을 반영하도록 보정한다.\n\n\n\n2. 평균, 중앙값, 최빈값 대체(Mean/Median/Mode Imputation)\n\n(1) 평균 또는 중앙값 대체(Mean/Median Imputation)\n평균 대체는 결측값을 해당 변수의 평균 값으로 대체하는 방법이며, 중앙값 대체는 결측값을 해당 변수의 중앙값으로 대체하는 방식이다. 두 방법 모두 결측값을 단일 값으로 채우는 단순 대체 방식에 속하며, 주로 소득, 나이, 키, 체중과 같은 연속형 변수에 적용된다.\n평균 대체는 전체 응답자의 평균을 활용하므로 데이터의 중심 경향을 반영할 수 있지만, 이상값의 영향을 크게 받을 수 있다는 단점이 있다. 반면, 중앙값 대체는 극단값에 덜 민감하므로 데이터의 분포가 비대칭이거나 이상값이 존재하는 경우 보다 안정적인 대체 방법으로 간주된다.\n이러한 대체 방법은 분석에 사용할 수 있는 표본 수를 늘리는 데는 도움이 되지만, 데이터의 변동성을 과소추정하거나 분산을 왜곡할 수 있으므로 해석에 주의가 필요하다.\n\\(X_{\\text{missing}} = \\frac{1}{n}\\overset{n}{\\sum_{i = 1}}X_{i}\\), \\(X_{\\text{missing}} = \\text{Median}(X_{1},X_{2},\\ldots,X_{n})\\)\n\n\n(2) 최빈값 대체(Mode Imputation)\n최빈값 대체는 결측값을 해당 변수에서 가장 자주 나타나는 값, 즉 최빈값으로 대체하는 방법이다. 이 방법은 성별, 직업, 지역과 같은 범주형 변수에서 주로 사용되며, 다음과 같은 방식으로 표현할 수 있다: \\(X_{\\text{missing}} = \\text{Mode}(X_{1},X_{2},\\ldots,X_{n})\\)\n최빈값 대체는 계산이 간단하고 해석이 명확하다는 장점이 있으나, 모든 결측값을 동일한 값으로 대체하므로 데이터의 분포를 왜곡하거나 변이를 과소추정할 수 있다는 단점도 있다.\n보다 신뢰성 있는 대체를 위해, 전체 데이터를 기반으로 대체하는 대신, 층화변수와 내재적 층화변수(즉, 표본 추출에 사용된 층화 기준)를 결합한 세분화된 층 내에서 최빈값을 계산하여 대체하는 방식이 활용될 수 있다. 이렇게 하면 각 응답자 집단의 특성을 보다 잘 반영할 수 있어, 결측값 대체의 정확성과 타당성이 높아진다.\n\n\n\n3. 핫덱(Hot Deck) 또는 콜드덱(Cold Deck) 대체\n핫덱(Hot Deck)과 콜드덱(Cold Deck) 대체 방법은 결측 데이터를 보완하기 위해 사용되는 대표적인 대체 기법이다. 이들은 무응답자의 값을 유사한 응답자나 외부 데이터로부터 가져와 채워 넣는 방식으로, 특히 설문조사나 표본조사에서 자주 활용된다.\n핫덱 대체는 동일한 조사 내에서 결측값이 있는 응답자와 유사한 특성을 가진 응답자의 값을 이용하여 결측값을 채우는 방법이다. 예를 들어, 연령, 성별, 지역 등이 유사한 응답자 중에서 해당 항목의 값을 가져오는 방식이다. 이 방법은 동일한 데이터셋 내에서 정보를 활용하므로 일관성과 응답 환경의 유사성을 유지할 수 있다는 장점이 있다.\n반면, 콜드덱 대체는 외부의 독립적인 데이터나 과거 조사 데이터를 활용하여 결측값을 보완하는 방식이다. 예를 들어, 이전 조사에서 축적된 데이터를 참조하여 현재 결측된 항목을 채우는 방식이다. 이 방법은 현재 조사에서 해당 값이 확보되지 않은 경우에도 활용이 가능하지만, 자료 간 차이로 인해 편차가 생길 수 있다는 점에 유의해야 한다.\n두 방법 모두 무응답 문제를 해결하고 분석의 완성도를 높이는 데 도움이 되며, 선택 시에는 조사 목적, 데이터 특성, 대체 가능한 정보의 적절성 등을 고려해야 한다.\n\n(1) 핫덱 대체 (Hot Deck Imputation)\n핫덱(Hot Deck) 대체는 현재 조사에서 수집된 응답 데이터를 활용하여 결측값을 보완하는 방법이다. 이 방식은 동일한 조사 내에서 무응답자와 유사한 특성을 가진 응답자를 찾아, 해당 응답자의 값을 결측값에 할당함으로써 데이터를 보완한다.\n핫덱 대체는 주로 성별, 연령, 지역 등과 같은 보조 변수를 기준으로 유사한 응답자를 찾는 방식으로 이루어지며, 두 가지 방식으로 수행될 수 있다. 첫째, 무작위 핫덱(random hot deck) 방식은 유사한 집단 내에서 무작위로 한 응답자를 선택하여 그 값을 결측값에 할당한다. 둘째, 층화 핫덱(stratified hot deck) 방식은 사전에 정의된 층화 기준에 따라 동일한 층 내에서 가장 유사한 응답자를 선택하여 대체한다.\n핫덱 대체는 실제 응답 데이터 기반으로 이루어지므로 현실적인 값이 할당될 가능성이 높고, 응답자의 특성을 고려한 대체가 가능하다는 점에서 비교적 신뢰성이 높은 방법으로 간주된다. 다만, 유사한 응답자를 선정하는 기준과 방식에 따라 대체 결과가 달라질 수 있으므로, 적절한 기준 설정이 중요하다.\n핫덱 대체는 결측값을 유사한 응답자의 값으로 대체한다.\n\\[Y_{\\text{결측값},i} = Y_{\\text{유사},j}\\]\n핫덱 대체에서 유사한 응답자를 선택하는 기준은 결측값을 얼마나 정확하게 보완할 수 있는지를 결정짓는 핵심 요소이다. 일반적으로 다음과 같은 세 가지 방법이 활용된다.\n첫째, 계층적 방법(stratified hot deck)은 성별, 연령, 지역 등과 같은 주요 변수를 기준으로 응답자를 그룹화한 뒤, 동일한 그룹 내에서 유사한 응답자의 값을 결측값에 할당하는 방식이다. 이 방법은 미리 정의된 계층 구조를 활용하여 응답자의 특성을 최대한 반영하려는 목적에 적합하다.\n둘째, 무작위 방법(random hot deck)은 응답자의 특성과 상관없이 동일한 모집단 내에서 임의로 응답자의 값을 선택하여 결측값을 대체하는 방식이다. 이 방법은 간단하고 계산이 빠르지만, 유사성 기준이 적용되지 않아 오차가 발생할 가능성이 있다.\n셋째, 최근접 이웃 방법(nearest neighbor hot deck)은 응답자 간 유사도를 수치적으로 계산한 후, 가장 유사한 응답자를 선택하여 해당 값을 대체하는 방식이다. 이 방법은 응답자 특성을 세밀하게 고려할 수 있다는 장점이 있다.\n예를 들어, 설문조사에서 소득 정보가 결측된 응답자 A가 20대 남성이며 대학을 졸업한 경우, 같은 조사 내에서 동일한 특성을 가진 응답자 B가 소득 정보를 제공했다면, A의 결측값을 B의 소득 값으로 대체할 수 있다. 이처럼 핫덱 대체는 현재 조사 내에서 유사한 응답자의 데이터를 활용하여 결측값을 보완한다는 점에서 실용적이며, 현실적인 응답을 반영할 수 있는 유용한 방법이다.\n\n\n(2) 콜드덱 대체 (Cold Deck Imputation)\n콜드덱(Cold Deck) 대체는 현재 조사 내의 데이터를 활용하는 핫덱 대체와 달리, 외부의 독립적인 데이터원을 활용하여 결측값을 보완하는 방법이다. 이때 활용되는 외부 데이터는 이전에 실시된 조사, 행정자료, 공공 데이터, 또는 기존 연구에서 축적된 정보 등이 될 수 있다.\n콜드덱 대체는 과거 조사에서 수집된 자료 중에서 현재 조사 대상자와 유사한 특성을 가진 응답자의 값을 활용하여 결측된 항목을 대체한다. 이 방식은 데이터의 일관성과 안정성이 유지된다면 핫덱 대체보다 더 신뢰도 높은 결과를 제공할 수 있다. 특히 조사 환경이나 문항 구성이 유사할 경우 효과적이다.\n그러나 콜드덱 방식은 외부 데이터가 오래되었거나 현재의 모집단 특성과 차이가 클 경우, 대체의 정확도가 떨어질 수 있다. 시간의 경과로 인한 사회적 변화나 조사 방식의 차이로 인해 과거 데이터가 현재 상황을 적절히 반영하지 못할 위험이 있기 때문이다.\n결론적으로, 콜드덱 대체는 외부 자료의 품질과 최신성, 그리고 현재 조사와의 정합성 여부에 따라 성과가 달라질 수 있으며, 외부 데이터의 적절성을 충분히 평가한 후 활용하는 것이 중요하다.\n\\[Y_{\\text{결측값},i} = Y_{\\text{이전조사},k}\\]\n예를 들어, 2025년에 실시된 소득 조사에서 일부 응답자의 소득 정보가 누락된 경우, 콜드덱 대체 방법을 활용하여 이전 자료에서 해당 결측값을 보완할 수 있다. 이때 2020년 인구조사와 같은 과거 데이터를 참고하여, 동일한 연령, 성별, 지역에 해당하는 집단의 평균 소득 값을 활용하는 방식이다.\n2025년 조사에서 소득 정보가 누락된 응답자 A가 30대 남성이고 특정 지역에 거주하고 있다면, 2020년 인구조사에서 동일한 특성을 가진 집단의 평균 소득이 4,000만 원으로 나타났을 경우, A의 결측된 소득 값은 4,000만 원으로 대체할 수 있다. 이와 같은 방식은 적절한 외부 자료가 존재하고, 그 자료가 현재 조사와 충분히 유사한 구조를 갖고 있을 때 신뢰성 있는 대체 수단이 될 수 있다.\n\n\n\n4. 모델 기반 대체(Model-Based Imputation)\n모델 기반 대체(Model-Based Imputation)는 통계적 또는 기계 학습 모델을 활용하여 결측값을 예측하는 방법이다. 이 방식은 기존 응답 데이터를 바탕으로 변수 간의 패턴을 학습한 뒤, 무응답자의 결측값을 예측하여 채우는 절차로 이루어진다. 단순한 평균이나 최빈값 대체와 달리, 여러 변수 간의 관계를 고려한다는 점에서 보다 정교하고 유연한 접근이 가능하다.\n대표적인 방법으로는 회귀 대체와 다중 대체가 있다. 회귀 대체는 결측값이 있는 변수를 종속 변수로 설정하고, 다른 관측 가능한 변수들을 독립 변수로 사용하여 회귀모형을 적합시킨 후, 예측값으로 결측값을 대체하는 방식이다. 다중 대체(Multiple Imputation)는 단일 예측값이 아닌, 확률적 방법을 통해 여러 개의 대체값을 생성하고, 각각의 대체된 데이터를 분석한 후 그 결과를 종합하여 최종 추정치를 도출하는 방식이다.\n모델 기반 대체는 복잡한 데이터 구조와 변수 간 상호작용을 반영할 수 있다는 장점이 있으나, 모델의 적합성과 가정에 따라 대체 결과가 달라질 수 있으므로 주의 깊은 검토와 모형 진단이 필요하다.\n\n(1) 회귀 대체(Regression Imputation)\n회귀 대체는 응답자의 데이터를 활용하여 회귀 모형을 구성한 뒤, 이를 바탕으로 무응답자의 결측값을 예측하는 방법이다. 이 기법은 변수 간의 통계적 관계를 이용해 결측값을 보완하며, 예측하려는 변수의 성격에 따라 다른 회귀 모형이 사용된다. 예를 들어, 연속형 변수의 경우에는 선형 회귀를, 범주형 변수의 경우에는 로지스틱 회귀를 적용할 수 있다.\n회귀 대체는 단순한 평균이나 최빈값 대체보다 더 많은 정보를 활용하므로 예측력이 높고, 데이터의 구조를 잘 반영할 수 있는 강력한 대체 방법이다. 하지만 회귀 모형의 성능에 따라 대체 결과가 달라질 수 있으며, 특히 모형이 과적합되는 경우에는 실제보다 과도하게 정확한 예측을 제공하는 듯 보일 수 있어 주의가 필요하다. 따라서 회귀 대체를 사용할 때는 적절한 변수 선택, 교차 검증, 잔차 분석 등을 통해 모형의 타당성을 충분히 점검해야 한다.\n선형 회귀 모델(측정형 무응답)\n연속형 변수가 결측된 경우, 회귀식을 통해 예측한다.\n\\(Y = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\ldots + \\beta_{k}X_{k} + \\epsilon\\), 여기서 \\(Y\\)은 응답자의 값을 사용해 예측할 종속 변수(결측값을 포함하는 변수), \\(X_{1},X_{2},\\ldots,X_{k}\\)은 예측에 사용되는 독립 변수(결측값이 없는 변수들) 회귀 분석을 통해 계수를 추정한 후, 무응답자의 값을 예측값으 로 대체한다.\n\\[Y_{\\text{miss}} = \\widehat{Y} = {\\widehat{\\beta}}_{0} + {\\widehat{\\beta}}_{1}X_{1} + {\\widehat{\\beta}}_{2}X_{2} + \\ldots + {\\widehat{\\beta}}_{k}X_{k}\\]\n예를들어, 설문조사에서 연령, 교육 수준, 직업을 기반으로 소득이 결측된 응답자의 소득을 예측한다고 가정하자. 데이터셋에는 연령, 교육 수준, 직업, 소득 변수가 포함되어 있고 일부 응답자가 소득을 응답하지 않았다면 다음 추정값으로 대체한다. \\(\\widehat{\\text{Income}} = {\\widehat{\\beta}}_{0} + {\\widehat{\\beta}}_{1}\\text{Age} + {\\widehat{\\beta}}_{2}\\text{Education} + {\\widehat{\\beta}}_{3}\\text{Occupation}\\)\n\n\n(2) 다항 로짓회귀모형(범주형 무응답)\n\\[P(Y = j|X) = \\frac{\\exp(X\\beta_{j})}{\\sum_{k = 1}^{J}\\exp(X\\beta_{k})},j = 1,2,\\ldots,J\\]\n\\(P(Y = j|X)\\): 독립 변수 \\(X\\)가 주어졌을 때, 종속 변수가 범주 \\(j\\)를 선택할 확률\n\\(X\\): 예측에 사용되는 독립 변수(결측값이 없는 변수들\n\\(J\\): 가능한 범주의 개수\n\n\n(3) 다중 대체(Multiple Imputation, MI)\n다중 대체(Multiple Imputation)는 결측값을 하나의 예측값으로 대체하는 단일 대체 방법과 달리, 여러 개의 가능한 대체값을 생성하여 결측에 따른 불확실성을 반영하는 방식이다. 단일 대체 방법, 예를 들어 회귀 대체는 하나의 고정된 값을 결측값에 할당하기 때문에 대체값 간의 변동성을 반영하지 못하는 한계가 있다. 반면, 다중 대체는 확률 기반 접근을 통해 서로 다른 대체값을 여러 개 생성하고, 각 대체된 데이터셋에 대해 분석을 수행한 뒤, 그 결과를 통합하여 최종 추정치를 도출한다. 이 과정은 결측으로 인한 통계적 불확실성을 분석 결과에 포함시키는 효과가 있다.\n예를 들어, 개인의 소득(Income), 연령(Age), 교육 수준(Education), 직업(Occupation)을 포함한 설문조사를 수행했을 때 일부 응답자의 소득 정보가 누락되어 결측값이 발생했다고 가정하자. 이 경우, 다중 대체를 적용하면 연령, 교육 수준, 직업 등의 정보를 이용해 소득에 대해 여러 개의 가능한 예측값을 생성할 수 있다. 이후 각 대체값을 포함한 데이터셋으로 동일한 분석을 반복 수행하고, 그 결과를 통합함으로써 보다 신뢰할 수 있고 불확실성이 반영된 추정치를 얻을 수 있다.\n다중 대체는 결측값 처리에서 가장 권장되는 방법 중 하나로, 결측이 분석 결과에 미치는 영향을 최소화하면서도 통계적 일관성을 유지하는 데 효과적인 기법이다. 다중 대체 단계는 다음과 같다.\n1. 대체(Imputation)\n다중 대체는 결측값이 존재하는 데이터를 대상으로 여러 개의 대체값을 생성하는 절차를 포함한다. 이 과정에서는 회귀 분석이나 예측 모델 등 통계적 기법을 활용하여 결측값을 예측하고, 여기에 확률적 오차를 반영함으로써 반복적으로 다양한 대체값을 생성한다.\n예를 들어, 소득 변수에 결측값이 존재하는 경우, 연령, 교육 수준, 직업 등의 변수를 설명 변수로 활용하여 소득을 예측하는 회귀 모형을 구축한다. 이 회귀 모형을 기반으로 확률적 요소를 포함한 예측값을 생성하고, 이를 반복하여 서로 다른 다섯 개의 대체 데이터셋을 만든다. 각 데이터셋은 동일한 결측값에 대해 서로 다른 값을 가지며, 이후 각 데이터셋에 대해 독립적인 분석을 수행한다. 마지막으로 그 결과를 통합함으로써 결측으로 인한 불확실성이 반영된 최종 추정치를 도출할 수 있다.\n이와 같은 방식은 단일 대체에서 발생할 수 있는 과소추정 문제를 보완하고, 보다 신뢰도 높은 분석 결과를 제공하는 데 효과적이다.\n\n\n\n\n\n결측값이 있는 ID 3, 5번의 소득을 5가지 방법으로 대체하여 총 5개의 데이터셋을 생성하여 대체값 추정하였다.\n데이터셋 1: ID 3 → 3,500 / ID 5 → 4,000\n데이터셋 2: ID 3 → 3,800 / ID 5 → 4,200\n데이터셋 3: ID 3 → 3,600 / ID 5 → 4,100\n데이터셋 4: ID 3 → 3,700 / ID 5 → 4,300\n데이터셋 5: ID 3 → 3,900 / ID 5 → 4,500\n2. 분석(Analysis)\n생성된 각 대체 데이터셋을 이용하여 동일한 분석을 수행한다. 각 데이터셋에서 회귀 분석, 평균 추정 등의 통계 분석을 진행한다. 각각의 대체 데이터셋에서 동일한 분석을 수행한다. 예를 들어, 소득과 연령 간의 회귀 분석을 수행하면,\n\n데이터셋 1에서 회귀 계수(β) = 0.25\n데이터셋 2에서 회귀 계수(β) = 0.27\n데이터셋 3에서 회귀 계수(β) = 0.26\n데이터셋 4에서 회귀 계수(β) = 0.28\n데이터셋 5에서 회귀 계수(β) = 0.29\n\n3. 결합(Pooling)\n여러 개의 분석 결과를 결합하여 최종 추정치를 계산한다. 보통 Rubin’s Rules을 사용하여 평균과 표준 오차를 결합한다.\n회귀 계수(β)의 평균 및 표준 오차를 계산: \\(\\overline{\\beta} = \\frac{1}{m}\\overset{m}{\\sum_{j = 1}}\\beta_{j}\\), \\(T = W + \\left( 1 + \\frac{1}{m} \\right)B\\) 여기서, \\(m = 5\\) (대체 데이터셋 개수), \\(W\\) 는 대체 데이터셋 내부의 분산(Within-Imputation Variance), \\(B\\) 는 대체 데이터셋 간의 분산(Between-Imputation Variance)\n최종적으로 회귀 계수(β) = 0.27 ± 0.02로 사용한다.\n\n\n\n5. 최근접 이웃 대체(Nearest Neighbor Imputation)\n응답자 간의 유사성을 바탕으로 결측값을 대체하는 방법은, 결측값을 예측하는 것이 아니라 기존 응답자 중에서 가장 유사한 대상을 찾아 해당 값을 그대로 할당하는 방식이다. 이 방법은 모델 기반 예측이 아닌 실제 데이터 값을 활용하므로, 기존 데이터의 분포를 잘 보존할 수 있다는 장점이 있다.\n무응답자의 특성과 가장 유사한 응답자를 선택하기 위해 거리 기반 알고리즘이 활용되며, 대표적으로 유클리드 거리, 맨해튼 거리, 코사인 유사도 등이 사용된다. 이들 거리 지표는 응답자 간의 특성 차이를 수치적으로 측정하여 가장 가까운 이웃을 찾는 데 사용된다.\n이러한 방식에서 가장 널리 쓰이는 알고리즘은 K-최근접 이웃(K-Nearest Neighbors, KNN) 알고리즘이다. 이 알고리즘은 결측값이 있는 무응답자에 대해, K개의 가장 유사한 응답자를 찾아 그들의 값을 참조하여 대체한다. K가 1인 경우에는 가장 가까운 단일 응답자의 값을 그대로 사용하는 방식이 된다. 이 기법은 연속형 변수와 범주형 변수 모두에 적용이 가능하며, 특히 복수의 예측 변수를 바탕으로 유사도를 정량화할 수 있다는 점에서 유연성이 크다.\n거리계산\n예를 들어, 응답자 i와 j 사이의 유클리드 거리는 다음과 같은 방식으로 계산할 수 있다: \\[d(i,j) = \\sqrt{(X_{i1} - X_{j1})^{2} + (X_{i2} - X_{j2})^{2} + \\ldots + (X_{ik} - X_{jk})^{2}}\\]\n가장 가까운 이웃인 응답자 \\(j^{*}\\) 를 찾고 해당 응답자의 값을 무응답자 \\(i\\) 에게 대체한다. \\(Y_{\\text{결축값},i} = Y_{\\text{유사},j^{*}}\\)\nK-최근접 이웃(K-Nearest Neighbors, KNN) 대체\n최근접 이웃 기반 대체 방법에서는 하나의 이웃만을 사용하는 방식보다, 여러 개의 최근접 이웃(K개의 이웃)을 선택하여 대체값을 산출하는 방식이 보다 안정적인 결과를 제공할 수 있다. 이 접근은 개별 응답자 간의 변동성을 완화하고, 대체값에 대한 신뢰도를 높이는 데 유리하다.\n연속형 변수의 경우, 선택된 K개의 최근접 이웃의 값을 평균하여 결측값을 대체한다. 이 방법은 극단값의 영향을 줄이고, 보다 일반적인 값을 반영할 수 있다는 점에서 효과적이다.\n범주형 변수의 경우에는 K개의 이웃 중 가장 빈번하게 나타나는 값을 선택하여 대체하는데, 이는 최빈값(mode)을 기준으로 결측값을 채우는 방식이다. 이와 같이 최근접 이웃을 복수로 활용하는 K-최근접 이웃(KNN) 대체 방법은 데이터의 유형에 따라 유연하게 적용 가능하며, 단일 이웃 방식보다 일반적으로 더 안정적인 대체 결과를 제공한다.\n\\(Y_{\\text{miss},i} = \\frac{1}{K}\\sum_{j \\in KNN(i)}Y_{j}\\), 여기서 \\(KNN(i)\\)은 무응답자 \\(i\\)와 가장 가까운 \\(K\\)개의 응답자 집합, \\(Y_{j}\\)은 선택된 이웃 응답자의 값이다.\n예를 들어, 설문조사에서 소득(Income) 값이 누락된 응답자 A가 있다고 가정하자.\nA의 특성: 연령: 35세, 교육 수준: 대졸, 직업: 엔지니어\n기존 응답자 중 A와 가장 유사한 가장 가까운 응답자 B, C를 선택 (K=2, KNN방식)\n\n\n\n\n\n\\[{\\widehat{Y}}_{A} = \\frac{4,500 + 4,700}{2} = 4,600\\text{만}\\]\n\n\n6. 기계 학습 기반 대체(Machine Learning Imputation)\n기계 학습 기반 대체는 평균 대체나 핫덱 대체와 같은 전통적인 방식보다 더 정교한 예측 기법을 활용하여 결측값을 보완하는 방법이다. 이 접근은 결측값 예측을 회귀 또는 분류 문제로 간주하고, 머신 러닝 알고리즘을 사용하여 데이터 내의 패턴을 학습한 후 결측값을 예측한다는 점이 특징이다.\n연속형 변수(예: 소득, 키, 체중 등)에 대해서는 회귀(regression) 모델을, 범주형 변수(예: 성별, 직업, 지역 등)에 대해서는 분류(classification) 모델을 사용한다. 대체 과정은 다음과 같이 구성된다:\n\n\n예측 모델 학습: 결측값이 없는 데이터를 이용하여 예측 모델을 학습시킨다.\n결측값 예측: 학습된 모델에 결측이 존재하는 데이터를 입력하여 결측값을 예측한다.\n결측값 보완: 예측된 값을 실제 결측값에 대체함으로써 데이터셋을 보완한다.\n\n\n이러한 방식에 활용되는 대표적인 알고리즘으로는 랜덤 포레스트(Random Forest), K-최근접 이웃(K-Nearest Neighbors, KNN), 그리고 신경망(Neural Networks) 등이 있으며, 각각의 알고리즘은 변수의 특성 및 데이터 구조에 따라 다양한 방식으로 결측값 보완에 활용될 수 있다.\n기계 학습 기반 대체는 데이터의 구조를 충분히 반영하여 보다 정밀한 대체값을 제공할 수 있으며, 특히 다변량 데이터 환경에서 효과적인 결측값 처리 방법으로 평가받는다.\n\n(1) 랜덤 포레스트 기반 대체 (Random Forest Imputation)\n랜덤 포레스트는 여러 개의 결정 트리(Decision Tree)를 앙상블하여 예측하는 모델로, 결측값을 예측할 때 기존 응답자의 데이터를 활용하여 랜덤 포레스트 회귀 또는 분류 모델을 학습한 후, 이를 바탕으로 결측값을 예측한다.\n결측값이 연속형 변수일 경우 → 회귀(Random Forest Regression) 모델을 이용해 예측된 평균값으로 대체 결측값이 범주형 변수일 경우 → 분류(Random Forest Classification) 모델을 이용해 가장 자주 등장한 값(다수결)으로 대체\n이 방식은 다음과 같은 절차로 진행된다:\n\n\n결측값이 없는 데이터를 사용해 랜덤 포레스트 모델을 학습한다.\n결측값이 존재하는 관측치에 대해 예측 수행한다.\n예측된 값을 해당 결측 셀에 대체한다.\n\n\n이 방법은 변수 간 상호작용이나 비선형 관계를 잘 포착할 수 있으며, 기존 데이터의 분포를 유지하면서도 예측 정확도를 높이는 데 효과적이다.\n\\(\\widehat{Y} = \\frac{1}{T}\\overset{T}{\\sum_{t = 1}}f_{t}(X)\\), 여기서, \\(T\\) 랜덤 포레스트에서 사용된 결정 트리의 개수, \\(f_{t}(X)\\)은 각 트리에서의 예측값, \\(\\widehat{Y}\\)은 최종 대체값 (회귀: 평균, 분류: 다수)\n예를 들어 소득 변수에 결측값이 존재하는 경우, 랜덤 포레스트 회귀(Random Forest Regression)를 활용하여 이를 대체할 수 있다. 이 방법은 먼저 소득 값이 결측되지 않은 응답자들의 데이터를 이용해 예측 모델을 학습하는 것으로 시작된다. 이때 소득을 예측하기 위한 독립 변수로는 응답자의 연령, 교육 수준, 직업 등이 사용된다. 학습된 랜덤 포레스트 모델은 다수의 결정 트리(decision tree)로 구성되어 있어, 변수들 간의 복잡한 관계를 효과적으로 포착할 수 있다.\n이후, 소득 값이 결측된 응답자에 대해 해당 응답자의 연령, 교육 수준, 직업 정보를 모델에 입력하면, 랜덤 포레스트는 이를 바탕으로 해당 응답자의 소득을 예측하게 된다. 마지막으로, 이렇게 예측된 값을 원래 결측되어 있던 소득 항목에 대체함으로써 데이터를 보완한다.\n이와 같은 방식은 단순히 평균이나 중앙값으로 대체하는 방법보다 예측 정확도가 높고, 데이터의 구조적 특성을 반영할 수 있다는 장점이 있다. 또한 랜덤 포레스트는 이상값에 강하고 과적합 위험이 낮아, 결측값 보완을 위한 실무적 대안으로 널리 사용된다.\n\n\n(2) K-최근접 이웃(KNN) 기반 대체 (K-Nearest Neighbors Imputation)\nKNN 기반 대체(K-Nearest Neighbors Imputation)는 결측값이 있는 관측치에 대해, 해당 관측치와 유사한 특성을 가진 다른 관측치들을 찾아 그 정보를 이용해 결측값을 보완하는 기계 학습 기반 방법이다. 기본 개념은 전통적인 최근접 이웃 대체 방식과 유사하지만, KNN 알고리즘의 특성을 활용하여 보다 정교하고 자동화된 방식으로 수행된다는 점에서 차별화된다.\n이 방법에서는 먼저 결측값이 없는 관측치를 기준으로, 결측값이 포함된 관측치와의 거리를 계산한다. 거리 측정에는 유클리드 거리, 맨해튼 거리, 마할라노비스 거리 등 다양한 지표가 사용될 수 있으며, 변수 간 스케일 차이를 보정하기 위해 정규화(normalization)를 적용하기도 한다.\n그 후, 계산된 거리값을 기준으로 가장 가까운 K개의 관측치를 선택한다. 이때 K 값은 교차검증(cross-validation) 등을 통해 최적의 값을 자동으로 결정할 수 있으며, 고정된 값이 아닌 데이터 구조에 맞게 유연하게 설정된다.\n결측값이 연속형 변수인 경우에는 K개의 이웃값의 평균이나 중앙값을 사용하여 대체하며, 범주형 변수인 경우에는 가장 자주 등장하는 값(최빈값, mode)을 사용한다.\n예를 들어, 어떤 응답자의 소득 정보가 결측된 상황에서 그 사람의 연령, 직업, 교육 수준 등이 다른 응답자와 유사하다면, 이와 유사한 응답자 K명을 찾아 이들의 소득 평균으로 결측값을 대체한다. 이렇게 하면 개별 응답자의 맥락을 반영한 대체가 가능해져, 보다 정확하고 현실적인 결측값 보완이 가능해진다.\nKNN 기반 대체는 연속형 변수와 범주형 변수 모두에 적용 가능하고, 데이터 분포를 유지하면서도 단순 대체 방식보다 유연하고 정밀한 보완이 가능하다는 점에서 강력한 결측 대체 기법으로 평가된다.\n\\(Y_{\\text{miss},i} = \\frac{1}{K}\\sum_{j \\in KNN(i)}Y_{j}\\), 여기서 \\(KNN(i)\\)은 무응답자 \\(i\\) 와 가장 가까운 \\(k\\) 개의 응답자 집합,\\(Y_{j}\\)은 선택된 이웃 응답자의 값이다.\n예를 들어, 어떤 응답자의 키(height)가 결측된 상황을 가정해 보자. 이때 KNN 기반 대체 방법을 적용하면 다음과 같은 절차로 결측값을 보완할 수 있다.\n먼저, 기존 응답자들의 연령(Age), 체중(Weight), 성별(Gender) 등의 정보를 활용하여 결측된 응답자와의 거리를 계산한다. 이때 거리 계산은 유클리드 거리와 같은 수학적 기준을 사용하며, 변수들의 척도 차이를 보정하기 위해 표준화가 선행될 수 있다.\n그다음, 계산된 거리값을 바탕으로 가장 가까운 K명의 응답자를 선택한다. 이웃 수 K는 사전에 지정하거나 교차검증을 통해 결정할 수 있으며, 일반적으로 3명 또는 5명 등의 값이 많이 사용된다.\n선정된 K명의 응답자 중 키(height) 정보가 결측되지 않은 사람들의 키 값을 평균 내어, 해당 평균값을 결측된 응답자의 키 대신 입력한다. 이를 통해 결측값은 유사한 특성을 가진 집단의 평균을 반영한 값으로 대체되며, 데이터의 구조적 일관성을 유지할 수 있다.\n이러한 방식은 단순 평균 대체보다 개별 응답자의 맥락을 반영할 수 있다는 점에서 통계적 타당성과 해석 가능성을 동시에 확보할 수 있다.\n\n\n(3) 신경망(Neural Network) 기반 대체\n신경망을 활용한 결측값 대체는, 특히 변수 간 관계가 복잡하고 비선형적인 경우에 효과적인 방법이다. 이때 주로 사용되는 구조는 다층 퍼셉트론(MLP, Multi-Layer Perceptron)으로, 입력층(input layer), 하나 이상의 은닉층(hidden layer), 그리고 출력층(output layer)으로 구성된다.\n결측값 대체를 위한 일반적인 절차는 다음과 같다.\n1. 데이터 전처리\n먼저, 결측값이 없는 관측값을 기반으로 입력 변수(예: 연령, 성별, 직업 등)와 타겟 변수(예: 소득, 키, 체중 등)를 분리하여 모델 학습용 데이터를 구성한다. 변수 간 범위 차이가 클 경우에는 정규화(normalization) 또는 표준화(standardization)를 통해 모델 학습을 안정화시킨다.\n2. 신경망 모델 학습\n전처리된 데이터를 이용해 신경망 모델을 학습시킨다. 이 과정에서 모델은 입력 변수와 타겟 변수 간의 비선형 관계를 반복적으로 학습하면서, 결측된 값을 예측할 수 있는 패턴을 습득한다. 역전파(backpropagation) 알고리즘과 옵티마이저(예: Adam, SGD)를 활용해 가중치를 조정하며 학습을 진행한다.\n3. 결측값 예측 및 대체\n학습된 모델을 사용하여 결측이 발생한 관측값의 입력 변수들을 모델에 넣고, 해당 타겟 변수(결측된 값)를 예측한다. 이렇게 생성된 예측값을 원래 데이터의 결측값에 대체하여 보완한다.\n예를 들어, 어떤 응답자의 체중 데이터가 누락된 경우, 신경망은 동일한 조사에서 얻은 연령, 키, 성별 등의 정보를 활용하여 체중을 예측하고, 그 값을 해당 응답자의 결측값에 입력한다.\n이 방식은 단순 대체 방법에 비해 학습 기반의 정교한 예측을 제공하며, 특히 변수 간 관계가 복잡한 대규모 데이터셋에서 우수한 성능을 발휘할 수 있다.\n신경망은 다층 퍼셉트론(MLP)을 기반으로 가중치 \\(w\\)를 최적화하여 결측값을 예측한다.\n\\(Y_{\\text{miss}} = f(WX + b)\\) 여기서, \\(f\\)은 활성화 함수(예: ReLU, Sigmoid), \\(W\\)은 가중치, \\(X\\)은 입력 변수, \\(b\\)는 편향이다.\n예를 들어, 건강 관련 조사에서 일부 응답자의 BMI(체질량지수) 정보가 누락된 경우, 신경망을 이용해 이 결측값을 보완할 수 있다. 이때 먼저 BMI와 밀접하게 관련된 변수들, 예컨대 연령, 체중, 성별, 운동 습관 등의 데이터를 활용하여 신경망 모델을 학습시킨다.\n모델 학습이 완료되면, BMI가 결측된 응답자에 대해 해당 변수들을 입력하여 BMI를 예측한다. 이렇게 예측된 BMI 값은 결측된 위치에 삽입되어 데이터셋을 보완하게 된다. 이 과정은 단순히 평균이나 중앙값을 넣는 방식보다 더 정밀하게 데이터의 패턴을 반영할 수 있다는 장점이 있다.\n\n\n\n7. 재조사 및 보완 조사(Follow-up Survey & Call-back)\n재조사 및 보완 조사(Follow-up Survey & Call-back)는 최초 조사에서 응답하지 않은 대상자에게 다시 연락하여 실제 응답을 확보하는 전략이다. 이 방법은 단순히 통계적 기법으로 결측값을 대체하는 방식과 달리, 응답자에게 직접 접근하여 응답을 얻는다는 점에서 데이터의 정확성과 신뢰도를 크게 향상시킨다.\n이러한 접근은 특히 정부 통계, 보건의료 연구, 선거 여론 조사처럼 정책 결정이나 사회적 영향력이 큰 조사에서 중요하게 활용된다. 보완 조사는 전화, 이메일, 방문 등의 다양한 방식으로 수행되며, 무응답 편향을 줄이고 대표성을 높이는 데 기여한다. 또한, 재조사를 통해 무응답자의 특성과 응답행태를 파악할 수 있어 향후 조사 설계의 개선에도 유용하다.\n후속 조사(Follow-up Survey)\n후속 조사는 초기 조사에서 응답하지 않은 대상자에게 다시 연락하여 응답을 유도하는 방식으로, 무응답률을 낮추고 조사 결과의 신뢰도를 높이는 데 중요한 역할을 한다. 이러한 후속 조사는 다양한 형태로 이루어질 수 있다.\n가장 일반적인 방법 중 하나는 전화 재조사(call-back survey)이다. 이는 초기 연락에서 응답을 얻지 못한 대상자에게 다시 전화를 걸어 설문 참여를 요청하는 방식이다. 전화 재조사는 비교적 빠르게 응답을 확보할 수 있는 장점이 있으며, 응답자의 부담이 적을 경우 응답률이 높아질 가능성이 크다.\n또 다른 방법으로는 이메일이나 문자 메시지를 활용한 독려(contact reminder)가 있다. 설문 링크나 마감일, 간단한 조사 목적을 포함한 메시지를 전송함으로써 대상자에게 설문 참여를 다시 상기시키는 방식이다. 이 방법은 시간과 비용이 적게 들고, 자기기입식 조사와 같이 비접촉 방식의 설문에서 특히 효과적이다.\n보다 적극적인 방식으로는 대면 방문(face-to-face interview)이 있다. 이는 조사원이 직접 대상자의 집을 방문하여 설문에 응하도록 요청하는 방식으로, 인구총조사나 국가 단위의 중요 조사에서 주로 활용된다. 응답자가 조사원과 직접 대화하면서 설문에 참여할 수 있어 응답률을 크게 향상시킬 수 있는 반면, 시간과 비용 부담이 크다는 단점이 있다.\n예를 들어, 선거 여론조사에서 초기 응답률이 낮은 경우, 조사 기관은 응답하지 않은 대상자에게 다시 전화를 걸거나 문자 메시지를 보내 설문 참여를 유도할 수 있다. 이러한 후속 조치를 통해 조사에 대한 응답을 확보하고, 조사 결과의 대표성과 신뢰성을 제고할 수 있다.\n보완 조사(Supplementary Survey)\n기존 조사 방식과는 다른 대체 수단을 활용하여 무응답자에게서 응답을 확보하는 방식은, 조사 대상자의 편의성과 접근성을 고려하여 설계된 전략이다. 이는 조사 모드 변경(mode switch) 또는 혼합 모드 설계(mixed-mode design)로도 불리며, 특정 조사 방식에 대한 응답자의 선호나 제약을 고려해 유연하게 대응할 수 있다는 장점이 있다.\n예를 들어, 전화 설문을 중심으로 한 의료 연구에서 응답률이 낮은 경우, 조사자는 대상자에게 우편 설문지를 보내거나, 온라인 응답 링크를 제공하여 다른 방식으로 응답할 수 있는 기회를 부여할 수 있다. 이는 시간대나 장소, 개인적 선호 등 다양한 이유로 기존 조사 방식에 응답하지 못한 사람들에게 효과적인 대안이 될 수 있다.\n이러한 보완 조사를 통해 확보된 응답 데이터는 원래 조사 데이터와 결합되어 분석되며, 이는 전체 데이터의 완전성을 높이고 무응답 편향을 줄이는 데 기여한다. 단, 조사 방식이 다를 경우 질문 해석이나 응답 방식의 차이로 인해 모드 효과(mode effect)가 발생할 수 있으므로, 결합 시에는 적절한 통계적 조정이 필요할 수 있다.\n\n\n8. 데이터 결합(Data Fusion)\n기존 조사 방식과는 다른 대체 수단을 활용하여 무응답자에게서 응답을 확보하는 방식은, 조사 대상자의 편의성과 접근성을 고려하여 설계된 전략이다. 이는 조사 모드 변경(mode switch) 또는 혼합 모드 설계(mixed-mode design)로도 불리며, 특정 조사 방식에 대한 응답자의 선호나 제약을 고려해 유연하게 대응할 수 있다는 장점이 있다.\n예를 들어, 전화 설문을 중심으로 한 의료 연구에서 응답률이 낮은 경우, 조사자는 대상자에게 우편 설문지를 보내거나, 온라인 응답 링크를 제공하여 다른 방식으로 응답할 수 있는 기회를 부여할 수 있다. 이는 시간대나 장소, 개인적 선호 등 다양한 이유로 기존 조사 방식에 응답하지 못한 사람들에게 효과적인 대안이 될 수 있다.\n이러한 보완 조사를 통해 확보된 응답 데이터는 원래 조사 데이터와 결합되어 분석되며, 이는 전체 데이터의 완전성을 높이고 무응답 편향을 줄이는 데 기여한다. 단, 조사 방식이 다를 경우 질문 해석이나 응답 방식의 차이로 인해 모드 효과(mode effect)가 발생할 수 있으므로, 결합 시에는 적절한 통계적 조정이 필요할 수 있다.\n정확한 키 매칭(Exact Matching)\n유일한 식별자(Unique Identifier)를 활용한 데이터 결합 방식은 가장 정밀하고 신뢰도 높은 방법으로, 주민등록번호, 사업자등록번호, 학생번호 등 각 개인 또는 단위를 고유하게 식별할 수 있는 정보를 기반으로 서로 다른 데이터셋을 연결한다.\n이 방식의 핵심 장점은 데이터 간 연결 정확도가 매우 높다는 점이다. 예를 들어, 인구조사 데이터와 국세청의 소득 신고 자료를 주민등록번호를 기준으로 결합하면, 설문에서 소득 정보를 응답하지 않은 무응답자의 소득 데이터를 행정 기록을 통해 보완할 수 있다. 마찬가지로, 환자의 건강 관련 설문조사 데이터를 건강보험청구자료와 연결하면 병원 방문 이력이나 치료 내역을 확인할 수 있어, 설문 응답 외에 객관적 행태 정보를 확보할 수 있다.\n하지만 이러한 방식은 개인정보 보호 측면에서 큰 주의가 필요하다. 유일 식별자를 직접 사용하는 경우, 개인 식별 가능성이 매우 높아지므로, 법적·윤리적 제한이 뒤따르며, 데이터 마스킹이나 가명 처리 등의 조치가 필요하다. 따라서, 이 방식은 통상적으로 통계청, 건강보험공단 등 공공기관이 보안 체계 하에 한정적으로 운영하거나, 연구 목적에 따라 엄격한 심사를 거친 후에만 사용된다."
  },
  {
    "objectID": "notes/survey/sample_design.html",
    "href": "notes/survey/sample_design.html",
    "title": "조사방법론. 2. 표본설계",
    "section": "",
    "text": "chapter 1. 표본설계 개요\n표본 설계는 설문조사가 모집단의 특성을 신뢰성 있고 효율적으로 반영하며 조사 목적을 충실히 달성하기 위해 필요한 핵심 과정이다.\n설문조사의 주요 목적은 모집단 전체의 특성을 이해하거나 추론하는 것이다. 그러나 모집단의 모든 구성원을 조사하는 것은 현실적으로 어렵기 때문에, 이를 대체할 수 있는 대표 표본을 구성하는 과정이 필수적이다. 표본 설계를 통해 모집단의 다양한 특성을 균형 있게 반영할 수 있으며, 이는 신뢰할 수 있는 통계 추정의 기반이 된다.\n표본이 특정 집단에 치우치거나 무작위성이 확보되지 않는다면 조사 결과는 왜곡될 수 있다. 표본 설계는 모집단의 모든 하위 그룹이 적절히 포함되도록 구성하여 편향을 방지하고, 통계적 균형을 유지하는 데 기여한다.\n또한, 표본 설계는 조사 자원을 효율적으로 사용하는 데 중요한 역할을 한다. 제한된 시간과 예산 안에서 필요한 정확도를 확보하기 위해, 층화 표본이나 군집 표본 등 다양한 표본 추출 방법이 활용된다. 이는 조사 비용을 절감하면서도 충분한 정보를 얻을 수 있도록 돕는다.\n표본이 체계적으로 설계되면 통계적 편향과 오차가 줄어들고, 결과적으로 조사 결과의 신뢰성이 향상된다. 이는 조사 데이터를 기반으로 한 정책 수립이나 연구 분석의 질을 높이는 데 직접적인 영향을 미친다.\n마지막으로, 설문조사는 특정 하위 집단에 대한 통찰을 요구하는 경우가 많다. 표본 설계를 통해 특정 집단을 적절히 포함하거나 과대표함으로써, 해당 집단에 대한 정밀한 분석이 가능해진다. 이를 통해 보다 세분화된 해석과 의사결정이 이루어질 수 있다.\n\n1. 용어\n모집단 population\n조사를 할 때 정보를 얻고자 하는 관심 집단, 즉 관심 대상이 되는 모든 사람들의 모임을 모집단이라고 한다.\n\n목표 모집단은 조사 대상 전체를 의미하며, 조사 시점 기준의 유권자가 이에 해당한다.\n조사 모집단은 실제로 조사가 가능한 모집단으로, 예를 들어 전화번호부 CD에 등재된 유권자가 이에 해당한다.\n모수는 모집단의 관심 특성을 의미하며, 예를 들어 A 후보에 대한 지지율이 이에 해당한다.\n\n표본 sample\n모집단 중 조사를 위하여 추출한 일부를 표본이라고 한다. 추정량은 모수를 추정하기 위하여 표본으로부터 계산된 통계량이며, 이를 통계량(statistic)이라고도 한다. 예를 들어, 표본 1,000명 중 A 후보를 지지하는 사람이 560명이라면, A 후보의 지지율에 대한 추정량은 56%이다.\n표본 프레임 sample frame\n표본을 추출하기 위해 모집단 대상을 식별하고, 컨택(contact)에 필요한 정보를 포함한 목록을 말한다. 일반적으로 식별 아이디, 이름, 주소, 연락처 등으로 구성된다. 예를 들어 전화번호 CD를 활용한 조사에서는 해당 가구의 가구원 정보를 알 수 없기 때문에, 조사원이 “최근 생일이 지난 유권자”를 선정하거나, 현장에서 할당 인원을 조정하며 가구원 중 한 명을 조사 대상으로 선정한다. 표본프레임의 3가지 요건은 다음과 같다.\n\n\n포괄성: 표본프레임은 조사 가능한 대상을 모두 포함하고 있어야 한다.\n추출 확률의 동일성: 모집단의 각 구성원이 표본으로 추출될 확률이 동일해야 한다.\n효율성: 사전에 조사되기를 바라는 사람들로만 표본프레임을 구성하는 것은 불가능하지만, 가능한 한 조사 목적에 부합하는 대상이 추출되도록 효율성을 고려한다.\n\n\n표본추출: 표본추출은 조사 대상인 표본을 모집단으로부터 확률적으로 선택하는 과정이며, 조사 목적을 최대한 달성할 수 있도록 설계되어야 한다.\n표본 크기: 표본 크기는 조사의 신뢰수준, 표본추출 방법, 허용오차(예: 변동계수) 등을 고려하여 결정한다.\n조사단위\n\n표본추출단위: 표본을 추출하는 기본 단위. 예를 들어 전화여론조사의 경우 ’가구’가 해당된다.\n\n\n조사단위: 실제로 응답하는 사람. 대부분의 경우 표본추출단위와 조사단위는 일치하지만, 다른 경우도 존재한다. (상이한 경우) 전화여론조사에서 가구를 추출한 뒤, 그 안의 가구원 중 한 명이 응답하는 경우 (동일한 경우) 인터넷 쇼핑몰 이용 고객 실태조사에서 고객 자체가 추출단위이자 조사단위인 경우\n\n\n\n2. 표본과 추정\n모든 설문조사 표본이 확률적 방법으로 선택되는 것은 아니다. 많은 설문조사는 즉흥적으로 표본을 구성하거나, 조사 목적에 부합하도록 표본을 선택한다. 예를 들어, 쇼핑몰에 방문하는 사람들에게 설문 응답을 요청하고, 일정 수의 인터뷰가 완료될 때까지 조사를 계속 진행하는 경우가 있다. 이러한 즉흥적 또는 편의 표본추출 방법에는 공통된 약점이 존재하는데, 바로 모집단의 특성을 설명하기 위한 이론적 기반이 부족하다는 점이다. 이에 반해, 확률 표본추출은 단일 표본으로부터 모집단에 대해 통계적으로 유의미한 진술을 할 수 있는 기반을 제공하며, 일정한 신뢰 수준에서 추론이 가능하다는 장점이 있다.\n외식비용 가구 설문조사의 프레임 모집단은 전화 서비스를 이용하는 모든 가구의 성인을 포함한다. 외식비의 전체 분포를 관찰하거나 완벽히 알 수는 없다. 설문조사는 이러한 분포를 알아내기 위해 수행된다. 모집단 개별 개체는 \\(Y\\)로 표시하고 모집단 평균은 \\(\\overline{Y}\\), 모집단 분산 \\(S^{2}\\)으로 표현하고 설문조사의 주목적은 \\(\\overline{Y}\\)를 추정하는 것이다.\n각 설문조사는 여러 가지 발생 가능한 확률 표본 설계 중 하나의 실현으로 간주될 수 있다. 표본 조사 결과는 소문자를 사용하여 표현한다. 표본 관측값 \\(y\\) 값은 모집단 분포에 대한 평균과 분산을 가지고 있다. 표본평균은 \\(\\overline{y}\\)로 불리며 이를 이용하여 \\(\\overline{Y}\\)를 추정한다. \\(y_{i}\\) 관측값의 표본분산은 \\(s^{2}\\)으로 표시된다.\n표본평균의 표집 분포 분산을 추정하기 위해 하나의 표본 실현에서 계산을 사용하여 \\(V(\\overline{y})\\)를 추정한다. 표본평균의 표집 분포 분산의 또 다른 용어는 ”표본평균의 표본분산”이며 그 제곱근은 ”평균의 표준오차”라고 한다.\n주어진 표본 조사(하나의 실현)에서 프레임 모집단 평균을 추정하고자 할 때, 표준오차를 사용하여 주어진 추정치에 대한 신뢰 구간을 설정한다. ”신뢰구간”은 모든 표본 실현에서 계산된 평균이 전체 프레임 모집단 평균으로부터 일정한 거리 내에 있을 신뢰 수준을 설명한다(포괄성, 비응답 및 기타 설문 조사 오류를 무시한 경우).\n예를 들어, 소비자 조사에서 표본 외식비 평균을 \\(\\overline{y} = 42\\)(천원)로 추정했다고 가정하자. 이 추정치의 표준오차를 2(천원)으로 추정 했다면, 95% 신뢰구간은 (42 - 2*2, 42 + 2*2) = (38, 46)가 된다.\n표본통계의 표준오차는 동일한 설계에서 가능한 표본 실현들 간의 통계적 분포 또는 변동성을 측정하는 지표이다. 표준오차는 \\(se(\\overline{y}) = \\sqrt{v(\\overline{y})}\\) 이며, 표본분산의 제곱근으로 계산된다.\n\n\n\n\n\n\n\n\n\n구분\n모집단 분포\n표본 분포\n표본평균 분포\n\n\n\n\n현황\n실현된 분포\n모름\n모름\n\n\n크기\n\\[i = 1,2,...,n\\]\n\\[i = 1,2,...,N\\]\n\\[s = 1,2,...,S\\]\n\n\n개별 원소\n\\[y_{i}\\]\n\\[Y_{i}\\]\n\\[{\\overline{y}}_{s}\\]\n\n\n평균\n\\[\\overline{y}\\]\n\\[\\overline{Y}\\]\n\\[E({\\overline{y}}_{s})\\]\n\n\n분포 분산\n\\[s^{2}\\]\n\\[S^{2}\\]\n\\[V(\\overline{y})\\]\n\n\n표준오차\n\\[s\\]\n\\[S\\]\n\\[se(\\overline{y})\\]\n\n\n\n샘플링으로 인한 오류의 정도는 설계의 네 가지 기본 원칙에 의해 결정된다.\n\n선택된 표본의 크기.\n다른 모집단 요소가 표본에 선택될 가능성.\n개별 요소가 독립적으로 또는 그룹(요소 또는 클러스터 샘플로 불리는) 내에서 선택되었는지 여부\n표본이 샘플 내 주요 하위 모집단(층화)의 대표성을 제어하도록 설계되었는지 여부\n\n\n\n3. 표본설계 절차\n\n(1) 조사 목표 모집단 정의\n조사의 출발점은 명확한 조사 목표를 설정하는 것이다. 이는 어떤 주제에 대해 누구를 대상으로 정보를 수집할 것인지를 규정하는 단계이다. 예를 들어, 고객 만족도를 평가하거나 특정 지역의 유권자 여론을 파악하고자 할 때, 각각의 조사 목적에 따라 관심 대상이 되는 모집단이 달라진다. 따라서 조사 목표에 부합하는 모집단을 명확히 정의하는 것이 설계 과정의 핵심이다.\n\n\n(2). 모집단 정의 및 분석\n조사 목표가 설정되면, 그에 따라 모집단의 범위를 명확히 정의해야 한다. 모집단이란 조사 대상이 되는 전체 집단으로, 예를 들어 특정 연령대의 고객이나 특정 지역의 거주자 등이 이에 해당한다. 모집단을 정의한 후에는 그 특성을 구체적으로 파악하는 작업이 필요하다. 모집단의 크기, 인구 구성, 지리적 분포와 같은 정보는 표본 설계의 기초가 되며, 이러한 분석을 통해 조사 대상의 대표성을 확보할 수 있다. 모집단에 대한 충분한 분석은 조사 과정 전반의 신뢰성을 높이며, 궁극적으로 정확하고 의미 있는 조사 결과를 도출하는 데 필수적인 단계이다.\n\n\n(3). 표본 프레임 정의\n표본을 추출하기 위해서는 먼저 모집단을 대표할 수 있는 표본 프레임을 정의해야 한다. 표본 프레임은 모집단의 구성원을 식별하고 접근할 수 있도록 구성된 명단이나 데이터베이스로, 예를 들어 고객 리스트, 유권자 명부, 전화번호 디렉터리 등이 이에 해당한다.\n표본 프레임이 조사 목적에 부합하려면 그 정확성과 적절성을 면밀히 평가해야 한다. 프레임이 모집단 전체를 충분히 포괄하고 있는지, 동일한 대상이 중복 포함되어 있지는 않은지, 정보가 최신 상태로 유지되고 있는지 등을 점검하는 과정이 필요하다. 이러한 검토를 통해 불포함 오류나 중복 오류와 같은 표본 추출상의 문제를 최소화할 수 있다.\n\n\n(4). 표본 설계 유형 선택\n표본 설계는 조사 목표와 모집단의 특성에 따라 가장 적합한 추출 방법을 선택하는 과정이다. 이는 조사 결과의 신뢰성과 대표성을 확보하기 위한 핵심 단계로, 단순 무작위추출, 층화추출, 집락추출, 다단계추출 등 다양한 방법 중에서 조사 상황에 맞는 방식을 선택하게 된다. 적절한 표본 설계 유형을 선택하기 위해서는 모집단의 이질성 여부, 표본 프레임의 구조, 예산 및 시간 제약 등 여러 요소를 종합적으로 고려해야 한다.\n\n\n(5). 표본 크기 결정\n표본의 크기는 조사 결과의 정밀도와 신뢰도를 확보하는 데 직접적인 영향을 미치므로 신중하게 결정되어야 한다. 표본크기는 조사 목적, 허용 오차, 신뢰 수준, 모집단의 변동성, 그리고 예산 및 시간 제약 등을 종합적으로 고려하여 산정한다.\n\n\n(6). 표본 추출\n표본 추출은 사전에 설계된 표본 설계 유형에 따라 모집단에서 실제 표본을 선택하는 과정이다. 이 과정에서는 주관적 판단이 개입되지 않도록 무작위성을 철저히 확보해야 하며, 이는 추후 통계적 추론의 타당성을 담보하는 핵심 요건이다.\n\n\n(7). 조사 및 데이터 수집\n표본으로 선정된 대상에게 설문조사, 전화 인터뷰 등 다양한 방법을 통해 자료를 수집한다. 높은 응답률을 확보하기 위해 조사 전 사전 안내를 실시하고, 비응답자에 대해서는 추후 연락을 계획하는 등 응답 유도를 위한 전략이 병행된다.\n\n\n(8). 자료 분석 및 결과 검토\n수수집된 데이터를 분석하여 모집단의 특성을 추정한다. 분석 과정에서는 표본 설계에 따른 가중치를 적용하여 편향을 보정하고, 설계 효과(design effect)를 산출함으로써 표본 설계가 추정 결과에 미친 영향을 평가한다.\n\n\n(9). 결과 보고\n분석 결과는 조사 목적에 맞게 해석하여 보고되며, 조사 결과와 함께 사용된 표본 설계 방법, 표본 추출 방식, 표본 크기, 조사 한계점 등을 함께 제시해야 한다. 이를 통해 결과의 신뢰성, 정밀도, 해석 가능성을 독자가 판단할 수 있도록 한다.\n\n\n\n\nchapter 2. 표본설계 방법\n\n1. 단순임의추출방법 SRS Simple Random Sampling\n\n(1) 정의 및 절차\n\n\n\n\n\n단순임의 표본추출은 모집단에 포함된 모든 요소가 동일한 확률로 선택될 수 있도록 하는 표본 추출 방법이다. 즉, 크기 n의 모든 가능한 표본이 동일한 확률로 선택될 수 있도록 설계된다. 이 방법은 대표성과 무작위성을 보장하는 가장 기본적인 확률 표본 추출 방식으로, 표본 추출의 이론적 기준점이 된다.\n단순임의 표본추출의 절차는 다음과 같다.\n\n\n표본 프레임에 포함된 N개의 모든 원소에 일련번호를 부여한다.\n난수 생성기를 활용하여 중복되지 않는 n개의 난수를 생성한다.\n해당 난수에 해당하는 원소를 표본으로 선택한다.\n\n\n이 과정은 모집단의 각 구성원이 표본에 포함될 동등한 기회를 가지도록 하며, 편향 없는 표본 구성을 가능하게 한다.\n\n\n(2) 추정\n단순 무작위 표본에서 평균 및 표본분산 계산\n\\(\\overline{y} = \\frac{1}{n}\\overset{n}{\\sum_{j = 1}}y_{i}\\), \\(v(\\overline{y}) = \\frac{(1 - f)}{n}s^{2}\\), 여기서 \\(f = n/N\\) 표본 비율, \\(s^{2}\\)은 표본분산이다. \\((1 - f)\\)은 유한모집단보정계수(Finite Population Correction, FPC)이라 하고 \\(N\\)이 충분히 크면 1에 근사하여 \\(v(\\overline{y}) \\approx \\frac{s^{2}}{n}\\) 이다.\n\\(v(\\overline{y})\\)는 표본평균의 샘플링 분산에 대한 표본 기반 추정치에 불과하다는 점을 주목할 필요가 있다. 여기에는 실제 모집단 값 \\(V(\\overline{y})\\)이 존재하며 \\(v(\\overline{y})\\)는 \\(V(\\overline{y})\\)의 불편 추정치로 간주된다. 여론조사와 같이 응답자의 선호 비율을 묻는 경우 표본평균(표본비율)의 표본분산은 다음과 같다. \\(v(p) = \\frac{(1 - f)}{n - 1}p(1 - p)\\). 표본분산 \\(v(p)\\)는 \\(fpc\\)(유한모집단보정계수), 표본크기 \\(n\\), 모집단 비율 \\(p\\) 값 자체에만 의존하므로 \\(y_{i}\\) 값을 알 필요 없이 계산 가능하다.\n표본크기 결정 시 모평균 추정의 경우 모집단 분산 \\(S^{2}\\)에 대한 정보가 있어야 하지만 모비율 추정 시에는 보수적으로 \\(p = 0.5\\)을 사용하여 결정한다.\n모집단 평균 95% 신뢰구간\n\\(\\overline{y} + z_{0.975}se(\\overline{y})\\), 여기서 \\(se(\\overline{y}) = \\frac{s}{\\sqrt{n}}\\)\n모비율 평균 95% 신뢰구간\n\\(\\widehat{p} + z_{0.975}se(\\overline{y})\\), 여기서 \\(se(\\widehat{p}) = \\frac{p(1 - p)}{\\sqrt{n}}\\)\n표본크기 허용오차 margin of error 표본오차: \\(e\\)\n【표본크기 : 유한 모집단】\n모평균 추정: \\(n = \\frac{N \\cdot z^{2} \\cdot S^{2}}{(N - 1) \\cdot e^{2} + z^{2} \\cdot S^{2}}\\)\n모비율 추정: \\(n = \\frac{N \\cdot z^{2} \\cdot p \\cdot (1 - p)}{(N - 1) \\cdot e^{2} + z^{2} \\cdot p \\cdot (1 - p)}\\)\n【표본크기 : 무한 모집단】\n모평균 추정: \\(n = \\frac{z^{2} \\cdot S^{2}}{e^{2}}\\)\n모비율 추정: \\(n_{0} = \\frac{z^{2} \\cdot p \\cdot (1 - p)}{e^{2}}\\) (유한 \\(n = \\frac{n_{0}}{1 + \\frac{n_{0} - 1}{N}}\\))\n\n\n\n2. 군집추출방법 cluster sampling\n\n\n\n\n\n단순임의표본추출과 군집표본추출의 비교\n단순임의표본추출은 모집단의 모든 구성 요소 중에서 각각이 동일한 확률로 선택될 수 있도록 표본을 추출하는 방법이다. 이 방식은 통계적으로 가장 이상적인 방법 중 하나지만, 실제 조사에서는 표본 프레임의 구성과 개별 요소에 접근하는 데 드는 시간과 비용이 상당히 크다는 한계가 있다.\n이러한 실용적 제약을 해결하기 위해 사용되는 방법이 군집표본추출이다. 군집표본추출은 모집단을 사전에 정의된 군집(집단) 단위로 나누고, 이 군집들 중 일부를 무작위로 선택한 뒤, 선택된 군집 내의 모든 요소를 조사하는 방식이다. 이는 전체 프레임을 구성하지 않고도 비교적 적은 비용으로 표본을 수집할 수 있다는 장점이 있다.\n군집표본추출의 절차와 사례\n예를 들어, 표본 프레임이 총 60가구로 구성되어 있고, 그 중 30가구는 O로, 나머지 30가구는 +로 표시되어 있다고 하자. 전체 가구 중 20가구를 조사 대상으로 선택해야 하는 경우, 단순임의추출을 사용할 경우 60가구 중 무작위로 20가구를 선택하게 된다.\n반면 군집표본추출을 적용하면, 예컨대 10가구씩 구성된 6개의 단지를 군집으로 보고, 이 중 2개의 단지를 무작위로 선택한 후, 선택된 단지의 모든 가구(총 20가구)를 조사하게 된다.\n군집표본추출의 장점과 주의점\n군집표본추출은 조사 단위를 군집화함으로써 조사에 소요되는 시간과 비용을 크게 줄일 수 있다. 예를 들어 단지 단위로 이동하거나 접촉하는 것이 개별 가구를 조사하는 것보다 훨씬 효율적일 수 있다.\n그러나 이 방법에는 중요한 단점도 존재한다. 만약 무작위로 선택된 두 개의 단지(예: 5번과 6번 단지)에 O로 표시된 가구가 거의 없는 경우, 전체 표본에서 O 가구의 비율이 실제 모집단에서의 비율과 현저히 달라질 수 있다. 이로 인해 표본의 대표성이 훼손되고, 왜곡된 추정 결과를 초래할 수 있다.\n\n(1) 군집표본 추출 절차\n군집표본추출은 모집단을 일정 기준에 따라 여러 개의 소집단, 즉 군집으로 나눈 뒤, 일부 군집만을 무작위로 선택하고 그 안의 구성원들을 표본으로 조사하는 방법이다. 모집단을 그룹으로 나눈다는 점에서는 층화추출과 유사하지만, 군집 간에는 응답의 차이가 없다고 가정한다는 점에서 차이가 있다. 따라서 한 군집이 무작위로 선택되면, 그 안에 포함된 구성원만을 대상으로 표본을 추출하게 된다.\n군집표본추출의 절차는 다음과 같다.\n\n\n모집단을 인구학적 특성이나 지리적 위치 등을 기준으로 군집으로 나눈다.\n난수를 이용하여 군집을 무작위로 선택한다.\n선택된 군집에 속한 모든 응답자를 표본으로 포함시킨다. 단, 군집의 크기가 표본 크기보다 클 경우에는 군집 내부에서 다시 단순임의추출 방법으로 일부 응답자만 선택한다.\n\n\n군집추출은 조사 비용과 시간을 줄이는 데 효과적이지만, 군집 간의 동질성이 확보되지 않을 경우 표본의 대표성이 떨어질 수 있으며, 그에 따라 추정의 정확도도 낮아질 수 있다. 따라서 군집을 설정할 때에는 군집 간 차이를 최소화하고, 군집 내의 다양성을 충분히 확보하는 것이 중요하다.\n가구조사 표본추출 사례\n가구조사에서는 규모 비례 확률 방법을 사용하여 전국을 200개 지역으로 층화하고, 이후 일련의 계통추출 과정을 통해 가구 내 응답자를 선택한다. 표본추출은 다음과 같은 네 단계로 이루어진다.\n첫째, 전국을 12개 층으로 구분한다. 6개 광역도시는 서울, 부산, 대구, 인천, 대전, 광주이며, 8개 도는 경기, 강원, 충청남북도, 경상남북도, 전라남북도로 구분된다. 도 지역은 다시 시, 읍, 면으로 세분화한다.\n둘째, 6개 도시와 각 도의 시·읍·면을 모집단으로 배열한 후, 각 지역 내 동(또는 면의 경우 리)을 계통추출 방식으로 선택한다. 이 단계에서 선택된 동 또는 리는 1차 표본 지역(primary sampling location)으로 정의된다. 표본의 전체 크기가 1,500일 경우, 약 200개의 1차 표본 지역이 확보된다.\n셋째, 실질적인 최종 표본 지역(actual final sampling location)인 반 또는 부락이 선택될 때까지 계통추출을 반복한다. 반은 대체로 약 20가구, 부락은 20~80가구로 구성된다.\n넷째, 조사원은 선정된 표본 지역을 직접 방문하여 주민 명부를 바탕으로 8가구를 임의로 선정한다. 각 가구에서 응답자는 18세 이상인 사람 중 생일이 가장 빠른 사람으로 지정하며, 최초 방문 시 해당 응답자를 만나지 못한 경우에는 재방문하여 조사를 진행한다.\n이 사례는 다단계 층화 계통추출의 전형적인 구조를 보여주며, 실제 조사의 대표성과 실현 가능성을 동시에 고려한 표본설계의 예라 할 수 있다. 필요하시면 이 내용을 도식화하거나 표본설계 흐름도로도 제공해드릴 수 있습니다.\n\n\n(2) 표본평균 추정\n평균은 SRS와 동일하게 계산되지만, 각 단지 내의 모든 소득을 합한 후, 각 단지의 합계를 더하고 최종적으로 표본크기로 나누는 방식으로 이루진다.\n\\(\\overline{y} = \\frac{\\sum_{\\alpha = 1}^{a}\\sum_{\\beta = 1}^{B}y_{\\alpha\\beta}}{aB}\\), 여기서 \\(a\\)는 단지 수, \\(\\beta\\)는 가구 수이다.\n평균의 표본분산\n무작위화는 단지에만 적용되며, 단지가 표본 단위이다. 어떤 단지가 선택되는지에 따라 \\(\\overline{y}\\)의 값이 달라진다. 어떤 면에서는 모든 것이 SRS와 동일하게 유지되지만, 군집을 표본 내 요소로 간주한다는 점이 다르다.\n\\(v(\\overline{y}) = \\left( \\frac{1 - f}{a} \\right)s_{a}^{2}\\), 여기서 \\(s_{a}^{2}\\)는 \\(a\\)개의 단지에 걸친 평균 소득의 변동성을 나타낸다. 즉, \\(s_{a}^{2} = \\left( \\frac{1}{a - 1} \\right)\\overset{a}{\\sum_{\\alpha = 1}}\\left( \\overline{y}\\alpha - \\overline{y} \\right)^{2}\\), 여기서 \\(\\overline{y}\\alpha\\)는 \\(\\alpha\\)번째 단지의 평균 소득이다. 군집표본의 경우, 요소 분산 \\(s^{2}\\)대신 ”군집 간 분산”을 사용한다.\n\n\n(3) 설계효과 design effect\n단순임의추출과 비교했을 때 실제 사용된 표본설계로 인해 표본분산이 얼마나 증가했는지를 나타내는 지표를 설계효과(design effect)라고 한다. 설계효과는 설문조사에서 군집화 효과, 층화 효과, 또는 복합 표본설계가 추정 결과에 미치는 영향을 정량적으로 표현하는 데 사용된다.\n설계효과: \\(d^{2} = \\frac{v(\\overline{y})}{v_{\\text{SRS}}(\\overline{y})}\\)\n\\(v(\\overline{y})\\): 군집표본에서의 표본 분산\n\\(v_{\\text{SRS}}(\\overline{y})\\): 동일한 표본 크기에서 SRS 표본분산\n설계효과와 군집 내 동질성\n설계효과는 군집 표본 추출이 단순임의추출에 비해 표본분산에 미치는 영향을 측정하는 지표로, 군집 내 요소들의 동질성과 밀접한 관련이 있다. 일반적으로 군집 표본은 요소 단위의 표본에 비해 표본분산이 더 크게 나타나는 경향이 있다. 이는 군집 간 평균값의 차이가 존재한다는 것을 의미하며, 동시에 각 군집 내에서는 요소들이 서로 유사한 특성을 가질 가능성이 높다는 것을 나타낸다.\n예를 들어, 단지 간 평균 소득에 차이가 있다는 것은 각 단지 내 가구들의 소득이 서로 유사하다는, 즉 군집 내 동질성이 높다는 의미로 해석될 수 있다. 이러한 경우, 한 군집에서 여러 요소를 표본으로 포함시켜도 얻어지는 정보는 중복될 가능성이 높다.\n이러한 맥락에서 다음과 같은 질문이 제기된다. “같은 군집에서 한 요소를 추가로 표본에 포함시킬 때, 모집단에 대한 어떤 새로운 정보를 얻을 수 있는가?” 극단적인 예로, 교실의 모든 학생이 동일한 시험 점수를 가지고 있다고 가정하면, 한 학생의 점수를 알게 된 순간 나머지 학생들의 점수는 별다른 추가 정보를 제공하지 못하게 된다. 이 경우, 각 교실에서 단 한 명만 조사해도 전체 분포를 파악할 수 있으므로, 조사 비용을 크게 절감할 수 있게 된다.\n군집 내 동질성이 높을수록 설계효과는 커지며, 이는 추정의 정확도를 낮출 수 있다. 따라서 군집 표본을 설계할 때는 군집 간 이질성을 확보하고 군집 내 동질성을 최소화하려는 노력이 필요하다.\n설계효과 측정\n군집 내 요소 값의 상관성 intraclass correlation을 사용하는 것이다. 이는 군집 간을 평균으로 한 상관계수로, 군집 내 변수 값들이 군집 외부의 값들과 비교하여 서로 얼마나 상관되어 있는지를 측정한다. 군집 내 동질성 rate of homogeneity은 \\(roh\\)로 나타내며, 이는 거의 항상 0보다 큰 양수이다.또한, 이 \\(\\rho\\)를 설계효과와 연결할 수 있다. 이는 크기 n인 SRS에서 크기 n인 군집 표본으로 전환할 때 표본 분산 변화의 요약값을 제공한다.\n설계효과는 \\(d^{2} = 1 + (b - 1)roh\\), 여기서 \\(b\\)는 각 군집(예: 단지)에서 표본으로 추출된 요소의 크기를 나타낸다. 즉, 표본분산의 증가는 단지 소득에서 관찰된 가구 간 동질성의 정도와 각 단지에서 추출된 표본크기 \\(b\\)에 실제로 의존한다. \\(roh\\)는 변수의 유형에 따라 달라지며, 군집 내 동질성의 비율이 높은 변수는 평균에 대해 더 큰 설계효과를 가진다. 일반적으로 이 표는 사회경제적 변수에서 높은 roh 값을 보이며, 태도나 여성의 출산 경험과 같은 변수에서는 낮은 roh 값을 보인다. 군집에서 추출된 표본 크기가 클수록 설계효과도 커진다. 각 군집에서 1개만 선택하거나, \\(roh = 0\\)이면 설계효과는 1로 SRS 분산과 동일하다.\n\\(roh\\) 추정 및 활용\n추정: \\(roh = \\frac{(d^{2} - 1)}{(b - 1)}\\)\n동일하거나 유사한 주제에 대해, 거의 동일한 모집단에서 사전 조사 결과로부터 \\(roh_{old}\\)값을 계산했다고 가정한다. 새로운 설계에서 표본 분산을 추정하려면, 먼저 새로운 설계 효과를 계산해야 한다.\n\\(d_{\\text{new}}^{2} = 1 + (b_{\\text{new}} - 1)roh_{\\text{old}}\\), 여기서 \\(b_{\\text{new}}\\)는 새로운 설계에서 군집당 표본 요소 수이다. 그런 다음, 이 새로운 설계 효과를 사용하여 새 표본의 평균에 대한 SRS 분산 추정치에 곱한다.\n\\(v(\\overline{y}) = \\left( \\frac{1 - f}{n} \\right)s^{2},\\) 여기서 \\(s^{2}\\)는 사전 조사에서 추정되며, \\(n\\)은 새로운 설계에 의해 결정된다.\n설계효과 \\(d^{2}\\)의 또 다른 해석\n\\(d^{2}\\)는 군집 표본을 추출함으로써 정밀도가 손실된 정도를 나타낸다. 표본 크기는 200명이고 설계효과 \\(d^{2} = 3.13\\)라 하자. 실제로 동일한 분산을 가지는 SRS 표본 크기는 \\(n_{\\text{eff}} = \\frac{200}{3.13} \\approx 64\\)로 200명이 아니다. ”효과적 표본 크기”는 실제 설계로 달성된 것과 동일한 표본 분산을 산출하는 SRS 표본 크기이다.\n선택된 군집 내 하위 표본 추출\n선택된 군집 내 표본 크기(예: 단지당 선택된 가구 수)를 줄이면 평균 소득의 표본 분산에 대한 군집 효과를 감소시킬 수 있다. 이는 군집화가 결과의 정밀도에 미치는 해로운 영향을 완화하려는 타협점이다. 군집 표본을 더 많은 군집에 분산시키는 것은 전체 표본 요소 수를 유지하면서도 일반적으로 총 비용을 증가시킨다.\n\n\n\n3. 층화추출방법 stratified sampling\n\n\n\n\n\n확률 표본 설계는 모집단의 하위 그룹들이 표본 내에 적절히 대표되도록 보장하는 방식으로 개선될 수 있다. 이러한 기능 중 하나가 층화(stratification)이다.\n층화는 표본 프레임에 포함된 모집단 요소들이 사전에 정의된 기준에 따라 상호 배타적인 그룹, 즉 층(strata)으로 구분될 수 있는 정보를 가지고 있다는 전제에 기반한다. 각 요소는 오직 하나의 층에만 속할 수 있으며, 이처럼 나뉜 층은 서로 겹치지 않는 범주로 구성된다.\n층화표본추출에서는 각 층에서 표본을 독립적으로 선택한다. 이때 모든 층에서 동일한 표본추출 절차(예: 단순임의추출)를 사용할 수도 있고, 층의 특성에 따라 서로 다른 추출 방법(예: 어떤 층에서는 단순임의추출, 다른 층에서는 군집추출)을 적용할 수도 있다.\n층화는 특히 모집단 내에 중요한 이질적 특성이 존재할 경우 유용하며, 각 하위 집단의 특성을 보다 정확하게 추정할 수 있도록 도와준다. 또한 전체 표본의 분산을 줄이는 데에도 기여할 수 있다.\n\n(1) 층화표본 추출 절차\n층화추출과 군집추출은 모두 모집단을 그룹으로 나누는 방식이지만, 그 목적과 활용 방식에서 중요한 차이가 있다.\n층화추출은 모집단을 사전에 정의된 기준에 따라 여러 개의 층으로 구분하고, 각 층에서 독립적으로 표본을 추출하는 방법이다. 이때 각 층은 내부적으로는 비교적 동질적이고, 층 간에는 이질적인 특성을 가지도록 구성된다. 이러한 방식은 모집단 내 다양한 하위 집단이 표본에 반드시 포함되도록 보장하므로, 조사 결과의 대표성과 정밀도를 높이는 데 효과적이다. 특히 성별, 연령대, 지역 등과 같이 사전에 알려진 중요한 구분 기준이 있는 경우 유용하다.\n반면, 군집추출은 모집단을 물리적 또는 행정적 단위에 따라 군집으로 나눈 후, 이들 군집 중 일부만을 무작위로 선택하여 조사하는 방식이다. 선택된 군집 내에서는 모든 구성원을 조사하거나, 추가적인 표본추출 절차를 통해 일부만을 조사할 수 있다. 군집 간에는 큰 차이가 없다고 가정하며, 각 군집은 내부적으로 다양한 특성을 가진 이질적인 집단으로 구성되는 것이 일반적이다. 군집추출은 시간과 비용을 절감하는 데 유리하지만, 군집 간 이질성이 크고 군집 내 동질성이 높을 경우 표본 오차가 증가할 수 있다는 단점이 있다.\n요약하자면, 층화추출은 하위 집단의 대표성을 보장하고 정밀도를 높이기 위해 사용되며, 군집추출은 접근성과 비용 효율성을 고려할 때 활용되는 방법이다. 두 방법은 모두 확률 표본 설계의 일종이지만, 조사 목적과 상황에 따라 적절히 선택되어야 한다.\n\n\n(2) 층화표본 추출 절차\n층화표본추출은 모집단을 인구학적 특성에 따라 서로 다른 집단으로 구분한 뒤, 각 집단에서 일정 수의 표본을 선택하여 전체 표본을 구성하는 방식이다. 여기서 각 집단은 ’층’이라고 하며, 층화의 목적은 모집단 내 서로 다른 응답 성향을 가진 하위 집단이 표본에 적절히 대표되도록 보장하는 데 있다.\n일반적으로 집단 간에는 응답의 차이가 존재하며, 각 집단 내의 개체는 모집단의 특성을 반영하는 정보를 고르게 가지고 있다고 본다. 따라서 각 층에서 고르게 표본을 추출함으로써, 전체 표본의 대표성과 추정의 정확도를 높일 수 있다.\n층화표본추출은 다음과 같은 절차에 따라 진행된다.\n첫째, 모집단을 인구학적 특성에 따라 분류한다. 성별, 연령, 학년, 직업, 거주 지역 등과 같이 응답 성향에 영향을 미칠 수 있는 변수들을 기준으로 그룹화하며, 이를 통해 모집단을 이질적인 하위 집단으로 나눈다.\n둘째, 각 층에서 몇 개의 표본을 추출할 것인지를 결정한다. 이는 각 층의 크기를 기준으로 하여 비례적으로 할당하거나, 조사 목적에 따라 비례하지 않게 배정할 수도 있다. 표본 수를 층의 크기에 비례하여 결정하는 방식을 확률비례추출이라 한다.\n셋째, 각 층에서 배정된 표본을 실제로 추출한다. 이때 표본추출 방법은 단순임의추출(SRS)이나 계통추출(Systematic Sampling)과 같은 무작위 방법을 사용할 수 있다.\n이와 같이 층화표본추출은 표본의 구조적 대표성을 높이는 데 효과적인 방법이며, 특히 모집단 내 이질성이 예상될 때 유용하게 활용된다.\n\n\n(3) 표본평균 추정\n비례 할당은 각 층에서 동일한 선택 확률을 사용하여 표본을 선택하는 것과 동일하며, 이는 동등한 확률 선택 방법이다. 즉, \\(f_{h} = n_{h}/N_{h}\\)로 층 \\(h\\) 의 표본 추출 비율이다. 층 \\(h\\)의 \\(n_{h}\\)크기의 표본을 선택할 수 있으며, 이때 표본에서 해당 층의 요소 비율은 모집단에서 해당 층의 요소 비율 \\(\\frac{N_{h}}{N}\\)과 동일하다. 여기서 \\(N_{h}\\)는 층 \\(h\\)에 있는 모집단 요소의 수를 의미하며, \\(\\frac{N_{h}}{N}\\)은 각 층의 모집단 비율이다.\n전체 모집단에 대한 추정치를 얻으려면 각 층의 결과에 모집단 비율 \\(W_{h}\\)를 가중치로 사용하는 것이다. 예를 들어, 모집단 평균을 추정하고자 하고, 각 층에 대한 평균 \\({\\overline{y}}_{h}\\)를 계산했다고 하자. 모집단 평균에 대한 층화된 추정치는 \\({\\overline{y}}_{st}\\)로 불리며, 여기서 st는 ”층화”를 나타낸다.\n\\({\\overline{y}}_{st} = \\overset{H}{\\sum_{h = 1}}W_{h}{\\overline{y}}_{h}\\), 여기서 \\({\\overline{y}}_{st}\\)는 층 평균의 가중 합이다.\n\n\n(4) \\({\\overline{y}}_{st}\\)의 표본 분산\n\\(v({\\overline{y}}_{h}) = \\left( \\frac{1 - f_{h}}{n_{h}} \\right)s_{h}^{2}\\), 여기서 \\(f_{h} = n_{h}/N_{h}\\)는 층 h의 표본 추출률이다. \\(s_{h}^{2}\\)는 층 \\(h\\)의 요소 분산으로, 층 내 요소 평균 \\({\\overline{y}}_{h}\\)를 기준으로 다음과 같이 계산된다. \\(s_{h}^{2} = \\left( \\frac{1}{n_{h} - 1} \\right)\\overset{n_{h}}{\\sum_{i = 1}}(y_{hi} - {\\overline{y}}_{h})^{2}\\).\n따라서, 층화된 임의 표본 추출에서는 SRS에서처럼 하나의 요소 분산만 계산하는 것이 아니라, 각 층에 대해 별도의 분산을 계산해야 한다.\n\\(v(\\overline{y}st) = \\overset{H}{\\sum_{h = 1}}W_{h}^{2}\\left( \\frac{1 - f_{h}}{n_{h}} \\right)s_{h}^{2}\\), 여기서 \\(W_{h}\\)는 각 층의 모집단 비율로, 각 층의 SRS 분산에 대해 모집단 비율의 제곱을 가중치로 사용한다.\n\n\n(5) 설계효과\n\\[d^{2} = \\frac{v(\\overline{y}st)}{v\\text{SRS}(\\overline{y})} = \\frac{\\sum_{h = 1}^{H}W_{h}^{2}\\left( \\frac{1 - f_{h}}{n_{h}} \\right)s_{h}^{2}}{\\left( \\frac{1 - f}{n} \\right)s^{2}}\\]\n이 설계효과는 1보다 작거나, 1과 같거나, 심지어 1보다 클 수도 있다. 설계효과의 크기는 각 층에서 선택된 표본 크기, 즉 층화 내 표본 할당 방식에 크게 의존한다.\n비율의 추정 절차는 평균에 대한 추정 절차와 유사하며, 실제로 동일한 공식을 사용할 수 있다. 그러나 비율의 추정은 종종 다음과 같은 비율의 형태로 표현된다.\n\\(p_{st} = \\overset{H}{\\sum_{h = 1}}W_{h}p_{h}\\), \\(v(p_{st}) = \\overset{H}{\\sum_{h = 1}}W_{h}^{2}\\left( \\frac{1 - f_{h}}{n_{h} - 1} \\right)p_{h}(1 - p_{h})\\)\n모평균 추정치 \\({\\overline{y}}_{st} = \\overset{H}{\\sum_{h = 1}}W_{h}{\\overline{y}}_{h} = \\overset{H}{\\sum_{h = 1}}\\left( \\frac{N_{h}}{N} \\right){\\overline{y}}_{h}\\)을 대수적 방법으로 재표현 하면 \\(\\overline{y}st = \\frac{\\sum_{h = 1}^{H}\\sum_{i = 1}^{n_{h}}w_{hi}y_{hi}}{\\sum_{h = 1}^{H}\\sum_{i = 1}^{n_{h}}w_{hi}}\\), 여기서 \\(w_{hi}\\)는 데이터 세트의 가중치 변수로, 층 \\(h\\)에 있는 요소 \\(i\\)의 \\(w_{hi} = \\frac{N_{h}}{n_{h}}\\)이다. 즉, 가중 평균은 가중 총합을 가중치의 합으로 나눈 값이다.\n\\({\\overline{y}}_{st}\\)의 표본 분산은 가장 간단하게 층 전체의 분산에 대한 가중 합으로 표현될 수 있다. 각 층에서 단순 임의 표본 추출(SRS)을 사용했다면, 다음과 같이 계산된다.\n\\[v({\\overline{y}}_{st}) = \\overset{H}{\\sum_{h = 1}}W_{h}^{2}(\\text{variance of}h\\text{-th stratum mean})\\]\n\\(v({\\overline{y}}_{st}) = W_{1}^{2}\\left( \\frac{1 - f_{1}}{n_{1}} \\right)s_{1}^{2} + W_{2}^{2}\\left( \\frac{1 - f_{2}}{n_{2}} \\right)s_{2}^{2} + W_{3}^{2}\\left( \\frac{1 - f_{3}}{n_{3}} \\right)s_{3}^{2} + \\cdots\\), 여기서 \\(W_{h}\\)는 층 \\(h\\)의 모집단 비율, \\(f_{h} = n_{h}/N_{h}\\)는 층 \\(h\\)의 표본 추출률, \\(s_{h}^{2}\\)는 층 \\(h\\)의 분산이다. 즉, 분산의 추정은 층별로 계산된 후, 층별 결과를 결합하여 이루어진다.\n\n\n(6) 층화 추출의 설계효과가 \\(d^{2} &lt; 1\\) (1보다 작은 경우)\n설계효과 \\(d^{2} = \\frac{v(\\overline{y}st)}{v\\text{SRS}(\\overline{y})} = \\frac{\\sum_{h = 1}^{H}W_{h}^{2}\\left( \\frac{1 - f_{h}}{n_{h}} \\right)s_{h}^{2}}{\\left( \\frac{1 - f}{n} \\right)s^{2}}\\)이므로 만약 \\(\\overset{H}{\\sum_{h = 1}}W_{h}^{2}s_{h}^{2}\\)가 \\(s^{2}\\)보다 작아지면 설계효과는 1보다 작아진다.\n1. 층 간 변동이 큰 경우\n층화 추출의 가장 큰 이점은 **층 간의 이질성(층 간 변동)**을 활용하여 전체 모집단의 변동을 줄이는 데 있다. 층화 추출은 동일한 크기의 단순 임의 추출(SRS)보다 표본이 더 모집단을 잘 대표하도록 설계된다. 각 층 내부는 상대적으로 동질적이지만, 층 간 차이가 클 경우, 층화는 표본 평균의 변동성을 줄여 설계효과가 1보다 작아지게 된다.\n예를 들어, 수입 수준, 교육 수준, 지역별 생활비 등에서 층 간 큰 차이가 있는 경우 설계효과가 1보다 작아질 가능성이 높다.\n2. 적절한 층화 및 비례 할당\n층화는 모집단을 적절히 나누고, 각 층에서 비례적으로 표본을 추출할 때 설계효과가 줄어들 가능성이 크다.\n\\(f_{h} = \\frac{n_{h}}{N_{h}},W_{h} = \\frac{N_{h}}{N}\\) 비례 할당을 통해 각 층이 모집단을 더 잘 대표하도록 표본을 추출하면, 분산 감소 효과가 더 크게 나타난다.\n3. 층 내 내부 변동이 작은 경우\n각 층 내부의 요소들이 상대적으로 동질적일수록(층 내 변동이 작을수록), 해당 층의 분산 s_h^2가 감소하여 전체 표본 분산이 줄어든다.\n층 내 요소들이 비슷한 특성을 가지고 있다면, 적은 표본으로도 각 층을 충분히 대표할 수 있다.\n4. 효율적인 표본 배분 (Neyman Allocation)\nNeyman Allocation과 같은 최적 배분 방식을 사용하면 각 층의 변동성에 비례하여 표본을 배분할 수 있다. \\(n_{h} \\propto N_{h} \\cdot s_{h}\\)\n각 층의 크기와 분산을 고려하여 표본을 배분하면, 층화 추출의 효율성이 높아지고 설계효과가 줄어든다.\n\n\n(7) 층에 대한 비례하지 않은 할당\n층화표본추출에서 가장 일반적인 표본 할당 방식은 각 층의 크기에 비례하여 표본을 배분하는 비례할당이다. 그러나 비례할당 외에도 단순임의표본추출에 비해 더 작은 표본 분산을 유도할 수 있는 다양한 할당 방법이 존재한다.\n표본설계에서 어떤 할당 방식이 사용되느냐에 따라 추정값의 정확도가 달라질 수 있으며, 특정 할당 방법은 가능한 모든 할당 방식 중에서 표본 평균의 분산을 최소화하는 특징을 가진다. 이러한 최적의 할당 방식은 폴란드의 통계학자 예지 네이만(Jerzy Neyman)에 의해 제안되었으며, 그의 이름을 따서 네이만 할당(Neyman allocation)이라 불린다.\n네이만 할당은 각 층의 표준편차와 크기를 함께 고려하여 표본을 배분하는 방식으로, 층 간 변동성이 클수록 더 많은 표본을 배정하게 된다. 이를 통해 표본의 효율성을 극대화하고, 동일한 표본 크기 하에서 보다 정밀한 추정을 가능하게 한다.\n층화 표본을 위한 네이만 할당은 여러 비례하지 않은 할당 방법 중 하나이다. 하지만 이 방법은 동일한 크기의 표본을 사용할 때 가장 작은 표본 분산을 가지는 특징을 가진다. 네이만 할당을 사용하려면 각 층의 모집단 비율 \\(W_{h}\\)뿐만 아니라, 표준편차 \\(S_{h} = \\sqrt{S_{h}^{2}},\\)도 알고 있어야 한다.\n표본크기\n각 층에 대해 \\(W_{h}S_{h}\\)의 곱을 계산하고, 이를 모든 층에서 합산한다. 그러면 네이만 할당 방식에서 각 층의 표본 크기는 다음과 같이 주어진다. \\(n_{h} = n\\frac{W_{h}S_{h}}{\\sum_{h = 1}^{H}W_{h}S_{h}}\\). 즉, 표본 크기는 \\(W_{h}\\)에 비례하는 것이 아니라 \\(W_{h}S_{h}\\)에 비례하도록 할당된다. 따라서 층의 크기가 크면, 비례 할당과 마찬가지로 더 많은 표본을 할당한다. 하지만, 층 내 요소들의 변동성이 클 경우에도 더 많은 표본을 할당하게 된다. 즉, 층 내 변동성이 높을수록 표본 크기를 증가시키게 된다.\n\\(S_{h} = \\sqrt{S_{h}^{2}}\\) 값이 클수록 해당 층에 더 많은 표본을 할당해야 한다. 다시 말해, 층 내 요소들의 분산이 높은 경우, 해당 층에서 더 큰 표본을 추출하여 다른 층보다 상대적으로 더 안정적인 표본 통계를 얻을 수 있도록 한다.\n네이만 할당 관련 코멘트\n네이만 할당은 단순 임의 표본 추출(SRS)보다, 심지어 비례 할당보다도 정밀도를 크게 향상시킬 수 있다. 그러나 이 방법에는 몇 가지 단점이 있다.\n첫째, 네이만 할당은 반드시 비율 추정에 적합하지 않다. 비율 데이터를 다룰 때 층 간 비율 차이가 크게 나야 하지만, 그러한 차이를 가지는 변수를 찾기가 어려울 수도 있다.\n둘째, 네이만 할당은 한 번에 하나의 변수에 대해서만 최적화된다. 만약 조사에서 여러 개의 변수를 수집하고 있다면, 한 변수에 대한 네이만 할당이 다른 변수에 대한 할당과 다를 수 있다. 그리고 주된 관심 변수에 대해 최적화된 네이만 할당이 다른 변수들에는 적절하지 않을 가능성이 있다. 이로 인해 일부 변수에서는 오히려 설계효과가 1보다 커지는 경우가 발생할 수 있다.\n층 내 분산에 대한 충분한 정보 없이 비례하지 않은 할당을 적용하는 것은 위험하다. 이는 전체 표본의 표준 오차 증가로 이어질 수 있다. 예를 들어, 단순한 할당 방식으로 모든 층에 동일한 표본 크기를 배정하는 경우를 생각해 보자. 층 크기가 다름에도 불구하고 동일한 표본 크기를 배정하면 표본 오차가 증가할 수 있다.\n\n\n\n4. 계통 표본 추출 systematic selection\n\n\n\n\n\n\n(1) 계통 추출 절차\n표본을 추출하기 위해 먼저 모집단의 크기와 원하는 표본의 크기를 정한다. 그런 다음, 모집단 크기를 표본 크기로 나눈 값을 추출 간격 k로 계산한다. 이때 \\(k = \\frac{\\text{모집단 크기}}{\\text{표본 크기}}\\) 이며, k는 정수일 수도 있고 아닐 수도 있다. k가 정수가 아닌 경우에는 소수점을 포함한 값을 사용한 뒤, 최종적으로 추출 시 정수 부분만을 활용한다.\n초기 시작점은 1부터 k 사이의 숫자 중 무작위로 하나를 선택하여 결정하며, 이 값을 시작으로 이후 매 k번째 위치에 있는 요소를 순차적으로 표본에 포함시킨다. 이러한 방식은 간단하지만, 모집단이 일정한 방식으로 배열되어 있거나 정렬된 상태일 경우, 특정 패턴에 따라 다양한 모집단 특성을 균등하게 반영할 수 있다.\n이러한 체계적 표본추출은 표면적으로는 단순한 방식이지만, 적절한 조건 하에서는 층화표본추출처럼 모집단의 하위 구조를 고르게 대표할 수 있는 장점을 지닌다. 특히, 모집단 요소들이 조사 변수와 관련 있는 기준에 따라 정렬되어 있는 경우에는 단순임의추출보다 더 높은 정밀도를 확보할 수 있다.\n\n\n(2) 계통추출 관련 코멘트\n체계적 표본추출은 단순임의추출(SRS)이나 층화임의추출에 비해 절차가 간단하고 적용이 용이한 방법이다. 일정한 간격을 기준으로 모집단에서 표본을 선택하는 방식으로, 모집단 전체에 대한 리스트가 준비되어 있다면 빠르고 효율적으로 표본을 구성할 수 있다.\n첫째, 체계적 표본추출에서 사용되는 추출 간격 k는 모집단 크기 N을 원하는 표본 크기 n으로 나누어 계산된다. 이때 k가 항상 정수가 되지 않을 수 있는데, 이러한 경우에는 소수점을 포함한 값을 계산한 뒤 소수점 이하는 버리고 정수 부분만을 사용하여 추출 간격을 설정한다.\n둘째, 체계적 표본추출은 정렬된 리스트를 기반으로 수행될 경우 묵시적 층화 효과를 제공할 수 있다. 이를 ’묵시적 층화 표본추출(implicit stratified sampling)’이라고 하며, 실제 층화를 하지 않았더라도 비례할당이 적용된 층화표본추출과 유사한 결과를 낳을 수 있다. 특히, 정렬 기준이 조사 변수와 상관관계를 가질 경우 표본의 정밀도는 단순임의추출보다 현저히 향상될 수 있다.\n셋째, 이러한 정렬 방식의 대표적인 예로는 지리적 정렬을 들 수 있다. 예를 들어, 특정 지역 내 기업들을 대상으로 평균 종업원 수를 추정하고자 할 때, 기업을 남동쪽에서 북서쪽으로 이동하는 순서로 정렬하면, 대도시 지역과 농촌 지역의 기업들이 자연스럽게 구분되어 배치된다. 일반적으로 대도시 기업은 종업원 수가 많고, 농촌 기업은 적은 경향이 있으며, 유사한 규모의 기업들이 지리적으로 모여 있는 경우도 많다. 이러한 리스트에서 체계적 표본을 추출하면 자동으로 규모별 층화와 유사한 효과를 얻게 되어, 단순임의추출보다 높은 정밀도의 추정을 가능하게 한다.\n이처럼 체계적 표본추출은 간단한 절차에도 불구하고, 적절한 정렬이 이루어진 경우 상당한 효율성을 확보할 수 있는 표본설계 방법이다.\n\n\n\n\nchapter 3. 표본설계 방법 가중치, 추정분산\n\n(1) 단순임의추출\n단순임의추출은 모집단 내 모든 요소가 동일한 확률로 선택되는 가장 기본적인 확률 표본추출 방법이다. 이 방식에서는 각 요소가 표본에 포함될 기회가 동등하게 주어지며, 통계학에서 널리 사용되는 이론적 기준이 된다.\n단순임의추출은 절차가 명확하고 이해하기 쉬우며, 통계적 추론의 기초를 이루는 중요한 방법이다. 그러나 모집단의 이질성이 크거나 하위 집단 간에 중요한 차이가 존재하는 경우에는 층화추출이나 군집추출과 같은 다른 표본설계 방식보다 효율성이 떨어질 수 있다. 특히 동일한 표본 크기 하에서 추정의 정확도나 분산 측면에서 상대적으로 불리할 수 있다.\n이 방식에서는 모든 표본 요소의 가중치가 동일하게 적용된다. 각 표본 요소의 가중치는 \\(w_{i} = \\frac{N}{n}\\) 으로 계산되며, 여기서 N은 모집단의 크기, n은 표본의 크기를 의미한다. 이는 각 표본이 모집단에서 차지하는 비율이 같다는 것을 의미하며, 단순임의추출의 대표성과 균형성을 수학적으로 뒷받침한다.\n표본분산 (추정 오차)\n\\(v(\\overline{y}) = \\left( \\frac{1 - f}{n} \\right)s^{2}\\), \\(s^{2}\\) 은 모집단의 분산, \\(f = \\frac{n}{N}\\)은 표본비율 (유한 모집단 보정) \\(n\\) 증가 시 표본분산 감소한다.\n\n\n(2) 계통추출\n계통추출은 모집단을 일정한 순서로 정렬한 후, 고정된 간격마다 표본을 선택하는 확률 표본추출 방법이다. 추출 간격 k는 모집단 크기 N을 표본 크기 n으로 나누어 계산하며, \\(k = \\frac{N}{n}\\) 으로 정의된다. 먼저 1부터 k까지의 숫자 중 무작위로 하나를 선택하여 시작점을 정한 뒤, 그 이후로 매 k번째 요소를 표본으로 포함시킨다.\n계통추출의 장점은 단순임의추출보다 적용이 간편하고 조사 준비 시간이 짧다는 점이다. 특히 모집단이 정렬되어 있을 때, 그 정렬 기준이 조사 변수와 상관관계를 가질 경우 표본의 대표성과 추정의 정밀도가 높아질 수 있다. 예를 들어, 지리적 순서, 알파벳 순서, 시간 순서 등으로 정렬된 목록에서 계통추출을 수행하면 묵시적 층화 효과를 얻을 수 있다.\n계통추출에서도 각 표본 요소는 동일한 확률로 선택되므로, 가중치는 단순임의추출과 동일하게 적용된다. 각 요소의 가중치는 \\(w_i = \\frac{N}{n}\\) 이며, 이는 전체 모집단을 표본으로 환산할 때의 비율을 나타낸다.\n표본분산 (추정 오차)\n\\(v({\\overline{y}}_{sys}) \\approx v({\\overline{y}}_{SRS})\\)\n\n모집단이 주기성을 가지면 편향 발생 가능이 있다.\n모집단이 정렬된 상태라면 층화표본추출과 유사한 효과를 가진다.\n\n\n\n(3) 군집추출\n군집표본추출은 모집단을 여러 개의 군집으로 나눈 뒤, 이들 중 일부 군집을 무작위로 선택하여 표본으로 삼는 방법이다. 선택된 군집에 포함된 모든 개체를 조사 대상으로 포함시킨다는 점에서, 개별 요소가 아닌 집단 단위로 표본을 구성하는 특징이 있다.\n이 방식은 조사 대상이 지리적으로 넓게 분포해 있거나, 개별 단위에 직접 접근하는 데 시간이 많이 소요되는 경우에 유리하다. 군집 단위로 접근하고 조사함으로써 조사 비용과 시간이 크게 절감될 수 있다. 그러나 군집 내 개체들이 서로 유사한 특성을 가질 가능성이 높기 때문에, 군집 간의 이질성이 충분히 확보되지 않으면 표본 오차가 커질 수 있다는 단점이 있다.\n가중치는 단순임의추출과 유사하게 계산되며, 선택된 군집 내의 각 표본 요소는 동일한 가중치를 갖는다. 이때 가중치는 \\(w_{c} = \\frac{N}{n}\\) 으로 표현되며, 여기서 N은 모집단 전체의 개체 수, n은 조사에 포함된 전체 표본 개체 수를 의미한다.\n표본분산 (추정 오차)\n\\(v({\\overline{y}}_{cl}) = \\left( \\frac{1 - f}{a} \\right)s_{a}^{2}\\), 여기서 \\(a\\)는 선택된 군집 수, \\(s_{a}^{2}\\)은 군집 평균 간 분산,\n\n군집 내 동질성이 클수록(높은 \\(\\rho\\)) 표본 오차가 증가한다.\n군집 내 이질성이 크고, 군집 간 동질성이 높을수록 효과적이다.\n\n\n\n(4) 층화추출\n층화표본추출은 모집단을 서로 겹치지 않는 여러 개의 층(stratum)으로 구분한 뒤, 각 층에서 단순임의추출(SRS)을 독립적으로 수행하는 방식이다. 각 층은 내부적으로는 동질적이고, 층 간에는 이질적인 특성을 갖도록 구성된다. 이 방법은 모집단 내 특정 특성이 층마다 다르게 나타나는 경우, 보다 정밀하고 대표성 있는 추정을 가능하게 한다.\n층화표본추출의 가장 큰 장점은 표본 분산을 줄이고 추정의 정확도를 높일 수 있다는 점이다. 특히 조사 대상의 응답 성향이나 특성이 층별로 뚜렷하게 구분될 경우, 단순임의추출보다 훨씬 효율적인 결과를 기대할 수 있다.\n이 방법에서 가중치는 층별로 계산되며, 각 층 h에 속한 표본 요소의 가중치는 다음과 같다. \\(w_h = \\frac{N_h}{n_h}\\) , 여기서 \\(N_h\\) 는 층 h의 모집단 크기, n_h는 해당 층에서 추출된 표본의 크기를 의미한다. 이는 층별 대표성 보정을 위해 각 표본의 기여도를 조정하는 역할을 한다.\n표본분산 (추정 오차)\n\\(v(\\overline{y}st) = \\overset{H}{\\sum_{h = 1}}W_{h}^{2}\\left( \\frac{1 - f_{h}}{n_{h}} \\right)s_{h}^{2}\\), 여기서 \\(s_{h}^{2}\\)은 층 \\(h\\)의 분산, \\(W_{h} = \\frac{N_{h}}{N}\\)은 층의 모집단 비율, \\(f_{h} = \\frac{n_{h}}{N_{h}}\\)은 층의 표본비율\n\n층 간 변동이 크고, 층 내 변동이 작을수록 효율적이다."
  },
  {
    "objectID": "notes/survey/data_process.html",
    "href": "notes/survey/data_process.html",
    "title": "조사방법론. 5. 데이터 처리",
    "section": "",
    "text": "chapter 1. 데이터 처리 개요\n설문조사 데이터 처리 단계는 전체 분석의 신뢰성과 타당성을 확보하기 위한 일련의 핵심 절차로, 수집된 원자료(raw data)를 정제하고 분석 가능한 형식으로 전환하는 과정이다. 이 단계는 단순히 데이터를 저장하거나 정리하는 수준을 넘어, 조사 설계의 오류를 최소화하고 결과 해석의 타당성을 높이는 데 목적이 있다.\n우선, 데이터 수집은 설문 응답을 체계적으로 취합하는 초기 단계로, 온라인 조사, 전화 인터뷰, 대면 면접, 우편 설문 등 다양한 방법을 통해 이루어진다. 이때 수집된 응답은 원자료 형태로 존재하며, 즉각적인 분석보다는 사전 정제와 구조화가 필요하다. 그다음 단계인 텍스트 데이터 코딩은 자유응답형(예: 기타 의견 서술) 응답을 분류 기준에 따라 범주화하고, 이를 수치형 코드로 전환하여 정형 데이터와 통합할 수 있도록 한다. 이 과정은 주관적 해석이 개입될 수 있으므로 사전 정의된 코딩 기준이 필수적이다.\n데이터 입력은 응답 정보를 전산화된 데이터베이스로 옮기는 단계로, 자동화 시스템을 사용하더라도 이중 입력 검증, 일관성 점검 등을 통해 정확성을 확보해야 한다. 이어서 편집 및 오류 확인 단계에서는 응답 값 간 논리적 불일치, 이상치, 무응답 값 등 오류 가능성을 점검하고, 필요한 경우 수정하거나 주석을 붙인다. 이 과정은 설문 설계상의 문제를 사후적으로 보완하는 역할도 수행한다.\n결측값 대체는 응답 누락으로 인해 생기는 데이터 불완전성을 해소하기 위한 과정으로, 단순 평균 대체, 회귀 추정, 다중 대체(Multiple Imputation) 등의 통계적 기법이 사용된다. 결측값을 어떻게 다루느냐에 따라 분석 결과의 신뢰도와 일반화 가능성이 달라질 수 있으므로, 대체 방법의 선택은 신중해야 한다.\n가중치 생성은 조사 표본이 실제 모집단을 얼마나 잘 대표하는지를 보정하기 위한 단계로, 층화 변수(예: 성별, 연령, 지역) 기반의 보정 가중치, 비응답 보정, 사후 층화(post-stratification) 등이 사용된다. 이는 특히 비확률 표본이거나 응답률이 낮은 조사에서 필수적인 절차이다.\n마지막으로 분산 추정은 분석 결과의 불확실성을 측정하는 단계로, 표준 오차, 신뢰구간 등을 산출한다. 복잡 표본 설계(예: 층화, 군집)가 사용된 경우, 단순 무작위 표본 추출을 가정한 일반 분석 방법이 적합하지 않기 때문에 설계 효과(design effect)를 고려한 분산 추정 기법을 적용해야 한다. 이로써 표본 추정치의 통계적 정확도를 보다 정교하게 평가할 수 있다.\n전체적으로 이 과정은 단순한 데이터 정리의 수준을 넘어서, 분석의 정합성과 재현 가능성을 높이기 위한 필수 절차로 기능하며, 설문조사의 신뢰성과 타당성을 실질적으로 결정짓는 핵심 단계라 할 수 있다.\n\n1. 데이터 코딩\n설문 조사에서 코딩은 응답 데이터를 정형화하여 분석 가능한 형태로 전환하는 과정으로, 전체 데이터 품질과 해석의 정확성을 좌우하는 핵심 단계다. 폐쇄형 질문의 경우, 미리 정의된 선택지에 따라 각 응답을 숫자로 부호화하는 것이 일반적이며, 이는 비교적 간단하고 자동화가 용이하다. 예를 들어, “귀하의 현재 고용 상태는 무엇입니까?”라는 질문에 대해 ‘정규직’, ‘비정규직’, ‘실업’, ‘학생’ 등의 응답 항목이 있을 경우, 각각을 1, 2, 3, 4 등으로 코드화할 수 있다.\n반면, 개방형 질문은 응답자가 자신의 생각을 자유롭게 서술하는 형태로, 훨씬 더 복잡한 코딩 절차를 요구한다. 동일한 의미를 전달하더라도 표현 방식이 제각각이기 때문에, 일관된 분류 체계를 적용하기 위해서는 사전에 코딩 기준표(codebook)를 개발하고, 훈련된 코더가 이를 토대로 수작업 혹은 반자동화 방식으로 응답을 분류해야 한다. 예를 들어, “귀하가 생각하는 현재 경제의 가장 큰 문제는 무엇입니까?”라는 질문에 대해 ‘물가 상승’, ‘인플레이션’, ’가격이 너무 비쌈’이라는 응답이 들어왔다면, 이들을 하나의 범주로 묶어 같은 코드값을 부여해야 한다.\n이 과정에서 주관적 판단이 개입될 수 있으므로, 동일한 응답에 대해 다른 코더가 동일한 코드를 부여하도록 하는 코딩 일치도(inter-coder reliability) 점검이 필요하다. 또한 산업, 직업, 질병 분류 등과 같이 공공 표준 분류체계(KSIC, ISCO 등)를 사용하는 경우에는 더 정교한 매핑 작업이 요구된다.\n결과적으로, 코딩은 단순한 기술적 작업이 아니라 설문 응답의 의미를 체계적으로 해석하고 분석 가능하게 만드는 중요한 지적 과정이다. 특히 개방형 응답이나 복잡한 다중응답 항목에서는 코딩의 품질이 조사 전체의 신뢰성과 타당성에 직결되므로, 코딩 기준의 명확성, 코더의 훈련, 품질 점검 절차가 필수적이다.\n\n예비 분석: 수집된 응답을 검토하여 공통 패턴을 파악한다. 응답 내용을 기반으로 주요 범주를 설정한다.\n코드북 개발: 응답을 분류할 코드 체계를 설계한다. 각 코드에 대한 명확한 정의를 포함한다. 예를 들어, 산림 활용 관련 개방형 질문이 있다면, 1 = 목재 생산, 2 = 레크리에이션(산림욕, 캠핑 등), 3 = 환경 보호, 4 = 연구 및 교육, 5 = 기타\n응답 매핑: 개별 응답을 코드북에 따라 적절한 코드로 변환한다. 응답이 여러 개의 범주에 해당할 경우, 우선순위 규칙을 적용하거나 다중 코드를 허용할 수 있다.\n신뢰성 검토: 여러 명의 분석자가 같은 응답을 동일한 코드로 부여하는지 확인한다. 코딩 일관성 검증을 위해 상호 신뢰도 테스트를 수행한다.\n\n\n(1) 코딩의 본질\n코딩은 단순히 텍스트를 숫자로 바꾸는 기계적 과정이 아니라, 조사 응답 내용을 분석이 가능한 형태로 요약하고 구조화하는 핵심 작업이다. 개별 응답을 의미 있는 범주로 분류함으로써, 방대한 데이터를 정리하고 비교 가능한 자료로 전환할 수 있다. 즉, 코딩은 원자료를 해석 가능하고 통계 처리에 적합한 형태로 가공하는 과정이며, 응답자의 다양한 의견을 정제된 분석 단위로 추출해내는 역할을 한다.\n효과적인 코딩 시스템을 구축하기 위해서는 몇 가지 필수 요소가 갖추어져야 한다. 첫째, 모든 코드는 통계 분석 과정에서 고유하게 식별될 수 있도록 독립된 숫자 값으로 설정되어야 하며, 이는 데이터 처리의 정확성과 효율성에 직결된다. 둘째, 각 코드에는 응답 내용을 명확하게 설명해주는 텍스트 라벨이 함께 제공되어야 해, 코드가 어떤 의미를 담고 있는지를 쉽게 파악할 수 있도록 해야 한다. 셋째, 코딩 구조는 포괄적이어야 하며, 응답자의 어떤 답변도 최소한 하나의 코드에 포함될 수 있어야 한다. 넷째, 각 코드는 서로 겹치지 않도록 상호 배타적으로 구성되어야 하며, 동일한 응답이 중복해서 분류되는 일이 없어야 한다. 마지막으로, 코드 범주는 분석의 목적과 샘플 크기에 맞추어 실용적인 수준으로 유지되어야 하며, 지나치게 세분화된 코드는 분석의 복잡성을 높일 수 있다.\n이러한 코딩의 원칙은 산림 관련 조사를 포함한 다양한 주제의 조사에 적용될 수 있다. 예를 들어, 응답자가 “건강을 위해 산에 자주 간다”고 응답한 경우, 이 내용을 ‘산림 복지 이용’이라는 범주로 정의하고 ‘2’라는 숫자 코드를 부여할 수 있다. 마찬가지로 “목재를 직접 채취해서 사용한다”는 응답은 ‘1=목재 생산’ 코드에 포함시킬 수 있다. 이처럼 명확한 코딩 구조는 응답자의 서술형 답변을 체계적으로 정리하고, 정량적 분석의 기반을 다지는 데 필수적인 도구로 작동한다.\n코드 구조의 지속적인 검토와 개선\n코딩 과정에서는 사전에 정의된 코드 체계를 기반으로 응답을 분류하지만, 실제 조사 현장에서 수집되는 응답은 예외적이거나 복합적인 경우가 많아 기존 코드 구조에 완벽히 부합하지 않을 수 있다. 특히 개방형 문항이나 새로운 사회 현상을 반영한 응답에서는, 기존의 분류 기준으로는 설명이 어려운 경우가 발생한다. 이러한 상황을 해결하기 위해 초기 응답 데이터를 활용하여 코드 체계의 타당성을 사전에 검토하고, 필요 시 코딩 카테고리를 수정하거나 보완하는 절차가 필요하다.\n예를 들어, 기존의 산림 이용 목적을 ‘목재 생산’, ‘관광’, ‘사유림 보존’ 등으로 분류하던 코드 체계는 ’탄소중립을 위한 산림 보전’과 같은 새로운 응답 내용을 충분히 설명하지 못할 수 있다. 이런 경우 기존 코드를 억지로 적용하기보다는, 새로운 분류를 도입하거나 세부 카테고리를 추가하여 코드 구조를 유연하게 재편성하는 것이 바람직하다.\n이처럼 코딩 구조는 한 번 설정하고 끝나는 것이 아니라, 응답 자료의 다양성과 변화하는 조사 환경에 맞춰 지속적으로 검토하고 개선해야 한다. 이를 통해 코딩의 정확성과 응답 분류의 적절성을 높일 수 있으며, 조사 결과의 해석도 보다 정밀해진다. 따라서 코딩 체계는 고정된 틀이라기보다, 실질적인 데이터와 맥락에 맞춰 유기적으로 진화해야 하는 작업으로 이해되어야 한다.\n모든 응답을 포괄할 수 있는 코딩 체계를 설계하는 것은 데이터의 완전성과 분석의 정확성을 확보하는 데 필수적이다. 조사 과정에서는 응답자가 질문에 명확하게 답변하는 경우만 있는 것이 아니라, 무응답, 해당 없음, 거부 응답 등 다양한 예외 상황이 발생한다. 이러한 모든 경우를 체계적으로 반영할 수 있도록 코딩 구조는 사전에 신중하게 설계되어야 한다.\n첫 번째 전략은 응답이 없는 경우를 위한 코드 설정이다. 응답자가 질문에 아무런 답변을 하지 않았을 때, 이를 단순한 누락으로 처리하면 분석 과정에서 혼란이 발생할 수 있다. 따라서 이 경우에는 “미확인”이라는 의미의 별도 코드를 부여하여, 해당 응답이 의도적으로 빠졌음을 명확히 표시한다. 예를 들어, 단일 숫자 체계에서는 9, 두 자리 숫자 체계에서는 99를 사용할 수 있다.\n두 번째로는 특정 질문이 응답자에게 적용되지 않는 경우이다. 이는 설문 흐름상 논리적으로 해당 질문이 불필요한 경우인데, 이를 구분 없이 단순 결측으로 처리하면 응답자의 특성을 왜곡할 수 있다. 따라서 “적용 불가”라는 의미의 고유 코드(예: 0 또는 00)를 사용하여, 분석자가 이를 명확히 식별하고 분석 대상에서 제외하거나 별도로 처리할 수 있도록 해야 한다.\n세 번째는 기타 특수 응답의 처리이다. 예를 들어, “답변을 거부함”, “잘 모르겠다”와 같은 응답은 설문 문항에 대한 반응이긴 하지만, 내용적으로 유효한 데이터로 보기 어려운 경우가 많다. 이 역시 별도의 코드를 부여하여 정규 응답과 구분하는 것이 바람직하다. 이를 통해 분석자는 이러한 특수 응답을 전체 응답률 계산에서 제외하거나, 추가 분석 시 변수로 활용할 수 있다.\n이러한 보조 응답 코드들을 미리 정의하고, 설문지 설계 시점부터 적용하는 것은 조사 자료의 품질을 높이고, 추후 분석 시 오류나 혼동을 줄이는 데 중요한 역할을 한다. 특히 대규모 표본조사나 반복조사에서는 이러한 표준화된 코딩 체계가 일관성과 비교 가능성을 보장하는 데 필수적이다.\n결론 및 시사점 코딩은 단순히 응답을 숫자로 변환하는 기술적 절차를 넘어, 조사 목적에 맞는 응답 내용을 요약하고 구조화하는 해석적 과정이다. 이를 위해 코드의 수와 범주 분류 체계는 분석 목표에 부합하도록 신중하게 설계되어야 하며, 이 과정에서 상호 배타성과 포괄성이라는 원칙을 동시에 충족해야 한다. 즉, 하나의 응답이 두 개 이상의 코드에 중복되지 않도록 하면서도, 어떤 응답도 누락되지 않도록 체계를 갖추는 것이 중요하다.\n연구자가 설정한 가설이나 분석 목적에 따라 코드 체계는 유연하게 설계되어야 하며, 통계적으로 의미 있는 비교와 해석이 가능하도록 조정되어야 한다. 특히 새로운 데이터가 기존 코드 체계와 맞지 않을 경우, 해당 구조가 여전히 유효한지 재검토하고 필요한 경우 수정하는 과정이 필수적이다. 이를 통해 변화하는 응답 경향과 사회적 맥락에 맞춰 설문의 분석력을 유지할 수 있다.\n또한, “응답 없음”, “미확인”, “적용 불가” 등과 같은 예외 응답들을 위한 별도 코드 체계를 마련하는 것은 데이터 누락이나 분석 왜곡을 방지하는 데 큰 역할을 한다. 이러한 부가 응답 코드는 설문 응답의 전체 구조를 온전하게 반영할 수 있게 해주며, 분석 시 결과의 신뢰성을 높여준다.\n결론적으로, 코딩 체계의 설계와 유지보수는 단순한 데이터 정리 작업이 아니라, 조사 데이터의 질을 결정짓는 핵심적인 과정으로 이해되어야 하며, 그 중요성은 설문 설계 초기 단계부터 반영되어야 한다.\n\n\n(2) 필드 코딩\n필드 코딩의 개념\n필드 코딩은 설문조사 현장에서 개방형 질문의 장점과 폐쇄형 질문의 효율성을 결합한 방식으로, 조사원이 응답자의 자유로운 진술을 들은 직후, 해당 응답을 사전에 정의된 코드 범주 중 하나로 분류하는 실시간 코딩 기법이다. 응답자는 자신의 언어로 서술형 답변을 제공하되, 조사원은 이미 준비된 코딩 체계에 따라 즉시 해당 응답을 구조화된 데이터로 전환한다.\n이러한 방식은 사후에 별도로 개방형 응답을 수집하고 코딩하는 번거로움을 줄이고, 조사 현장에서 코딩 기준이 일관되게 적용될 수 있다는 장점을 지닌다. 특히 대규모 조사를 수행하거나 반복적인 질문이 많은 경우, 시간과 인력의 효율성을 크게 향상시킨다. 단, 조사원의 코딩 판단이 결과에 직접 영향을 미치기 때문에, 사전 교육과 명확한 코드북 제공이 필수적이며, 조사 중 혼란이 발생하지 않도록 지속적인 모니터링과 품질 점검이 필요하다.\n필드 코딩의 절차\n\n응답자에게 개방형 질문을 제시 → 자유롭게 서술형 응답을 하도록 유도한다.\n조사원이 즉시 응답을 해석 → 해당 응답이 포함될 수 있는 코드 범주를 검토한다.\n사전 정의된 코드 리스트와 비교하여 적절한 코드 선택 → 가장 적합한 카테고리에 배정한다.\n코딩을 완료하고 데이터 저장 → 이후 데이터 분석에서 활용 가능하도록 정리한다.\n\n필드 코딩 장단점\n\n\n\n\n\n\n\n\n구분\n항목\n설명\n\n\n장점\n즉각적인 코딩 가능\n응답을 수집하면서 동시에 코딩을 수행하여 사후 코딩 과정이 불필요\n\n\n질문에 대한 깊이 있는 탐색 가능\n인터뷰어가 응답 내용을 추가로 탐색하여 보다 정확한 분류 가능\n\n\n응답자의 자유도 보장\n완전한 폐쇄형 질문과 달리, 응답자의 입장에서 보다 자연스러운 답변 제공 가능\n\n\n단점\n인터뷰어의 해석에 따른 오류 발생 가능\n같은 응답이라도 조서자마다 코드 부여 방식이 다를 수 있음\n\n\n실시간 처리의 부담\n조사원이 실시간으로 응답을 분석하고 코드화해야 하므로 부담이 클 수 있음\n\n\n복잡한 코드 체계의 경우 어려움\n코드의 수가 많거나 복잡하면 인터뷰어가 즉시 적절한 범주를 선택하기 어려울 수 있음\n\n\n\n필드 코딩과 사후 코딩 비교\n\n\n\n\n\n\n\n\n구분\n필드 코딩\n오피스 코딩\n\n\n코딩 시점\n실시간 코딩 (인터뷰 진행 중)\n조사 후 코딩 (설문 응답을 저장한 후)\n\n\n책임자\n조사원이 직접 코드화\n전문 코더가 응답을 해석하여 코드화\n\n\n장점\n즉각적인 데이터 정리 가능, 추가 탐색 가능\n보다 체계적이고 일관성 있는 코딩 가능\n\n\n단점\n인터뷰어의 주관 개입 가능, 실시간 처리 부담\n시간이 많이 소요됨, 사후 코드 검토 필요\n\n\n\n\n\n(3) 코딩 품질 지표\n코딩 과정에서 발생할 수 있는 개념적 오류나 실행의 비일관성은 설문조사 데이터의 신뢰성과 타당성에 중대한 영향을 미친다. 개념적 오류는 질문의 의도와 코딩 범주 간의 불일치에서 비롯되며, 응답자의 진술을 잘못 해석하거나 본래의 의미와 다르게 분류하는 경우 발생한다. 예를 들어, 응답자가 “산림을 가족과 함께 쉬러 간다”고 했을 때, 이를 단순히 ’여가활동’으로만 코딩하면 ’가족 중심 활동’이라는 사회문화적 맥락이 누락될 수 있다.\n또한 실행의 비일관성은 동일한 응답이 조사원마다 서로 다른 코드로 분류되는 경우로, 코딩 지침이 모호하거나 조사원 교육이 충분하지 않을 때 자주 발생한다. 이는 데이터의 비교 가능성을 떨어뜨리고 분석 결과의 왜곡을 초래할 수 있다. 따라서 일관된 코딩 기준을 마련하고, 정기적인 코딩 검토 및 품질 관리를 통해 이러한 오류를 최소화하는 것이 중요하다.\n코딩 구조의 취약점\n코딩 구조가 취약하게 설계될 경우, 의미적으로 서로 다른 응답이 동일한 코드 범주에 포함되어 분석 결과에 왜곡을 초래할 수 있다. 이는 단순한 분류상의 실수가 아니라, 체계적인 오분류로 이어져 분석의 신뢰성을 떨어뜨리는 요인이 된다. 특히 응답 항목 간의 차이가 미묘하거나 사회문화적 맥락이 개입되는 경우, 이러한 위험은 더욱 커진다.\n예를 들어, 학력을 기준으로 소득을 분석할 때 “고등학교 졸업”이라는 항목에 정규 고등학교 졸업자와 검정고시 합격자가 동일하게 포함되면, 두 집단 간 경험과 사회적 배경의 차이를 간과하게 된다. 더 나아가, ’3년 전 졸업’과 ’최근 검정고시 합격’은 시간적, 교육적 맥락에서도 차이가 있으므로 별도의 코딩 처리가 필요하다. 따라서 코딩 구조는 분석 목적과 변수의 의미를 충분히 반영하도록 정교하게 설계되어야 하며, 애매하거나 복합적인 응답에 대해 세분화된 코드 범주를 마련하는 것이 체계적인 오류를 줄이는 핵심이다.\n코더 변량 coder variance\n코더 변량(coder variance)은 동일한 응답에 대해 서로 다른 코더들이 다르게 코딩함으로써 발생하는 데이터의 변동성을 의미한다. 이는 주관적인 판단이 개입되는 개방형 질문이나 복잡한 분류 작업에서 자주 나타나며, 조사 결과의 일관성과 신뢰도를 저하시킬 수 있다.\n코더 변량은 조사 데이터의 전체 오차 중 ’코딩 단계’에서 발생하는 오차를 구성하며, 설문 응답 그 자체의 내용이나 응답자의 특성이 아닌 코더의 해석이나 경험, 숙련도에 따라 달라질 수 있다. 예를 들어, 동일한 “기타 의견” 응답을 어떤 코더는 ’환경 보호’로, 다른 코더는 ’산림 복지’로 분류할 경우, 해당 항목에 대한 통계적 추정치에 차이가 발생하게 된다.\n따라서 코더 변량을 줄이기 위해서는 명확한 코딩 지침서 제공, 사전 훈련, 사후 일관성 검사 등의 조치가 필요하며, 가능한 경우 자동화된 코딩 시스템이나 복수 코더 간의 교차 검토 절차를 도입하는 것이 바람직하다. 이처럼 코더 변량은 조사 설계의 품질 관리와 데이터 정합성을 확보하는 데 반드시 고려되어야 하는 요소이다.\n코더마다 같은 코딩 구조를 다르게 사용할 가능성이 있음\n코딩 과정에서 각 코더가 동일한 코딩 구조를 다르게 해석하고 사용하는 경우가 발생할 수 있다. 이는 코더마다 특정 코드 범주를 선택하는 경향성이 다르기 때문이며, 조사 데이터의 일관성과 정확성에 영향을 미치는 주요 요인 중 하나다.\n예를 들어, 어떤 코더는 애매한 응답에 대해 “기타”나 “명확히 지정되지 않음”과 같은 잔여 코드를 자주 사용하는 반면, 다른 코더는 더 구체적인 범주에 억지로라도 할당하려는 경향을 보일 수 있다. 또한, 동일한 응답 내용에 대해 해석 방식이 달라 각기 다른 코드가 부여되는 경우도 발생한다. 이러한 차이는 코더의 경험, 훈련 수준, 또는 주관적 판단 기준에서 기인할 수 있다.\n결과적으로, 이러한 비일관성은 동일한 응답이 상황에 따라 다르게 처리되어 통계 분석의 왜곡을 초래할 수 있으므로, 코더 간의 해석 차이를 줄이기 위한 명확한 지침과 코딩 기준의 일관된 적용이 필수적이다.\n코더별 코딩 편차를 측정하는 방법\n코더별 코딩 편차는 조사 데이터의 품질을 정량적으로 평가하기 위해 중요한 분석 대상이다. 이를 측정하는 대표적인 방법 중 하나는 내집단 상관계수(interclass correlation coefficient, ICC)를 활용하여 코더 간의 일관성을 분석하는 것이다. 이 계수는 동일한 응답에 대해 여러 코더가 얼마나 유사한 코드를 부여했는지를 수치로 표현하며, 값이 1에 가까울수록 높은 일치도를 의미한다.\n실제 사례로, 영국에서 수행된 한 연구에서는 코더 간 ICC 평균값이 0.001로 보고되었다. 이는 매우 낮은 값으로, 코더 간 일치도가 크지 않다는 것을 보여준다. 비록 이 수치는 일반적으로 조사원(interviewer) 효과보다 작은 수준이지만, 여전히 조사 통계의 변동성과 신뢰도에 영향을 줄 수 있다.\n따라서, 코딩 과정에서 코더 간 편차를 최소화하고, 통계 결과의 왜곡을 방지하기 위해서는 코더 훈련 강화, 코드북의 명확화, 정기적인 모니터링과 평가가 필요하다.\n코더 변량이 조사 통계에 미치는 영향\n코더 변량은 코딩 과정에서 각 코더가 동일한 응답을 해석하고 분류하는 방식의 차이로 인해 발생하는 변동성으로, 이로 인해 조사 통계의 정확도와 신뢰도에 영향을 미칠 수 있다. 특히 개방형 질문이나 복잡한 분류 기준이 있는 항목의 경우, 코더 간 해석 차이는 미묘한 코딩 편차를 초래할 수 있으며, 이러한 편차가 누적되면 전체 통계 추정치에 영향을 줄 수 있다.\n예를 들어, 특정 직업을 “전문직”으로 분류할지 “기술직”으로 분류할지를 놓고 코더마다 판단이 다르면, 직업군별 분포나 관련 변수와의 연관성 분석에서 통계적으로 유의미한 차이가 나타날 수 있다. 비록 개별 코딩의 차이는 작을지라도, 표본 규모가 크고 코더 수가 많을수록 이 편차가 전체 조사 결과의 분산을 증가시키고, 결과적으로 통계적 해석의 불확실성을 높일 수 있다.\n코더 변량이 조사 통계의 분산에 미치는 영향을 나타내는 공식: \\(Deff = 1 + \\rho_{c}(m - 1)(1 - r)\\), 여기서 \\(\\rho_{c}\\)은 코더의 내집단 상관계수, \\(m\\)은 개별 코더가 코딩한 평균 사례 수, \\(r\\)은 특정 코드의 신뢰도이다.\n코더 변량이 조사 결과에 미치는 영향\n코더 변량이 조사 결과에 미치는 영향은 작지만 무시할 수 없는 수준이다. 비록 동일한 코드 구조를 사용하더라도, 코더는 개인의 판단과 해석 방식에 따라 동일한 응답을 다르게 분류할 수 있다. 이러한 차이는 특히 자유응답형(open-ended) 문항이나 복잡한 범주 체계를 사용하는 경우 두드러지며, 결과적으로 조사 추정치의 일관성과 신뢰성을 저해할 수 있다.\n훈련된 코더는 일반적으로 코딩 결정에서 더 높은 일관성을 보이며, 조사원에 비해 상대적으로 작은 변동성을 유발한다. 그러나 한 명의 코더가 처리하는 응답 수는 대개 매우 많기 때문에, 적은 수준의 코더 변량도 전체 표본 추정치에 영향을 줄 수 있다. 이는 표준 오차의 증가로 이어져 결과 해석 시 통계적 불확실성을 높이는 요인이 된다. 따라서 코딩 매뉴얼의 명확화, 반복 교육, 이중 코딩(double coding)을 통한 검증 과정이 중요하다.\n\n\n\n2. 수치 데이터를 파일에 입력하기\n데이터 입력의 개념\n데이터 입력, 또는 데이터 캡처는 설문조사 과정에서 수집된 정보를 전자적 형태로 전환하는 단계로, 분석을 위한 기초 작업 중 하나이다. 이 과정은 수집된 응답을 컴퓨터 파일에 체계적으로 입력하여 이후 통계 처리와 해석이 가능하도록 준비하는 것을 의미한다. 데이터 입력 방식은 설문조사의 수행 방식에 따라 다양하게 결정된다.\n예를 들어, 컴퓨터 지원 면접 조사(CAPI, Computer-Assisted Personal Interviewing)의 경우, 조사원이나 응답자가 설문 소프트웨어를 통해 직접 데이터를 입력함으로써 별도의 입력 과정 없이 응답과 동시에 데이터가 수집된다. 전화 응답 시스템에서는 터치톤 입력 또는 음성 인식을 통해 응답자가 직접 입력한 정보가 자동으로 기록되며, 이는 인터뷰어 없이도 데이터 입력이 이루어지는 자동화 방식이다.\n반면 종이 설문지를 사용하는 전통적인 조사에서는 데이터 입력자가 일일이 수기로 응답 내용을 전산 시스템에 입력해야 한다. 이 과정은 시간이 많이 소요되며 오류 가능성이 존재하기 때문에, 최근에는 마크 문자 인식(Mark Recognition) 또는 광학 문자 인식(OCR, Optical Character Recognition) 기술을 활용하여 입력 속도를 높이고 정확성을 개선하려는 노력이 증가하고 있다.\n결국, 데이터 입력은 수집된 응답을 디지털 자산으로 전환하는 핵심 과정이며, 입력 방식의 선택은 조사 방식, 예산, 시간, 데이터 정확성 요구 수준 등에 따라 결정된다.\n인간 데이터 입력 방식의 한계\n인간이 직접 수행하는 데이터 입력 방식은 설문조사에서 전통적으로 사용되어 왔으나, 여러 가지 한계를 가지고 있다. 가장 큰 문제는 높은 인건비와 시간 소요이다. 사람이 응답지를 일일이 검토하고 숫자화하는 과정은 정확도를 확보하기 위해 반복 검증이 요구되며, 이는 전반적인 조사 비용을 크게 증가시키는 요인이 된다.\n보통 이러한 방식에서는 데이터 정확성을 확보하기 위해 100% 재입력(Double Data Entry) 또는 2인 검증 등의 절차가 수행된다. 하지만 이러한 노력에도 불구하고 사람의 실수로 인한 오류 가능성은 완전히 제거되지 않는다. 특히 대규모 조사에서는 수만 건의 응답을 처리해야 하므로, 누락, 중복, 오타 등 다양한 입력 오류가 발생할 수 있다.\n이러한 한계를 극복하고자 최근에는 컴퓨터 지원 데이터 수집(CAPI, CAWI 등) 방식이 선호되고 있다. 이는 입력 작업을 자동화함으로써 입력 오류를 줄이고, 동시에 비용과 시간을 절감하는 효과를 기대할 수 있다. 결과적으로, 설문조사의 효율성과 정확성을 동시에 확보하기 위해 사람의 수작업보다 디지털 기반 입력 방식이 점차 주류로 자리잡고 있는 추세다.\n\n\n3. 데이터 편집 editing\n데이터 편집의 개념\n데이터 편집은 설문조사에서 수집된 응답 자료가 통계 분석에 적합하도록 정제하는 초기 단계로, 데이터의 정확성과 논리적 일관성을 확보하는 데 필수적인 과정이다. 수집된 데이터는 종종 응답 누락, 상호 모순된 답변, 비현실적인 값 등 다양한 오류를 포함할 수 있기 때문에, 분석 전에 반드시 점검과 수정이 필요하다.\n이 과정은 인터뷰어가 현장에서 수기로 응답을 확인하거나, 조사 감독자가 응답지를 검토하며 오류를 찾아내는 방식으로 진행될 수 있다. 또한, 데이터 입력 과정에서 입력 담당자가 입력값을 확인하고, 전문 연구자가 조사 설계와 비교하여 논리적 타당성을 점검하는 작업도 포함된다. 최근에는 자동화된 컴퓨터 소프트웨어를 활용한 논리적 규칙 기반 검증 시스템을 통해 일관성 없는 응답이나 허용 범위를 벗어난 값을 자동으로 탐지하고 수정하는 방식이 널리 사용되고 있다.\n편집의 목적은 단순히 오류를 제거하는 데 그치지 않고, 원래 설계된 질문 의도에 부합하는 응답 체계를 회복하는 데 있다. 이를 통해 분석 결과의 신뢰성을 높이고, 조사 데이터의 품질을 한층 더 향상시킬 수 있다.\n편집의 주요 내용\n편집의 주요 내용은 다음과 같은 세 가지 요소로 요약할 수 있다.\n첫째, 편집은 조사원이나 응답자가 기록한 원자료를 점검하고 보정함으로써 데이터 품질을 향상시키는 데 중점을 둔다. 응답자가 실수로 잘못 기입했거나 조사원이 부정확하게 기록한 항목을 수정하여, 수집된 데이터가 현실을 보다 정확하게 반영하도록 한다.\n둘째, 코딩과 결측값 대체도 편집의 일환으로 포함된다. 특히 개방형 응답을 범주화하여 수치 코드로 변환하는 코딩 작업과, 누락된 값을 적절한 통계기법으로 보완하는 대체 작업은 편집 과정 중 핵심적인 절차에 해당한다.\n셋째, 편집은 무엇보다도 데이터가 논리적 정합성을 유지하도록 정리하는 데 목적이 있다. 예를 들어, 연령이 5세인데 직업이 있다고 응답한 경우처럼 명백히 논리적으로 모순된 자료를 탐지하고 수정함으로써, 전체 분석 결과의 타당성과 신뢰도를 확보할 수 있다. 이러한 논리적 일관성은 단일 항목 내에서도 중요하지만, 항목 간 관계에서도 일관되게 유지되어야 한다.\n데이터 편집 주요 유형\n\n\n\n\n\n\n\n\n편집 유형\n설명\n예시\n\n\n범위 편집\n데이터 값이 허용된 범위 내에 있는지 확인\n연령 값이 1개월 이상, 120년 이하인지 검사\n\n\n비율 편집\n특정 값 간 비율이 논리적으로 맞는지 확인\n농장에서 생산된 우유 갤런 수와 젖소의 수 비율이 적절한지 확인\n\n\n이력 데이터 비교\n이전 조사 데이터와 비교하여 일관성을 점검\n1차 조사와 2차 조사에서 가구원 수가 유사한지 확인\n\n\n균형 편집\n여러 변수의 합이 일정해야 하는 경우 확인\n집, 직장, 기타 장소에서 보낸 시간의 합이 100%인지 검사\n\n\n최대·최소 값 확인\n비정상적으로 큰 값이나 작은 값이 존재하는지 검사\n극단적인 소득 값이 존재하는지 확인\n\n\n일관성 편집\n논리적 관계가 성립하는지 점검\n12세 미만 응답자의 혼인 상태는 '미혼'이어야 함\n\n\n\nCAPI와 편집\n컴퓨터 지원 면접조사(CAPI: Computer-Assisted Personal Interviewing)의 도입은 편집 과정을 설문 응답 단계에서 실시간으로 수행할 수 있게 해 주었다. 이러한 방식은 설문 응답이 완료되기 전부터 오류 탐지 및 수정 작업을 자동화함으로써, 전체 데이터 품질을 크게 향상시킬 수 있다는 장점이 있다.\n예를 들어, 응답자가 나이를 “5세”로 입력하고 직업을 “회사원”으로 응답했을 경우, CAPI 시스템은 논리적 오류를 탐지하고 즉시 경고 메시지를 띄워 인터뷰어나 응답자가 해당 항목을 다시 확인하도록 유도할 수 있다. 이처럼 실시간 편집은 응답 도중 오류를 줄이고, 후속 데이터 정제 부담을 줄이는 데 효과적이다.\nCAPI에서 사용하는 오류 점검 방식은 일반적으로 두 가지로 구분된다. 첫째는 강제 체크(hard edit check)로, 명백한 오류가 발생했을 때 설문 진행이 중단되며 반드시 수정이 이루어져야 한다. 둘째는 소프트 체크(soft edit check)로, 값이 비정상적으로 보이긴 하지만 이론적으로 허용 가능한 범위 내에 있을 경우 경고 메시지만 제공하고 응답을 유지할 수 있도록 한다.\n그러나 이러한 시스템이 항상 응답자의 실제 상황을 완벽하게 반영하는 것은 아니다. 응답자가 비표준적인 특수 사례에 속하거나, 반복적으로 유사한 방식으로 응답을 고집하는 경우, 인터뷰어가 시스템의 논리에 따라 응답을 수정하도록 유도하다 보면 실제 상황과 불일치가 발생할 수 있다. 따라서 실시간 편집 기능은 설문 설계자의 전문적 판단과 병행되어야 하며, 시스템 오류 경고에 과도하게 의존하지 않는 균형이 필요하다.\n데이터 편집 발전\n데이터 편집의 방식은 전통적인 수작업 중심에서 점점 더 규칙 기반(rule-based) 및 컴퓨터 지원 방식으로 진화하고 있다. 이러한 전환은 데이터 품질을 보다 체계적이고 일관되게 관리할 수 있도록 하며, 전체 조사 비용을 절감하는 데도 기여하고 있다.\n자동화된 편집 시스템은 설문 응답이 데이터베이스에 입력되는 즉시 미리 정의된 논리 규칙에 따라 오류를 탐지하고 수정 가능성을 평가한다. 예를 들어, 응답자의 연령과 직업이 논리적으로 맞지 않는 경우, 시스템은 사전에 설정된 규칙에 따라 경고를 띄우거나 자동으로 수정 여부를 제안할 수 있다. 이러한 규칙 기반 편집은 복잡한 변수 간 논리 관계를 빠르게 탐지하고, 반복적인 오류를 자동 처리함으로써 사후 편집의 필요성을 크게 줄인다.\n특히 최근에는 데이터 수집 단계에서 편집 절차를 선제적으로 통합하는 경향이 두드러지고 있다. 이는 실시간 오류 수정 기능(CAPI, CAWI 등)과 연계되어, 조사 중에 잘못된 응답이 입력되는 것을 방지하거나 수정하도록 유도하는 방식이다. 이처럼 편집이 데이터 수집과 동시에 이루어지면, 조사 이후의 대규모 오류 수정 작업이 불필요해질 수 있다.\n더 나아가, 최신 편집 시스템은 점차 전문가 지식과 인공지능(AI) 기반 알고리즘을 활용하는 방향으로 발전하고 있다. 예컨대, 과거 편집 사례에서 학습한 패턴을 기반으로 오류 가능성을 자동 예측하거나, 비정상적 응답에 대해 맥락 기반 추천을 제시하는 기능이 개발되고 있다. 이는 전문가 개입 없이도 더 정교하고 신뢰할 수 있는 편집이 가능하게 하며, 편집 작업의 일관성과 효율성을 한층 높일 수 있다.\n\n\n\nchapter 2. 가중치 산정\n조사 표본에서 가중치는 통계적 추정의 정확성을 높이고, 모집단을 보다 대표할 수 있도록 설계상의 왜곡과 응답 편향을 보정하는 데 사용된다. 특히 현실의 많은 표본조사에서는 단순무작위추출(SRS)을 적용하기 어렵고, 실제로는 층화(stratification), 집락(clustering), 비확률(nonresponse) 등의 복잡한 설계가 포함되기 때문에, 이에 대한 보정이 필수적이다.\n예를 들어, 특정 연령대나 지역 집단이 과도하게 추출되었거나, 응답률이 낮은 집단이 있을 경우, 해당 집단의 실제 비중을 반영하기 위해 가중치를 조정해야 한다. 또한, 조사 응답자가 표본설계 당시 예상했던 분포와 다르게 분포되었을 경우에도 보정이 필요하다. 이때 가중치는 개별 응답자의 수치를 모집단 전체에 합리적으로 확장하는 기능을 하며, ’확장 계수(expansion factor)’로 불리기도 한다.\n가중치는 단일 방식으로 계산되지 않으며, 조사 설계의 복잡도와 조사 목적에 따라 다양한 조정 절차가 적용된다. 예를 들어, 층화 및 군집 표본 설계에 따른 기본 가중치(base weight), 비응답 조정을 위한 보정 가중치(nonresponse adjustment weight), 외부 모집단 분포와의 정합성을 맞추기 위한 보정 계수(post-stratification or calibration weight) 등이 순차적으로 적용될 수 있다. 이렇게 다단계로 조정된 최종 가중치는 분석 단계에서 반드시 반영되어야 하며, 그렇지 않으면 모집단을 왜곡하는 결과를 초래할 수 있다.\n이와 같은 가중치 조정의 이론적 토대와 실무 적용에 대해서는 Kalton(1981)의 표본조사 기법에 대한 논의와 Bethlehem(2002)의 응답 편향 보정 연구가 대표적인 참고 문헌으로 자주 인용된다. 두 연구는 표본조사에서의 가중치 조정이 단순한 비율 조정이 아니라, 정교한 통계 모델링과 설계 기반 추정 절차의 일부임을 강조한다.\n\n1. 단계 비율 조정 가중치\n다단계 표본 설계에서는 모집단 전체를 한 번에 추출하지 않고, 여러 단계를 거쳐 표본을 선택한다. 가장 일반적인 예는 1단계에서 지역 단위의 기본 표본 단위(PSU)를 선택하고, 그 안에서 가구 또는 개인을 다시 추출하는 방식이다. 이때 PSU는 모집단의 특정 속성(예: 인구 수, 가구 수 등)을 나타내는 크기 척도에 비례하여 추출된다. 즉, 규모가 큰 PSU일수록 선택될 확률이 높다.\n이러한 방식으로 표본을 추출하면, 각 단위의 선택 확률이 서로 다르게 되므로, 이를 보정하기 위한 가중치가 필요하다. 이 가중치는 보통 “확률의 역수”로 정의되며, 어떤 단위가 선택될 확률이 작을수록 더 큰 가중치를 갖는다. 이를 통해 각 단위가 모집단 전체를 대표할 수 있도록 보정한다.\n또한, 모집단의 실제 크기가 아닌 대체 가능한 보조 지표(예: 인구센서스, 행정자료 등)를 통해 PSU를 선정하는 경우가 많기 때문에, 가중치 산정 시 이 지표에 대한 신뢰성과 대표성을 충분히 고려해야 한다. 이처럼 단계 비율 조정 가중치는 복잡 설계에서 모집단 전체를 대표하는 데 필수적인 절차이며, 분석 단계에서 반드시 반영되어야 한다.\n1단계 비율 조정 가중치 개념\n1단계 비율 조정 가중치는 다단계 표본 설계에서 균등 확률 표본(EPSM: Equal Probability Sample)을 실현하기 위해 사용되는 보정 방식이다. 이 방식의 핵심은, 최종적으로 추출된 표본이 각 층의 모집단 크기에 비례하도록 가중치를 부여하는 것이다.\n예를 들어, 어떤 층이 전체 모집단에서 차지하는 비율이 0.5%라면, 이 층에서는 전체 표본의 약 0.5%가 추출되도록 설계되어야 한다. 그러나 실제로는 조사비용이나 가용 인력, 지역 간 접근성 등의 이유로 층별 표본 수가 균형 있게 배분되지 않을 수 있다. 이런 경우, 1단계에서 선택된 기본 표본 단위(PSU, 예: 시군구)에 대해 가중치를 조정하여 층별 대표성을 확보하게 된다.\n이때 사용되는 가중치는 각 층 내 PSU가 선택될 확률의 역수를 기반으로 하며, 모집단 내 각 층의 상대적 규모를 고려하여 조정된다. 이를 통해 결과적으로, 조사 결과가 전체 모집단의 구조를 더 정확하게 반영할 수 있게 된다. 이러한 비율 조정은 모집단 크기에 대한 외부 보조 정보(예: 인구총조사, 등록 자료 등)를 바탕으로 수행되며, EPSM 설계 원칙에 따라 각 층의 비중이 전체 추정치에 제대로 반영되도록 한다. \\[\\text{Estimated Stratum Population Total} = \\frac{\\text{Population Total in Selected PSU}}{\\text{Probability of Selecting PSU}}\\]\n즉, 1단계 비율 조정 가중치의 핵심은 층 전체의 모집단 규모를 반영하여, 실제로 선택된 PSU(Primary Sampling Unit, 예: 시군구)의 모집단 총계를 기반으로 층 내 대표성을 확보하는 것이다.\n이는 선택된 PSU가 그 층의 전체를 제대로 대표하지 못하는 경우라도, 해당 PSU의 모집단 규모를 활용하여 가중치를 조정함으로써 층 전체의 특성을 보다 정확히 추정할 수 있도록 한다. 다시 말해, 어떤 특정 PSU가 선택되었든지 간에 그 층의 다른 PSU가 선택되었을 때와 유사한 결과가 도출되도록 설계하는 것이다.\n이러한 가중 조정 방식은 층 내 비선택 PSU들이 포함하는 모집단의 정보까지도 간접적으로 반영하는 역할을 하며, 복잡한 표본 설계에서도 추정의 일관성과 신뢰성을 유지하는 데 중요한 기법이다.\n실질적인 가중치 적용\n실질적인 가중치 적용 단계에서는, 1단계에서 선택된 PSU(Primary Sampling Unit, 예: 시군구 등)에 포함된 모든 조사 대상자(응답자)에게 동일한 1단계 비율 조정 가중치가 부여된다. 이때 생성되는 새로운 가중치 변수는 \\(W_{i1}\\) 로 표시되며, 여기서 첨자 1은 이 가중치가 여러 단계 중 첫 번째 조정 단계에서 부여된 값임을 의미하고, 대문자 W는 이 가중치가 표본 데이터가 아닌 프레임 모집단(설계 당시 모집단)의 구조를 반영한 것임을 나타낸다.\n즉, \\(W_{i1}\\) 은 선택된 PSU의 모집단 규모와 표본 추출 비율에 따라 계산된 값이며, 해당 PSU 내 모든 응답자에게 동일하게 적용된다. 이 과정은 PSU가 포함된 층 전체의 대표성을 확보하는 데 필수적인 절차로, 이후 단계에서 추가 가중치 조정이 이루어질 경우, 이 \\(W_{i1}\\) 이 기초 가중치로서 출발점이 된다.\n\n\n2. 차등 선택 확률 가중치\n예를 들어, 성폭력 피해 경험 조사를 수행할 때 전체 모집단이 1,000명이고 이 중 남성이 600명, 여성이 400명이라고 하자. 이 경우, 전체 인구 비율을 반영한다면 표본도 남성 120명, 여성 80명으로 구성되어야 모집단의 비율과 일치한다. 그러나 연구자는 여성의 피해 경험을 보다 정밀하게 분석하고자 여성 응답자를 120명, 남성을 80명으로 선정했다면, 이는 여성을 과대표본(over-sampling) 한 셈이다.\n이처럼 각 계층이 모집단 내 실제 비율과 다르게 추출된 경우, 분석 결과는 전체 모집단을 제대로 반영하지 못할 수 있다. 이러한 대표성 왜곡을 보정하기 위해 차등 선택 확률 가중치를 부여한다. 이 가중치는 모집단 내 각 집단의 비율과 표본에서의 비율을 비교하여 계산된다. 예를 들어, 남성은 모집단의 60%를 차지하지만 표본에서는 40%에 불과하므로, 이 차이를 보정하기 위해 남성 응답자에게는 더 높은 가중치가 부여된다. 반대로 여성은 과대표집 되었으므로 상대적으로 낮은 가중치를 받게 된다.\n결과적으로, 차등 선택 확률 가중치는 표본 설계의 불균형을 보정하여, 표본으로부터 계산한 통계량이 실제 모집단의 특성을 보다 정확하게 반영할 수 있도록 돕는다.\n비례 배분(EPSEM, Equal Probability Selection Method)\n표본이 모집단의 주요 특성 분포를 그대로 반영하도록 설계된 추출 방식이다. 예를 들어, 모집단의 성비가 남성 60%, 여성 40%인 경우, 200명의 표본을 추출할 때 이를 그대로 반영하여 남성 120명, 여성 80명으로 구성하는 방식이다. 이때 각 성별이 동일한 확률로 선택되며, 이는 모집단의 구성 비율에 비례한다는 점에서 “비례 배분”이라고 부른다.\n이러한 방식에서는 모든 단위가 동일한 선택 확률을 가지므로, 결과적으로 표본 설계 자체가 모집단을 잘 대표하게 된다. 따라서 분석 과정에서 추가적인 가중치를 적용할 필요가 없다. 모든 표본 단위의 가중치는 동일하며, 예를 들어 1,000명의 모집단에서 200명을 추출했다면 각 표본의 가중치는 \\(1/(1/5) = 5\\)가 된다. 남녀 모두 동일한 5의 가중치를 가지므로 통계 추정에 있어 왜곡이 발생하지 않는다.\n즉, 비례 배분 방식은 설계 자체가 균형을 유지하므로 별도의 보정 없이도 신뢰할 수 있는 분석 결과를 제공하는 장점이 있다. 하지만, 소수 집단이나 관심 집단의 표본 수가 너무 적어 분석이 어려울 경우에는 비례 배분보다 과표집(over-sampling) 방식이 필요하며, 이때는 앞서 설명한 차등 선택 확률 가중치가 적용되어야 한다.\n차등 배분(Disproportionate Allocation)\n차등 배분(disproportionate allocation)은 표본 추출 시 특정 집단의 표본 수를 인위적으로 조정하는 방식으로, 특히 드문 특성을 조사할 때 통계적 정밀도를 확보하기 위해 사용된다. 예를 들어, 성폭력 피해율처럼 일반적으로 여성에게 더 많이 나타나는 현상을 분석할 때, 여성 응답자의 수를 늘려 보다 정확한 추정치를 확보하려는 경우다.\n모집단이 남성 600명, 여성 400명으로 구성되어 있다고 가정하고, 전체 표본을 200명으로 설정할 때, 단순히 모집단 비율에 따라 추출한다면 남성 120명, 여성 80명을 선택하게 된다. 이는 비례 배분(equal allocation)이며, 따로 가중치 조정이 필요하지 않다.\n그러나 여성 피해자의 수를 늘려 보다 정밀한 분석을 수행하기 위해, 남성과 여성을 각각 100명씩 조사하는 차등 배분을 실시한다고 가정하자. 이 경우, 모집단 대비 표본 비율은 다음과 같다: • 남성: 600명 중 100명 → 표본 비율 1/6 → 가중치 6 • 여성: 400명 중 100명 → 표본 비율 1/4 → 가중치 4\n즉, 각 응답자의 응답은 그가 속한 집단의 모집단 대비 표본 비율의 역수만큼 가중치를 부여받는다.\n조사 결과, 다음과 같은 피해율이 관찰되었다고 가정하자: • 남성: 10% (100명 중 10명) • 여성: 30% (100명 중 30명)\n이때, 가중치를 적용한 전체 모집단의 추정 피해율은 다음과 같이 계산된다.\n\\({\\overline{Y}}_{w} = \\frac{\\sum w_{i}Y_{i}}{\\sum w_{i}}\\), \\(w_{i}\\) 성별 총 가중치, 남성 (100x6), 여성 (100x4)\n\\[\\text{추정 피해율} = \\frac{(10\\% \\times 600) + (30\\% \\times 400)}{600 + 400} = 18\\%\\]\n즉, 단순 표본 평균(20%)이 아닌, 모집단 구조를 반영한 추정값은 18%가 된다. 이처럼 차등 배분은 분석의 정확도를 높이는 동시에, 대표성 유지를 위해 가중치 조정이 필수적이라는 점을 잘 보여준다.\n가중치 조정이 필요한 이유\n차등 배분을 활용한 조사에서는 특정 집단의 표본 수를 인위적으로 늘려 분석의 정밀도를 확보할 수 있지만, 그만큼 가중치 조정이 반드시 필요하다. 예를 들어 성폭력 피해율처럼 여성에게서 더 빈번히 나타나는 현상을 조사할 경우, 여성 응답자의 수를 늘리는 것은 더 많은 사례 확보와 정밀한 분석이라는 측면에서 바람직하다.\n하지만 이렇게 여성 표본이 과대표본(over-represented) 상태가 되면, 그 자체로는 모집단의 실제 구조를 왜곡하게 된다. 이 경우 여성의 피해율이 과장되어 전체 피해율이 실제보다 높게 추정될 수 있다. 따라서, 남성과 여성의 실제 모집단 비율에 맞춰 가중치를 적용함으로써, 편향된 표본 구성을 보정할 수 있다.\n가중치는 표본에서 각 집단이 차지하는 비중을 조정하는 역할을 하며, 이를 통해 모집단 전체를 대표할 수 있는 평균값(가중 평균)을 산출할 수 있다. 예를 들어 남성 가중치를 6, 여성 가중치를 4로 설정하면, 실제 인구 구성(남성 600명, 여성 400명)에 비례한 결과를 계산할 수 있게 된다.\n이처럼 성폭력 피해 조사에서 차등 선택 확률 가중치는 두 가지 측면에서 반드시 필요하다.\n\n분석 정밀도 확보: 여성 응답자 수를 늘려 피해율의 신뢰도를 높일 수 있음\n대표성 회복: 가중치를 적용하여 실제 인구 구조를 반영한 추정치를 산출\n\n결과적으로, 가중치 조정은 조사 결과의 타당성과 일반화 가능성을 동시에 확보하기 위한 필수적인 절차다.\n\n\n3. 단위 무응답 조정을 위한 가중치\n\n(1) 무응답의 문제와 표본 구성\n성폭력 피해 조사는 주제의 민감성으로 인해 응답률이 낮을 수 있으며, 특히 성별에 따라 응답률이 상이하게 나타나는 경향이 있다. 위의 예시에서와 같이 모집단은 남성 600명(60%), 여성 400명(40%)으로 구성되어 있고, 이 구조를 반영한 비례 배분으로 표본 200명을 선정하여 남성 120명, 여성 80명이 포함되었다고 가정하자.\n그러나 실제 조사에 응답한 인원은 성별 응답률에 따라 다음과 같이 달라진다.\n\n남성 응답률: 90% → 120명 중 108명 응답\n여성 응답률: 75% → 80명 중 60명 응답\n\n결과적으로 실제 응답자 중 성별 분포는 다음과 같다: - 전체 응답자 수: 168명 - 남성 비율: 108 / 168 ≈ 64.3% - 여성 비율: 60 / 168 ≈ 35.7%\n이렇게 되면 여성은 원래 모집단에서 40%를 차지했음에도 불구하고, 실제 응답자 중에서는 35.7%로 과소 대표되는 문제가 발생한다. 만약 이를 보정하지 않으면, 여성 집단의 특성이 전체 피해율 추정에 충분히 반영되지 않아 편향된 결과가 도출될 수 있다.\n\n\n(2) 무응답 조정 가중치 계산\n각 집단의 응답률의 역수를 사용하여 가중치를 설정한다.\n\\[W_{male} = \\frac{1}{\\text{응답률}_{male}} = \\frac{1}{0.9} = 1.11\\]\n\\[W_{female} = \\frac{1}{\\text{응답률}_{female}} = \\frac{1}{0.75} = 1.33\\]\n\n\n(3) 가중 평균 적용\n조사 응답 결과에 따르면, 남성 응답자 108명 중 약 10%인 10.8명이 성폭력 피해를 경험하였고, 여성 응답자 60명 중 30%에 해당하는 18명이 피해 경험이 있는 것으로 나타났다. 그러나 이 응답자 구성은 실제 모집단의 성비를 반영하지 않으며, 특히 여성의 응답률이 낮아 원래보다 적은 수가 응답에 포함되었기 때문에, 피해율이 과소 추정될 가능성이 있다.\n이러한 문제를 해결하기 위해 무응답 조정 가중치를 적용한다. 남성의 응답률이 90%이므로 가중치는 1 / 0.9 = 1.11, 여성은 응답률이 75%이므로 가중치는 1 / 0.75 = 1.33으로 설정한다. 이에 따라 가중치를 적용한 전체 피해자 수는 다음과 같이 계산된다.\n\n남성 피해자 가중치 총합: 10.8 = 11.988\n여성 피해자 가중치 총합: 18 = 23.94\n전체 피해자 가중치 총합: 11.988 + 23.94 = 35.928\n\n한편, 가중치를 반영한 응답자 수는 다음과 같다. • 남성 응답자 총 가중치: 108 = 119.88 • 여성 응답자 총 가중치: 60 = 79.8 • 전체 응답자 가중치 합계: 119.88 + 79.8 = 199.68\n따라서 무응답 조정 가중치를 적용한 피해율은 다음과 같이 계산된다.\n\\(\\text{추정 피해율} = \\frac{(10\\% \\times 119.88) + (30\\% \\times 79.8)}{199.68} = \\frac{11.988 + 23.94}{199.68} \\approx 0.1799 = 17.99\\%\\)\n이는 단순 응답자의 피해율 평균인 (10% + 30%) / 2 = 20%보다 낮은 수치로, 모집단 성비와 응답률 차이를 반영해 보다 현실적인 피해율을 제시한다.\n\n\n\n4. 사후 가중치\n\n(1) 사후 층화 가중치 개념\n사후 층화 가중치(post-stratification weight)는 조사 과정에서 마지막으로 수행되는 가중치 조정 절차로, 조사 표본이 실제 모집단 분포와 최대한 일치하도록 조정하는 데 목적이 있다. 특히 성별, 연령대, 지역 등 인구 통계학적 특성이 외부의 신뢰할 수 있는 자료(예: 국가 통계청, 인구총조사)와 비교해 불일치할 경우, 그 차이를 보정하기 위해 사용된다.\n예를 들어, 성폭력 피해 실태조사를 수행한 후, 비례 배분, 차등 선택 확률 가중치, 무응답 조정 가중치 등을 단계적으로 적용하여 조사 표본을 보정했다고 하자. 그 결과, 최종적으로 남성과 여성의 가중치 총합이 각각 전체의 50%로 나타났다고 가정할 수 있다. 그런데 외부의 신뢰할 수 있는 모집단 자료에 따르면, 실제 모집단은 여성 52%, 남성 48%로 구성되어 있다면, 이 가중치 분포는 모집단과 일치하지 않는다.\n이처럼 기존의 모든 가중치 조정을 적용한 뒤에도 여전히 조사 표본의 가중 분포가 모집단과 불일치할 수 있다. 이 경우, 사후 층화(post-stratification)를 통해 응답자의 가중치를 다시 조정하여, 성별 비율이 48:52로 되도록 재보정한다.\n사후 층화는 응답자 특성에 따라 사후적으로 층(stratum)을 구분하고, 각 층별로 모집단 분포와 표본 분포를 비교하여 비례에 따라 가중치를 조정하는 방식이다. 예를 들어, 남성 응답자에게는 가중치를 0.96배, 여성 응답자에게는 1.04배 곱하여 가중치 총합이 48:52가 되도록 한다.\n\n사후 층화는 모집단 외부 정보를 기준으로 최종적으로 가중치를 조정하는 방식이다.\n기존 가중치 적용만으로는 실제 모집단 분포와 완전히 일치하지 않을 수 있으며, 그 차이를 보정하기 위해 필수적이다.\n대표성을 더욱 높이고자 하는 실증연구나 공공통계 생산에서 정확하고 현실적인 추정값을 제공하는 데 중요한 역할을 한다.\n\n\n\n(2) 사후 층화 가중치 적용 방법\n\n현재 조사 표본의 성별 가중치 비율 확인 조사 결과에서 남성과 여성의 총 가중치 합이 각각 50%씩 동일한 상태라고 가정한다. 이는 표본 내 가중치 분포가 남녀 각각 600:400으로 구성되어 있을 때 비례 가중치를 적용한 결과일 수 있다.\n모집단의 실제 성비 확인 및 비교 외부 인구통계 자료에 따르면, 모집단은 남성 48%, 여성 52%로 구성되어 있다. 이와 비교하면, 조사 데이터에서 남성이 과대표본되었고 여성이 과소표본되었음을 알 수 있다.\n가중치 조정 비율 계산 표본과 모집단 간의 차이를 반영하기 위해 다음과 같은 비율로 가중치를 조정한다.\n\n\n남성 가중치 감소: \\(\\frac{0.48}{0.50} = 0.96\\)\n여성 가중치 증가: \\(\\frac{0.52}{0.50} = 1.04\\)\n\n이는 남성의 가중치를 4% 줄이고, 여성의 가중치를 4% 증가시키는 조정이다.\n\n조정된 가중치를 적용한 총 가중치 합 계산\n\n\n남성 총 가중치 조정 후 합: \\(0.96 \\times 600 = 576.0\\)\n여성 총 가중치 조정 후 합: \\(1.04 \\times 400 = 416.0\\)\n\n\n가중 평균을 통한 성폭력 피해율 추정\n\n남성과 여성의 피해율이 각각 10%, 30%일 경우, 사후 층화 가중치를 반영한 최종 성폭력 피해율은 다음과 같이 계산된다. \\[\\text{추정 피해율} = \\frac{(10\\% \\times 576.0) + (30\\% \\times 416.0)}{576.0 + 416.0} = 18.39\\%\\]\n\n\n\n\nchapter 3. 결측치 대체\n조사에서 항목 무응답(item nonresponse)은 응답자가 전체 설문에는 참여했지만 특정 문항에는 답변하지 않는 현상을 의미한다. 이는 응답자가 질문을 민감하게 느껴 의도적으로 답변을 거부하거나, 설문 진행 과정에서 실수로 특정 문항을 건너뛰는 등의 이유로 발생한다. 예를 들어, 성폭력 피해 조사에서 응답자는 ‘피해 경험 유무’에는 답했지만, ‘가해자와의 관계’나 ‘자신의 소득 수준’ 등 민감한 항목에는 응답하지 않는 경우가 이에 해당한다.\n이처럼 항목 무응답이 누적되면 해당 변수에 대한 분석이 어려워지고, 전체 조사 결과의 신뢰도와 대표성에도 영향을 미칠 수 있다. 특히 특정 집단에서 무응답이 체계적으로 발생할 경우, 표본이 왜곡되어 모집단의 특성을 제대로 반영하지 못할 위험이 있다. 이를 방지하고 분석 가능성을 높이기 위해 결측값 대체(Imputation) 기법이 활용된다.\n결측값 대체는 단순히 빈칸을 임의의 값으로 채우는 것이 아니라, 응답자의 특성이나 다른 문항과의 관계를 고려하여 가장 적절한 값을 통계적으로 추정하는 과정이다. 예컨대, 소득 항목이 누락된 경우 유사한 성별, 연령, 직업을 가진 응답자의 평균 소득을 활용하거나, 회귀모형을 이용해 예측값을 산출하여 채워 넣는 방식이 있다. 보다 정교한 방법으로는 여러 번의 예측을 수행해 불확실성을 반영하는 다중 대체(Multiple Imputation)가 있으며, 최근에는 조사 데이터 분석에서 점차 널리 사용되고 있다.\n결론적으로 항목 무응답은 조사 데이터 품질을 저하시킬 수 있는 중요한 문제이며, 이를 보완하기 위한 체계적이고 신뢰성 있는 대체 기법의 적용은 필수적인 분석 준비 절차라 할 수 있다.\n\n1. 결측값을 처리하는 방법\n결측값을 무시하는 방법\n결측값을 무시하는 방법은 조사 데이터에서 특정 항목에 응답하지 않은 사례를 통째로 제외하고 나머지 완전한 응답만을 가지고 분석을 수행하는 방식이다. 이는 완전 사례 분석(complete case analysis) 혹은 사례 삭제(casewise deletion)라고 불린다.\n예를 들어, 성폭력 피해 경험에 관한 조사를 실시하고, 응답자들의 나이, 성별, 소득 수준을 바탕으로 피해율을 분석한다고 가정해보자. 이때, 응답자가 소득 수준에 대해 응답하지 않았다면, 해당 항목만 생략하지 않고 전체 응답을 분석에서 제거하게 된다. 즉, 분석에 필요한 모든 변수를 완전히 응답한 사례만을 선택하여 분석을 수행한다.\n이 방법의 장점은 분석이 매우 단순하고 직관적이라는 데 있다. 별도의 통계적 가정이나 복잡한 계산 없이, 응답이 완전한 자료만을 사용해 분석할 수 있으므로 절차가 간단하고 구현이 용이하다. 또한, 추가적인 대체값 생성이나 추정 과정이 없기 때문에 분석 결과 해석이 비교적 명확하다.\n그러나 단점도 뚜렷하다. 첫째, 결측값이 있는 응답을 통째로 제거하므로 분석에 사용 가능한 표본 크기가 줄어들게 되며, 이로 인해 통계적 검정의 정확도와 신뢰도가 저하될 수 있다. 둘째, 더 큰 문제는 결측이 무작위로 발생하지 않을 경우, 즉 특정 응답자 집단에서 결측이 집중된다면, 표본의 대표성이 왜곡될 수 있다. 예컨대, 고소득층이나 심각한 피해 경험을 가진 응답자가 소득을 밝히지 않는 경향이 있다면, 이들을 제거하는 과정에서 해당 집단이 과소표집되어 분석 결과가 편향될 위험이 있다.\n따라서 결측값을 무시하는 방식은 가장 단순한 처리 방법이지만, 결측의 발생 원인과 패턴을 충분히 고려한 후 적용해야 하며, 무작위 결측(missing completely at random, MCAR) 조건이 충족되지 않을 경우에는 대체 방법의 도입이 바람직하다.\n결측값을 보완하는 방법\n결측값을 보완하는 방법은 분석 대상 데이터에서 누락된 값을 합리적인 방식으로 예측하거나 추정하여 채우는 절차를 말하며, 이를 일반적으로 결측값 대체(imputation)라고 한다. 이 방법은 단순히 결측 사례를 제거하는 것보다 분석의 신뢰성과 표본의 대표성을 유지하는 데 유리하다.\n결측값을 무시하고 분석할 경우 표본 수가 줄어들어 분석의 정밀도가 떨어지며, 특정 집단이 과소대표될 수 있다. 반면, 결측값을 대체하면 기존의 정보는 유지하면서도 누락된 부분을 보완할 수 있기 때문에 분석 결과의 왜곡을 줄이고 더 나은 추정을 가능하게 만든다.\n예를 들어, 성폭력 피해 경험에 관한 설문에서 일부 응답자가 소득 수준을 누락했다면, 같은 연령대, 성별, 지역 등의 응답 정보를 바탕으로 해당 소득 값을 추정해 채워 넣을 수 있다. 이렇게 하면 해당 응답자의 다른 정보는 그대로 유지되므로 분석 대상에서 제외되지 않으며, 보다 풍부하고 정확한 분석이 가능해진다.\n\n(3) 결측값 대체 방법\n\n\n\n\n\n\n\n\n대체 방법\n장점\n단점\n\n\n완전 사례 분석\n단순하고 직관적이며, 추가적인 가정 없이 분석 가능\n데이터 손실 발생 가능, 모집단 대표성이 감소할 위험\n\n\n평균 대체\n계산이 간단하고 빠르며, 데이터 손실 없음\n분산 감소로 인해 데이터 변동성이 왜곡될 가능성 있음\n\n\n확률적 대체\n변동성을 유지하여 데이터 왜곡을 방지\n무작위성이 도입되어 결과 변동성이 증가할 수 있음\n\n\n회귀 대체\n다른 변수와의 관계를 고려하여 현실적인 값 대체 가능\n모델이 잘못 설정되면 왜곡된 값이 대체될 위험 있음\n\n\n핫덱 대체\n실제 응답자의 데이터를 활용하여 자연스러운 대체 가능\n적절한 유사 기준을 설정하는 것이 중요, 표본 크기 작으면 부적절한 대체 발생 가능\n\n\n다중 대체\n불확실성을 반영하여 보다 신뢰성 높은 결과 제공\n계산량이 많고 통계적 해석이 다소 복잡할 수 있음\n\n\n\n\n\n\n2. 대체방법\n\n(1) 평균 대체 mean imputation\n평균 대체(mean imputation)는 결측값을 처리하는 가장 단순한 방식 중 하나로, 누락된 값을 해당 변수의 평균값으로 채워 넣는 방법이다. 예를 들어, 성폭력 피해 조사에서 응답자의 가족 소득 정보를 수집했는데 일부 응답자가 해당 질문에 답하지 않은 경우, 그 결측된 소득 값을 다른 응답자들의 평균 소득으로 대체하는 식이다. 이 방식은 계산이 간단하고, 결측값이 있다고 해서 해당 응답을 분석에서 제외하지 않아도 되므로 표본 수를 유지할 수 있다는 장점이 있다.\n하지만 평균 대체는 몇 가지 중요한 한계를 갖는다. 모든 결측값이 동일한 평균값으로 채워지기 때문에, 원래 데이터가 가지고 있던 자연스러운 변동성이 줄어들게 된다. 결과적으로 변수 간 상관관계나 회귀 분석 결과 등이 왜곡될 수 있으며, 데이터의 분산도 인위적으로 낮아질 수 있다. 또한 평균 대체는 결측이 발생한 원인이나 맥락을 전혀 고려하지 않기 때문에, 결측값이 체계적인 이유로 발생한 경우에는 적절한 대처 방식이 되지 못한다. 따라서 평균 대체는 응답률이 높고 결측이 무작위로 발생한 경우에만 제한적으로 사용하는 것이 바람직하며, 보다 정교한 대체 기법과 병행하여 활용하는 것이 권장된다.\n\n\n(2) 확률적 대체 stochastic imputation\n확률적 대체(stochastic imputation)는 평균 대체가 가지는 변동성 손실 문제를 보완하기 위해 고안된 방식으로, 평균값을 중심으로 하되 무작위성을 부여하여 보다 현실적인 데이터를 생성한다. 이 방법에서는 결측값을 단순히 전체 평균으로 채우는 것이 아니라, 해당 변수의 분포—일반적으로 정규분포—를 가정하고, 평균과 표준편차를 기준으로 난수를 생성해 그 값을 결측값에 채운다. 이를 통해 원래 데이터의 분산과 패턴을 보다 충실히 보존할 수 있다.\n예를 들어, 응답자 100명이 보고한 월소득의 평균이 500만원, 표준편차가 100만원인 상황을 가정해보자. 이때, 5명의 응답자가 소득 항목에 응답하지 않아 결측이 발생하였다면, 평균 대체 방식에서는 이 5명을 모두 500만원으로 채우게 된다. 하지만 확률적 대체 방식은 평균값 500만원을 중심으로 하는 정규분포 N(500, 100^2) 에서 임의의 값을 5개 추출하여 각 응답자의 결측값에 입력하게 된다. 이렇게 하면 소득 데이터의 자연스러운 분산이 유지되고, 분석 시 통계량이 왜곡될 위험도 줄어든다.\n다만 이 방법은 무작위 요소를 포함하기 때문에, 대체할 때마다 결과가 달라질 수 있다는 점에서 분석의 재현성과 일관성에 주의가 필요하다. 또한, 정규분포와 같은 통계적 가정이 적절하지 않다면 오히려 왜곡을 유발할 수도 있다. 따라서 확률적 대체는 결측의 성격과 변수의 분포를 충분히 고려한 후 신중하게 적용해야 한다.\n\n\n(3) 회귀 대체 regression imputation\n회귀 대체(Regression Imputation)는 결측값을 보완하는 보다 정교한 방법으로, 해당 변수와 관련 있는 다른 변수들을 활용하여 결측값을 예측하는 방식이다. 이 방법은 단순히 평균이나 확률적 수치로 채우는 것보다, 데이터 내 변수 간의 관계를 반영하여 보다 현실성 있는 추정값을 산출할 수 있다는 장점이 있다.\n예를 들어, 응답자의 소득 정보에 결측이 있는 경우, 같은 응답자가 응답한 나이(Age), 교육 수준(Education Level), 직업(Job Type) 등의 정보를 바탕으로 회귀모형을 설정할 수 있다. 이 회귀모형은 소득이 응답된 응답자들의 데이터를 기반으로 회귀계수를 추정하고, 해당 계수를 이용해 소득이 누락된 응답자들의 소득을 예측한다. 회귀식은 다음과 같다. \\[y_{i(r)} = \\alpha + \\beta_{1}\\text{Age}_{i(r)} + + \\beta_{2}\\text{Edu}_{i(r)} + \\beta_{3}\\text{Job}_{i(r)} + e_{i(r)}\\]\n여기서 \\(\\hat{y}{i(r)}\\) 는 소득이 결측된 i번째 응답자의 예측 소득이고, \\(\\alpha, \\beta_1, \\beta_2, \\beta_3\\) 는 회귀계수이며, \\(e{i(r)}\\) 는 오차항이다.\n이 방법의 장점은, 단순 대체보다 훨씬 더 응답자 개인의 특성을 반영한 맞춤형 대체가 가능하다는 점이다. 예컨대, 고학력자이면서 특정 직종에 종사하는 중년의 응답자는 실제로도 소득이 높을 가능성이 있기 때문에, 단순 평균이 아닌 회귀 예측을 통한 값이 더 설득력 있다.\n하지만 단점도 존재한다. 회귀모형이 잘못 설정되면 편향된 추정치가 생성될 수 있으며, 대체된 값들이 모형의 구조를 따르기 때문에 실제 데이터보다 변동성이 작고 지나치게 규칙적인 값을 보일 수 있다. 이는 전체 데이터 분석에서 과도한 일관성을 유발하여 통계적 검정이나 분산 추정에 오류를 가져올 수 있다.\n따라서 회귀 대체는 변수 간 관계가 명확하고 모형이 잘 적합될 때 강력한 결측 보정 방법이지만, 그만큼 모형 설정과 변수 선택에 대한 신중한 검토가 필수적이다.\n\n\n(4) 핫덱 대체 Hot-Deck imputation\n핫덱 대체(Hot-Deck Imputation)는 결측값을 비슷한 특성을 가진 응답자의 실제 데이터로 대체하는 방법이다. 이는 결측값이 있는 항목과 유사한 특성을 가진 다른 응답자의 값을 찾아 채워 넣는 방식으로, 조사 데이터에서 유사한 패턴을 유지하면서도 데이터의 신뢰도를 높일 수 있는 장점이 있다.\n예를 들어, 성폭력 피해 조사에서 피해자의 나이, 성별, 지역 등이 유사한 다른 응답자의 데이터를 참조하여 결측값을 채운다면 보다 현실적인 대체가 가능하며, 데이터의 변동성을 유지하면서도 모집단을 반영할 수 있다. 핫덱 대체는 통계적 방법뿐만 아니라 설문 조사 및 행정 데이터 분석에서도 널리 사용되는 결측값 처리 기법이다.\n이 방법의 장점은 평균 대체나 회귀 대체보다 현실적인 값이 채워질 가능성이 크다는 점이다. 그러나 적절한 유사 기준을 설정하는 것이 중요하며, 표본 크기가 작을 경우에는 적절한 대체값을 찾기 어려울 수 있다는 단점도 존재한다.\n핫덱 Hot-Deck\n핫덱(Hot-Deck) 대체는 동일한 조사 데이터셋 내에서 결측값이 있는 응답자와 유사한 특성을 가진 다른 응답자의 값을 가져와 결측값을 대체하는 방식이다. 이 방법은 동일한 조건을 가진 응답자가 충분히 많을 때 특히 효과적이며, 현실적인 값을 유지하면서도 데이터의 구조와 분포를 보존할 수 있다는 장점이 있다.\n핫덱 대체는 성별, 연령, 지역, 교육 수준 등 주요 변수들이 일치하거나 유사한 응답자를 기준으로 결측값을 채워 넣기 때문에, 평균 대체나 회귀 대체보다 더 실제적인 데이터 보완이 가능하다. 또한 외부 자료 없이도 자체 데이터만으로 대체가 가능하므로, 조사 대상자가 많은 대규모 조사에서 활용도가 높다.\n콜드덱 Cold-Deck\n콜드덱(Cold-Deck) 대체는 과거의 다른 데이터셋이나 외부 자료에서 값을 가져와 결측값을 대체하는 방식이다. 이 방법은 현재 조사에서 유사한 특성을 가진 응답자가 부족하거나, 결측값을 직접적으로 대체할 수 있는 정보가 내부 데이터에 없는 경우에 활용된다.\n콜드덱 방식은 이미 수집된 자료를 바탕으로 하므로 대체 기준이 명확할 수 있고, 반복되는 조사에서 일관성을 유지하는 데 유리하다. 예를 들어, 전년도에 수행된 동일한 주제의 조사에서 유사한 응답자의 값을 가져와 결측값을 보완하는 경우가 이에 해당한다.\n그러나 이 방법은 사용하는 데이터가 과거 자료이거나 시차가 있는 외부 자료이기 때문에, 현재 상황과 불일치할 가능성이 있으며, 시대적 변화나 환경의 차이가 반영되지 않을 위험이 있다. 따라서 콜드덱 대체는 데이터의 맥락을 충분히 고려한 신중한 적용이 필요하다.\n핫덱 대체 과정\n핫덱(Hot-Deck) 대체는 동일한 데이터셋 내에서 유사한 특성을 가진 응답자의 값을 활용하여 결측값을 보완하는 방식이다. 이 과정은 몇 가지 단계를 거쳐 체계적으로 이루어진다.\n첫째, 데이터 정렬 및 유사 집단 형성 단계에서는 응답자들의 연령, 성별, 교육 수준, 지역 등의 변수에 따라 그룹화를 수행한다. 예컨대, ’20~29세 여성, 서울 거주’와 같이 세부 집단을 정의하여 응답자 간 유사성을 확보한다.\n둘째, 결측값이 있는 응답자 식별 단계에서는 특정 변수에서 값이 누락된 사례들을 찾아낸다. 예를 들어, ‘소득 수준’ 항목에서 결측된 응답자를 선별한다.\n셋째, 적절한 응답 값 선택 단계에서는 동일한 그룹 내에서 결측 항목을 갖지 않은 응답자의 데이터를 참조하여, 해당 결측값을 채운다. 이때 일반적으로 가장 유사한 응답자의 값을 사용하지만, 유사한 응답자가 여럿일 경우 무작위로 선택하여 대체할 수도 있다.\n넷째, 결측값 대체 수행 단계에서는 선택된 응답자의 값을 결측값이 있는 변수에 그대로 적용하여 데이터를 완성한다.\n핫덱 대체는 내부 데이터 기반으로 결측을 보완하므로 현실성이 높고, 데이터의 분포나 구조를 잘 보존할 수 있다는 장점이 있다. 다만, 적절한 유사 기준을 설정하고, 충분한 표본이 확보되어야 효과적인 적용이 가능하다.\n\n\n(5) 다중 대체 multiple imputation\n다중 대체(Multiple Imputation)는 하나의 결측값에 대해 하나의 추정값만을 사용하는 기존의 단일 대체 방식과 달리, 여러 개의 대체값을 생성하여 각각의 데이터셋을 구성하고 독립적으로 분석한 후, 이들의 결과를 종합하는 방법이다. 이 방식은 결측값에 내재된 불확실성을 반영하고자 하는 목적에서 출발한다.\n예를 들어, 성폭력 피해 조사에서 소득 정보를 응답하지 않은 사례가 있을 때, 이 결측값에 대해 평균 대체, 회귀 대체, 핫덱 대체 등 다양한 방식으로 3~5개의 서로 다른 대체값을 생성하여 각각의 대체값을 포함하는 데이터 세트를 만든다. 각 데이터 세트를 별도로 분석한 뒤, 최종 분석 결과는 이들 결과의 평균이나 조합을 통해 도출된다. 이렇게 하면 대체 과정에서 발생할 수 있는 편향과 추정의 불확실성을 함께 고려할 수 있다.\n다중 대체의 장점은 단일 대체보다 더 신뢰할 수 있는 통계 추정치를 제공하며, 결측값으로 인한 분석의 왜곡을 줄일 수 있다는 것이다. 특히 표준오차와 같은 추정의 정확도에 대한 정보를 함께 제공할 수 있어, 불확실성을 정량화할 수 있는 장점이 있다.\n반면, 다중 대체는 계산량이 많고 구현이 복잡하다는 단점이 있다. 특히 대체 방법의 설정, 반복 횟수, 결과의 통합 방식 등에 대한 통계적 이해와 숙련된 기술이 필요하다. 그럼에도 불구하고 최근에는 통계 소프트웨어에서 다중 대체 기능을 쉽게 사용할 수 있게 되어, 복잡한 조사나 사회과학 데이터 분석에서 점점 널리 활용되고 있다.\n\n\n\n\nchapter 4. 복합표본 분산 추정\n조사 데이터는 실제 수집 과정에서 단순한 무작위 추출 방식이 아닌, 층화(stratification), 군집(clustering), 다단계 추출(multi-stage sampling), 가중치(weighting), 결측값 대체(imputation) 등의 다양한 절차가 적용되기 때문에 복잡한 구조를 지닌다. 이러한 복합 설계는 표본 추출 단위 간의 독립성을 약화시키고, 집단 내 응답자들 간의 유사성을 증가시켜 표본 분산에 영향을 준다.\n예를 들어, 동일한 지역에서 다수의 가구를 선택하는 클러스터 표본의 경우, 해당 지역 내 응답자들은 비슷한 사회경제적 특성을 가질 가능성이 높아 서로 상관관계가 형성된다. 이로 인해 실제 분산은 단순 확률 표본보다 작거나 클 수 있으며, 만약 이를 무시하고 일반적인 분산 추정 방식을 사용하면 표준 오차가 부정확하게 추정될 위험이 있다.\n따라서, 통계 분석에서는 단순한 표본 설계 가정이 아닌, 조사에서 실제 사용된 복합 표본 설계 정보를 반영한 분산 추정 방법(예: Taylor 선형화, 재표집 기법, Balanced Repeated Replication 등)을 적용해야 하며, 이를 통해 보다 정확한 신뢰구간과 유의성 검정이 가능해진다. 이 과정은 특히 정책 결정이나 민감한 사회 이슈를 다루는 조사에서 필수적인 절차라 할 수 있다.\n\n1. 테일러 급수 근사법(Taylor Series Approximation)\n테일러 급수 근사법(Taylor Series Linearization)은 비선형 통계량—예를 들어 비율, 평균 대비 비율, 오즈비(odds ratio)와 같은 복잡한 함수형 통계량—의 분산을 추정할 때 널리 사용되는 대표적인 방법이다. 이러한 통계량은 단순한 합산이나 평균 연산으로는 분산을 직접 계산할 수 없기 때문에, 함수 형태를 일차 선형화하여 근사하는 방식이 필요하다.\n테일러 급수 근사법 핵심 개념\n테일러 급수 근사법은 분석 대상 통계량을 주어진 모수(parameter)에 대한 함수로 보고, 이 함수를 일차 테일러 급수로 전개하여 근사한 후 분산을 추정하는 기법이다. 다시 말해, 복잡한 비선형 함수를 선형 함수로 근사하여 분산 추정이 가능한 형태로 바꾸는 것이다.\n테일러 급수 근사를 이용한 가중 평균의 분산\n조사 데이터에서 가중 평균(\\({\\overline{Y}}_{w})\\)을 사용하여 분산을 추정하는 방법은 다음과 같다.\n\\[\\overline{Y}w = \\frac{\\sum{i = 1}^{n}w_{i}y_{i}}{\\sum_{i = 1}^{n}w_{i}}\\]\n테일러 급수 근사법을 사용하면, 해당 가중 평균의 분산은 다음과 같이 표현된다.\n\\[\\frac{1}{(\\sum w_{i})^{2}}\\left\\lbrack Var(\\sum w_{i}y_{i}) + {\\overline{Y}}_{w}^{2}Var(\\sum w_{i}) - 2{\\overline{Y}}_{w}Cov(\\sum w_{i}y_{i},\\sum w_{i}) \\right\\rbrack\\]\n이는 단순한 분산 계산보다 복잡하지만, 복합 표본 설계에서의 정확한 분산 추정을 위해 필수적인 접근법이다.\n테일러 급수 근사법 특징\n테일러 급수 근사법은 현재 복합 표본 설계 데이터를 분석할 때 가장 널리 사용되는 분산 추정 방법 중 하나다. 여러 통계 소프트웨어 패키지—예: SAS, Stata, SUDAAN—에서 기본 옵션으로 제공되며, 그만큼 신뢰성과 적용성이 높다.\n이 방법은 비율, 평균, 회귀 계수와 같은 다양한 통계량에 적용 가능하며, 특히 비선형 함수 형태를 선형 근사로 바꾸어 처리할 수 있기 때문에 활용 범위가 넓다. 무엇보다도, 단순 무작위 표본이 아닌 층화, 군집화, 가중치 부여 등 복합 표본 설계의 구조적 특성을 반영할 수 있어 표본 설계로 인한 분산 과소 추정을 방지하고 정확한 표준오차 계산을 가능하게 한다.\n따라서, 조사 통계 분석에서 테일러 근사는 복잡한 설계의 현실을 반영한 정밀한 분산 추정 기법으로 자리잡고 있다.\n\n\n2. 균형 반복 복제법(Balanced Repeated Replication, BRR)\n균형 반복 복제법(BRR)은 복합 표본 설계에서 분산을 추정하기 위해 널리 사용되는 방법 중 하나로, 전체 표본을 여러 개의 하위 표본(Replicates)으로 나누어, 각 하위 표본에 대해 통계량을 계산한 뒤 이들의 변동성을 이용해 모집단 통계량의 분산을 추정한다.\n가장 기본적인 방식은 전체 표본을 두 개의 하위 표본으로 나누는 작업을 반복하면서 여러 개의 균형 잡힌 복제(Replicate)를 생성하는 것이다. 이러한 반복 분할은 표본 설계의 층화 구조를 고려하여 체계적으로 수행되며, 각 복제본에 대해 통계량을 계산하고 그 결과의 분산을 기반으로 전체 분산을 추정한다.\nBRR의 핵심은 다음과 같다.\n\n각 복제본은 전체 표본의 하위 집합이며, 균형 잡힌 방식으로 구성된다.\n전체 표본의 통계량과 복제 통계량 간의 차이를 통해 분산을 계산한다.\n보통 Fay’s BRR처럼 가중치를 부드럽게 조정하는 변형 방식도 존재한다.\n\n이 방법은 특히 2차 단위 선택이 없는 이단계 층화 설계에서 유용하며, 여러 통계 소프트웨어(SAS, Stata, SUDAAN 등)에서 BRR 지원 기능이 제공된다.\n각 표본에서 평균(\\({\\overline{Y}}_{r}\\))을 계산하고, 그 평균의 변동성을 기반으로 전체 표본의 분산을 추정한다.\n\\[\\overline{Y} = \\frac{1}{c}\\overset{c}{\\sum_{r = 1}}{\\overline{Y}}_{r}\\]\n분산은 다음과 같이 계산된다.\n\\[Var(\\overline{Y}) = \\frac{1}{c(c - 1)}\\overset{c}{\\sum_{r = 1}}({\\overline{Y}}_{r} - \\overline{Y})^{2}\\]\n균형 반복 복제법(BRR)의 특징\n균형 반복 복제법(BRR)은 복합 표본 설계에서 분산을 추정하기 위해 널리 사용되는 방법 중 하나이다. 이 기법은 전체 표본을 여러 개의 하위 표본(복제본, replicates)으로 나누어 반복적으로 통계량을 계산하고, 이들 간의 변동성을 통해 전체 통계량의 분산을 추정하는 방식이다. 특히, 층화된 복합 표본 설계에서 매우 효과적으로 활용될 수 있으며, 2단계 이상의 다단계 표본 설계에도 적절하게 적용된다.\nBRR의 가장 큰 장점은 복잡한 조사 설계의 구조를 반영하면서도 실제 표본의 변동성을 잘 반영할 수 있다는 점이다. 이는 단순한 이론적 공식보다 더 현실적인 분산 추정을 가능하게 한다. 그러나 BRR을 적용하려면 각 층(stratum)마다 두 개의 1차 표본 단위(PSU)가 존재해야 하며, 복제본을 만들기 위해 층별로 적절히 균형을 맞추는 것이 필요하다. 표본 설계가 지나치게 복잡하거나 PSU 수가 부족한 경우에는 이러한 균형을 유지하기 어려워, BRR의 적용이 제한될 수 있다. 이처럼 BRR은 강력한 분산 추정 도구이지만, 설계와 구현에 있어 정교한 구조 설정이 요구된다.\n\n\n3. 잭나이프 반복 복제법(Jackknife Repeated Replication, JRR)\n잭나이프 반복 복제법(Jackknife Repeated Replication, JRR)은 복합 표본 설계에서 분산을 추정하는 데 널리 사용되는 기법으로, 데이터에서 하나의 표본 또는 클러스터를 순차적으로 제거하면서 반복적으로 통계량을 계산하는 방식이다. 이 기법의 핵심은 표본 전체를 사용하는 것이 아니라, 매 반복마다 하나의 단위를 제거한 후 통계량(예: 평균)을 계산하고, 이렇게 얻은 여러 개의 통계량을 바탕으로 그 변동성을 측정함으로써 전체 표본의 분산을 추정하는 데 있다.\n잭나이프 방법은 계산이 비교적 단순하다는 장점을 가지며, 특히 비선형 통계량(예: 비율, 오즈비 등)의 분산 추정에도 안정적인 결과를 제공할 수 있다. 반복 복제 방식으로 인해 복잡한 분포를 따르는 표본에서도 적용이 가능하며, 다양한 통계 소프트웨어에서 지원된다.\n다만, 잭나이프 방법은 표본 수가 충분히 많을 때 그 효과가 극대화되며, 표본 크기가 작을 경우 반복 횟수가 제한되어 분산 추정의 정확도와 신뢰도가 낮아질 수 있다는 한계도 존재한다. 그럼에도 불구하고, 단순함과 안정성 덕분에 복잡한 조사 설계에서도 유용하게 사용되는 방법 중 하나이다.\n\n\n4. 방법 비교\n복합 표본 설계에서 분산을 추정하는 주요 방법들은 각각의 장점과 제한점을 가지고 있으며, 적용 환경에 따라 적절한 방법을 선택하는 것이 중요하다.\n테일러 급수 근사법은 가장 널리 사용되는 방식으로, 비선형 통계량(비율, 회귀 계수 등)을 근사화하여 분산을 추정한다. 이 방법은 계산이 비교적 효율적이고, 대부분의 통계 소프트웨어(SAS, Stata, SUDAAN 등)에서 기본값으로 제공되므로 실무 활용도가 높다.\n균형 반복 복제법(BRR)은 층화된 복합 표본 설계에서 특히 높은 정확도를 보인다. 전체 표본을 반복적으로 절반씩 나누어 복제 통계량을 계산함으로써 분산을 추정하며, 구조가 일정하고 표본 크기가 충분할 때 신뢰도가 높다. 하지만 설계 구조가 복잡하거나 층화 기준이 불균형할 경우 적용에 제한이 있을 수 있다.\n잭나이프 반복 복제법(JRR)은 표본이나 클러스터를 하나씩 제거하여 복제 통계량을 계산하는 방식으로, 계산 구조가 단순하다는 장점이 있다. 특히 비선형 통계량에도 안정적으로 적용 가능하나, 복잡한 다단계 표본 설계에서는 반복 횟수 부족이나 표본 구조의 제약으로 인해 한계를 보일 수 있다.\n따라서, 테일러 급수 근사법은 일반적인 기본값으로 활용되고, BRR은 층화 구조가 명확할 때, 잭나이프는 구조가 단순하거나 반복 제거 방식이 적합할 때 선택적으로 사용된다.\n\n\n\nchapter 5. 조사 데이터 문서화 및 메타 데이터\n조사 데이터는 단 한 번의 분석을 위해 수집되는 것이 아니다. 데이터 수집 이후에도 다양한 연구자가 수년에 걸쳐 반복적으로 재분석하고, 새로운 분석 목적에 맞추어 지속적으로 활용된다. 이러한 재사용 가능성을 높이기 위해서는 조사 데이터를 체계적으로 문서화하고, 그 의미와 구조를 명확하게 설명하는 정보가 반드시 필요하다.\n이때 활용되는 핵심 정보가 바로 메타데이터(metadata)이다. 메타데이터는 데이터 자체가 아니라 데이터를 설명하는 데이터로, 변수의 정의, 측정 단위, 응답 범주, 결측 처리 방식, 코딩 기준 등 연구자가 데이터 분석 전에 반드시 이해해야 할 기본 속성을 포함한다. 메타데이터는 연구자 간 일관된 해석을 가능하게 하고, 데이터의 맥락을 제공함으로써 정확한 분석과 비교 연구를 지원한다.\n한편, 설문조사 과정에서 자동으로 수집되는 보조적 데이터인 파라데이터(paradata)도 함께 중요한 역할을 한다. 이는 설문 응답 자체가 아니라 응답이 생성되는 과정을 설명하는 데이터로, 예를 들어 문항별 응답 시간, 응답 수정 여부, 조사 기기의 종류, 응답자의 이동 경로, 면접자의 질문 방식 등이 해당된다. 파라데이터는 설문 문항의 난이도나 응답자의 이해 수준을 파악하거나, 성의 없는 응답이나 비정상적인 응답 패턴을 식별하는 데 유용하다.\n따라서 조사 데이터의 품질과 활용도를 높이기 위해서는 메타데이터와 파라데이터를 함께 수집하고 체계적으로 관리하는 것이 필수적이다. 이 두 정보는 단순한 부속 자료를 넘어, 조사 데이터의 해석과 재사용 가능성을 결정짓는 핵심 도구로 기능한다.\n\n1. 메타 데이터\n메타데이터란 조사 데이터에 대한 정보(”데이터에 대한 데이터”)를 의미하며 연구자가 데이터를 이해하고 활용할 수 있도록 제공하는 모든 정보를 포함한다.\n메타데이터의 주요 목적은 조사 데이터의 속성을 명확하게 설명하여 연구자가 데이터를 효과적으로 활용할 수 있도록 하는 것이다.\n특정 연구자가 아닌, 전 세계 누구나 데이터의 의미를 쉽게 이해할 수 있도록 표준화된 문서화를 제공하는 것이 핵심이다.\n메타데이터의 주요 유형\n\n\n\n\n\n\n\n메타데이터 유형\n설명\n\n\n정의적 메타데이터\n조사 대상 모집단, 표본 설계, 질문 문구, 코딩 용어 등을 설명\n\n\n절차적 메타데이터\n조사원 교육 절차, 표본 선정 방법, 데이터 수집 과정 등 조사 프로토콜을 설명\n\n\n운영적 메타데이터\n결측 데이터 비율, 데이터 수정 실패율, 평균 조사 시간, 조사원이 완료한 케이스 수 등 조사 품질 평가 정보 포함\n\n\n시스템 메타데이터\n데이터 파일 형식, 파일 위치, 데이터 검색 및 호출 방법, 변수 정의 등을 설명\n\n\n\n메타데이터 예시\n\n\n\n\n\n\n\n항목\n설명\n\n\n변수명\nAR21 (피해 보고 항목)\n\n\n질문 문구\n당신의 재산이 손상되었거나 파괴된 적이 있습니까?'\n\n\n데이터 위치\n컬럼 140, 너비 1\n\n\n결측값 처리\n-9 (무응답), -0 (모름)\n\n\n데이터 수준\n가구 데이터 또는 개인 데이터\n\n\n추가 메타데이터\n표시(X)하여 해당하는 모든 항목을 선택하세요.'\n\n\n\n메타데이터 설계의 중요성\n메타데이터의 발전은 조사 방법론 연구자에게 새로운 기회와 도전 과제를 동시에 제공한다.\n조사 품질 평가 및 사용자 확장: 조사 품질을 측정하는 재조사 연구, 응답 분산 추정 등의 정보가 쉽게 제공될 수 있다. 이를 통해, 조사 데이터의 신뢰성을 높이고, 다양한 연구자들이 데이터를 활용할 수 있도록 지원한다.\n설문지 개발 과정에서의 연계: 특정 문항에 대해 과거 연구에서의 활용 방식, 문항 재설계 사례, 응답자 행동 데이터(Behavior Coding) 등과 연계하여 문항 개발이 가능하다.\n연구자의 데이터 활용 지원: 연구자가 분석을 수행하기 전, 특정 변수가 과거 연구에서 어떻게 활용되었는지를 쉽게 확인할 수 있도록 설계할 수 있다. 이를 통해 조사 데이터의 신뢰성을 유지하면서도, 보다 효율적인 데이터 분석을 지원할 수 있다.\n메타데이터는 단순한 부가 정보가 아니라, 조사 데이터를 보다 효과적으로 활용할 수 있도록 지원하는 핵심 요소이다. 특히, 대규모 조사 데이터에서는 메타데이터의 체계적인 관리와 전자 문서화가 필수적이다.\n메타데이터는 조사 데이터의 활용도를 높이고, 연구자가 데이터를 쉽게 이해할 수 있도록 돕는 중요한 역할을 한다.\n전통적인 코드북에서 벗어나, 전자 문서화와 웹 기반 시스템이 발전하면서 보다 효율적인 데이터 관리가 가능해지고 있다.\n조사 설계 단계에서부터 메타데이터의 체계적인 구성을 고려하는 것이 중요하며, 이를 통해 조사 품질을 높이고 연구자들이 보다 쉽게 데이터를 활용할 수 있도록 해야 한다.\n결국, 좋은 조사 데이터는 메타데이터가 잘 정리되어 있어야 한다. 조사 데이터를 체계적으로 문서화하고, 연구자들이 손쉽게 접근할 수 있도록 메타데이터를 설계하는 것이 향후 조사 연구의 핵심 과제가 될 것이다.\n\n\n2. 파라 데이터\n조사 데이터 문서화 체계에서 파라데이터(paradata)는 설문 응답이라는 결과물이 생성되는 과정을 실시간으로 추적하고 기록한 행태적(behavioral) 및 기술적(technical) 정보의 집합이다. 이는 응답자가 어떤 답변을 했는지에 대한 내용적 정보가 아니라, 그 답변을 어떻게 도출했는지에 대한 과정 정보로서, 설문 조사 품질을 정밀하게 평가하고 설계 오류를 사전에 진단할 수 있는 중요한 도구로 기능한다.\n파라데이터의 구체적 예\n웹 기반 자기기입식 설문(CAWI)에서는 다음과 같은 항목이 대표적인 파라데이터로 수집된다.\n\n각 문항에 소요된 응답 시간\n응답자가 뒤로 가기(back) 버튼을 눌러 응답을 수정한 횟수\n문항 미응답 또는 건너뛰기 횟수\n키보드 입력의 정정 횟수 (backspace, delete 키 입력 빈도)\n응답 순서 변경 패턴\n디바이스 정보(PC, 모바일, 태블릿 등)\n브라우저 및 운영체제 정보\n응답자의 위치 정보(IP 또는 GPS 기반) 등\n\n면접조사(CAPI, CATI 등)에서는 다음과 같은 파라데이터가 활용된다.\n\n면접자가 질문을 읽는 데 걸린 시간\n응답자가 주저하거나 이해하지 못하는 구간의 음성/행동 코딩\n면접 환경(예: 소음, 제3자 존재 여부)\n질문 순서를 건너뛴 경우나 보완 질문 삽입 여부\n면접 시작 및 종료 시각, 소요 시간\n면접 중 발생한 기술적 문제 로그 등\n\n파라데이터의 활용 목적\n\n응답 품질 진단: 지나치게 짧은 응답 시간이나 동일 패턴 반복(예: 한쪽 극단값만 선택)은 무성의한 응답자의 특징일 수 있다. 문항별 응답시간 분포가 비정상적으로 길 경우, 문항 이해가 어려웠음을 시사한다.\n설문 설계 개선: 반복적으로 건너뛰는 문항이나 수정 빈도가 높은 문항은 설계의 문제(문항 길이, 복잡성, 용어 선택 등)를 내포할 가능성이 있다. 파라데이터를 분석함으로써 특정 문항이 응답자의 인지 부담을 초래하는지 파악할 수 있다.\n면접자 모니터링 및 교육: 면접자의 응답 시간 패턴, 질문 생략 여부 등을 통해 조사 수행의 일관성과 품질을 평가할 수 있다. 특정 면접자가 다른 면접자에 비해 비정상적인 면접 패턴을 보일 경우, 교육 강화나 재훈련이 필요할 수 있다.\n데이터 후처리 및 가중치 조정: 응답 완결성, 무응답 패턴, 설문 중단률 등을 기준으로 분석에 포함할 응답자 범위를 결정하거나, 가중치를 부여하는 데 활용된다.\n\n파라데이터의 의의\n파라데이터는 단순히 “보조적 로그 정보”를 넘어, 응답자가 설문에 어떻게 접근했는지, 설문 시스템이 어떻게 작동했는지, 그리고 데이터 생성의 맥락이 무엇이었는지를 입증하는 정량적 기록이다. 따라서 현대 조사 연구에서 파라데이터는 데이터 품질 관리의 핵심 요소로 간주되며, 점차 정밀한 설문 설계를 위한 기반 자료로 적극 활용되고 있다. 특히 빅데이터 분석, 응답자 분류, AI 기반 설문 인터페이스 개발 등에서도 파라데이터의 활용 범위는 계속 확장되고 있다.\n결론적으로, 파라데이터는 응답자의 행동적 궤적을 가시화하는 데이터이며, 이는 설문조사의 타당성과 신뢰도를 평가하고 향후 조사 설계를 개선하는 데 없어서는 안 될 핵심 자원이라 할 수 있다.\n\n\n3. 메타데이터 vs 파라데이터 비교\n\n\n\n\n\n\n\n\n구분\n메타데이터 (Metadata)\n파라데이터 (Paradata)\n\n\n\n\n정의\n조사 데이터에 대한 기술적 정보 (데이터에 대한 데이터)\n조사 과정 중 생성되는 부차적 정보 (조사 절차의 부산물)\n\n\n주요 내용\n변수명, 질문 문항, 응답 코드, 데이터 유형 등\n응답 시간, 응답 순서, 설문 경로, 중단 여부, 장치 종류 등\n\n\n사용 목적\n데이터의 해석 및 분석 지원, 일관성 유지\n응답 품질 평가, 비표본오차 분석, 조사 설계 개선\n\n\n생성 시점\n설문 설계 및 자료 구축 단계에서 생성\n조사 수행(수집) 과정 중 자동적으로 생성\n\n\n관리 주체\n조사 설계자, 데이터 관리자\n조사 시스템, 조사 소프트웨어, 응답 로그 등 자동 기록 시스템\n\n\n활용 예시\n분석 시 변수 라벨 확인, 코드북 제작, 설문 설계 문서 활용\n응답 시간 분석을 통한 신뢰도 판단, 반복 응답 여부 확인\n\n\n형식 예시\nQ1 = 성별 (1: 남자, 2: 여자), Q2 = 연령 (숫자형)\nQ1 응답 시간: 15초, 설문 중 3번 중단, 모바일 응답\n\n\n\n【참고】 메타데이터는 주로 분석 전 준비 정보, 파라데이터는 분석 및 품질평가 보조 정보로 구분된다."
  },
  {
    "objectID": "notes/math/derivate_integral.html",
    "href": "notes/math/derivate_integral.html",
    "title": "수학의 기초 2. 미분과 적분",
    "section": "",
    "text": "chapter 1. 미분\n세상에는 정지해 있는 것이 없다. 우리가 함께 움직이고 있기 때문에 느끼지 못할 뿐, 지구는 자전 속도로 약 시속 1,660킬로미터, 공전 속도로는 약 시속 10만 7천5백 킬로미터로 끊임없이 움직이고 있다. 이러한 사실은 코페르니쿠스가 제안한 지동설에 바탕을 두고 있다. 갈릴레오는 망원경을 통해 목성의 위성을 관찰하고 금성의 위상 변화를 확인함으로써 지동설을 뒷받침했다. 케플러는 행성의 궤도가 완전한 원이 아니라 타원임을 밝혔으며, 이는 지동설의 정밀함을 더하는 데 기여했다. 같은 시대를 살았던 뉴턴은 왜 달은 하늘에 떠 있는 반면, 사과는 땅으로 떨어지는지를 고민하며 만유인력의 법칙을 세우고 중력 개념을 정립했다.\n이러한 천체의 움직임과 자연 현상의 본질은 결국 변화에서 출발한다. 미분은 변화의 순간을 정량적으로 포착하는 방법이다. 상태가 변할 때, 우리는 그 변화의 양상에 주목하게 된다. 거리의 변화는 속도로, 속도의 변화는 가속도로 표현되며, 경제학에서는 비용과 효용의 변화가 한계비용과 한계효용으로 나타난다.\n미분은 함수의 특정 지점에서 접선의 기울기를 계산하는 도구다. 이 접선의 기울기는 함수가 그 점에서 얼마나 빠르게 증가하거나 감소하는지를 나타낸다. 다항함수, 지수함수, 로그함수, 삼각함수 등 대부분의 함수는 미분 가능하며, 특히 통계학에서 자주 사용되는 함수들은 거의 예외 없이 미분이 가능한 형태를 가지고 있다.\n통계학에서 미분은 여러 분야에 활용된다. 회귀분석에서는 오차의 제곱합을 최소화하기 위해 미분을 통해 회귀계수를 추정하고, 확률 밀도 함수의 극댓값을 찾거나 함수의 모양을 분석할 때도 미분이 필수적이다. 또한 최대우도법이나 베이지안 추정 등에서도 목적함수의 최적값을 구하기 위한 과정에 미분이 사용된다.\n이처럼 미분은 단순히 수학적인 연산을 넘어서, 변화와 움직임을 이해하는 데 필요한 핵심 개념으로 작용한다. 자연의 움직임을 설명하고자 했던 과학자들의 질문이 결국 수학적 사고와 연결되듯, 통계학에서도 미분은 현상을 분석하고 설명하는 데 중요한 역할을 수행한다.\n\n 1. 평균변화율 average rate of change\n구간 \\(a \\leq x \\leq b\\)에서 함수 \\(f\\)의 평균 변화량으로 \\(\\frac{rise}{run} = \\frac{\\Delta y}{\\Delta x} = \\frac{f(b) - f(b)}{b - a}\\)이다.\n\n\n\n\n\n\\(a \\leq x \\leq b\\) 구간에서 단위당 평균적으로 함수의 변화량을 측정한 것이다. 평균변화량은 고속도로 구간단속에 이용된다. 미분은 지점 과속 단속에 이용된다.\n\n\n\n\n\n측정 1: 구간단속 시작, 종료 지점에서 과속여부 측정 (미분 응용)\n측정 2: 예를 들어 구간 거리가 6km라 하자. 2분만에 구간을 통과했다면 평균속도는 \\(\\frac{6 - 0}{2 - 0} = 3km/min.\\)분당 3km를 달렸으므로 시간당 180km를 달렸으니 과속이 되는 것입니다. (평균변화량)\n\n\n 2. 미분 정의\n함수 \\(f(x)\\)의 임의의 점 \\(x = a\\)에서의 미분값 \\(f'(a)\\)는 다음과 같이 정의된다. \\(f'(a) = \\lim_{h \\rightarrow 0}\\frac{f(a + h) - f(a)}{h}\\)\n\\(\\frac{f(a + h) - f(a)}{h}\\)는 Fermat’s Difference Quotient로 불리며, 점 \\(a\\)에서의 평균 변화율을 나타낸다.\n극한이 존재하면 \\(f'(a)\\)는 \\(x = a\\)에서의 접선의 기울기로 해석할 수 있다.\n미분 가능성: \\(f'(a)\\)가 존재하면, 점 \\(x = a\\)에서 함수 \\(f(x)\\)는 미분 가능하다고 한다. 함수 \\(f(x)\\)가 정의역 전체에서 미분 가능하, 함수 f(x)는 미분 가능 함수이다.\n미분의 기하학적 해석: 미분값 \\(f'(a)\\)는 곡선 \\(y = f(x)\\)의 점 \\(x = a\\)에서의 접선의 기울기를 의미한다. \\(h\\)가 0으로 가까워질수록 평균 변화율은 접선의 기울기에 점점 가까워진다.\n미분 가능성과 연속성: 함수 \\(f(x)\\)가 점 \\(x = a\\)에서 미분 가능하면 \\(f(x)\\)는 반드시 그 점에서 연속이다. 하지만, 연속이라고 해서 항상 미분 가능한 것은 아니다. 예를 들어, 절대값 함수 가능하지 않다.\n\n\n\n\n\n\n\n3. 미분 규칙\n상수 함수의 미분 \\[\\frac{d}{dx}\\lbrack c\\rbrack = 0\\]\n거듭제곱 함수의 미분 \\[\\frac{d}{dx}\\lbrack x^{n}\\rbrack = nx^{n - 1}, f(x) = x^{n}(n \\in \\mathbb{R})\\]\n【예제】 \\(f(x) = 2\\sqrt{x}\\) 을 미분하시오.\n\\[f'(x) = 2(\\frac{1}{2})x^{1/2 - 1} = x^{- 1/2} = \\frac{1}{\\sqrt{x}}\\]\n상수배의 미분: \\[\\frac{d}{dx}\\lbrack c \\cdot f(x)\\rbrack = c \\cdot \\frac{d}{dx}\\lbrack f(x)\\rbrack\\]\n합/차의 미분\n\\[\\frac{d}{dx}\\lbrack f(x) \\pm g(x)\\rbrack = \\frac{d}{dx}\\lbrack f(x)\\rbrack \\pm \\frac{d}{dx}\\lbrack g(x)\\rbrack\\]\n곱의 미분\n\\[\\frac{d}{dx}\\lbrack f(x) \\cdot g(x)\\rbrack = f'(x) \\cdot g(x) + f(x) \\cdot g'(x)\\]\n나눗셈의 미분\n\\(\\frac{d}{dx}\\left\\lbrack \\frac{f(x)}{g(x)} \\right\\rbrack = \\frac{f'(x) \\cdot g(x) - f(x) \\cdot g'(x)}{\\lbrack g(x)\\rbrack^{2}}\\), \\(g(x) \\neq 0\\)\n체인룰 chain rule 연쇄규칙\n\\[\\frac{d}{dx}\\lbrack f(g(x))\\rbrack = f'(g(x)) \\cdot g'(x)\\]\n【예제】 \\(f(x) = 2\\sqrt{3x^{2} - 1}\\)을 미분하시오.\n\n\n\n\n\n  바깥부분 미분하고 안쪽 부분 그대로 적는다.\n  \\(2*(1/2){\\sqrt{(3x^{2} - 1)}}^{- 1/2}\\) 그리고 안쪽부분을 미분한다.\n\\[f'(x) = {\\sqrt{(3x^{2} - 1)}}^{- 1/2}6x = \\frac{6x}{\\sqrt{3x^{2} - 1}}\\]\n로그함수 미분 \\[\\frac{d}{dx}\\lbrack\\log_{a}(x)\\rbrack = \\frac{1}{x\\ln(a)},x &gt; 0\\]\n\\[\\frac{d}{dx}\\lbrack\\ln(x)\\rbrack = \\frac{1}{x},x &gt; 0\\]\n【예제】 \\(f(x) = ln(x^{2} - 1)\\)을 미분하시오.\n  연쇄법칙 적용 : \\(f'(x) = \\frac{1}{x^{2} - 1}2x\\)\n지수함수 미분\n\\[\\frac{d}{dx}\\lbrack a^{x}\\rbrack = a^{x}\\ln(a)\\]\n\\[\\frac{d}{dx}\\lbrack e^{x}\\rbrack = e^{x}\\]\nimport sympy as sp\n\n# 변수와 함수를 정의\nx = sp.Symbol('x')\nf = 5*(x**2 - 2*x)**2\n\n# 함수 입력을 파싱하여 미분\nfunc = sp.sympify(f)\nderivative = sp.diff(func, x)\n\n\n4. 미분 응용\n\n(1) 최대, 최소\n1차 미분정리\n함수 f(x) 가 일정 구간 (a, b) 안의 모든 점에서 미분 가능하고, 구간 내 임의의 점 c 에서 1차 미분이 0이면, f(x) 함수는 c 점에서 지역 최대값이나 최소값을 갖는다. 이는 페르마의 정리에 Fermat’s 해당하며, 극대값 또는 극소값이 존재하는 필수 조건을 설명한다.\n함수 f(x) 가 c 에서 미분 가능하고, 극값이 c 에서 존재하면, 반드시 \\(f'(c) = 0\\)이어야 한다.\n다만, \\(f'(c) = 0\\)이라고 해서 반드시 극값이 존재하는 것은 아니며, 이는 필요조건일 뿐 충분조건은 아니다. 극값의 존재를 확실히 판단하려면 2차 도함수 테스트나 첫 도함수의 부호 변화를 추가로 고려해야 한다.\n증가 함수와 감소 함수\n함수 f(x)가 구간 \\(I\\)에서 정의되어 있을 때, \\(x_{1} &lt; x_{2} \\Longrightarrow f(x_{1}) \\leq f(x_{2})\\) 이면 구간 \\(I\\)에서 증가 함수이다.\n\\(x_{1} &lt; x_{2} \\Longrightarrow f(x_{1}) \\geq f(x_{2})\\) 이면 구간 \\(I\\)에서 감소 함수이다.\n1차 미분과 증가·감소 함수의 관계\n함수 f(x) 가 구간 \\(I\\)에서 미분 가능하다면,\n\n\\(f'(x) &gt; 0\\) 이면, f(x) 는 구간 \\(I\\)에서 엄격히 증가한다\n\\(f'(x) &lt; 0\\) 이면, f(x) 는 구간 \\(I\\)에서 엄격히 감소한다.\n\n오목성 concavity 정의\n함수 f(x) 의 기울기가 감소하는 경우 \\(f''(x) &lt; 0\\),\n\n함수 f(x) 는 concave down (오목 아래)이다.\n그래프가 아래로 휘어진 모양을 갖는다.\n\n함수 f(x) 의 기울기가 증가하는 경우 \\(f''(x) &gt; 0\\),\n\n함수 f(x) 는 concave up (오목 위)이다.\n그래프가 위로 휘어진 모양을 갖는다.\n\n\n\n\n\n\n변곡점 inflexion point 정의\n함수 \\(f(x)\\)의 오목성이 변하는 점이 있을 때, 이 점을 변곡점이라고 한다. 즉, \\(f(x)\\)가 \\(f’’(x) &gt; 0\\)에서 \\(f’’(x) &lt; 0\\)로 바뀌거나 \\(f’’(x) &lt; 0\\)에서 \\(f’’(x) &gt; 0\\)로 바뀌는 점이 변곡점이다.”\n1차 미분과 2차 미분을 이용한 최대, 최소 판단\n주어진 \\(f'(c) = 0\\)에서, \\(f''(c)\\)를 확인한다.\n\n\\(f''(c) &gt; 0\\) 이면 \\(x = c\\)에서 (지역) 최소값\n\\(f''(c) &lt; 0\\) 이면 \\(x = c\\)에서 (지역) 최대값\n\\(f''(c) = 0\\) 이고 \\(f''(x)\\) 부호가 바뀌면 \\(x = c\\)에서 변곡점\n\n\n\n(2) 통계학 응용\n단순 회귀모형 \\[y_{i} = \\beta_{0} + \\beta_{1}x_{i} + \\epsilon_{i},i = 1,2,\\ldots,n\\]\nOLS 추정치 \\[\\text{Minimize:}S(\\beta_{0},\\beta_{1}) = \\overset{n}{\\sum_{i = 1}}(y_{i} - \\beta_{0} - \\beta_{1}x_{i})^{2}\\]\n오차 제곱합    \\(S(\\beta_{0},\\beta_{1})\\)을 \\(\\beta_{0}\\)와 \\(\\beta_{1}\\)에 대해 편미분한 뒤 0으로 설정하여 최소값(OLS)을 찾는다.\n정규방정식\n\\[\\frac{\\partial S}{\\partial\\beta_{0}} = - 2\\overset{n}{\\sum_{i = 1}}(y_{i} - \\beta_{0} - \\beta_{1}x_{i}) = 0\\]\n\\[\\overset{n}{\\sum_{i = 1}}y_{i} = n\\beta_{0} + \\beta_{1}\\overset{n}{\\sum_{i = 1}}x_{i}\\]\n\\[\\frac{\\partial S}{\\partial\\beta_{1}} = - 2\\overset{n}{\\sum_{i = 1}}x_{i}(y_{i} - \\beta_{0} - \\beta_{1}x_{i}) = 0\\]\n\\[\\overset{n}{\\sum_{i = 1}}x_{i}y_{i} = \\beta_{0}\\overset{n}{\\sum_{i = 1}}x_{i} + \\beta_{1}\\overset{n}{\\sum_{i = 1}}x_{i}^{2}\\]\n두 식을 함께 사용하여 \\(\\beta_{0}\\)와 \\(\\beta_{1}\\)를 계산한다.\n\\[\\beta_{1} = \\frac{\\sum_{i = 1}^{n}(x_{i} - \\overline{x})(y_{i} - \\overline{y})}{\\sum_{i = 1}^{n}(x_{i} - \\overline{x})^{2}} = \\frac{\\text{Cov}(x,y)}{\\text{Var}(x)}\\]\n\\[\\beta_{0} = \\overline{y} - \\beta_{1}\\overline{x}\\]\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import curve_fit\n\n# 가상의 데이터 생성 n=20\nnp.random.seed(0)\nx_data = np.linspace(-5, 5, 20)\ny_data = 2 * x_data**3 - 3 * x_data**2 + 4 * x_data + 10 + np.random.normal(0, 10, 20)\n\n# 직선 적합 함수\ndef linear(x, a, b):\n    return a * x + b\n# 2차 함수 적합 함수\ndef quadratic(x, a, b, c):\n    return a * x**2 + b * x + c\n# 3차 함수 적합 함수\ndef cubic(x, a, b, c, d):\n    return a * x**3 + b * x**2 + c * x + d\n# 최소자승법을 이용한 직선, 2차, 3차 적합\nparams_linear, _ = curve_fit(linear, x_data, y_data)\nparams_quadratic, _ = curve_fit(quadratic, x_data, y_data)\nparams_cubic, _ = curve_fit(cubic, x_data, y_data)\n\n# 적합된 함수의 값을 계산\ny_fit_linear = linear(x_data, *params_linear)\ny_fit_quadratic = quadratic(x_data, *params_quadratic)\ny_fit_cubic = cubic(x_data, *params_cubic)\n\n# Residual Sum of Squares 계산\nrss_linear = np.sum((y_data - y_fit_linear) ** 2)\nrss_quadratic = np.sum((y_data - y_fit_quadratic) ** 2)\nrss_cubic = np.sum((y_data - y_fit_cubic) ** 2)\n\n# 최소자승법을 이용한 직선, 2차, 3차 적합\nparams_linear, _ = curve_fit(linear, x_data, y_data)\nparams_quadratic, _ = curve_fit(quadratic, x_data, y_data)\nparams_cubic, _ = curve_fit(cubic, x_data, y_data)\n\n# 적합된 함수의 값을 계산\ny_fit_linear = linear(x_data, *params_linear)\ny_fit_quadratic = quadratic(x_data, *params_quadratic)\ny_fit_cubic = cubic(x_data, *params_cubic)\n\n# Residual Sum of Squares 계산\nrss_linear = np.sum((y_data - y_fit_linear) ** 2)\nrss_quadratic = np.sum((y_data - y_fit_quadratic) ** 2)\nrss_cubic = np.sum((y_data - y_fit_cubic) ** 2)\n\n# 그래프 그리기\nplt.figure(figsize=(10, 6))\nplt.scatter(x_data, y_data, label='data', color='black')\nplt.plot(x_data, y_fit_linear, label='Linear fit (y = {:.2f}x + {:.2f}) : RSS={:.2f}'.format(params_linear[0], params_linear[1],rss_linear), color='blue')\nplt.plot(x_data, y_fit_quadratic, label='Quardratic fit (y = {:.2f}x^2 + {:.2f}x + {:.2f}) : RSS={:.2f}'.format(params_quadratic[0], params_quadratic[1], params_quadratic[2],rss_quadratic), color='green')\nplt.plot(x_data, y_fit_cubic, label='Cubic fit (y = {:.2f}x^3 + {:.2f}x^2 + {:.2f}x + {:.2f}) : RSS={:.2f}'.format(params_cubic[0], params_cubic[1], params_cubic[2], params_cubic[3],rss_cubic), color='red')\nplt.axhline(0, color='grey', lw=0.5, ls='--')\nplt.axvline(0, color='grey', lw=0.5, ls='--')\nplt.title('fit by OLS')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.legend()\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n(3) 한계효용체감의 법칙\n한계효용 marginal utility은 재화가 증가 혹은 감소함에 따라 주관적으로 매겨지는 경제적 효용(혹은 가치)의 관계에 대한 개념으로 합리적인 경제에서 인간 행동은 자신에게 가장 시급한 욕구를 충족하는 일을 가장 먼저 하거나 가치를 두는 특성이 있다. 따라서 어떤 사람이 재화나 용역을 이용하여 효용을 얻고자 할 때 주관적으로 판단되는 욕망 충족의 정도인 효용의 가치가 높은 것부터 낮은 것 쪽으로 추구한다. 재화나 용역의 한계효용은 그 재화나 용역을 사용하는 것을 증가하거나 감소함에 따라 변화한 가치의 양을 상정한 것인데 이런 변화에서 추가의 1단위 즉 경계인 단위에서의 재화나 용역의 효용을 한계효용이라고 한다.[위키피디아]\n\n\n\n\n\n총효용 total utility 은 주어진 기간 동안 소비된 특정 상품의 모든 단위에서 얻은 총만족입니다. 한계효용 marginal utility 마지막 소비량에서 상품 소비의 1단위 변화로 인해 발생하는 총 효용의 변화이다. 더 많은 단위의 상품을 구매하면 한계 효용은 감소하기 시작하지만 총 효용은 계속해서 감소 비율이 줄어든다. 한계효용이 0가 되는 포화점 satiety에 이르렀을 때 이 지점에서의 총효용은 최대가 된다. 이 지점에서 소비가 더 증가하면 한계 효용은 음수가 되고 총 효용은 감소하기 시작한다.\n\n\n(4) Cobb-Douglas 생산함수\n\\(Q = f(K,L) = AL^{\\alpha}K^{\\beta}\\), \\(Q\\)= 생산, \\(K\\)=자본, \\(L\\)=노동, \\(A,\\alpha,\\beta\\)는 모수이다. \\(K,L\\)에 대하여 각각 편미분 하면 다음과 같다.\n  - 양변에 로그를 취한다. \\(ln(Q) = lnA + \\alpha lnL + \\beta lnK\\)\n  - \\(\\frac{\\partial(lnQ)}{\\partial L} = \\alpha\\) : 한계 노동 생산량\n  - \\(\\frac{\\partial(lnQ)}{\\partial K} = \\beta\\) : 한계 자본 생산량\n\n\n\n\n\nchapter 2. 적분\n고대 수학자들은 직선으로 이루어진 도형의 면적을 비교적 쉽게 계산할 수 있었습니다. 사각형, 삼각형, 평행사변형, 사다리꼴과 같은 도형은 밑변과 높이를 활용한 간단한 공식을 통해 면적을 구할 수 있었기 때문입니다. 그러나 곡선이 포함된 도형의 면적을 계산하는 문제는 훨씬 더 복잡한 도전 과제였습니다.\n곡선이 포함된 도형의 면적을 구하기 위해 현대 수학에서는 적분이라는 개념이 도입되었습니다. 이는 고대 그리스의 수학자 아르키메데스가 처음으로 탐구한 주제 중 하나였습니다. 아르키메데스는 곡선 아래의 면적을 구하기 위해 곡선을 아주 작은 직사각형들로 나누고, 그 면적을 합산하여 근사값을 구하는 방식을 사용했습니다. 이 과정은 시간이 지나며 점점 더 체계적으로 발전하였고, 마침내 미적분학으로 이어졌습니다.\n아이작 뉴턴과 고트프리트 라이프니츠는 아르키메데스의 아이디어를 발전시켜 적분과 미분이라는 두 가지 핵심 개념을 정립하였고, 이를 통해 곡선 아래의 면적을 정확히 계산할 수 있는 도구를 완성했습니다. 오늘날 우리가 사용하는 적분법은 이들의 연구에 기반을 두고 있으며, 곡선의 면적뿐만 아니라 물리학, 공학, 경제학 등 다양한 분야에서 중요한 역할을 하고 있습니다.\n적분은 통계학에서 확률 계산, 기대값, 분산, 베이지안 추론 등 다양한 개념과 도구에 중요한 역할을 합니다. 확률을 곡선 아래 면적으로 해석하는데서부터 시작해, 통계적 추론의 기초를 형성하는 데 적분이 필수적입니다. 이러한 적분 개념은 통계학 이론뿐만 아니라 데이터 분석, 머신러닝, 신뢰구간 계산 등 실무적인 응용에서도 널리 사용됩니다.\n\n1. 부정 적분\n함수 F(x) 가 주어진 함수 f(x) 에 대해 정의역의 모든 점에서 \\(F'(x) = f(x)\\)를 만족한다면, F(x) 를 f(x) 의 역-미분 anti-derivative 또는 원시함수 primitive function 합니다. 이는 적분이 미분의 역연산임을 의미합니다.\n적분이 미분의 역연산이라는 사실을 처음 체계적으로 증명하고 이를 수학적으로 정립한 사람들은 아이작 뉴턴(Isaac Newton)과 고트프리트 라이프니츠(Gottfried Wilhelm Leibniz)입니다. 이들은 독립적으로 미적분학의 기본 개념을 발전시켰으며, 이 과정에서 적분과 미분의 관계를 설명한 미적분학의 기본정리를 도출했습니다.\n정적분과 미분의 관계\n특정 구간에서의 정적분은 미분을 통해 함수의 값을 복원할 수 있습니다. 예를 들어, 함수 f(x) 에 대해 다음과 같은 정적분이 있을 때,\n\\(F(x) = \\int_{a}^{x}f(t)dt\\). 이를 x 에 대해 미분하면 \\(\\frac{d}{dx}F(x) = f(x)\\)\n즉, 적분을 통해 구한 누적 변화량을 다시 미분하면, 원래의 함수로 돌아갑니다.\n적분과 미분은 서로 반대되는 과정처럼 보이지만, 실제로는 상호보완적입니다. 적분은 함수의 누적적인 변화(예: 곡선 아래의 면적)를 측정하며, 미분은 순간적인 변화(예: 기울기)를 측정합니다.\n\n\n2. 정적분\n\n(1) 정적분 개념\n정적분(면적)은 부정적분(역-미분 함수)과는 다른 접근 방식에서 출발합니다. 그러나 이 두 개념은 17세기에 뉴턴(Newton)과 라이프니츠(Leibniz)에 의해 서로 밀접하게 연결되었고, 이를 통합하여 적분(integral)이라고 명명하였습니다.\n우선, 정적분의 개념을 살펴보겠습니다. 구간 [a, b]에서 함수 f(x) 아래의 면적을 어떻게 구할 수 있을까요? 이를 위해 구간 [a, b]를 여러 작은 구간으로 나눈 다음, 각 구간에서 직사각형의 면적을 계산하여 합산하는 방법을 생각할 수 있습니다. 이러한 직사각형의 면적 합은 점점 더 작은 구간으로 나눌수록 실제 면적에 근사하게 됩니다.\n\n\n\n\n\n함수와 x-축 사이에 형성된 이 면적은 정적분이라 하며, 이는 구간 [a, b]에서 함수 f(x)와 x-축 사이의 공간에 해당합니다. 직사각형을 이용해 근사한 면적은 실제 면적보다 클 수도 있고 작을 수도 있습니다. 하지만 구간을 점점 더 세분화하면, 이 근사값은 실제 정적분 값에 수렴하게 됩니다.\n정적분은 함수의 곡선 아래의 면적을 계산하는 방법으로 출발했지만, 부정적분(역-미분 함수)과의 연결을 통해 더욱 강력한 수학적 도구로 발전하였습니다.\n\n\n(2) 정적분과 부정적분의 관계\n함수 f(x) 가 구간 [a, b]에서 연속일 때:\n\n부정적분(역-미분 함수): 함수 F(x) 가 f(x) 의 부정적분이라면 \\(F'(x) = f(x)\\)\n정적분(구간의 면적): 함수 f(x) 의 정적분은 구간 [a, b]에서 f(x) 와 x -축 사이의 면적을 나타냅니다. \\(\\int_{a}^{b}f(x)dx\\)\n뉴턴-라이프니츠 정리: 부정적분과 정적분은 다음과 같이 연결됩니다. \\(\\int_{a}^{b}f(x)dx = F(b) - F(a)\\)\n여기서 F(x) 는 f(x) 의 부정적분입니다.\n\n이 정리는 정적분(구간에서의 면적 계산)이 부정적분(역-미분 함수)을 사용하여 계산될 수 있음을 보여줍니다.\n\n\n(3) 정적분 규칙\n특정 점에서의 확률\n\\[\\int_{a}^{a}f(x)dx = 0\\]\n이는 구간의 길이가 0 일 때, 정적분의 결과가 항상 0 임을 나타냅니다(통계적으로: 연속 확률변수에서 특정 점에서의 확률은 0 이다).\n구간 순서 반대\n\\[\\int_{a}^{b}f(x)dx = - \\int_{b}^{a}f(x)dx\\]\n구간의 순서를 바꾸면 정적분의 부호가 반대가 됩니다.\n상수 배율\n\\[\\int_{a}^{b}c \\cdot f(x)dx = c\\int_{a}^{b}f(x)dx(\\text{c is constant})\\]\n적분 내부에 상수가 곱해져 있을 경우, 상수를 적분 기호 밖으로 꺼낼 수 있습니다.\n합과 차\n\\[\\int_{a}^{b}\\left( f(x) \\pm g(x) \\right)dx = \\int_{a}^{b}f(x)dx \\pm \\int_{a}^{b}g(x)dx\\]\n적분은 덧셈과 뺄셈 연산에 대해 분배법칙을 따릅니다.\nDomination Rule\n만약 \\(f(x) \\geq 0\\)가 구간 [a, b]에서 항상 성립하면\n\\(\\int_{a}^{b}f(x)dx \\geq 0\\) 이다. 통계적으로 확률변수의 분포 함수는 항상 0 이상 이므로, 확률값은 항상 0 이상이다.\n부등식 관계\n만약 \\(f(x) \\leq g(x)\\)가 구간 [a, b]에서 항상 성립하면\n\\(\\int_{a}^{b}f(x)dx \\leq \\int_{a}^{b}g(x)dx\\) 이다.\n구간 쪼개기\n\\[\\int_{a}^{c}f(x)dx + \\int_{c}^{b}f(x)dx = \\int_{a}^{b}f(x)dx\\]\n적분 구간을 나누어 계산할 수 있습니다.\n확률밀도함수 전체 구간\n\\(\\int_{- \\infty}^{\\infty}f(x)dx = 1\\). 확률밀도함수(PDF)는 전체 구간에서의 적분, 확률의 총합이 1 임을 나타냅니다.\n지수함수 적분\n\\[\\int a^{x}dx = \\frac{a^{x}}{\\ln a} + C(a &gt; 0,a \\neq 1)\\]\n\\[\\int e^{x}dx = e^{x} + C\\]\n로그함수 적분\n\\[\\int\\log_{a}(x)dx = \\frac{1}{\\ln(a)}\\left( x\\ln(x) - x \\right) + C\\]\n\\[\\int\\ln(x)dx = x\\ln(x) - x + C\\]\n특수한 적분\n\\[\\int\\frac{1}{x} = ln|x| + C\\]\n치환적분\n함수 g(x) 가 x 에 대한 미분가능한 함수이고, f(u) 가 u = g(x) 에 대한 함수라고 가정하겠습니다.\n\\[\\int f(g(x)) \\cdot g'(x)dx = \\int f(u)du\\]\n\\[u = g(x) , du = g'(x)dx\\]\n【사례】 \\(\\int x \\cdot e^{x^{2}}dx = \\frac{1}{2}e^{x^{2}} + C\\)\n\\(u = x^{2}\\)로 치환하면, \\(du = 2xdx\\). 따라서 \\(xdx = \\frac{1}{2}du\\)\n\\(\\int x \\cdot e^{x^{2}}dx = \\int e^{u} \\cdot \\frac{1}{2}du = \\frac{1}{2}\\int e^{u}du\\)=\\(\\frac{1}{2}\\int e^{u}du = \\frac{1}{2}e^{u} + C\\)\n\\(u = x^{2}\\) 이므로 \\(\\int x \\cdot e^{x^{2}}dx = \\frac{1}{2}e^{x^{2}} + C\\) 이다.\n부분적분\n함수 u(x) 와 v(x) 가 미분 가능할 때, 다음 공식이 성립합니다:\n\\[\\int udv = uv - \\int vdu\\]\n\n\\(u\\): 미분할 함수 (\\(u \\rightarrow du\\))\n\\(dv\\): 적분할 함수 (\\(dv \\rightarrow v\\))\n\n【사례】 \\(\\int xe^{x}dx\\)\n1) 함수 선택: \\(u = x,dv = e^{x}dx\\)\n2) 미분 및 적분: \\(u \\rightarrow du = dx\\),\\(dv \\rightarrow v = e^{x}\\)\n3) 부분적분 공식 적용: \\(\\int xe^{x}dx = uv - \\int vdu\\)\n\\(= xe^{x} - \\int e^{x}dx\\)\\(= xe^{x} - e^{x} + C\\).\n【사례】 \\(\\int_{0}^{1}x^{2} + \\sqrt{x}dx\\) 구하시오.\n\\(f(x) = x^{2} + \\sqrt{x}\\)이므로 \\(F(x) = \\frac{1}{3}x^{3} + \\frac{2}{3}x^{\\frac{3}{2}}\\)\n\\(F(1) = 1\\), \\(F(0) = 0\\)이므로 1이다.\n\\[\\int_{0}^{1}x^{2} + \\sqrt{x}dx = \\frac{1}{3}x^{3} + \\frac{2}{3}x^{\\frac{3}{2}}\\rbrack_{0}^{1} = 1 - 0 = 1\\]\n#부정적분\nfrom sympy import *\nx=Symbol('x')\nintegrate(x**2+x**(0.5), x)\n\\[ x^3/3 + 0.66667x^{1.5}\n\\]\n#정적분\nfrom scipy.integrate import quad\ndef integrand(x):\n   return x**2+x**(0.5)\nquad(integrand,0, 1)\n【결과】 첫번째 값은 적분값이고 두 번째는 적분 값을 얼마나 근사하게 계산하였는지 값이다. 완벽한 값이면 0이어야 하나 출력된 값은 0.0(14개)11…이다. root는 실제 근이다. (1.0, 1.1102230246251565e-15)\n【사례】 표준 정규확률분포함수\\(\\int_{0}^{\\infty}\\frac{1}{\\sqrt{2\\pi}}e^{- \\frac{x^{2}}{2}}dx\\) 구하시오.\n#부정적분\nfrom sympy import *\nimport numpy as np\nx=Symbol('x')\nintegrate(1/(2*np.pi)**0.5*exp(-x**2/2), x)\n\\[\n0.199471140200716 \\sqrt{2} \\sqrt{\\pi} \\, \\mathrm{erf}\\left( \\frac{\\sqrt{2}x}{2} \\right)\n\\]\nimport numpy as np\n#정적분\nfrom scipy.integrate import quad\ndef integrand(x):\n   return 1/(2*np.pi)**0.5*exp(-x**2/2)\nquad(integrand,0,np.inf)\n【결과】 (0.49999999999999983, 5.08909572547112e-09)\n\n\n(4) 표적분 tabular integral\n표 적분은 부분적분을 용이하게 한다. 미분 부분 \\(f(x)\\)는 미분하면서 차수가 용이해야 하고, 적분함수 \\(g(x)\\)는 용이하게 적분할 수 있어야 한다.\n(방법1) 미분 부분이 0이 될 때까지 미분과 적분을 반복 시행한다.\n\\[\\int_{a}^{b}udv = (1)*(a) - (2)*(b) + (3)(c)...\\rbrack_{a}^{b}\\]\n(방법2)한 번만 미분하고 \\(\\int_{a}^{b}udv = (1)*(a) - \\int_{a}^{b}(2)*(b)dx\\)\n\n\n\n\n\n【예제】 \\(\\int_{0}^{\\infty}xe^{- x}dx\\) 표 적분하시오.\n\n\n\n\n\n(방법1) \\(x( - e^{- x}) - e^{- x}\\rbrack_{0}^{\\infty} = 1\\)\n(방법2) \\(x( - e^{- x})\\rbrack_{0}^{\\infty} - \\int_{0}^{\\infty} - e^{- x} = 1\\)으로 계산한다.\n【예제】 \\(\\int_{1}^{2}ln(x)dx\\) 표 적분하시오.\n\n\n\n\n\n\\[\\int_{1}^{2}ln(x)dx = ln(x)x\\rbrack_{1}^{2} - \\int_{0}^{1}1dx = 2ln(2) - ln(1) - x\\rbrack_{0}^{1} = 0.386\\]\n\n\n\n3. 적분 응용\n연속형 확률분포의 확률밀도함수\n\n\n\n\n\n연속형 확률변수 X 의 확률밀도함수 f(x) 는 특정 구간에서 확률을 계산하는 데 사용됩니다. 이때 확률은 적분을 통해 구합니다:\n\\[P(a \\leq X \\leq b) = \\int_{a}^{b}f(x)dx\\]\nf(x) 는 음수가 아니며, 전체 구간에서의 적분값은 항상 1이 됩니다:\n\\[\\int_{- \\infty}^{\\infty}f(x)dx = 1\\]\n【예제】 정규분포 N(0, 1) 에서 \\(P( - 1 \\leq Z \\leq 1) = \\int_{- 1}^{1}\\phi(z)dz\\) 이다. 여기서 \\(\\phi(z) = \\frac{1}{\\sqrt{2\\pi}}e^{- z^{2}/2}\\)는 표준정규분포의 확률밀도함수입니다.\n누적확률분포함수 cumulative probability density fuction\n\n\n\n\n\n기대값\n  연속형 확률변수 X 의 확률밀도함수 f(x)라 하면 기대값은 \\(E(X) = \\int xf(x)dx\\) 이다.\n적분과 백분위값\n  백분위값 percentile은 확률분포에서 특정 비율의 누적 확률을 기준으로 하는 값입니다. P번째 백분위값은 확률변수 X의 값 \\(X_{P}\\)로, 확률변수가 \\(X_{P}\\)이하일 확률이 \\(\\frac{P}{100}\\)이 되는 값입니다.\n\\[F(x_{P}) = \\int_{- \\infty}^{x_{P}}f(x)dx = \\frac{P}{100}\\]\n  - \\(f(x)\\): 확률밀도함수(PDF)\n  - \\(F(x)\\): 누적분포함수(CDF)\n  - \\(x_{P}\\): \\(P\\)번째 백분위값"
  },
  {
    "objectID": "notes/math/function.html",
    "href": "notes/math/function.html",
    "title": "수학의 기초 1. 함수",
    "section": "",
    "text": "chapter 1. 기초\n\n 1. 함수와 통계학\n함수는 통계학에서 데이터를 설명하고 모델링하는 수단이며, 이론적 개념을 수학적으로 표현하는 핵심 도구이다. 데이터 간의 관계를 나타내고, 확률분포, 추정, 검정 등 다양한 통계 기법에서 필수적인 역할을 수행한다.\n통계함수: 통계함수는 독립변수(\\(x\\))와 종속변수(\\(y\\)) 데이터 간 관계를 설명한다. \\(y = f(x) + e\\)로 표현되며 \\(e\\)는 오차항이다.\n확률밀도함수: 확률밀도함수 \\(p(x)\\)는 확률변수의 확률이 함수값이다.\n기대값: 확률변수의 평균적인 값이다. \\(E(X) = \\sum xp(x)\\)\n\n\n 2. 함수와 시리즈\n시리즈는 복잡한 함수를 단순한 다항식으로 근사하거나, 함수의 특성을 분석하는 데 사용된다. 시리즈는 유한하거나 무한한 항들로 이루어진 수열의 합으로 정의된다.\n유한 시리즈: \\(S_{n} = {\\sum_{i = 1}^{n}}a_{k}\\)\n무한 시리즈: \\(S_{\\infty} = {\\sum_{i = 1}^{\\infty}}a_{k}\\)\n이항시리즈 binomial series\n\\[(a + b)^{n} = a^{n} + \\binom{n}{1}a^{n - 1}b + ... + \\binom{n}{n - 1}ab^{n - 1} + b^{n}\\]\n\n특수한 경우\n\n\\[\\frac{1}{(1 + x)^{2}} = - 1 + 2x - 3x^{2} + 4x^{3} - ...\\]\n\\[\\frac{1}{1 + x} = 1 - x + x^{2} - x^{3} + x^{4} - ...\\]\n지수시리즈 exponential series\n\\[e^{x} = 1 + x + \\frac{x^{2}}{2!} + \\frac{x^{3}}{3!} + ...\\]\n\\[e^{x} = lim_{n \\rightarrow}^{\\infty}(1 + \\frac{x}{n})^{n}\\]\n\\[ln(1 + x) = x - \\frac{{}^{2}}{2} + \\frac{x^{3}}{3} - \\frac{x^{4}}{4} + ..., - 1 &lt; x &lt; 1\\]\n산술시리즈 arithmetic series\n\\[S_{n} = a + (a + d) + (a + 2d) + \\cdots + \\lbrack a + (n - 1)d\\rbrack\\]\n      - \\(a\\): 첫 번째 항, \\(d\\): 공차(항 사이의 일정한 차이), \\(n\\): 항의 개수\n\\[S_{n} = \\frac{n}{2}\\lbrack 2a + (n - 1)d\\rbrack\\]\n기하시리즈 geometric series\n\\[S_{n} = a + ar + ar^{2} + \\cdots + ar^{n - 1}\\]\n     - \\(a\\): 첫 번째 항, \\(r\\): 공비(항 사이의 일정한 차이)\n\\[S_{n} = \\frac{a(1 - r^{n})}{1 - r},r \\neq 1\\]\n무한 기하시리즈: \\(S_{n} = \\frac{a}{1 - r}, - 1 &lt; r &lt; 1\\)\n\n\n 3. 통계학 주요상수\n지수 exponent \\(e\\)\n  자연로그 함수의 밑으로 정의되며, 무한 급수로 표현된다.\n  \\(e \\approx 2.71828182845904\\ldots\\)(무리수)\n  통계학의 주요 확률분포함수(정규분포, 포아송분포)의 항이다.\n자연상수 \\(ln2\\)\n\\[\\ln 2 \\approx 0.69314718056\\ldots \\text{(무리수)}\\]\n  정보 이론: 1비트의 정보. 이진수 체계와 로그 연산.\n황금비 \\(\\phi \\approx 1.61803398874989\\ldots\\)\n  \\(a/b = (a + b)/a\\)를 만족하는 비율 \\(\\phi = \\frac{1 + \\sqrt{5}}{2}\\)\n오일러상수: 조화급수와 자연로그의 차이로 정의된다.\n\\[\\gamma = \\lim_{n \\rightarrow \\infty}\\left( \\overset{n}{\\sum_{k = 1}}\\frac{1}{k} - \\ln n \\right) \\approx 0.577215664901532\\ldots\\]\n\n기호\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n소문자\nα\nβ\nγ\nδ\nε\nζ\nη\nθ\n\n\n대문자\nΑ\nΒ\nΓ\nΔ\nΕ\nΖ\nΗ\nΘ\n\n\n발음\nalpha\nbeta\ngamma\ndelta\nepsilon\nzeta\neta\ntheta\n\n\n소문자\nι\nκ\nχ\nλ\nμ\nν\nξ\nο\n\n\n대문자\nΙ\nΚ\nΧ\nΛ\nΜ\nΝ\nΞ\nΟ\n\n\n발음\niota\nkappa\nchi\nlambda\nmu\nnu\nxi(ksi)\nomicron\n\n\n소문자\nπ\nρ\nσ\nτ\nυ\nϕ\nψ\nω\n\n\n대문자\nΠ\nΡ\nΣ\nΤ\nΥ\nΦ\nΨ\nΩ\n\n\n발음\npi\nrho\nsigma\ntau\nupsilon\nphi\npsi\nomega\n\n\n\n\n\n\n\n\nchapter 2. 좌표와 직선방정식\n\n 1. 이차원평면과 데카르트 좌표\n\n\n\n\n\n이차원 평면에서 모든 점은 숫자 좌표로 coordinate 표현할 수 있으며, 점들의 집합으로 이루어진 선이나 곡선은 좌표방정식으로 나타낼 수 있다. 이를 위해 이차원 평면에는 두 개의 직선이 설정된다.. 수평선인 \\(x\\)-축 axis과 수직선인 \\(y\\)-축이다. 이 두 직선은 원점에서 직각으로 교차하며, 원점은 두 축의 기준점이 된다.\n원점을 기준으로 \\(x\\)-축에서 \\(a\\)만큼, \\(y\\)-축에서 \\(b\\)만큼 떨어진 점의 좌표는 \\((a,b)\\)로 표기된다. 이러한 표기 방식은 데카르트 좌표라고 한다. 여기서 \\(a\\)와 \\(b\\)는 각각 \\(x\\)-좌표와 \\(y\\)-좌표를 나타내며, 이 값들은 모두 실수 값으로 구성된다.\n데카르트 Cartesian 좌표계는 이차원 평면에서 점의 위치를 명확하고 직관적으로 나타내는 데 사용되며, 수학적 분석 및 응용의 기초가 된다. 이를 활용하면 점, 선, 곡선, 그리고 다양한 기하학적 형태를 방정식으로 표현하고, 이를 통해 여러 문제를 해결할 수 있다.\n\n\n 2. 직선과 증가\n\n직선\n두 점을 가장 짧은 거리로 연결하는 선을 직선이라고 한다. 직선은 두 점 사이의 최단 경로로 정의되며, 그 위에는 무수히 많은 점이 존재한다. 좌표평면에서 직선은 중요한 기하학적 구조로, 점과 점 사이의 관계를 나타내는 기본 도구이다.\n\n\n증가량 (Increment)\n\n\n\n\n\n좌표평면에서 두 점 \\((x_{1},y_{1})\\)과 \\((x_{2},y_{2})\\)의 이동을 고려할 때, x-좌표와 y-좌표의 변화량을 각각 증가량이라고 한다.\nx-좌표의 증가량: \\(\\Delta x = x_{2} - x_{1}\\)\ny-좌표의 증가량: \\(\\Delta y = y_{2} - y_{1}\\)\n증가량의 부호와 크기는 두 점의 좌표 차이에 의해 결정되며, x-좌표나 y-좌표의 변화 방향을 나타낸다.\n\n\n기울기 slope\n증가량은 두 점을 지나는 직선의 기울기를 계산하는 데 활용된다. 기울기 m은 두 점 사이의 x-좌표의 증가량에 대한 y-좌표의 증가량의 비율로 정의되며, 다음과 같은 식으로 표현된다:\n\\[m = \\frac{\\Delta y}{\\Delta x} = \\frac{y_{2} - y_{1}}{x_{2} - x_{1}},\\Delta x \\neq 0\\]\n    - \\(m &gt; 0\\): 직선이 오른쪽으로 올라간다.\n    - \\(m &lt; 0\\): 직선이 오른쪽으로 내려간다.\n    - \\(m = 0\\): 직선이 수평이다.\n    - \\(m\\)이 정의되지 않음 (\\(\\Delta x = 0\\)): 직선이 수직이다.\n\n\n수평 parallel과 수직 perpendicular\n두 직선 \\(L_{1}\\)과 \\(L_{2}\\)의 기울기가 동일하면, 즉 \\(m_{1} = m_{2}\\)이면 두 직선은 서로 평행 하다고 한다. 이 경우, 두 직선은 교차하지 않으며, 동일한 방향으로 뻗어 있다.\n두 직선 \\(L_{1}\\)과 \\(L_{3}\\)의 기울기의 곱이 -1이면, 즉 \\(m_{1} \\cdot m_{2} = - 1\\)이면 두 직선은 서로 수직하다고 한다. 이는 두 직선이 교차할 때 \\(90^{\\circ}\\)의 각을 이루는 경우이다.\n\n\n3. 직선 방정식 linear equation\n직선 방정식은 직선 위의 모든 점의 좌표를 만족하며, 직선 이외의 점의 좌표에서는 만족하지 않는 방정식이다. 좌표평면에서 직선은 절편 intercept과 기울기 slope를 이용해 다음과 같은 일반적인 형태로 표현된다. \\(y = bx + a\\)\n\n\\(b\\): 직선의 기울기, \\(a\\): y-축과 교차하는 절편\n\n\n\n직선 구성요소\n기울기 \\(b\\)는 직선이 얼마나 가파르게 증가하거나 감소하는지를 나타내며, x-좌표의 변화량에 대한 y-좌표의 변화량의 비율로 정의된다:\n\\[b = \\frac{\\Delta y}{\\Delta x}\\]\n    - b &gt; 0: 직선이 오른쪽으로 올라간다.\n    - b &lt; 0: 직선이 오른쪽으로 내려간다.\n    - b = 0: 직선이 수평이다.\n절편 a는 직선이 y-축과 만나는 점의 y-좌표를 나타낸다. x = 0일 때, 직선 방정식에서 y = a가 된다.\n\n\n수평선 horizontal line\n기울기 b = 0인 경우, 직선은 수평선이 된다. 이러한 직선의 방정식은 \\(y = a\\)이다. 이 직선은 x-축과 평행하며, y-축 상에서 y = a를 지난다.\n\n\n수직선 vertical line\ny-축과 평행한 직선의 방정식으로 \\(x = c\\)이다. 이 직선은 x-축과 x = c에서 교차한다. 기울기가 정의되지 않으며, 수직선은 y-축과 항상 평행하다.\n\n\n\n\n\nchapter 3. 함수란?\n\n 1. 함수 정의\n함수는 두 집합 사이의 특정 규칙에 따라 값을 대응시키는 관계를 나타낸다. 함수는 정의역과 치역으로 구성되며, 정의역의 각 원소에 대해 치역의 단 하나의 원소만 대응된다. 이를 통해 y가 x에 의해 결정된다고 표현하며, 수학적으로 다음과 같이 나타낸다. \\(y = f(x)\\)\n이는 ”y는 x의 함수이다”라고 읽는다.\n\n정의역 domain: 정의역은 함수에서 x가 가질 수 있는 값들의 집합을 말한다. 즉, 함수 f(x)가 유효하게 정의될 수 있는 모든 입력값의 집합이다.\n치역 range: 치역은 함수가 출력할 수 있는 값들의 집합이다. 정의역의 원소 x가 함수 f를 통해 출력되는 값 y = f(x)의 모임이 치역이다.\n대응 규칙: 함수는 정의역의 각 원소를 치역의 한 원소에 대응시키는 규칙을 가지고 있다. 각 정의역의 값 x는 치역에서 정확히 하나의 값 y에 대응해야 한다. (2)번은 동일 x-값에 대하여 2개 y-값이 대응되므로 함수가 아니고 다른 모든 것은 함수이다.\n\n\n\n\n\n\n\n 2. 우함수와 기함수 \n우함수 even function: 함수 \\(f(x)\\)가 다음 조건을 만족하면 우함수라 한다.\n\\[f( - x) = f(x)\\text{모든}x \\in \\text{정의역(domain)}\\]\n우함수는 y-축을 기준으로 대칭적이다. 즉, 그래프의 왼쪽 부분을 y-축을 따라 접으면 오른쪽 부분과 정확히 일치한다.\n기함수 odd function: 함수 \\(f(x)\\)가 다음 조건을 만족하면 기함수라 정의한다.\n\\[f( - x) = - f(x)\\text{모든}x \\in \\text{정의역(domain)}\\]\n기함수는 원점을 기준으로 대칭적이다. 즉, 그래프를 원점을 중심으로 180° 회전시키면 동일한 모양이 된다.\n\n\n 3. 함수 종류\n\n(1) 함성함수 Composite Function\n합성함수는 두 함수 f(x)와 g(x)가 주어졌을 때, 함수 g(x)의 출력값이 함수 f(x)의 입력값으로 사용되는 새로운 함수이다. 이를 다음과 같이 나타낸다. \\((f \\circ g)(x) = f(g(x))\\)\n    - g(x): 먼저 적용되는 함수.\n    - f(x): g(x)의 출력값을 입력값으로 사용하는 함수.\n    - \\((f \\circ g)(x)\\): f(x)와 g(x)의 합성함수.\n합성함수 \\((f \\circ g)(x)\\)의 정의역은 g(x)와 f(x)가 동시에 유효하게 정의되는 입력값으로 구성된다. 즉, x는 g(x)의 정의역에 속하고, g(x)의 출력값은 f(x)의 정의역에 속해야 한다.\n\\((f \\circ g)(x)\\)는 다음 두 단계를 거친다:\n    - 먼저 x에 대해 g(x)를 계산하고 그런 다음, f(x)에 g(x)를 대입하여 f(g(x))를 계산한다.\n\\[f(x) = 2x + 1,g(x) = x^{2}\\]\n\\[f(g(x)) = f(x^{2}) = 2x^{2} + 1\\]\n\\[g(f(x)) = g(2x + 1) = (2x + 1)^{2}\\]\n\n\n(2) 절대값 함수\n숫자 x의 절대값(absolute value)은 x의 크기(거리를 나타냄)를 의미하며, 항상 0 이상의 값을 가진다. 절대값은 다음과 같이 정의된다.\n\\[|x| = \\{\\begin{matrix}\nx, & \\text{if}x \\geq 0 \\\\\n- x, & \\text{if}x &lt; 0\n\\end{matrix}\\]\n절대값은 숫자 x와 0 사이의 거리로 해석된다. 절대값의 결과는 항상 양수이거나 0이다.\n\n\n(3) 정수함수 integer function\n정수 함수는 숫자 x를 넘지 않는 최대 정수를 반환하는 함수이다. 이를 바닥함수 floor function라고도 하며, 다음과 같이 정의된다.\n\\[\\lfloor x\\rfloor = \\text{최대 정수}n\\text{such that}n \\leq x\\]\n    - \\(\\lfloor x\\rfloor\\): x를 넘지 않는 가장 큰 정수.\n    - \\(\\lfloor x\\rfloor\\)는 항상 \\(n \\leq x &lt; n + 1\\)을 만족한다.\n\n\n\n 4. 함수의 사칙연산\n두 함수 f(x)와 g(x)가 주어졌을 때, 이들 함수에 대해 덧셈, 뺄셈, 곱셈, 나눗셈과 같은 사칙연산을 정의할 수 있다. 각 연산은 정의역에서 두 함수의 값에 기반하여 계산된다.\n함수의 덧셈/뺄셈: \\[(f \\pm g)(x) = f(x) \\pm g(x)\\]\n\n정의역: f(x)와 g(x)가 동시에 정의된 구간.\n결과: f(x)의 값과 g(x)의 값을 더한(뺀) 결과.\n\n함수의 곱셈: \\[(f \\cdot g)(x) = f(x) \\cdot g(x)\\]\n\n정의역: f(x)와 g(x)가 동시에 정의된 구간.\n결과: f(x)와 g(x)의 값을 곱한 결과.\n\n함수의 나눗셈: \\[\\left( \\frac{f}{g} \\right)(x) = \\frac{f(x)}{g(x)},g(x) \\neq 0\\]\n\n정의역: f(x)와 g(x)가 동시에 정의되고, \\(g(x) \\neq 0\\)인 구간.\n결과: f(x)의 값을 g(x)의 값으로 나눈 결과.\n\n\n\n\nchapter 4. 함수의 응용 및 극한\n\n 1. 함수의 통계 응용\n\n(1) 확률밀도함수 \\(f(x)\\)\n연속형확률변수의 분포를 나타내는 함수로, 특정 구간 내에서 값이 나타날 확률의 상대적인 가능성을 표현한다.\n    - 확률밀도함수 정의: \\(f(x) \\geq 0,\\int_{- \\infty}^{\\infty}f(x)dx = 1\\)\n    - 정규분포의 확률밀도함수: \\(f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}e^{- \\frac{(x - \\mu)^{2}}{2\\sigma^{2}}}\\)\n    - 데이터의 분포, 확률 계산 \\(P(a \\leq X \\leq b) = \\int_{a}^{b}f(x)dx\\)\n\n\n(2) 누적확률밀도함수\n확률변수가 특정 값 이하일 확률을 나타내는 함수이다.\n\n누적확률밀도함수 정의: \\(F(x) = P(X \\leq x) = \\int_{- \\infty}^{x}f(t)dt\\)\n정규분포 CDF: \\(F(x) = \\frac{1}{2}\\left\\lbrack 1 + \\text{erf}\\left( \\frac{x - \\mu}{\\sqrt{2}\\sigma} \\right) \\right\\rbrack\\)\n분위수 결정: \\(P(X \\leq x_{p}) = p\\) 만족하는 \\(X_{p}\\)를 찾음.\n\n\n\n(3) 회귀모형\n함수는 독립변수와 종속변수 간의 관계를 모델링하는 데 사용된다. 회귀모형은 함수 형태로 데이터의 추세를 설명한다.\n    - 선형회귀: \\(y = \\beta_{0} + \\beta_{1}x + \\epsilon\\)\n    - 비선형 회귀: \\(y = ae^{bx} + \\epsilon\\)\n    - 변수 간 관계 분석, 예측 모델 구축\n\n\n(4) 생존분석\n생존분석에서는 생존시간 분포를 분석하는 데 함수가 사용된다.\n\n생존survival 함수: \\(S(t) = P(T &gt; t) = 1 - F(t)\\)\n위험hazard 함수: \\(h(t) = \\frac{f(t)}{S(t)}\\)\n제품 수명 분석, 의료 데이터에서 생존 확률 평가\n\n\n\n(5) 시계열분석\n함수는 시간에 따른 데이터의 변화를 모델링하고 분석하는 데 사용된다.\n\n자기회귀 모델: \\(X_{t} = \\phi_{1}X_{t - 1} + \\phi_{2}X_{t - 2} + \\cdots + \\epsilon_{t}\\)\n주식 시장 예측, 온도 변화 모델링.\n\n\n\n(6) 함수와 몬테카를로 시뮬레이션\n함수는 확률 분포로부터 난수를 생성하여 복잡한 통계 문제를 해결하는 데 사용된다.\n\n\\(\\pi\\) 값 추정: \\(f(x) = \\sqrt{1 - x^{2}},\\text{for}x \\in \\lbrack 0,1\\rbrack\\)\n\n\n\n\n 2. 함수의 극한\n\n(1) 극한 정의\n임의의 \\(\\varepsilon &gt; 0\\)가 주어졌을 때, 모든 \\(x\\)가 특정 값 \\(a\\)에 충분히 가까워질 때 \\((0 &lt; |x - a| &lt; \\delta),f(x)\\)가 특정 값 \\(L\\)에 가까워진다면, 함수 \\(f(x)\\)의 극한은 존재하며 그 극한값은 \\(L\\)이라고 정의한다. 이를 수학적으로 표현하면 \\(\\lim_{x \\rightarrow a}f(x) = L\\) 이다.\n\n\\(\\varepsilon\\): \\(f(x)\\)와 \\(L\\)사이의 허용 오차.\n\\(\\delta\\): \\(x\\)와 \\(a\\) 사이의 거리 제한.\n\n엄밀한 정의 (\\(\\varepsilon - \\delta\\)정의)\\(\\forall\\varepsilon &gt; 0,\\exists\\delta &gt; 0\\text{such that}0 &lt; |x - a| &lt; \\delta \\Longrightarrow |f(x) - L| &lt; \\varepsilon\\)이 의미는 \\(x\\)와 \\(a\\)에 충분히 가까워지면 \\((|x - a| &lt; \\delta)\\) 함수 \\(f(x)\\)의 값이 \\(L\\)에 충분히 가까워짐 \\((|f(x) - L| &lt; \\varepsilon)\\)을 보장한다.\n\n\n(2) 함수값과 극한값\n함수값 \\(f(a)\\)는 함수가 특정 점 \\(x = a\\)에서 실제로 가지는 값이다. 반면, 극한값 \\(\\lim_{x \\rightarrow a}f(x)\\)는 \\(x\\)가 \\(a\\)에 가까워질 때 \\(f(x)\\)가 수렴하는 값을 나타낸다. 함수값과 극한값은 다를 수 있으며, 함수가 \\(x = a\\)에서 정의되지 않아도 극한값은 존재할 수 있다.\n함수값 \\(f(a) = k\\): 함수가 \\(x = a\\)에서 정의되어 있다면 \\(f(a)\\)는 \\(k\\), 특정 값을 가진다.\n극한값: 극한값은 좌극한(left-hand limit)과 우극한(right-hand limit)에 따라 달라질 수 있다:\n    - 좌극한 \\(L_{2}\\): \\(\\lim_{x \\rightarrow a^{-}}f(x) = L_{2}\\)\n    - 우극한 \\(L_{1}\\): \\(\\lim_{x \\rightarrow a^{+}}f(x) = L_{1}\\)\n    - 전체 극한은 좌극한과 우극한이 동일할 때 존재한다,\n\n\n(3) 연속함수 정의\n함수 \\(f(x)\\)가 \\(x = a\\)에서 연속하려면 다음 세 가지 조건을 모두 만족해야 한다:\n  1. \\(f(a)\\)가 정의되어 있어야 한다.\n  2. \\(\\lim_{x \\rightarrow a}f(x)\\)가 존재해야 한다.\n  3. 함수값과 극한값이 일치해야 한다. \\(\\lim_{x \\rightarrow a}f(x) = f(a)\\)\n\n\n(4) 극한 계산 규칙\n상수함수의 극한: \\(\\lim_{x \\rightarrow a}c = c\\), 상수 함수의 극한은 상수 자신이다.\n항등함수의 극한: \\[\\lim_{x \\rightarrow a}x = a\\]\n선형성: 극한 연산은 선형성을 가진다:\n\\[\\lim_{x \\rightarrow a}\\lbrack f(x) \\pm g(x)\\rbrack = \\lim_{x \\rightarrow a}f(x) \\pm \\lim_{x \\rightarrow a}g(x)\\]\n곱셈: 두 함수의 곱의 극한은 각 함수의 극한의 곱과 같다.\n\\[\\lim_{x \\rightarrow a}\\lbrack f(x) \\cdot g(x)\\rbrack = \\left( \\lim_{x \\rightarrow a}f(x) \\right) \\cdot \\left( \\lim_{x \\rightarrow a}g(x) \\right)\\]\n나눗셈: 두 함수의 나눗셈의 극한은 각 함수의 극한의 나눗셈과 같다 (분모가 0이 아닌 경우)\n\\[\\lim_{x \\rightarrow a}\\frac{f(x)}{g(x)} = \\frac{\\lim_{x \\rightarrow a}f(x)}{\\lim_{x \\rightarrow a}g(x)},\\lim_{x \\rightarrow a}g(x) \\neq 0\\]\n거듭제곱\n  \\(\\lim_{x \\rightarrow a}\\lbrack f(x)\\rbrack^{n} = \\left( \\lim_{x \\rightarrow a}f(x) \\right)^{n}\\), 여기서 \\(n\\)은 정수이다.\n루트\n  \\[\\lim_{x \\rightarrow a}\\sqrt[n]{f(x)} = \\sqrt[n]{\\lim_{x \\rightarrow a}f(x)},\\text{if}\\lim_{x \\rightarrow a}f(x) \\geq 0\\]\n합성함수의 극한 (연쇄법칙): 만약 \\(g(x)\\) 의 극한이 \\(a\\)로 접근할 때 \\(b\\)이고, \\(f(x)\\)가 \\(b\\)에서 연속이면\n\\(\\lim_{x \\rightarrow a}f(g(x)) = f\\left( \\lim_{x \\rightarrow a}g(x) \\right)\\) 이다.\nL’Hôpital’s Rule의 정의: 함수 f(x)와 g(x)가 x \\to a에서 각각 0/0 형태 또는 \\infty/\\infty 형태를 가지는 경우, 두 함수의 극한은 다음과 같이 계산할 수 있다:\n\\[\\lim_{x \\rightarrow a}\\frac{f(x)}{g(x)} = \\lim_{x \\rightarrow a}\\frac{f'(x)}{g'(x)},\\text{if}\\lim_{x \\rightarrow a}\\frac{f'(x)}{g'(x)}\\text{exists.}\\]\n\n형태: \\(\\frac{0}{0}\\) 또는 \\(\\frac{\\infty}{\\infty}\\)와 같은 불정형 형태를 가져야 한다.\n미분 가능성: \\(f(x)\\)와 \\(g(x)\\)는 \\(x \\rightarrow a\\)에서 미분 가능해야 한다.\n분모의 도함수가 0이 아님: \\(g'(x) \\neq 0\\)인 구간에서 적용 가능\n\\(\\frac{0}{0}\\) 형태: \\(\\lim_{x \\rightarrow 0}\\frac{\\sin(x)}{x} = \\lim_{x \\rightarrow 0}\\frac{\\cos(x)}{1} = \\cos(0) = 1\\)\n\\(\\frac{\\infty}{\\infty}\\) 형태: \\(\\lim_{x \\rightarrow \\infty}\\frac{x}{e^{x}} = \\lim_{x \\rightarrow \\infty}\\frac{1}{e^{x}} = 0\\)\n\n무한대 있는 극한: \\(x\\)가 무한대 \\(\\infty\\)혹은 \\(- \\infty\\)로 접근할 때 함수 \\(f(x)\\)의 극한을 구하는 규칙이다.\n\\[lim_{x \\rightarrow \\pm \\infty}\\frac{1}{x} = 0\\]\n\\(lim_{x \\rightarrow \\pm \\infty}c = c\\), \\(c\\)는 상수\n함수가 분수의 형태를 가지면 분모의 가장 큰 \\(x\\)차수로 나누고 위의 규칙을 이용하면 된다.\n특정 함수의 극한\n\n지수 함수: \\(\\lim_{x \\rightarrow \\infty}e^{- x} = 0\\)\n삼각 함수: \\(\\lim_{x \\rightarrow 0}\\frac{\\sin(x)}{x} = 1\\), \\(\\lim_{x \\rightarrow 0}\\frac{1 - \\cos(x)}{x^{2}} = \\frac{1}{2}\\)\n로그 함수: \\(\\lim_{x \\rightarrow \\infty}\\ln(x) = \\infty\\)\n\n\n\n\n 3. 수렴 convergence\n수렴의 정의: 함수 \\(f(x)\\) 또는 수열 \\(\\{ a_{n}\\}\\)가 특정 값에 수렴한다는 것은 극한값이 존재하며, 일정 값에 점점 가까워진다는 것을 의미한다.\n수열의 수렴: 수열 \\(\\{ a_{n}\\}\\)이 \\(L\\)로 수렴한다면, 임의의 \\(\\varepsilon &gt; 0\\)에 대해 \\(n \\geq N\\) 일 때 다음 조건을 만족하는 \\(N\\)이 존재한다.\n\\(|a_{n} - L| &lt; \\varepsilon\\), 여기서 \\(L\\)은 수열의 극한값이다.\n함수의 수렴: 함수 \\(f(x)\\)가 \\(L\\)로 수렴하면, \\(x \\rightarrow a\\)에서 \\(\\lim_{x \\rightarrow a}f(x) = L\\)\n수렴의 성질\n\n수열이나 함수가 수렴하면 극한값은 유일하다.\n수렴하는 함수나 수열은 경계값을 가지며, 점점 극한값에 가까워진다.\n\n극한과 수렴의 차이\n\n극한은 특정 값에 접근하는 경향을 나타내며, 함수나 수열이 특정 점에서 어떻게 동작 하는지 설명한다.\n수렴은 극한값이 존재하고 일정 값에 점점 가까워지는 성질을 나타낸다.\n\n\n\n 4. 확률수렴과 분포수렴\n\n(1) 확률수렴 (Convergence in Probability)\n확률변수의 열 \\(\\{ X_{n}\\}\\)이 확률변수 \\(X\\)에 확률수렴한다는 것은, 임의의 \\(\\varepsilon &gt; 0\\)에 대해 다음 조건을 만족하는 \\(n \\rightarrow \\infty\\)가 존재함을 의미한다. \\(\\lim_{n \\rightarrow \\infty}P(|X_{n} - X| \\geq \\varepsilon) = 0\\)\n  - 표기: \\(X_{n}\\overset{P}{\\rightarrow}X\\)\n해석: 확률적으로 \\(|X_{n} - X|\\)가 작아질 가능성이 1에 가까워짐을 나타낸다. 즉, \\(X_{n}\\)과 \\(X\\)가 점점 ”가까워진다”고 해석할 수 있다.\n성질\n\n확률수렴의 유일성: 극한값 \\(X\\)는 유일하다.\n확률수렴과 함수: \\(X_{n}\\overset{P}{\\rightarrow}X\\)이고 \\(g(x)\\)가 연속 함수라면 \\(g(X_{n})\\overset{P}{\\rightarrow}g(X)\\)\n\n통계학 응용: (추정량의 일치성) 추정량 \\({\\widehat{\\theta}}_{n}\\)이 모수 \\(\\theta\\)에 확률수렴하면 \\({\\widehat{\\theta}}_{n}\\)은 일치추정량이다. 법칙의 수렴: 큰 수의 약법칙은 확률수렴으로 표현된다:\n\\[{\\overline{X}}_{n}\\overset{P}{\\rightarrow}\\mu\\]\n\n\n(2) 분포수렴 (Convergence in Distribution)\n확률변수의 수열 \\(\\{ X_{n}\\}\\)이 확률변수 \\(X\\)에 분포수렴한다는 것은, 모든 연속점 \\(x\\)에서 누적분포함수(FDF) \\(F_{X_{n}}(x)\\)가 \\(F(x)\\)로 수렴함을 의미한다. \\(\\lim_{n \\rightarrow \\infty}F_{X_{n}}(x) = F_{X}(x),\\forall x\\) \\(F_{X}(x)\\)에서 연속함수.\n  표기: \\(X_{n}\\overset{\\mathcal{D}}{\\rightarrow}X\\)\n해석: 분포수렴은 \\(X_{n}\\)의 분포가 \\(X\\)의 분포로 점점 가까워지는 것을 의미한다. 개별적인 실현값이 아니라 분포 전체의 형태를 고려한다.\n성질\n\n연속성: 분포수렴은 누적분포함수의 연속점에서 정의된다.\n함수와 분포수렴: \\(X_{n}\\overset{\\mathcal{D}}{\\rightarrow}X\\)이고 \\(g(x)\\) 가 연속 함수라면 \\(g(X_{n})\\overset{\\mathcal{D}}{\\rightarrow}g(X)\\) 이다.\n\n응용: 중심 극한 정리: 표본 평균이 정규분포로 수렴하는 현상은 분포수렴으로 나타낸다. \\(\\sqrt{n}({\\overline{X}}_{n} - \\mu)\\overset{\\mathcal{D}}{\\rightarrow}N(0,\\sigma^{2})\\)\n\n\n(3) 확률수렴과 분포수렴의 관계\n확률수렴 → 분포수렴\n\\[X_{n}\\overset{P}{\\rightarrow}X \\Longrightarrow X_{n}\\overset{\\mathcal{D}}{\\rightarrow}X\\]\n분포수렴 ≠ 확률수렴\n  분포수렴이 확률수렴을 보장하지 않는다. 예를 들어, \\(X_{n} \\sim U( - n,n)\\)은 \\(X = 0\\)에 분포수렴하나 확률수렴하지 않는다."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "세상의 모든 통계 이야기",
    "section": "",
    "text": "🎓 Welcome to Prof. Kwon’s 통계이야기\n\n\n\n\n\n1995년부터 한남대학교에서 제공해온 통계학 강의노트를 데이터 사이언스 중심으로 새롭게 구성했습니다. since 1999.03(첫 웹이지 구축) / 2023.01 (1차 수정)\n\n| put a ding in the universe |\n\n\n\n\n👤 Who am I?\n\n\n\n성균관대학교 통계학 학사\n성균관대학교 통계학 석사\n미국 North Carolina State University 통계학 박사\n~ 1995. 전자통신연구원 선임연구원\n~ 2026. 한남대학교 통계학과 교수"
  },
  {
    "objectID": "notes/math/vector.html",
    "href": "notes/math/vector.html",
    "title": "수학의 기초 1. 함수",
    "section": "",
    "text": "chapter 1. 선형대수 개념\n\n1. 선형대수 정의\n선형대수는 벡터 공간과 그 안에 존재하는 벡터 간의 관계를 다루는 수학의 한 분야로, 벡터와 행렬을 이용한 수학적 표현과 계산을 중심으로 구성된다. 이 분야의 기본 구성 요소로는 벡터, 행렬, 스칼라가 있으며, 주요 개념에는 선형 변환, 고유값과 고유벡터, 내적과 외적, 행렬의 분해 등이 포함된다.\n통계학에서 선형대수는 데이터를 벡터와 행렬의 형태로 구조화함으로써 복잡한 수치 연산을 간결하게 수행할 수 있도록 돕는다. 특히 고차원 데이터의 계산과 변환을 수학적으로 명확하게 정의할 수 있기 때문에, 데이터 구조를 이해하고 차원을 축소하는 데 핵심적인 도구로 사용된다.\n이러한 선형대수의 기법은 통계 모델링과 머신러닝의 기초가 되며, 회귀 분석이나 주성분 분석(PCA), 군집 분석 등 다양한 통계적 방법론에서 필수적인 역할을 수행한다. 결과적으로, 선형대수는 현대 통계학에서 이론적 기반뿐 아니라 실용적 계산의 핵심 수단으로 작용한다.\n\n\n2. 선형대수와 선형변환\n선형대수는 선형적인 관계를 다루는 수학의 한 분야로, 이 이론 체계 내에서 이루어지는 연산과 변환은 모두 선형성을 만족해야 한다. 이러한 특성 때문에 일반적인 함수는 선형대수의 중심 개념으로 다루어지지 않지만, 함수의 특수한 형태인 선형 변환은 예외적으로 핵심 개념으로 간주된다. 선형 변환은 벡터 공간의 구조를 보존하면서 벡터를 다른 벡터로 사상하는 과정을 의미하며, 행렬을 이용해 구체적으로 표현될 수 있다. 따라서 선형 변환은 선형대수의 이론과 응용 모두에서 중심적인 역할을 수행한다.\n함수 \\(y = f(x)\\)\n\n함수는 두 집합 사이의 관계로, 각 입력값(정의역, domain)에 대해 정확히 하나의 출력값(공역, range)을 대응시키는 규칙이다.\n함수는 일반적으로 \\(f:D \\rightarrow R\\)와 같이 표기되며, \\(D\\)는 정의역, \\(R\\)는 공역입니다.\n특정함수에 대하여 함수값이 0인 \\(f(x) = 0\\)를 방정식이라 하고 이를 만족하는 \\(x\\)를 방정식의 해(root, solution)라고 한다.\n\n\n\n\n\n\n선형함수\n선형함수는 입력 변수와 출력 변수 사이의 관계를 직선으로 나타내는 함수로, 일반적으로 다음과 같은 형태로 표현된다: \\(f(x) = a + bx\\), \\(a:\\) 절편, \\(b:\\) 기울기\n\n가법성 additivity: \\(f(x + y) = f(x) + f(y)\\)\n동차성 homogeniety: \\(f(cx) = cf(x)\\), \\(c\\)는 상수\n\n선형변환\n선형 변환(linear transformation)은 벡터 공간에서 정의된 함수 중 하나로, 한 벡터를 동일하거나 다른 벡터 공간의 또 다른 벡터로 변환하는 함수의 특수한 형태이다. 이 변환은 선형성(linearity)이라 불리는 다음의 두 가지 성질을 만족해야 한다. \\(\\underset{¯}{u},\\underset{¯}{v}\\) 동일 차원의 벡터에 대하여 함수 \\(T\\)가 다음 조건을 만족하면 선형변환이다.\n\n덧셈에 대한 선형성: \\(T(\\underset{¯}{u} + \\underset{¯}{v}) = T(\\underset{¯}{u}) + T(\\underset{¯}{v})\\)\n스칼라 곱에 대한 선형성: \\(T(c\\underset{¯}{u}) = cT(\\underset{¯}{u})\\)\n\n\n\n\n\n\n\n\n\nchapter 2. 벡터 vector 기초\n\n1. 벡터정의\n벡터는 정렬된 유한한 수들의 목록으로, 일반적으로 정사각형 괄호 또는 곡선 괄호로 둘러싸인 수직 형태의 배열로 표현된다. 이러한 형태는 수평 배열인 행벡터(row vector)와 구별하여 열벡터(column vector)라고 부른다.\n\\(\\left( \\begin{array}{r}\n1 \\\\\n- 2 \\\\\n0\n\\end{array} \\right)\\), \\(\\left\\lbrack \\begin{array}{r}\n1 \\\\\n- 2 \\\\\n0\n\\end{array} \\right\\rbrack\\)벡터를 행으로 사용할 때는 쉼표로 구분되고 괄호로 둘러싸인 숫자로 쓴다. \\(\\left( \\begin{array}{r}\n1, - 2,0\n\\end{array} \\right)\\)\n배열의 값을 벡터의 원소 element 라 하고 원소의 개수를 벡터의 크기(차원 demension)라고 한다. 위 벡터는 크기가 3 이고 세 번째 원소는 0 이다. n 크기의 벡터는 n-벡터라고 불리고 1벡터는 숫자와 같은 것으로 간주한다. 즉, 우리는 1-벡터 [ 13 ]와 숫자 13을 구별하지 않으며 숫자는 스칼라 scalar 라 한다. 벡터의 각 원소는 스칼라이고 원소가 실수인 \\(a_{i} \\in R^{n}\\) 벡터를 실수 벡터라 한다.\n\n\n2. 벡터 기호\nn-벡터를 나타내기 위해 \\({\\underset{¯}{a}}_{n}\\)(구별이 가능한 경우 알파벳 \\(a\\)를 벡터로 표현) 기호를 사용한다. \\(a_{n}\\)벡터 의 i-번째 요소는 \\(a_{i}\\)로 표시되며, 여기서 첨자 i는 벡터의 크기인 1에서 \\(n\\)까지 정의되는 정수 인덱스이다.\n두 벡터 \\(a_{n},b_{n}\\)가 동일하다는 것은 (1)크기(차수)도 \\(n\\) 동일하고 (2) 각 대응 원소가 동일 \\(a_{i} = b_{i}\\)함을 의미한다.\n\n\n3. 특수한 벡터\n\n(1) 영벡터 zero vector\n모든 원소가 0인 벡터이며 \\(0_{n}\\)으로 표현된다. 일반적으로 모든 0 벡터는 0으로 표시되며, 숫자 0을 나타내는데 사용되는 것과 동일한 기호이다. 다른 크기의 제로 벡터를 나타내기 위해 모두 같은 기호 0을 사용하므로 기호 0은 문맥에 따라 다른 것을 의미할 수 있기 때문에 컴퓨터에서는 이를 과부하라 한다.\n\n\n(2) 단위벡터 unit vector\n(표준) 단위 벡터는 1인 하나의 원소를 제외한 모든 요소가 0과 같은 벡터이다. i-번째 단위 벡터(n 크기)는 i-번째 원소만 1을 가진 단위 벡터이며, \\(e_{i}\\)로 표현한다. 이렇게 되면 크기를 나타내는 첨자와 1인 원소 위치를 나타내는 첨자가 구별이 되지 않는 모호성을 갖는다.\n\n\n(3) 일벡터 ones vector\n모든 원소가 1인 n-벡터이며 \\(1_{n}\\)로 표현한다. 우리는 또한 벡터의 크기가 문맥에서 결정될 수 있다면 1로 쓴다.\n\n\n\n4. 벡터 개념\n\n(1) 위치 location\n2차원 공간, 즉 평면의 위치를 나타내는 데 사용될 수 있다. 3-벡터는 3차원(3-D) 공간에서 어떤 지점의 위치나 위치를 나타내는 데 사용된다. 벡터의 원소는 위치의 좌표를 제공한다.\n\n\n\n\n\n벡터는 주어진 시간에 평면이나 3차원 공간에서 움직이는 지점의 속도나 가속도를 나타내는 데 사용될 수 있다.\n\n\n\n\n\n\n\n(2) 희소성\n많은 원소가 0이면 희소하다고 한다. 그것의 희소성 패턴은 0이 아닌 항목의 인덱스 집합이다. \\(n\\)-벡터 \\(a_{n}\\)의 0이 아닌 항목의 수는 \\(nnz(a_{n})\\)로 표시한다다. 단위벡터는 0이 아닌 항목이 하나만 있기 있고 0 벡터는 0이 아닌 항목이 없기 때문에 희소한 벡터이다.\n\n\n(3) 이미지\n3차원 벡터는 빨간색, 녹색 및 파란색(R-G-B) 강도 값(0에서 1 사이)을 제공하는 항목을 통해 색상을 나타낸다. 벡터(0,0,0)는 검은색을 나타내고, 벡터(0, 1, 0)는 밝은 순수한 녹색을 나타내며, 벡터(1, 0.5, 0.5)는 분홍색을 나타낸다.\n\n\n\n\nchapter 3. 벡터 연산과 크기\n\n1. 벡터 연산\n\n(1) 벡터 합\n두 벡터를 합을 구한다는 것은 (1) 차수가 동일한 두 벡터의 (2) 동일 위치의 원소를 합하여 하나의 벡터를 계산한다는 것을 의미한다. 차도 동일하다.\n\\(\\left\\lbrack \\begin{array}{r}\n1 \\\\\n- 2 \\\\\n0\n\\end{array} \\right\\rbrack + \\left\\lbrack \\begin{array}{r}\n1 \\\\\n2 \\\\\n3\n\\end{array} \\right\\rbrack = \\left\\lbrack \\begin{array}{r}\n2 \\\\\n0 \\\\\n3\n\\end{array} \\right\\rbrack\\), \\(\\left\\lbrack \\begin{array}{r}\n1 \\\\\n- 2 \\\\\n0\n\\end{array} \\right\\rbrack - \\left\\lbrack \\begin{array}{r}\n1 \\\\\n2 \\\\\n3\n\\end{array} \\right\\rbrack = \\left\\lbrack \\begin{array}{r}\n0 \\\\\n- 4 \\\\\n- 3\n\\end{array} \\right\\rbrack\\)\n성질\n차수가 동일한 벡터 \\(a,b,c\\)에 대하여 다음이 성립한다.\n\n교환법칙 : \\(a + b = b + a\\)\n교환법칙 : \\((a + b) + c = a + (b + c)\\)\n영벡터를 더하거나 빼도 영향을 받지 않는다. \\(a \\pm 0 = a\\)\n벡터에서 자체 벡터를 빼면 영벡터가 된다. \\(a - a = 0\\)\n\n\n\n(2) 스칼라-벡터 곱\n벡터에 스칼라(즉, 숫자)를 곱하는 스칼라-벡터 곱셈은 벡터의 모든 요소에 스칼라를 곱하여 수행한다. 일반적으로 스칼라를 왼쪽, 벡터를 오른쪽에 적지만 순서를 바꾸어 사용해도 되고 계산 결과는 동일하다.\n\\(a = \\left\\lbrack \\begin{array}{r}\n1 \\\\\n- 2 \\\\\n0\n\\end{array} \\right\\rbrack\\)이면 \\(3a = a3 = \\left\\lbrack \\begin{array}{r}\n3 \\\\\n- 6 \\\\\n0\n\\end{array} \\right\\rbrack\\)\n성질\n벡터 \\(a\\), 스칼라 \\(c,k\\)에 대하여 다음이 성립한다.\n\n교환법칙 : \\(ka = ak\\)\n배분법칙 : \\((c + k)a = ca + ka\\)\n\n\n\n(3) 선형 결합 linear combination\n차수 \\(n\\)-벡터 \\(a_{1},a_{2},...,a_{m}\\), 스칼라 \\(k_{1},k_{2},...,k_{m}\\)에 대하여 다음 \\(n\\)-벡터를 벡터 \\(a_{1},a_{2},...,a_{m}\\)의 선형결합이라 하고 스칼라 \\(k_{1},k_{2},...,k_{m}\\)는 선형결합의 계수라 한다.\n\\[k_{1}a_{1} + k_{2}a_{2} + ... + k_{m}a_{m}\\]\n\n\\(k_{1} = k_{2} = ... = k_{m} = 1\\)이면, 선형결합은 벡터 합이다.\n\\(k_{1} = k_{2} = ... = k_{m} = \\frac{1}{m}\\)이면, 선형결합은 벡터 평균이다.\n\\(k_{1} + k_{2} + ... + k_{m} = 1\\)이면, 선형결합은 affine 결합이라 하고 모든 계수가 양수인 경우 선형결합을 가중평균이라 한다.\n\n\n\n(4) 내적 inner product\n두 벡터 간의 관계를 정의하고 벡터의 길이와 각도 등의 개념을 도입하는 중요한 연산이다. 차수(\\(m\\))가 동일한 두 벡터 (\\(u,v\\))의 내적 곱은 다음과 같이 정의하고 결과는 스칼라이다.\n\\[u^{T}v = \\lbrack u_{1},u_{2},...,u_{m}\\rbrack\\left\\lbrack \\begin{array}{r}\nv_{1} \\\\\nv_{2} \\\\\n... \\\\\nv_{m}\n\\end{array} \\right\\rbrack = u_{1}v_{1} + u_{2}v_{2} + ... + u_{m}v_{m} = \\overset{m}{\\sum_{i = 1}}u_{i}v_{i}\\]\n단, \\(u^{T}\\)는 \\(u\\)의 전치 transpose라 하고 열벡터를 행벡터로 변환한 것이다.\n【예제】\n\\[\\lbrack 1,3,5\\rbrack^{T}\\left\\lbrack \\begin{array}{r}\n  0 \\\\\n   - 1 \\\\\n  1\n  \\end{array} \\right\\rbrack = (1)(0) + (3)( - 1) + (5)(1) = 2\\]\n내적 성질\n\nunit 벡터 : \\(e_{i}v = v_{i}\\)\n벡터 합 : \\(1_{m}^{T}v = \\overset{m}{\\sum_{i = 1}}v_{i}\\)\n벡터 평균 : \\(avg(v) = (1/n)1_{m}^{T}v = (1/n)\\overset{m}{\\sum_{i = 1}}v_{i}\\)\n벡터 제곱합 : \\(v^{T}v = v_{1}^{2} + v_{2}^{2} + ... + v_{m}^{2} = \\overset{m}{\\sum_{i = 1}}v_{i}^{2}\\)\n\nCauchy–Schwarz inequality\n차수 동일한 두 벡터의 내적 inner product에 대하여 다음이 성립한다.\n\\[\\parallel a^{T}b \\parallel \\leq \\parallel a \\parallel \\parallel b \\parallel\\]\n\\[|\\overset{n}{\\sum_{i}}a_{i}b_{i}| \\leq (\\sum a_{i}^{2})^{\\frac{1}{2}}(\\sum b_{i}^{2})^{\\frac{1}{2}}\\]\n\n\n(5) 외적 cross product\n주로 3차원 공간에서 두 벡터로부터 새로운 벡터를 생성하는 연산입니다. 이 연산의 결과는 두 벡터에 모두 수직인 벡터이며, 크기는 두 벡터가 이루는 평행사변형의 면적에 해당합니다.\n외적 정의\n벡터 \\(\\underset{¯}{a} = (a_{1},a_{2},a_{3})\\)와 벡터 \\(\\underset{¯}{b} = (b_{1},b_{2},b_{3})\\) 의 외적 \\(\\underset{¯}{a} \\times \\underset{¯}{b}\\) 는 다음과 같이 계산한다.\n\n\\(x\\) 성분: \\(a_{2}b_{3} - a_{3}b_{2}\\)\n\\(y\\) 성분: \\(a_{3}b_{1} - a_{1}b_{3}\\)\n\\(z\\) 성분: \\(a_{1}b_{2} - a_{2}b_{1}\\)\n\n\n\n\n\n\n【예제】 벡터 \\(\\underset{¯}{a} = (2,3,4)\\)와 벡터 \\(\\underset{¯}{b} = (5,6,7)\\)의 외적은 \\(\\underset{¯}{c} = \\underset{¯}{a} \\times \\underset{¯}{b} = ( - 3,6, - 3)\\) 이다.\n외적은 벡터 \\(\\underset{¯}{a},\\underset{¯}{b}\\)와 수직(\\({\\underset{¯}{c}}^{T}\\underset{¯}{a} = 0\\), \\({\\underset{¯}{c}}^{T}\\underset{¯}{b} = 0\\))이며 외적의 크기(놈 norm)는 두 벡터가 이루는 평행사면형 면적이다.\n\n\n\n2. 선형함수\n선형함수 정의\n\\(f:R^{n} \\rightarrow R\\)는 크기 n-벡터를 실수(스칼라)로 매핑하는 함수이다. 함수 \\(f(x)\\)의 \\(x_{1},x_{2},...,x_{n}\\)은 함수 \\(f\\)의 인수 argument라 하고 결과 값 스칼라는 함수 값이다. \\(f(x) = f(x_{1},x_{2},...,x_{n})\\)\n【예제】\n\\[f:R^{4} \\rightarrow R$ : $f(x) = x_{1} - x_{2} + x_{4}^{2}\\]\n차수 n-벡터 \\(a,x\\)에 대하여 내적 함수 \\(f(x) = a^{T}x = scalar\\)는 선형함수일 때 다음이 성립한다. 단, \\(\\alpha,\\beta\\)는 스칼라, \\((x,y)\\)는 n-벡터이다. \\(f(\\alpha x + \\beta y) = \\alpha f(x) + \\beta f(y)\\)\n선형함수 조건\n다음 조건을 만족하는 \\(f:R^{n} \\rightarrow R\\) 는 선형함수이다. 단, \\(\\alpha\\)는 스칼라, \\((x,y)\\)는 n-벡터이다.\n\nHomogeniety : \\(f(\\alpha x) = \\alpha f(x)\\)\nAdditivity : \\(f(x + y) = f(x) + f(y)\\)\n\n\n(1) 절편 Affine 함수\n선형 함수에 상수 항을 추가한 형태의 함수이다. 이는 선형 변환과 평행 이동을 결합한 함수로, 다음과 같은 수식으로 표현된다.\nn-벡터, \\(x\\)에 대하여 다음 \\(f\\)는 절편 함수이다. 단, \\(a\\)는 n-벡터, \\(k\\)는 스칼라이다. \\(f(a^{T}x + k) = a^{T}f(x) + k\\)\n【예제】 \\(f(x) = 7 - 2x_{1} + 3x_{2} - x_{3}\\), \\(k = 7,a = \\left\\lbrack \\begin{array}{r}\n   - 2 \\\\\n  3 \\\\\n   - 1\n  \\end{array} \\right\\rbrack\\)\n\n\n(2) 선형함수의 내적 표현\n\\(e_{i}\\) 단위벡터, \\(x_{n}\\) 차수 n-벡터, \\(f\\) 선형함수라 하면, \\[\\begin{matrix}\nf(x) & = f(x_{1}e_{1} + x_{2}e_{2} + ... + x_{n}e_{n}) \\\\\n& = x_{1}f(e_{1}) + x_{2}f(e_{2}) + ... + x_{n}f(e_{n}) \\\\\n& = a^{T}x,wherea^{T} = \\lbrack f(e_{1}),f(e_{2}),...,f(e_{n})\\rbrack\n\\end{matrix}\\]\n\n\n(3) 사례 : sag 처짐 (단위: mm)\n하중벡터 \\(w = \\left( \\begin{array}{r}\nw_{1} \\\\\nw_{2} \\\\\nw_{3}\n\\end{array} \\right)\\)(단위:톤), 변형 compliance 민감도 벡터 \\(c = \\left( \\begin{array}{r}\nc_{1} \\\\\nc_{2} \\\\\nc_{3}\n\\end{array} \\right)\\)(단위:mm/톤)이라면 교량 처짐 sag은 \\(s = c^{T}w\\) (하중 가중합)이다.\n\n\n\n\n\n\n\n(4) 테일러 근사 Taylor proximation\n함수 \\(f:R^{n} \\rightarrow R\\)이 1차 미분이 가능하다고 하면 \\(n\\)-벡터 함수 \\(f(x)\\)의 근사값은 다음과 같이 구한다. 이를 1차 테일러 근사라 한다. 단, n-벡터 \\(z\\)는 n-벡터 \\(x\\)와 가까운 값이다.\n\\[\\widehat{f}(x) = f(z) + \\frac{\\partial f}{\\partial x_{1}}(z)(x_{1} - z_{1}) + ... + \\frac{\\partial f}{\\partial x_{n}}(z)(x_{n} - z_{n})\\]\n【예제】\n함수 \\(f:R^{2} \\rightarrow R\\)을 \\(f(x) = x_{1} + \\exp(x_{2} - x_{1})\\)라 하자. 이 함수는 선형함수는 아니다. 이를 선형함수로 근사하는 것을 테일러 근사라 한다. \\(z = (1,2)\\)라 하면,\n\\[\\triangledown f(z) = \\left\\lbrack \\begin{array}{r}\n1 - \\exp(z_{2} - z_{1}) \\\\  \n\\exp(z_{2} - z_{1})  \n\\end{array} \\right\\rbrack|_{z_{1} = 1,z_{2} = 2} = ( - 1.72,2.72)\\]\n그러므로 \\(z = (1,2)\\)에서 \\(f(x)\\)의 테일러 근사값은 다음과 같다:\n\\[\\widehat{f}(x) = 3.718 + \\left\\lbrack \\begin{array}{r}  - 1.72 \\\\  2.72 \\end{array} \\right\\rbrack^{T}(\\left\\lbrack \\begin{array}{r} x_{1} \\\\  x_{2} \\end{array} \\right\\rbrack - \\left\\lbrack \\begin{array}{r}  1 \\\\ 2  \\end{array} \\right\\rbrack)\\]\n\n\n(5) 회귀모형\n차원 2-예측(설명, 독립) 벡터 \\(x = \\left\\lbrack \\begin{array}{r}\nx_{1} \\\\\nx_{2}\n\\end{array} \\right\\rbrack\\), 회귀계수 벡터 \\(b = \\left\\lbrack \\begin{array}{r}\nb_{1} \\\\\nb_{2}\n\\end{array} \\right\\rbrack\\), 그리고 \\(a\\)을 절편 스칼라라 하면 회귀모형은 다음과 같다.\n\\(\\widehat{y} = \\left\\lbrack \\begin{array}{r}\n1 \\\\\nx\n\\end{array} \\right\\rbrack^{T}\\left\\lbrack \\begin{array}{r}\na \\\\\nb\n\\end{array} \\right\\rbrack = {\\overset{˜}{x}}^{T}\\overset{˜}{b}\\) OLS 추정치 : \\(\\widehat{\\overset{˜}{b}} = ({\\overset{˜}{x}}^{T}\\overset{˜}{x})^{- 1}{\\overset{˜}{x}}^{T}y\\)\n\n\n\n3. 벡터놈 norm\n\n(1) 정의\n벡터의 유클리디안 놈, \\(\\parallel x \\parallel\\)은 벡터의 크기에 대한 척도로 다음과 같이 구한다. 놈은 벡터의 원점에서의 거리이다.\n\\[\\parallel x \\parallel = \\sqrt{x_{1}^{2} + x_{2}^{2} + ... + x_{n}^{2}} = \\sqrt{x^{T}x}\\]\n【예제】\n\\[\\parallel \\left\\lbrack \\begin{array}{r}\n  0 \\\\\n   - 1 \\\\\n  1\n  \\end{array} \\right\\rbrack \\parallel = \\sqrt{2}$,\n  $\\parallel \\left\\lbrack \\begin{array}{r}\n   - 1 \\\\\n  2\n  \\end{array} \\right\\rbrack \\parallel = \\sqrt{5}\\]\n성질\n\n비음수 동차성: \\(\\parallel \\beta x \\parallel = |\\beta| \\parallel x \\parallel\\), where \\(\\beta\\)는 스칼라\n삼각 부등식: \\(\\parallel x + y \\parallel \\leq \\parallel x \\parallel + \\parallel y \\parallel\\)\n비음수: \\(\\parallel x \\parallel \\geq 0\\)\n\n\n\n(2) 놈의 종류\n\nL1 norm : \\(L_{1} = \\overset{n}{\\sum_{i}}|x_{i}|\\) 절대값의 합으로 맨하튼 Manhattan 놈이라고도 한다. 지도의 거리 측정에 사용된다.\nL2 norm : \\(L_{2} = (\\overset{n}{\\sum_{i}}x_{i}^{2})^{\\frac{1}{2}}\\) 제곱합의 제곱근으로 유클리디안 놈이라 한다. 통계학에서 가장 많이 사용된다. 회귀계수 추정치를 구하는 최소제곱추정치 구할 때 사용된다.\n\n\n\n\n\n\n#행렬 정의\nimport numpy as np\nA=np.array([[1,2,3], [4,5,7],[8,9,10]])\n#L1 norm Mahattan\nla.norm(A,axis=1,ord=1)\n【결과】 array([ 6., 16., 27.])\n#L2 norm Euclidean\nla.norm(A,axis=1,ord=2)\n【결과】 array([ 3.74165739, 9.48683298, 15.65247584])\n\n\n(3) 평균 제곱근 RMS root mean square value\n데이터 크기를 정량화하는데 사용되며 데이터의 평균적인 크기를 나타낸다. \\(rms(x) = \\frac{\\parallel x \\parallel}{\\sqrt{n}} = \\sqrt{\\frac{1}{n}\\sum x_{i}^{2}}\\)\n\n\n(4) 두 벡터의 합의 놈\n\\[\\parallel x + y \\parallel = \\sqrt{\\parallel x \\parallel^{2} + 2x^{T}y + \\parallel y \\parallel^{2}}\\]\n\n\n(5) Chebyshev inequality\n차수 n-벡터 \\(x\\), \\(x_{i}^{2} \\geq a^{2}\\)을 만족하는 원소 개수를 \\(k\\)라 하면, \\(\\parallel x \\parallel^{2} = x_{1}^{2} + ... + x_{2}^{2} \\geq ka^{2}\\)이다. \\(k \\leq n\\)이므로 \\(n \\leq \\frac{\\parallel x \\parallel}{a^{2}}\\)이다. 즉, 벡터의 어떠한 원소도 그 벡터의 놈보다 크지 않다.\n\\(\\frac{k}{n} \\leq (\\frac{rms(x)}{a})^{2}\\). 왼쪽 항은 벡터의 성분 중 절대값이 최소한 \\(a\\)이상인 성분의 비율을 나타낸다. 오른쪽 항은 \\(a\\)와 \\(rms(x)\\)의 비율의 제곱에 대한 역수이다. 예를 들어, 벡터의 성분 중 1/25 = 4% 이상은 RMS 값의 5배를 초과할 수 없다는 것을 의미한다.\n\n\n\n\nchapter 4. 벡터간 거리\n\n1. 유클리디안 거리\n\n(1) 정의\n차수가 동일한 두 벡터(\\(a,b\\))의 놈을 유클리디안 거리로 정의한다.\n\\[dist(a,b) = \\parallel a - b \\parallel = \\parallel b - a \\parallel\\]\n\\[||a - b|| = \\sqrt{(a_{1} - b_{1})^{2} + (a_{2} - b_{2})^{2} + ... + (a_{n} - b_{n})^{2}}\\]\n두 벡터의 Root Mean Square 편차 = \\(\\frac{\\parallel x - y \\parallel}{\\sqrt{n}}\\)\n【예제】\n\\[a = \\left\\lbrack \\begin{array}{r} 0 \\\\ - 1 \\\\ 1 \\end{array} \\right\\rbrack,b = \\left\\lbrack \\begin{array}{r} 1 \\\\ - 2 \\\\ 1  \\end{array} \\right\\rbrack,c = \\left\\lbrack \\begin{array}{r} 1 \\\\ 0 \\\\3 \\end{array} \\right\\rbrack\\] \\[dist(a,b) = \\sqrt{2},dist(b,c) = 2.8284\\]\n#행렬 정의\nimport numpy as np\na=np.array([[0],[-1],[1]])\nb=np.array([[1],[-2],[1]])\nc=np.array([[1],[0],[3]])\n#거리 계산\nnp.linalg.norm(a-b),np.linalg.norm(b-c)\n【결과】 (np.float64(1.4142135623730951), np.float64(2.8284271247461903))\n\n\n(2) 활용\n\nfeature distance: \\(\\parallel x - y \\parallel\\) 차수가 동일한 두 벡터의 거리를 개체의 유사성 척도로 사용한다.\nNearest neighbor: \\(\\parallel x - z_{i} \\parallel\\) 두 개체 간의 거리를 이용하여 유사한 개체를 군집으로 묶는다. k-means 알고리즘\nRMS prediction error: \\(rms(y - \\widehat{y})\\) 관측치와 예측치의 거리를 예측의 정확도 척도로 사용한다.\n\n#감성 분석\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n# 데이터 준비\ntexts = [\"I love this product\", \"This is terrible\", \"Absolutely fantastic\", \"Not good at all\"]\nlabels = [1, 0, 1, 0]  # 1: 긍정, 0: 부정\n# TF-IDF 벡터화\nvectorizer = TfidfVectorizer()\nX = vectorizer.fit_transform(texts)\n# KNN 모델\nknn = KNeighborsClassifier(n_neighbors=1, metric='euclidean')\nknn.fit(X, labels)\n# 새로운 리뷰 분류\nnew_text = [\"I hate this product\"]\nnew_vector = vectorizer.transform(new_text)\nprediction = knn.predict(new_vector)\nprint(f\"Prediction: {'Positive' if prediction[0] == 1 else 'Negative'}\")\n【결과】 Prediction: Positive\n\n\n(3) 삼각 부등식\n차수가 동일한 n벡터 \\(a,b,c\\)에 대하여 다음이 발생한다.\n\\[\\parallel a - c \\parallel \\leq \\parallel a - b \\parallel + \\parallel b - c \\parallel\\]\n\n\n(4) triangle 부등식\n\\[\\parallel a + b \\parallel^{2} \\leq ( \\parallel a \\parallel + \\parallel b \\parallel )^{2}\\]\n\n\n(5) 맨해튼 거리\n\\[d(\\mathbf{a},\\mathbf{b}) = \\overset{n}{\\sum_{i = 1}}|a_{i} - b_{i}|\\]\n맨해튼 거리는 벡터 간의 축을 따라 이동한 거리의 합으로 이는 그리드 기반 공간에서 이동하는 경우에 적합하다. 맨해튼 거리라는 이름은 도로망이 격자 형태로 이루어진 맨해튼 도시 구조에서 유래되었다. 자동차나 사람이 이동할 때 대각선으로 이동하지 못하고 도로를 따라 움직이는 경우에 적합하다. 예: 두 위치 간 최단 이동 거리 계산.\n\n\n\n\n\n\n\n\n2. 유클리디안 거리와 통계\n\n(1) de-meanded 벡터\n【reall】 치수 n-벡터 \\(x_{n}\\), 평균은 \\(avg(x) = (1_{n}^{T}x)/n = (instat) = \\overline{x}\\)\n【정의】 \\(\\overset{˜}{x} = x - avg(x)1_{n}\\) : 벡터의 각 원소를 평균을 뺀 벡터\n【성질】 \\(avg(\\overset{˜}{x}) = 0\\)\n\n통계 분석: 데이터의 평균을 제거함으로써 분산이나 공분산과 같은 통계적 특성을 더 명확하게 분석할 수 있다.\n주성분 분석(PCA): 데이터의 분산을 분석하기 전에 데이터를 중심에 맞추기 위해 사용된다.\n회귀 분석: 회귀 분석에서 독립 변수와 종속 변수의 평균을 제거하여 상수항 없이 회귀 모델을 구축할 수 있다.\n\n\n\n(2) 표준편차 standard deviation\n\\[std(x) = \\sqrt{\\frac{(x_{1} - avg(x))^{2} + (x_{2} - avg(x))^{2} + ... + (x_{n} - avg(x))^{2})}{n}}\\]\n\\[std(x) = \\frac{\\parallel x - (1^{T}x/n)1 \\parallel}{\\sqrt{n}}\\]\n【응용】 투자에서 평균은 일정기간 평균 수익율, 표준편차는 위험 척도이다.\n표준편차 성질\n상수를 더해도 표준편차는 동일하다. \\(std(x + a1) = std(x)\\)\n스칼라(상수) 곱 : \\(std(kx) = |k|std(x)\\)\n평균, RMS, STD 관계\n\\(std(x)^{2} = rms(x)^{2} - avg(x)^{2}\\)\n(in stat) \\(std(x)^{2} = var(x)\\) 분산\n표준편차와 Chebychev 부등식\n만약 차원 \\(n\\)-벡터에서 \\(|x_{i} - avg(x)| \\geq a\\)을 만족하는 원소 개수를 \\(k\\)라 하면 \\(\\frac{k}{n} \\leq (\\frac{std(x)}{a})^{2}\\)이다. 벡터 \\(x\\) 평균으로부터 \\(k\\) 표준편차 이내에 있는 성분 비율은 최소 \\(1 - 1/k^{2}\\)이다.\n\\[P(|X - \\mu| &gt; k\\sigma) \\leq 1 - \\frac{1}{k^{2}}\\]\n예를 들어, 일정 기간 투자 평균 수익률은 8%이고, 리스크(표준편차)는 3%입니다. 체비셰프의 부등식에 따르면, 손실을 기록한 기간의 비율(즉, 0% 이하인 기간, 16% 이상인 기간)은 최대 (3/8)^2 = 14.1%이다.\n\n\n(3) 실증적 규칙\n\\[P(|X - \\mu| \\leq k\\sigma)\\]\n\n\\(k = 1\\), 데이터의 68.3%가 \\((\\mu - \\sigma,\\mu + \\sigma)\\) 내에 있음\n\\(k = 2\\), 데이터의 95.4%, \\(k = 3\\), 데이터의 99.9%\n\n\n\n\n\n\n\n\n특징\n실증적 규칙\n체비세프 규칙\n\n\n\n\n분포가정\n정규분포에만 적용 가능\n모든 분포에 적용 가능\n\n\n그래프 모양\n종형 곡선(정규분포)\n다양한 분포(정규분포, 비대칭, 멀티모달 등)\n\n\n데이터 범위\n평균과 표준편차로 대칭적인 확률 분포\n최소한의 비율을 보장하며 보수적(더 큰 범위를 포함)\n\n\n데이터 비율\n±1σ: 68%, ±2σ: 95%, ±3σ: 99.7%\n±2σ: ≥75%, ±3σ: ≥88.9%\n\n\n\n\n\n\n\n3. 거리와 개체 군집화\n\n(1) 개념\n\\(N\\)개의 차수 \\(n\\)-벡터 \\((x_{1},x_{2},...,x_{N})\\)에 대하여 각 벡터(개체) 쌍 사이의 거리로 측정하여 서로 가까운 클러스터 또는 클러스터로 묶는 작업을 다룬다. 클러스터링의 목표는 가능한 경우 벡터들을 \\(k\\)개의 클러스터 또는 클러스터로 묶거나 나누어, 각 클러스터 내의 벡터들이 서로 가깝도록 하는 것이다. 클러스터링은 벡터들이 객체의 특징을 나타낼 때 널리 사용된다. 다음은 \\(n = 2\\)(군집변수 2개), \\(k = 3\\)으로 클러스터링 한 사례이다.\n\n\n\n\n\n\n\n(2) 클러스터 할당\n\\(N\\)개 개체, \\(x_{i}\\)를 개체(\\(i = 1,2,...,N\\)), \\(c_{i}\\)는 \\(i\\)-개체가 할당된 클러스터이고 (\\(j = 1,2,...k\\)), \\(G_{j}\\)을 \\(j\\)-클러스터에 속한 개체의 집합이라 하자.\n\\[G_{j} = \\{ i|c_{i} = j\\}\\]\n클러스터을 대표하는 차원 \\(n\\)-벡터를 \\(z_{1},z_{2},...,z_{k}\\)라 하자. \\(i\\)-개체가 \\(j = c_{i}\\)에 있다면 \\(\\parallel x_{i} - z_{c_{i}} \\parallel\\)은 모든 클러스터 중 가장 가까워야 한다.\n\n\n(3) 클러스터 목적\n\\(J^{clust} = ( \\parallel x_{1} - z_{c_{1}} \\parallel + \\parallel x_{2} - z_{c_{2}} \\parallel + ... + \\parallel x_{N} - z_{c_{N}} \\parallel )/N\\) 함수를 최소화 하는 \\(z_{c_{1}},z_{c_{2}},...,z_{c_{N}}\\)을 구한다.\n\n\n(4) 최적 클러스링\n목적함수 \\(J^{clust}\\)을 최소화 하는 \\(z_{c_{1}},z_{c_{2}},...,z_{c_{N}}\\)을 찾는 것은 개체 수가 많고 차원 개수가 커지면 계산 회수가 기하 급수적으로 늘어나 불가능하다. 그러므로 최적 대신 차선 sub-optimal 방법으로 대표 벡터를 고정화 하는 k-평균 방법을 사용한다.\n\n\n\n\n\n\n\n\n4. k-means 알고리즘\n\n(1) 개념\n클러스터 할당과 클러스터 대표자를 선택하여 \\(J^{clust}\\)를 최소화하는 문제를 해결할 수 있을 것처럼 보이나 두 가지 선택은 순환적입니다. 즉, 각각의 선택이 다른 하나에 의존한다. 클러스터 대표자를 선택하고 클러스터 할당을 선택하는 것을 반복하는 것이 벡터 집합을 클러스터링하는 데 있어서 유명한 k-means 알고리즘이다. k-means 알고리즘은 1957년에 Stuart Lloyd와 독립적으로 Hugo Steinhaus에 의해 처음 제안되어 때때로 Lloyd 알고리즘이라고도 불린다. k-means라는 이름은 1960년대부터 사용되었다.\n\n\n(2) k-평균 알고리즘\n\\(N\\)개 개체를 \\(k\\)개 클러스터으로 분류한다고 가정하자. \\(z_{1},z_{2},...,z_{k}\\)을 각 클러스터의 대표 벡터라 하자. k-평균 알고리즘은 다음 작업을 반복 실행한다.\n\n대표 벡터를 결정하고 각 개체를 가장 가까운 대표 벡터의 클러스터으로 분류한다.\n클러스터에 할당된 개체의 중심점(평균 벡터)을 대표 벡터로 설정한다.\n수렴 조건 만족 때까지 위의 작업을 반복한다.\n\n\n\n(3) 이슈사항\n타이 브레이커: 두 개 이상의 클러스터과 최소 거리인 개체는 클러스터 할당을 하지 않는다. 그러므로 이 개체는 다음 단계에서 대표 벡터 결정에는 활용되지 않는다.\n수렴 조건: 개체의 클러스터 이동이 더 이상 발생하지 않으면 대표 벡터는 움직이지 않음을 의미하므로 클러스터링 결과는 동일해진다.\nk-평균 알고리즘은 직관적이다.: 목표함수 \\(J^{clust}\\)을 최적화 하지 못하지만 반복을 통하여 줄여 나가게 된다.\n대표벡터 해석: 각 \\(N\\) 개의 회사마다 총 자본화, 분기별 수익 및 위험, 거래량, 손익, 배당금 등과 같은 금융 및 사업 속성을 구성 요소로 하는 n-벡터을 이용하여 k-평균 클러스터링 결과 얻은 대표벡터를 이용하여 클러스터(군집)에 이름을 부여한다. 기업연수, 기업종류, 매출액 등 군집변수로 사용하지 않은 특성 벡터를 이용하여 개체 군의 이름을 부여하고 해석한다.\n클러스터 \\(k\\) 결정: \\(k\\) 의 결정은 다소 주관적이고 시행착오 방법을 사용한다. \\((k,J^{clust})\\)을 이용하여 Elbow Method 팔꿈치 기법을 사용한다. 군집 개수가 증가할수록 \\(J^{clust}\\)는 감소하게 되지만, 이 감소율이 꺾이는 지점을 찾아내는 방법이다.\n고정 대표 벡터 분할하기: 만약 \\(j\\) 클러스터을 대표하는 벡터 \\(z_{1},z_{2},...,z_{j}\\)르 고정하면 모든 개체 \\(x_{1},x_{2},...,x_{N}\\)을 최적 클러스터으로 분류 문제는 다음과 같다.\n\\[\\parallel x_{i} - z_{c_{i}} \\parallel = min_{j = 1,2,...,k} \\parallel x_{i} - z_{j} \\parallel\\]\n고정 대표 벡터를 활용하면 최적 클러스터링 문제는 다음과 같이 sub 최적 문제로 변환된다. 각 \\(N\\)개 개체에 최적 \\(j\\)-클러스터(거리가 가장 가까운 클러스터)을 결정하는 개별적 문제와 동일하다.\n\\[J^{clust} = min_{j = 1,2,...,k} \\parallel x_{1} - z_{j} \\parallel + ... + min_{j = 1,2,...,k} \\parallel x_{N} - z_{j} \\parallel )/N\\]\n고정 벡터를 group(or cluster) centroid라 한다.\n\n\n(4) 사례\n# 60000(train 훈련)/10000(test 테스트), 28x28\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.datasets import mnist\n# MNIST 데이터셋 로드 및 훈련데이터, 테스트데이터 분할 \n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n# 데이터 형태 출력\nprint(f\"x_train shape: {x_train.shape}\")\nprint(f\"y_train shape: {y_train.shape}\")\nprint(f\"x_test shape: {x_test.shape}\")\nprint(f\"y_test shape: {y_test.shape}\")\n# 첫 10개 샘플 이미지와 레이블 시각화\nnum_samples = 10\nplt.figure(figsize=(10, 1))\nfor i in range(num_samples):\n    plt.subplot(1, num_samples, i+1)\n    plt.imshow(x_train[i], cmap='gray')\n    plt.title(y_train[i])\n    plt.axis('off')\nplt.show()\n\n\n\n\n\n# 훈련 데이터 클러스트링, 첫 20개 군집결과\n# 이미지 데이터를 2차원 배열로 변환\nx_train2 = x_train.reshape((x_train.shape[0], -1))\nx_test2 = x_test.reshape((x_test.shape[0], -1))\n# 데이터 정규화\nx_train2 = x_train2 / 255.0\nx_test2 = x_test2 / 255.0\n# k-means 모델 생성 및 학습\nkmeans = KMeans(n_clusters=10, random_state=42)\nkmeans.fit(x_train2)\n# 클러스터 할당 결과\ny_kmeans = kmeans.predict(x_train2)\n# 첫 20개 분류결과 이미지와 레이블 시각화\nnum_samples = 20\nplt.figure(figsize=(10, 1))\nfor i in range(num_samples):\n    plt.subplot(1, num_samples, i+1)\n    plt.imshow(x_train[i], cmap='gray')\n    plt.title(y_kmeans[i])\n    plt.axis('off')\nplt.show()\n 10개 클러스터명은 임의로 정해져 숫자와 매칭이 되지 않는다. 클러스터에 속한 이미지를 이용하여 결정한다. 클러스터9, 클러스터1에는 이미지 6/2이 두개이므로 숫자6,숫자2 클러스터으로 하면 된다. 클러스터3에는 2개 이지지 중 숫자5, 3, 8이 각각 1개이므로 나머지 클러스터3으로 분류된 이미지 번호 확인하여 숫자번호를 결정한다. 클러스터5에는 이미지9 2개, 이미지7, 이미지4 각각 1개이므로 클러스터5는 이미지9 군집으로 한다.\n# 클러스터 대표 이미지\n# 클러스터 3 평균벡터 출력\nplt.figure(figsize=(10, 1))\nplt.imshow((x_train[0]+x_train[7]+x_train[17])/3, cmap='gray')\nplt.title('cluster 3')\nplt.axis('off')\nplt.show()\n\n\n\n\n\n\n\n\n5. 벡터의 각도\n\n(1) 코사인 유사도\n벡터의 코사인 유사도(Cosine Similarity)는 두 벡터 간의 방향적 유사성을 측정하는 지표로, 벡터 간의 각도 \\(\\theta\\)의 코사인 값을 이용하여 계산된다.\n\\[\\text{Cosine Similarity} = cos(\\theta) = \\frac{\\mathbf{A} \\cdot \\mathbf{B}}{\\parallel \\mathbf{A} \\parallel \\parallel \\mathbf{B} \\parallel}\\]\n코사인 유사도와 유클리드 거리의 차이는 다음과 같다.\n\n코사인 유사도는 두 벡터의 방향에 집중하며, 벡터 크기의 차이를 무시한다.\n유클리드 거리는 두 벡터 사이의 실제 거리(크기 차이 포함)를 측정한다.\n예를 들어, 텍스트 데이터에서 코사인 유사도는 문서 간의 내용적 유사성을 비교하는 데 유리하며, 추천 시스템, 정보 검색, 클러스터링 등에서 널리 사용된다.\n\n【예제】\n\n\n\n\n\n\n\n(2) 코사인 유사도의 특징\n코사인 유사도 값의 범위는 [-1, 1]이고 다음의 특징을 갖는다.\n\\(cos(\\theta) = 1\\): 두 벡터가 완전히 같은 방향\n\\(cos(\\theta) = 0\\): 두 벡터가 직교(Orthogonal, 90도)\n\\(cos(\\theta) = - 1\\): 두 벡터가 완전히 반대 방향.\n코사인 유사도는 벡터의 크기가 아닌 방향만 고려되므로 벡터를 정규화하지 않고도 비교할 수 있다. 고차원 벡터에도 적용 가능하여 텍스트 데이터, 사용자 선호도 등 고차원 데이터에서 벡터 간 유사성 측정에 많이 사용된다.\n각도 종류\n\n각도가 \\(\\theta = 90^{o} = \\pi/2\\)이면 두 벡터는 직교 orthogonal 한다.\n각도가 \\(\\theta = 0^{o}\\)이면 두 벡터는 정렬 aligned 되어 있다.\n각도가 \\(\\theta = 180^{o} = \\pi\\)이면 두 벡터는 역정렬 anti-aligned 되어 있다.\n각도가 \\(\\theta &gt; 90^{o} = \\pi/2\\)이면 두 벡터의 각은 둔각 obtuse, \\(\\theta &lt; 90^{o} = \\pi/2\\)이면 두 벡터의 각은 예각 acute 이다.\n\n\n\n\n\n\n두 벡터 합의 놈과 각도\n\\[\\parallel x + y \\parallel^{2} = \\parallel x \\parallel^{2} + 2 \\parallel x \\parallel \\parallel y \\parallel \\cos(\\theta) + \\parallel y \\parallel^{2}\\]\n만약 \\(\\theta = 90^{o} = \\pi/2\\)이면 \\(\\parallel x + y \\parallel^{2} = \\parallel x \\parallel^{2} + \\parallel y \\parallel^{2}\\) (피타고라스 정리)\n\n\n\n6. 상관계수\n\n(1) 상관계수 정의\n만약 \\(\\overset{˜}{a} = a - avg(a)1,\\overset{˜}{b} = b - avg(b)1\\)이면, 상관계수(correlation coefficient) \\(\\rho\\)는 다음과 같이 정의된다.\n\\(\\rho = \\frac{{\\overset{˜}{a}}^{T}\\overset{˜}{b}}{\\parallel \\overset{˜}{a} \\parallel \\parallel \\overset{˜}{b} \\parallel}\\) ⇔ \\(\\rho = (\\frac{\\overset{˜}{a}}{std(a)})^{T}(\\frac{\\overset{˜}{b}}{std(b)})/n\\)\n\n\\(cov(a,b) = {\\overset{˜}{a}}^{T}\\overset{˜}{b}/n\\): 두 벡터의 공분산\n\\(var(a) = std(a)^{2}\\): 벡터의 분산\n상관계수와 공분산 관계: \\(cov(a,b) = \\rho std(a)std(b)\\)\n\\(\\rho = \\pm 1\\) (완전 상관) : 두 벡터가 (역)정렬되어 있음\n\\(\\rho = 0\\) (독립) : 두 벡터가 직교되어 있음. \\(cov(a,b) = 0\\)\n\n\n\n(2) 두 벡터 합의 분산\n\\[var(a + b) = var(a) + 2cov(a,b) + var(b)\\]\n\\[var(a + b) = var(a) + 2\\rho std(a)std(b) + var(b)\\]\n\n만약 \\(\\rho = 0\\)이면, \\(var(a + b) = var(a) + var(b)\\)\n만약 \\(\\rho = 1\\)이면, \\(var(a + b) = (std(a) + std(b))^{2}\\)\n만약 \\(\\rho = - 1\\)이면, \\(var(a + b) = (std(a) - std(b))^{2}\\)\n\n\n\n(3) 헤징 hedging 투자\n두 개 회사 주가 벡터 \\((a,b)\\)의 평균은\\(\\mu\\), 표준편차(위험) \\(\\sigma\\)이고 상관계수는 \\(\\rho\\)이다. 각각 50% 투자, \\(c = \\frac{(a + b)}{2}\\)의 평균 수익율과 표준편차은 다음과 같다.\n\n평균 : \\(avg(\\frac{a + b}{2}) = \\mu\\)\n표준편차 : \\(std(c) = \\sigma\\sqrt{(1 + \\rho)/2}\\)\n상관계수 \\(\\rho = 0\\)이면 (독립) 표준편차는 \\(\\frac{1}{\\sqrt{2}}\\)만큼 줄어든다.\n완벽한 상관관계가 있는 경우에만 표준편차는 동일하다.\n\n\n\n\n\nchapter 5. 선형독립\n\n1. 선형독립 정의\n\n(1) 선형 종속 linear dependence\n\\(k \\geq 2\\)개의 크기 n-벡터 \\(x_{1},x_{2},...,x_{k}\\)가 다음을 만족하면 선형종속이라 한다. 만약 \\(a_{1}x_{1} + a_{2}x_{2} + ... + a_{k}x_{k} = 0\\)을 만족하는 \\(a_{i}\\)가 적어도 하나는 0이 아니다.\n선형독립이면 적어도 하나의 \\(a_{i}\\)는 0이 아니므로 벡터 \\(x_{i}\\) 다음과 같이 다른 벡터의 선형함수로 표현될 수 있다.\n\\[x_{k} = \\frac{- a_{1}}{a_{i}}x_{1} + ... + \\frac{- a_{i - 1}}{a_{i}}x_{i - 1} + \\frac{- a_{i + 1}}{a_{i}}x_{i + 1} + ... + \\frac{- a_{k}}{a_{i}}x_{k}\\]\n【예제】\n\n\\(x_{1} = \\left\\lbrack \\begin{array}{r} &gt; 0 \\\\ &gt;  - 1 \\\\  &gt; 1 &gt; \\end{array} \\right\\rbrack,x_{2} = \\left\\lbrack \\begin{array}{r} &gt; 1 \\\\ &gt;  - 2 \\\\ &gt; 1  &gt; \\end{array} \\right\\rbrack,x_{3} = \\left\\lbrack \\begin{array}{r} &gt; 1 \\\\ &gt; 0 \\\\ &gt;  - 1  &gt; \\end{array} \\right\\rbrack\\) ⬄\\(- 2x_{1} + x_{2} - x_{3} = 0\\)\n\n\n\n(2) 선형 독립 linear independence\n만약 \\(a_{1}x_{1} + a_{2}x_{2} + ... + a_{k}x_{k} = 0\\)이 모든 \\(a_{k} = 0\\)일 때만 만족한다면, n-벡터 \\(x_{1},x_{2},...,x_{k}\\)을 선형독립이라 한다.\n【예제】\n\n\n\n\n\n\n\n\\[x_{1} = \\left\\lbrack \\begin{array}{r}\n1 \\\\\n0 \\\\\n0\n\\end{array} \\right\\rbrack,x_{2} = \\left\\lbrack \\begin{array}{r}\n0 \\\\\n- 1 \\\\\n1\n\\end{array} \\right\\rbrack,x_{3} = \\left\\lbrack \\begin{array}{r}\n- 1 \\\\\n1 \\\\\n1\n\\end{array} \\right\\rbrack\\]\n\n\n\n\n\n\n\n\n(3) 선형독립 벡터의 선형결합\n선형독립인 \\(x_{1},x_{2},...,x_{k}\\)의 선형결합의 모든 계수(\\(a_{k}\\))는 유일하다. 선형결합 \\(x = a_{1}x_{1} + a_{2}x_{2} + ... + a_{k}x_{k}\\)\n【증명】 다른 계수를 \\(b_{k}\\)라 하자. \\(x = b_{1}x_{1} + b_{2}x_{2} + ... + b_{k}x_{k}\\) \\(0 = (a_{1} - b_{1})x_{1} + (a_{2} - b_{2})x_{2} + ... + (a_{k} - b_{k})x_{k}\\)이다. \\(x_{1},x_{2},...,x_{k}\\)가 선형독립이므로 모든 \\((a_{i} - b_{i}) = 0\\) 만족한다.\n\n\n\n2. 기저\n\n(1) 기저 개념\n벡터 공간은 다양한 차원의 벡터로 이루어진 공간이며, 그 공간 안의 벡터들을 다른 벡터들의 선형 조합으로 표현할 수 있다. 이때, 특정 벡터 공간의 기저 basis 는 그 공간 안의 모든 벡터들을 생성할 수 있는 최소한의 독립적인 벡터들의 집합이다.\n예를 들어, 2차원 공간에서의 기저는 일반적으로 (1,0)과 (0,1)이다. 이 두 벡터는 선형 독립이며, 이들의 모든 선형 조합으로 2차원 평면 상의 어떤 점이든 표현할 수 있다. 따라서 (1,0)과 (0,1)은 2차원 공간의 기저입니다. 단, 벡터 공간의 기저는 유일하지 않다.\n\n\n\n\n\n크기 2인 벡터의 기저 벡터는 \\(k = 2\\)개이다. 위의 그림에서 \\(a_{3}\\)벡터는 \\((a_{1},a_{2})\\)(기저 벡터)의 선형결합으로 만들 수 있다.\n\n\n(2) 기저 정의\nn개의 선형독립인 크기 n-벡터를 기저 basis 라 한다. 즉, n-벡터 \\((x_{1},x_{2},...,x_{n})\\)가 기저이면, 모든 크기 n-벡터는 \\((x_{1},x_{2},...,x_{n})\\)의 선형 결합으로 표현할 수 있다.\n【증명】 (n+1)개 차원 n-벡터 \\((x_{1},x_{2},...,x_{n},y)\\)개가 있다고 가정하자. 단,\\((x_{1},x_{2},...,x_{n})\\) 선형독립이며 기저이다. 이들 벡터는 선형독립(차원개수 n보다 벡터 개수가 (n+1)로 크다)이므로 다음을 만족하는 모든 \\(a_{i}\\)가 0은 아니다. \\(a_{1}x_{1} + a_{2}x_{2} + ... + a_{n}x_{n} + a_{n + 1}y = 0\\)\n만약 \\(a_{n + 1} = 0\\)이면, \\(a_{1}x_{1} + a_{2}x_{2} + ... + a_{n}x_{n} = 0\\)을 만족하는 모든 \\(a_{i} = 0\\)이다. 왜냐하면 \\((x_{1},x_{2},...,x_{n})\\) 선형독립이기 때문이다.(모순)\n\n\n\n3. 직교정규\n\n(1) 정의\n만약 \\(\\parallel x_{i} \\parallel = 1\\)이고 \\(x_{i}^{T}x_{j} = 0fori \\neq j\\) (두 벡터 \\((x_{i},x_{j})\\)는 직교)이면, \\((x_{1},x_{2},...,x_{k})\\) 벡터 집합은 직교 정규 orthonormal 벡터라고 한다.\n직교정규성은 선형종속, 선형독립처럼 집합의 속성이지 개별 벡터의 속성은 아니다.\n\n\n(2) 예제\n\nn개의 단위벡터는 직교정규 벡터이다.\n직교정규벡터 \\(\\left\\lbrack \\begin{array}{r}\n   - 1 \\\\0 \\\\ 0\n  \\end{array} \\right\\rbrack,\\frac{1}{\\sqrt{2}}\\left\\lbrack \\begin{array}{r}\n  0 \\\\ 1 \\\\ 1\n  \\end{array} \\right\\rbrack,\\frac{1}{\\sqrt{2}}\\left\\lbrack \\begin{array}{r}\n  0 \\\\ - 1 \\\\ 1\n  \\end{array} \\right\\rbrack\\)\n직교정규 벡터는 선형독립이다.\n\n\n\n(3) 직교정규 성질\n\n벡터 \\(x\\)가 직교정규벡터 선형결합이면 \\(x = a_{1}x_{1} + a_{2}x_{2} + ... + a_{k}x_{k}\\) 내적을 이용하여 다음을 얻으므로 내적을 이용하여 계수를 얻을 수 있다.\n\\[x_{i}^{T}x = x_{i}^{T}(a_{1}x_{1} + a_{2}x_{2} + ... + a_{k}x_{k}) = a_{i}\\]\n벡터 \\((x_{1},x_{2},...,x_{k})\\)가 직교정규 (선형독립이고 기저임) 벡터이면 \\(x = (x_{1}^{T}x)x_{1} + (x_{2}^{T}x)x_{2} + ... + (x_{k}^{T}x)x_{k}\\)이 성립한다.\n\n벡터 (1, 2, 3)을 직교정규 벡터의 선형결합으로 표현하자.\n\\[\\left\\lbrack \\begin{array}{r}\n1 \\\\\n2 \\\\\n3\n\\end{array} \\right\\rbrack = 1\\left\\lbrack \\begin{array}{r}\n1 \\\\\n0 \\\\\n0\n\\end{array} \\right\\rbrack + 2\\left\\lbrack \\begin{array}{r}\n0 \\\\\n1 \\\\\n0\n\\end{array} \\right\\rbrack + 3\\left\\lbrack \\begin{array}{r}\n0 \\\\\n0 \\\\\n1\n\\end{array} \\right\\rbrack\\]\n\\(\\lbrack - 1 0 0\\rbrack\\left\\lbrack \\begin{array}{r}\n  1 \\\\\n  2 \\\\\n  3\n  \\end{array} \\right\\rbrack = - 1\\), \\(\\frac{1}{\\sqrt{2}}\\lbrack 011\\rbrack\\left\\lbrack \\begin{array}{r}\n  1 \\\\\n  2 \\\\\n  3\n  \\end{array} \\right\\rbrack = \\frac{5}{\\sqrt{2}}\\), \\(\\frac{1}{\\sqrt{2}}\\lbrack 0 - 11\\rbrack\\left\\lbrack \\begin{array}{r}\n  1 \\\\\n  2 \\\\\n  3\n  \\end{array} \\right\\rbrack = \\frac{1}{\\sqrt{2}}\\)\n\\[\\left\\lbrack \\begin{array}{r}\n1 \\\\\n2 \\\\\n3\n\\end{array} \\right\\rbrack = - 1\\left\\lbrack \\begin{array}{r}\n- 1 \\\\\n0 \\\\\n0\n\\end{array} \\right\\rbrack + \\frac{5}{2}\\left\\lbrack \\begin{array}{r}\n0 \\\\\n1 \\\\\n1\n\\end{array} \\right\\rbrack + \\frac{1}{2}\\left\\lbrack \\begin{array}{r}\n0 \\\\\n- 1 \\\\\n1\n\\end{array} \\right\\rbrack\\]\n\n\n\n4. Gram-Schmidt 알고리즘\n\n(1) 개념\nn-벡터 \\(x_{1},x_{2},...,x_{k}\\)가 선형 독립인지 여부를 결정할 수 있는 알고리즘으로 수학자 Jørgen Pedersen Gram과 Erhard Schmidt의 이름을 따서 명명되었다.\n만약 벡터들이 선형 독립이라면, Gram–Schmidt 알고리즘은 다음과 같은 속성을 가진 직교정규 벡터 \\(q_{1},q_{2},...,q_{k}\\) 을 생성한다.\n\n각 \\(i = 1,2,...,k\\)에서 \\(x_{i}\\)는 \\(q_{1},q_{2},...,q_{i}\\)의 선형결합이다.\n각 \\(i = 1,2,...,k\\)에서 \\(q_{i}\\)는 \\(x_{1},x_{2},...,x_{i}\\)의 선형결합이다.\n만약 \\(x_{1},x_{2},...,x_{i - 1}\\) 선형독립이나 \\(x_{1},x_{2},...,x_{i}\\)는 선형종속이면 멈춘다.\n\n\n\n(2) 알고리즘\n주어진 n-벡터 \\(x_{1},x_{2},...,x_{k}\\), \\(i = 1,2,...,k\\)일 때\n\n직교화 : \\({\\overset{˜}{q}}_{i} = x_{i} - (q_{1}^{T}x_{i})q_{1} - ... - (q_{i - 1}^{T}x_{i})q_{i - 1}\\)\n선형종속 검증 : 만약 \\({\\overset{˜}{q}}_{i} = 0\\)이면, 멈춘다.\n정규화 : \\(q_{i} = \\frac{{\\overset{˜}{q}}_{i}}{\\parallel q_{i} \\parallel}\\).\n\n이렇게 얻은 \\(q_{1},q_{2},...,q_{i}\\)는 직교정규 벡터이다. 알고리즘 적용 중 중간에 중단되면 기저젝터가 아니다.\n\n\n(3) Gram-Schmidt 알고리즘 예제\n\\(x_{1} = ( - 1,1, - 1,1),x_{2} = ( - 1,3, - 1,3),x_{3} = (1,3,5,7)\\) 에 대하여 Gram–Schmidt 알고리즘을 적용하자.\ni=1\n\\(\\parallel {\\overset{˜}{q}}_{1} \\parallel = 2\\)이므로 \\(q_{1} = \\frac{{\\overset{˜}{q}}_{1}}{\\parallel {\\overset{˜}{q}}_{1} \\parallel} = \\left\\lbrack \\begin{array}{r}\n- 1/2 \\\\\n1/2 \\\\\n- 1/2 \\\\\n1/2\n\\end{array} \\right\\rbrack\\)이다.\ni=2\n\\(q_{1}^{T}x_{2} = 4\\)이므로 \\({\\overset{˜}{q}}_{2} = x_{2} - (q_{1}^{T}x_{2})q_{1} = \\left\\lbrack \\begin{array}{r}\n1 \\\\\n1 \\\\\n1 \\\\\n1\n\\end{array} \\right\\rbrack\\)이고 \\(\\parallel {\\overset{˜}{q}}_{2} \\parallel = 2\\)이다. 그러므로 \\(q_{2} = \\frac{{\\overset{˜}{q}}_{2}}{\\parallel {\\overset{˜}{q}}_{2} \\parallel} = \\left\\lbrack \\begin{array}{r}\n1/2 \\\\\n1/2 \\\\\n1/2 \\\\\n1/2\n\\end{array} \\right\\rbrack\\).\ni=3\n\\(q_{1}^{T}x_{3} = 2,q_{2}^{T}x_{3} = 8\\)이므로 \\({\\overset{˜}{q}}_{3} = x_{3} - (q_{1}^{T}x_{3})q_{1} - (q_{2}^{T}x_{3})q_{2} = \\left\\lbrack \\begin{array}{r}\n- 2 \\\\\n- 2 \\\\\n2 \\\\\n2\n\\end{array} \\right\\rbrack\\)이고 \\(\\parallel {\\overset{˜}{q}}_{3} \\parallel = 4\\)이다. 그러므로 \\(q_{3} = \\frac{{\\overset{˜}{q}}_{3}}{\\parallel {\\overset{˜}{q}}_{3} \\parallel} = \\left\\lbrack \\begin{array}{r}\n- 1/2 \\\\\n- 1/2 \\\\\n1/2 \\\\\n1/2\n\\end{array} \\right\\rbrack\\).\n# Gram-Schmidt 알고리즘\nimport numpy as np\n\ndef gram_schmidt(A):\n    # Get the number of rows (n) and columns (k) in A\n    n, k = A.shape\n    # Initialize matrix Q with zeros, same shape as A\n    Q = np.zeros((n, k))\n    \n    for j in range(k):\n        # Start with the current column vector of A\n        v = A[:, j]\n        for i in range(j):\n            # Subtract the projection of v onto the ith orthonormal vector\n            v -= np.dot(Q[:, i], A[:, j]) * Q[:, i]\n        \n        # Normalize the vector\n        Q[:, j] = v / np.linalg.norm(v)\n    return Q\n# Example usage\nA = np.array([[-1,-1,1],\n              [1,3,3],\n              [-1,-1,5],\n              [1,3,7]], dtype=float)\n\ngram_schmidt(A)\n【결과】 array([[-0.5, 0.5, -0.5], [ 0.5, 0.5, -0.5], [-0.5, 0.5, 0.5], [ 0.5, 0.5, 0.5]])"
  },
  {
    "objectID": "notes/math/matrix.html",
    "href": "notes/math/matrix.html",
    "title": "수학의 기초 4. 행렬",
    "section": "",
    "text": "chapter 1. 행렬 기초\n\n1. 개념\n\n(1) 통계학과 행렬\n행렬은 통계학에서 데이터를 표현하고 분석하는 데 핵심적인 도구로 사용된다. 행렬은 대규모 데이터의 구조를 간단히 표현하고, 계산을 효율적으로 수행하여 통계학에서 중요한 역할을 한다.\n데이터 표현: 데이터를 행렬로 저장하여 표 형식으로 표현한다. 다음은 관측값(행)과 변수(열)로 구성된 데이터 행렬이다.\n\\[X = \\begin{bmatrix}\nx_{11} & x_{12} & \\cdots & x_{1p} \\\\\nx_{21} & x_{22} & \\cdots & x_{2p} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nx_{n1} & x_{n2} & \\cdots & x_{np}\n\\end{bmatrix}\\]\n연산의 간결화: 여러 변수와 관측값 간의 관계를 분석할 때 행렬식으로 간단히 표현하고 행렬 연산을 이용하여 추정값을 계산한다.\n\\(Y = X\\beta + \\epsilon\\), OLS 추정=\\(\\widehat{\\beta} = (X'X)^{- 1}X'Y\\)\n\n\n(2) 정의\n행과 열로 배열된 숫자, 기호 또는 표현식의 직사각형 배열을 행렬이라 한다. 행의 차수는 \\(m\\), 열의 차수는 \\(n\\)이다.\n\\(A_{m \\times n} = \\begin{bmatrix}\na_{11} & a_{12} & \\cdots & a_{1n} \\\\\na_{21} & a_{22} & \\cdots & a_{2n} \\\\\n\\cdots & \\cdots & \\cdots & \\cdots \\\\\na_{m1} & a_{m2} & \\cdots & a_{mn}\n\\end{bmatrix}\\) (간편식) \\(A = \\{ a_{ij}\\}\\)\n\n행렬의 각 셀을 원소 element라 한다.\n행의 차수 \\(m = 1\\)인 행렬을 열 column 벡터이다.\n열의 차수 \\(n = 1\\)인 행렬을 행 row 벡터이다.\n행의 차수, 열의 차수 모두 1인 행렬을 스칼라 scalar이다.\n행렬을 \\(n\\)-열벡터로 표현 : \\(A_{m \\times n} = \\begin{bmatrix}\n  a_{1} & a_{2} & \\cdots a_{n}\n  \\end{bmatrix}\\)\n행렬을 \\(m\\)-헹벡터로 표현 : \\(A_{m \\times n} = \\left\\lbrack \\begin{array}{r}\n  a_{1} \\\\\n  a_{2} \\\\\n  \\cdots \\\\\n  a_{m}\n  \\end{array} \\right\\rbrack\\)\n\n\n\n(3) 동일 행렬이란\n\n행의 차수와 열의 차수가 같다. \\(A_{m \\times n} = B_{m \\times n}\\)\n대응하는 모든 원소 값은 동일하다. \\(\\{ a_{ij} = b_{ij}\\} foralli,j\\)\n\n\n\n\n2. 특수한 행렬\n영행렬 zero matrix: 행렬의 모든 원소가 0인 행렬입니다. 기호 : \\(0_{m \\times n}or0\\) 숫자 0에 해당된다.\n정방행렬 square matrix: 행렬의 행차수와 열차수가 동일한 행렬이다. 기호 : \\(A_{m \\times m} = A_{m}\\)\n대각행렬 diagonal matrix: 대각원소를 제외한 모든 원소가 0인 정방행렬이다. 기호 : \\(A_{ij} = 0fori \\neq j\\), \\(diag(a_{11},a_{22},...,a_{mm})\\)\n\\[D = \\begin{pmatrix}\n- 1 & 0 \\\\\n0 & 7\n\\end{pmatrix}\\]\n대각합 trace: 대각행렬의 대각원소의 합을 대각합이라 한다. \\(tr(D) = 6\\)\n단위행렬 identity matrix: 정방행렬의 대각 원소가 모두 1이고 그외 원소는 0인 행렬로 숫자 1과 같은 역할을 한다. 기호 : \\(I_{ij} = \\{\\begin{array}{r}\n1i = j \\\\\n0i \\neq j\n\\end{array}\\) , \\(I_{m \\times m}orI_{m}\\)\n\\(A = \\begin{bmatrix}\n1 & 2 & 3 \\\\\n3 & 4 & 5\n\\end{bmatrix}\\)⇨ \\(A = \\begin{bmatrix}\n1 & 0 & 1 & 2 & 3 \\\\\n0 & 1 & 3 & 4 & 5 \\\\\n0 & 0 & 1 & 0 & 0 \\\\\n0 & 0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 0 & 1\n\\end{bmatrix} = \\begin{bmatrix}\nI & A \\\\\n0 & I\n\\end{bmatrix}\\)\n삼각행렬 triangular matrix\n\n【상삼각행렬】 대각원소 아래 원소가 모두 0인 정방행렬이다. 기호 : \\(A_{ij} = 0fori &gt; j\\)\n【하삼각행렬】 대각원소 윗 원소가 모두 0인 정방행렬이다. 기호 : \\(A_{ij} = 0fori &lt; j\\)\n\n희소행렬 Sparse matrices: 행렬 원소의 대부분이 0인 행렬을 의미하며 \\(nnz(A)\\)은 행렬 \\(A_{m \\times n}\\)에서 0인 아닌 원소의 개수를 나타내며 \\(nnz(A)/(m \\times n)\\) 을 행렬의 밀도라 정의한다.\n수학자 제임스 H. 윌킨슨(James H. Wilkinson)이 정의 : ”행렬이 충분히 많은 0 원소를 포함하고 있어 이를 활용하는 것이 유리한 경우, 그 행렬을 희소 행렬이라 한다.” 희소행렬은 컴퓨터에서 효율적으로 저장하고 조작할 수 있다.\n영행렬 &gt; 단위행렬 &gt; 대각행렬 &gt; 삼각행렬 : 대표적인 희소행렬\n\n\n3. 행렬 놈\n모든 원소의 제곱합의 양의 제곱근: \\(\\parallel A \\parallel = \\sqrt{\\overset{m}{\\sum_{i}}\\overset{n}{\\sum_{j}}a_{ij}}\\)\n행렬의 놈은 스칼라이며 행렬의 크기나 거리를 측정하며 행렬의 평균제곱근(Root Means Square)는 \\(RMS(A) = \\frac{\\parallel A \\parallel}{\\sqrt{mn}}\\)이다.\n\n\\(\\parallel A \\parallel \\geq 0\\) 행렬 놈은 0보다 크거나 같다.\n\\(\\parallel cA \\parallel = |c| \\parallel A \\parallel\\)\n\\(\\parallel A + B \\parallel \\leq \\parallel A \\parallel + \\parallel B \\parallel\\)\n\\(\\parallel A - B \\parallel\\) : 두 행렬의 유사성(거리)을 나타낸다.\n\\(\\parallel A \\parallel = \\parallel A^{T} \\parallel\\) : 원행렬 놈과 전치행렬 놈은 동일하다.\n\n\n\n4. 전치\n전치 transpose는 행과 열을 서로 바꾸는 연산: \\((A^{T})_{ij} = A_{ji}\\)\n\n\\((A^{T})^{T} = A\\) : 전치 행렬을 다시 전치하면 원래 행렬이 된다.\n\\((A + B)^{T} = A^{T} + B^{T}\\) : 행렬 합의 전치는 각 행렬의 전치 합과 같다.\n\\((cA)^{T} = cA^{T}\\) : 스칼라 곱의 전치는 스칼라 곱과 같다.\n\\((AB)^{T} = B^{T}A^{T}\\) : 행렬 곱의 전치는 각 행렬의 전치의 순서를 바꾼 곱과 같다.\n\n원행렬과 전치행렬과 동일한 행렬은 대칭행렬이다. \\(A = A^{T}\\)\n\n\n\nchapter 2. 행렬 연산\n\n1. 행렬 합 연산\n행렬의 합을 구하는 경우 두 행렬의 차수는 동일해야 하며(conformable for addition/substraction: 합 연산 적합) 각 행렬에서 대응하는 원소들의 합을 그 위치에 적으면 된다.\n\\[(A + B)_{m \\times n} = \\{ a_{ij} + b_{ij}\\}\\]\n\\[(A + B)_{m \\times n} = \\begin{bmatrix}\na_{11} + b_{11} & a_{12} + b_{12} & \\cdots & a_{1n} + b_{1n} \\\\\na_{21} + b_{21} & a_{22} + b_{22} & \\cdots & a_{2n} + b_{2n} \\\\\n\\cdots & \\cdots & \\cdots & \\cdots \\\\\na_{m1} + b_{m1} & a_{m2} + b_{m2} & \\cdots & a_{mn} + b_{mn}\n\\end{bmatrix}\\]\n\\[A = \\begin{bmatrix}\n1 & 3 & 5 \\\\\n7 & 3 & 1\n\\end{bmatrix}$, $B = \\begin{bmatrix}\n1 & 0 & 1 \\\\\n- 1 & 1 & 0\n\\end{bmatrix}$ ⇢ $A + B = \\begin{bmatrix}\n2 & 3 & 6 \\\\\n6 & 4 & 1\n\\end{bmatrix}\\]\n성질\n\n교환법칙 Commutativity : \\(A + B = B + A\\)\n결합법칙 Associativity : \\(A + (B + C) = (A + B) + C = A + B + C\\)\n영행렬과 합 : \\(A + 0 = 0 + A = A\\)\n합의 전치 : \\((A + B)^{T} = A^{T} + B^{T}\\)\n\n\n\n2. 스칼라-행렬 곱하기\n행렬 모든 원소에 스칼라 곱을 하여 결과는 원행렬과 동일한 차수의 행렬이다. (기호) \\(cA = \\{ ca_{ij}\\} = Ac\\) 다음의 성질을 갖는다.\n\n\\((cA)^{T} = cA^{T}\\)\n\\((c + d)A = cA + dA\\)\n\n\n\n3. 행렬x벡터 곱하기\n행렬 \\(A_{m \\times n}\\)와 행벡터 \\(x_{n}\\) 곱 연산은 다음과 같이 정의되며 결과는 행벡터 \\(y_{m \\times 1} = A_{m \\times n}x_{n \\times 1}\\)이며 차수는 \\(m\\)이다.\n\n\n\n\n\n연산 가능: 앞의 행렬(\\(A_{m \\times n}\\))의 열차수와 뒤의 행벡터(\\(x_{n}\\)) 행차수가 동일해야 한다.\n행 측면: 행렬 \\(A\\)의 \\(i\\)-번째 행벡터을 \\(a_{i}^{T}\\)라 하면 \\(y_{i} = a_{i}^{T}x\\)(내적)이다.\n열 측면: \\(A\\)의 \\(k\\)-번째 열벡터을 \\(a_{k}\\)라 하면 \\(y = x_{1}a_{1} + x_{2}a_{2} + + ... + x_{n}a_{n}\\).\n\n\n\n\n\n행렬 \\(A\\)의 열벡터 선형독립이다\n만약 \\(x = 0\\)인 경우에만 \\(Ax = 0\\)이 성립하면, 열벡터는 선형독립이다.\n활용\n\n행렬 \\(A\\)가 영행렬이면 \\(Ax = 0\\)는 영벡터이다.\n행렬 \\(A\\)가 단위행렬이면 \\(Ax = x\\)이다.\n행렬 \\(A\\)의 \\(j\\)-번째 열벡터는 \\(Ae_{j} = a_{j}\\)이다.\n행렬 \\(A\\)의 \\(i\\)-번째 행벡터는 \\((A^{T}e_{i})^{T}\\)이다.\n\n예제\n(예측데이터 행렬) Feature matrix \\(X_{N \\times n}\\)는 \\(N\\)개의 객체에 대한 특성 \\(n\\)-벡터, 객체들에 대한 가중치 \\(w\\)-벡터(차수 \\(N\\))라 하자. \\(X^{T}w\\)는 객체들에 대한 가중 점수 벡터이다.\n(포트폴리오 자산 수익율) 포트폴리오 자산 수익율 행렬 \\(R_{T \\times n}\\)(\\(T\\) 기간 동안 \\(n\\)개의 자산의 수익률)이라 하고 \\(w\\)을 포트폴리오 \\(n\\)-벡터라 하면 \\(Rw\\)는 \\(T\\)기간 포트폴리오 수익률이다.\n(오디오 믹싱) \\(A\\)의 \\(k\\)개 열이 길이 \\(T\\)의 오디오 신호나 트랙을 나타내는 벡터들이고, \\(w\\)가 \\(k\\)-벡터인 경우를 가정하면 \\(Aw\\)는 오디오 신호들을 믹싱한 결과를 나타내는 \\(T\\)-벡터이다.\n(문서 점수화) 검색 엔진은 검색 쿼리를 기반으로 w를 선택하여 문서의 점수를 예측한다. \\(A\\)는 \\(N \\times n\\)크기의 문서-단어 행렬로, \\(N\\)개의 문서가 \\(n\\)개의 단어 사전을 사용하여 단어의 출현 빈도, \\(w\\)는 \\(n\\)-벡터로, 단어 사전 내 단어들에 대한 가중치로 \\(Aw\\)는 \\(N\\)-벡터로, 각 문서의 점수를 나타낸다.\n\n\n4. 행렬x행렬 곱하기\n\n(1) 정의\n행렬을 곱하기 위해서는 앞 행렬의 열 차수와 뒤 행렬의 행의 차수와 일치해야 곱이 가능하다. conformable for product 결과의 차수는 앞 행렬의 행 차수, 뒤 행렬의 열 차수를 갖는다.\n\\(A_{m \\times n}B_{n \\times p} = (AB)_{m \\times p}\\)\n\\(A = \\{ a_{ij}\\}\\), \\(B = \\{ b_{ij}\\}\\) ⇢ \\(AB = \\{\\overset{n}{\\sum_{k = 1}}a_{ik}b_{kj}\\}\\)\n\n\n\n\n\n\n\n(2) 곱의 성질\n\n결합 associate 법칙: \\((AB)C = A(BC)\\)\n배분 distribution 법칙: \\(A(B + C) = AB + AC\\)\n전치 : \\((AB)^{T} = B^{T}A^{T}\\)\n\\((A + B)(C + D) = AC + AD + BC + BD\\)\n\\(y^{T}(Ax) = (y^{T}A)x = (A^{T}y)^{T}x\\)\n\n\n\n(3) 행렬의 거듭제곱\n\\[A^{2} = AA$, $A^{3} = AAA$, $A^{4} = AAAA \\cdots \\]\ndirected graph: 인접 adjacency 행렬을 다음과 같이 정의하자.\n\\[A_{ij} = \\{\\begin{array}{r}\n\\text{1 there is a edge from vertex j to vertex i} \\\\\n\\text{0 otherwise}\n\\end{array}\\]\n\n\n\n\n\n\n\n멱등행렬 idempotent\n자신의 행렬 곱이 자신이 되는 행렬을 멱등행렬이라 한다. \\(M^{2} = M^{3} = ... = M\\) 자신의 곱이 연산 가능해야 하므로 멱등행렬이려면 정방행렬이어야 한다.\n\n\n\n5. QR 분해, Q는 직교행렬, R은 상삼각행렬\n\n(1) 직교행렬 orthonormal matrix\n열벡터 \\(A_{m \\times n}\\)의 n-벡터 \\(a_{1},a_{2},...,a_{m}\\)들이 orthonomal 하면, 즉 \\(A^{T}A = I\\)을 만족하는 행렬을 직교정규행렬이라 한다.만약 \\(A_{m \\times n}\\)는 직교정규행렬, \\(x,y\\)는 n-벡터라 하고 \\(f:R^{n} \\rightarrow R^{m}\\) 함수가 \\(z\\)를 \\(Az\\)로 매핑한다고 가정하자.\n\n\\(\\parallel Ax \\parallel = \\parallel x \\parallel\\) : 함수 \\(f\\)는 놈을 보존한다.\n\\((Ax)^{T}(Ay) = x^{T}y\\) : 함수 \\(f\\)는 두 벡터의 내적을 보존한다.\n\\(\\angle(Ax,Ay) = \\angle(x,y)\\) : 함수 \\(f\\)는 두 벡터의 각도을 보존한다.\n\n【recall】 Gram-Schmidt 알고리즘\n만약 벡터들이 선형 독립이라면, Gram–Schmidt 알고리즘은 다음과 같은 속성을 가진 직교정규 벡터 \\(q_{1},q_{2},...,q_{k}\\) 을 생성한다.\n\n\n(2) QR분해 \\(A = QR\\)\n행렬 \\(A_{n \\times k}\\)의 n-벡터 \\(a_{1},a_{2},...,a_{k}\\)가 선형 독립인 행렬이다. 여기에 Gram-Schmidt 알고리즘을 적용하여 얻은 직교정규 벡터 \\(q_{1},q_{2},...,q_{k}\\)으로 직교정규 행렬 \\(Q\\)을 생성하자. \\(Q^{T}Q = I\\)이다.\n\\(a_{i}\\)와 \\(q_{i}\\)의 관계식 : \\(a_{i} = (q_{1}^{T}a_{i})q_{1} + \\cdots + (q_{i - 1}^{T}a_{i})q_{i - 1} + \\parallel {\\overset{˜}{q}}_{i} \\parallel q_{i}\\)\n이를 다시 쓰면 \\(a_{i} = R_{1i} + \\cdots + R_{ii}q_{1}\\)이다. \\(R_{ij} = q_{i}^{T}a_{j}fori &lt; j\\), \\(R_{ij} = 0fori &gt; j\\), 그리고\\(R_{ii} = \\parallel {\\overset{˜}{q}}_{i} \\parallel\\)\n그러므로 \\(A_{n \\times k}\\) (열이 독립인 행렬)은 직교정규 행렬 \\(Q_{n \\times k}\\)과 \\(R_{k \\times k}\\) 상삼각행렬로 분해된다.\n\n\n(3) QR 분해 활용\n선형 시스템의 해 구하기, 최소자승 문제, 정규방정식 문제\n선형 방정식 \\(Ax = b\\)를 푸는 데 사용될 수 있다. \\(A = QR\\)로 분해하면 \\(QRx = b\\)가 되고 \\(R_{x} = Q^{T}b\\)이므로 \\(R\\)이 상삼각 행렬이므로 후진 대입을 사용하여 해, \\(x\\)를 효율적으로 구할 수 있다.\n고유값 계산\n\\(QR\\) 알고리즘을 이용하여 특정 행렬의 고유값을 계산할 수 있다. \\(QR\\) 분해를 사용한 고유값 계산 알고리즘은 변환 행렬을 상삼각 행렬로 변환하고, 이로부터 고유값을 추출한다.\n행렬의 특성 분석\n\\(QR\\) 분해는 행렬의 특성을 분석하는 데 도움을 준다. 예를 들어, 행렬의 계수(rank)를 결정하거나, 행렬이 정칙인지 (역행렬이 존재하는지) 파악하는데 사용될 수 있다.\nimport numpy as np\n# 행렬 A 정의\nA = np.array([[1, 1], [1, -1], [1, 1]])\n# QR 분해\nQ, R = np.linalg.qr(A)\n# 결과 출력\nprint(\"Q:\")\nprint(Q)\nprint(\"\\nR:\")\nprint(R)\n【결과】 Q: [[-0.57735027 0.40824829] [-0.57735027 -0.81649658] [-0.57735027 0.40824829]]\nR: [[-1.73205081 -0.57735027] [ 0. 1.63299316]]\n\n\n\n6. 역행렬\n\n(1) 왼쪽 오른쪽 역행렬\n만약 \\(XA = I\\) 만족하는 \\(X\\)가 존재하면 A는 left-invertible 이라 한다. 동일하게 \\(AX = I\\) 만족하는 \\(X\\)가 존재하면 A는 right-invertible 이라 한다.\nleft-invertible과 열 벡터는 선형독립: 만약 행렬 \\(A\\)가 left-inverse 행렬 \\(C\\) 갖는다면 행렬 \\(A\\)의 열벡터는 선형 독립이다.\n【증명】 \\(Ax = 0\\)을 만족하는 \\(x = 0\\)이므로 \\(A\\)의 열벡터는 선형 독립이다. \\(0 = CAx = Ix = x\\)\nleft-invertible 행렬(\\(C\\)) 갖는 \\(A\\) 선형방정식 \\(Ax = b\\) 해 구하기\n\\[C_{m \\times m}A_{m \\times n}x_{n} = C_{n \\times n}b_{n} \\rightarrow x_{n} = C_{n \\times n}b_{n}\\]\nright-invertible과 행 벡터는 선형독립: 만약 행렬 \\(A\\)가 right-inverse 행렬 \\(B\\) 갖는다면 행렬 \\(A\\)의 행벡터는 선형 독립이다.\nleft, right invertible 관계: 행렬 \\(A\\)의 right inverse \\(B\\)을 가지면 \\(B^{T}\\)는 \\(A^{T}\\)의 left inverse 행렬이다.\n【증명】 \\(AB = I \\rightarrow (AB)^{T} = I^{T} \\rightarrow B^{T}A^{T} = I\\)\n\n\nright-invertible 행렬(\\(B\\)) 갖는 \\(A\\) 선형방정식 \\(Ax = b\\) 해 구하기\n해는 \\(x = Bb\\)이다. 【증명】 \\(Ax = A(Bb) = (AB)b = b\\)\n\n\n(2) 역행렬 구하기\n행렬의 역수 개념이다. 3에 어떤 수를 곱하면 1이 될까? 답은 \\(\\frac{1}{3}\\)(역수)이다. 마찬가지로 행렬 \\(A\\)에 무엇을 곱하면 항등행렬 \\(I\\)가 될까? 이를 역행렬이라 한다. \\(AA^{- 1} = A^{- 1}A = I\\)\n행렬식 determinant: 행렬식은 정방행렬에서만 계산되며 결과는 스칼라이다. 기호는 \\(det(A)\\)혹은 \\(|A|\\)으로 표현한다. 다음은 행렬식 계산 방법이다.\n\\(A_{2 \\times 2} = \\begin{bmatrix}\na & b \\\\\nc & d\n\\end{bmatrix}\\) ⇢ \\(det(A) = ad - bc\\) \\(A = \\begin{bmatrix}\n1 & 3 \\\\\n2 & 4\n\\end{bmatrix}\\), \\(|A| = - 2\\)\n\n\n\n\n\n행렬식 성질\n\n\\(|A^{T}| = |A|\\)\n\\(|AB| = |BA|\\)\n\\(|AB| = |A||B|\\)\n한 열에 \\(k\\)배 한 후 다른 열에 더하여도 행렬식은 변하지 않는다.\n한 열이 다른 열의 선형결합으로 표현된다면 행렬식은 0이다.\n\n소행렬 minor: \\(i\\)행, \\(j\\)열은 제외한 행렬을 소행렬(\\(M_{ij}\\))이라 하고 소행렬의 행렬식을 소행렬식(\\(|M_{ij}|\\))이라 한다. 일반적으로 소행렬은 소행렬식을 의미한다.\n\n\n\n\n\n여인수 cofactor\n\n\\(C_{ij} = ( - 1)^{i + j}|M_{ij}|\\)을 여인수라 한다. 여인수를 이용하여 다음과 같이 행렬식을 구할 수 있다.\n\\(|A_{n \\times n}| = \\overset{n}{\\sum_{i = 1}}a_{ij}( - 1)^{i + j}|M_{ij}|\\),\\(|A_{n \\times n}| = \\overset{n}{\\sum_{j = 1}}a_{ij}( - 1)^{i + j}|M_{ij}|\\)\n\n여인수 행렬 / 수반행렬 adjoint\n\\(C_{ij} = \\begin{bmatrix}\nC_{11} & C_{12} & C_{13} \\\\\nC_{21} & C_{22} & C_{23} \\\\\nC_{31} & C_{32} & C_{33}\n\\end{bmatrix}\\)⇢ \\(adj(A) = \\begin{bmatrix}\nC_{11} & C_{21} & C_{31} \\\\\nC_{12} & C_{22} & C_{32} \\\\\nC_{13} & C_{23} & C_{33}\n\\end{bmatrix}\\)\n역행렬 구하기: 정방행렬 \\(A\\)에 대하여 \\(AB = BA = I\\)을 만족하는 행렬 \\(B\\)를 \\(A\\)의 역행렬이라 하며 \\(A^{- 1}\\)로 표현한다.\n\\[A^{- 1} = \\frac{1}{|A|}adj(A)\\]\n역행렬 성질\n\n역행렬은 유일하고 \\((A^{- 1})^{- 1} = A\\)이 성립한다.\n\\((AB)^{- 1} = B^{- 1}A^{- 1}\\)\n\\((A^{T})^{- 1} = (A^{- 1})^{T}\\)\n\\(|A^{- 1}| = \\frac{1}{|A|}\\)\n\n계수 rank: 차수가 \\(n\\)인 정방행렬 \\(A_{n \\times n}\\)의 열벡터에 대하여 \\(k_{1}\\underset{¯}{a_{1}} + k_{2}\\underset{¯}{a_{2}} + ... + k_{n}\\underset{¯}{a_{n}} = \\underset{¯}{0}\\) 방정식이 모든 상수 \\(k_{j}\\)가 0일 때만 만족하는 경우 열벡터(\\(\\underset{¯}{a_{j}}\\))는 선형독립 linearly independent이라 한다. 만약 적어도 0이 아닌 상수가 하나라도 존재하면 종속이라 한다.\n정방행렬 \\(A_{n \\times n}\\)에 대하여 선형 독립인 행의 개수와 열의 개수 중 작은 것을 행렬의 계수라 한다. 행렬의 차수와 계수가 동일하면 이를 full-rank라 한다.\n행렬 \\(A_{n \\times n}\\)에 대하여 각 열은 동일하다.\n\n\n\n\n\n\n\n역행렬 \\(A^{- 1}\\)은 존재한다.\n역행렬 \\(A^{- 1}\\)은 존재하지 않는다.\n\n\n\n\n행렬식은 0이 아니다. \\(det(A) \\neq 0\\)\n행렬식은 0이다. \\(det(A) = 0\\)\n\n\nfull rank이다. \\(rank(A) = n\\)\nfull rank 아니다. \\(rank(A) &lt; n\\)\n\n\n행렬 A는 non-singular이다.\n행렬 A는 singular이다.\n\n\n\\(AX = \\underset{¯}{b}\\) 해가 존재한다.\n\\(AX = \\underset{¯}{b}\\) 해가 존재하지 않는다.\n\n\n\n\n\n\n\nchapter 3. 행렬 활용\n\n1. 연립방정식 해 구하기 \\(Ax = b\\)\n\n(1) \\(QR\\) 분해 이용\n\n행렬 \\(A\\)을 \\(QR\\)분해 한다. \\(A = QR\\)\n\\(Q^{T}b\\)을 구한다.\n후진 제거 방법으로 \\(Rx = Q^{T}b\\)을 구한다.\n\n\n\n(2) 역행렬 계산 \\(A^{- 1}\\)\n행렬 \\(A\\)의 역행렬 \\(A^{- 1}\\)을 이용하여 \\(\\widehat{x} = A^{- 1}b\\) 해를 구한다.\n\n\n\n2. 최소자승법 \\(Ax = b\\)\n\n(1) 최소자승 문제\n\\(A_{m \\times n}x_{n} = b_{m}\\)(단 \\(m &gt; n\\)) 선형방정식에서는 \\(m\\)개의 방정식이 \\(n\\)개 변수보다 많으므로 \\(b\\)가 행렬 \\(A\\)의 열의 선형결합일 때만 해를 갖는다. \\(b\\)을 어떻게 구할 것인가? 잔차 \\(r = Ax - b\\)최소화 하는 \\(x\\)을 찾는 것을 최소자승법이라 한다. \\(minmize \\parallel Ax - b \\parallel\\) \\(2x_{1} = 1, - x_{1} + x_{2} = 0,2x_{2} = - 1\\) : 방정식 3개, 미지수 2개\n\\(Ax = b\\): \\(\\begin{bmatrix}\n2 & 0 \\\\\n- 1 & 1 \\\\\n0 & 2\n\\end{bmatrix}\\left\\lbrack \\begin{array}{r}\nx_{1} \\\\\nx_{2}\n\\end{array} \\right\\rbrack = \\begin{bmatrix}\n1 & 0 & 1\n\\end{bmatrix}\\)\n\n\n(2) 최소자승 해 구하기\n\\(minmizef(x) = \\parallel Ax - b \\parallel^{2}\\) 해 \\(\\widehat{x}\\)는 \\(\\frac{\\partial f}{\\partial x_{i}}(\\widehat{x}) = 0,i = 1,2,...,n\\)을 만족하므로 \\(\\nabla f(x) = 2A^{T}(Ax - b)\\) 방정식에서 \\(\\nabla f(\\widehat{x}) = 0\\)이다. 그러므로 최소자승 해는 \\(\\widehat{x} = (A^{T}A)^{- 1}A^{T}b\\)이다.\n\n\n\n\n\n\\(A = QR\\) 분해 이용\n\\(Ax = b\\)의 최소자승 해는 \\(\\widehat{x} = R^{- 1}Q^{T}b\\)이다.\n\\[RMS = \\sqrt{\\parallel b - A\\widehat{x} \\parallel^{2}}\\]\n매출 광고\n행은 사회인구학적 특성 10개이고 열은 3개 광고 채널이고 \\(R_{ij}\\)는 \\(i\\)-사회인구학적특성의 \\(j\\)-광고채널의 1달러당 노출회수(단위: 1000)이다. 만약 각 사회인구학적 특성 집단별로 노출회수를 \\(10^{3}\\)으로 할 경우 광고비는 얼마?\n\n\n\n\n\n\\(R_{10 \\times 3}x_{3} = 10^{3}1_{3}\\)에 대한 최소자승해는 \\(\\widehat{x} = (62,100,1443)\\)으로 각 채널당 광고비이다. \\(RMS = 13.2\\%\\)이다.\n\n\n(3) 최소자승 데이터 적합\n\\(n\\)-벡터 \\(x\\)(feature 벡터, 독립변수), 스칼라 \\(y\\)는 다음 근사 함수 관계가 있다고 하자. \\(f:R^{n} \\rightarrow R,y \\approx f(x)\\)\n데이터\n\\[x^{(1)},x^{(2)},...,x^{(N)},y^{(1)},y^{(2)},...,y^{(N)}\\]\n모델 관측치 개수 \\(N\\), 예측변수 개수 \\(p\\)\nfeature 벡터와 스칼라 벡터 사이 함수 관계는 \\(f\\)(예측함수)은\\(y \\approx \\widehat{f}(x),where\\widehat{f}:R^{n} \\rightarrow R\\)\n\\(\\widehat{f}(x)\\)는 파라미터 \\(p\\)-벡터 \\(\\theta\\)의 선형 함수이다.\n\\(\\widehat{f}(x) = \\theta_{1}f_{1}(x) + \\theta_{2}f_{2}(x) + \\cdots + \\theta_{p}f_{p}(x)\\), where \\(f_{i}:R^{n} \\rightarrow R\\)\n예측값과 예측오차\n\\(y^{(i)} \\approx \\widehat{f}(x^{(i)})\\)이고 예측오차(잔차)는 \\(r^{(i)} = y^{(i)} - {\\widehat{y}}^{(i)}\\)이다.\n최소자승 모델 적합\n\\(i = 1,2,\\cdots,N,j = 1,2,\\cdots,p\\)\n\\(y^{d} = (y^{(1)},y^{(2)},...,y^{(N)})\\), \\({\\widehat{y}}^{d} = ({\\widehat{y}}^{(1)},{\\widehat{y}}^{(2)},...,{\\widehat{y}}^{(N)})\\)\n예측오차합 \\(\\parallel r^{d} = y^{d} - {\\widehat{y}}^{d} \\parallel^{2}\\)을 최소화 하는 모수 \\(\\theta\\)을 찾는다.\n\\[{\\widehat{y}}^{(i)} = A_{i1}\\theta_{1} + A_{i1}\\theta_{2} + \\cdots + A_{i1}\\theta_{p},whereA_{ij} = {\\widehat{f}}_{j}(x^{(i)})\\]\n\\({\\widehat{y}}^{d} = A\\theta\\)이므로 \\(\\parallel r^{d} \\parallel^{2} = \\parallel y^{d} - A\\theta \\parallel^{2}\\)이다.\n최소자승 추정 : \\(\\widehat{\\theta} = (A^{T}A)^{- 1}A^{T}y^{d}\\)\n상수항(절편) 있는 선형함수 최소자승 추정\n모든 \\(x\\)에 대하여 \\(f_{1}(x) = 1\\)을 갖는 상수함수를 고려하자. \\(\\widehat{f}(x) = \\theta_{1}\\)이고 \\(A_{(N \\times 1)} = 1_{N}\\)이다.\n\\[\\widehat{\\theta} = (A^{T}A)^{- 1}A^{T}y^{d} = N^{- 1}1^{T}y^{d} = avg(y^{d})\\]\n\n\n(4) 다항식 적합\n모형 \\(\\widehat{f}(x) = \\theta_{1} + \\theta_{2}x + \\cdots + \\theta_{p}x^{p - 1}\\)\n\\[A = \\begin{bmatrix}\n1 & x^{(1)} & \\cdots & (x^{(1)})^{p - 1} \\\\\n1 & x^{(2)} & \\cdots & (x^{(2)})^{p - 1} \\\\\n\\cdots & & & \\\\\n1 & x^{(N)} & \\cdots & (x^{(N)})^{p - 1}\n\\end{bmatrix}\\]\nPiecewise-Linear Fit 분절선형 적합\n\n절단점 식별: 선의 기울기가 변하는 지점을 결정한다.\n선형 구간 적합: 절단점으로 분리된 각 데이터 구간에 선형 모델을 적합한다.\n구간 결합: 절단점에서 구간함수를 연결하여 연속적인 분절선형 함수를 형성한다.\n\n\n\n\n\n\n# Piecewise-Linear Fit\nimport numpy as np\n# 합성 데이터 생성\nnp.random.seed(0)\nx = np.linspace(0, 10, 100)\ny = np.piecewise(x, [x &lt; 4, (x &gt;= 4) & (x &lt; 7), x &gt;= 7],[lambda x: 2 * x + 1 + np.random.normal(size=len(x)),lambda x: -x + 5 + np.random.normal(size=len(x)),lambda x: 0.5 * x - 1 + np.random.normal(size=len(x))])\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import curve_fit\n# 분절선형 함수 정의\ndef piecewise_linear(x, x0, x1, y0, y1, y2, k1, k2, k3):\n    conds = [x &lt; x0, (x &gt;= x0) & (x &lt; x1), x &gt;= x1]\n    funcs = [lambda x: k1 * x + y0, lambda x: k2 * x + y1, lambda x: k3 * x + y2]\n    return np.piecewise(x, conds, funcs)\n# 초기 파라미터 추정값\np0 = [4, 7, 1, 5, -1, 2, -1, 0.5]\n# 데이터를 분절선형 함수에 적합시킴\nparams, _ = curve_fit(piecewise_linear, x, y, p0=p0)\n# 데이터를 적합한 결과와 함께 플로팅\nx_fit = np.linspace(0, 10, 100)\ny_fit = piecewise_linear(x_fit, *params)\n\nplt.scatter(x, y, label='Data')\nplt.plot(x_fit, y_fit, color='red', label='Piecewise Linear Fit')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.legend()\nplt.show()\n\n\n\n3. 간선행렬 \\(Ax = b\\)\n간선 행렬 Incidence matrix은 그래프 이론에서 사용되는 개념으로, 정점과 vertices 간선 edges, nodes 사이의 관계를 나타내는 행렬이다.\n간선 행렬 \\(G_{n \\times m}\\)은 정점이 \\(n\\)개, 간선이 \\(m\\)개이다.\n\n\\(A_{ij} = 1\\) : 정점 \\(i\\)와 간선 \\(j\\)와 연결되어 있고 정점 \\(i\\)는 끝 정점이 아니다.\n\\(A_{ij} = 1\\) : 정점 \\(i\\)와 간선 \\(j\\)와 연결되어 있고 정점 \\(i\\)는 끝 정점이다.\n\\(A_{ij} = 0\\) : 정점 \\(i\\)와 간선 \\(j\\)와 연결되어 않음\n\n\n\n\n\n\n\n\n4. 네트워크\n만약 \\(x\\)가 네트워크에서의 흐름을 나타내는 \\(m\\)-벡터라면, \\(x_{j}\\)는 간선 \\(j\\)를 통한 흐름으로 해석된다. 여기서 양의 값은 흐름이 간선 \\(j\\)의 방향으로 이동하고, 음의 값은 흐름이 간선 \\(j\\)의 반대 방향으로 이동함을 의미한다. 네트워크에서 간선이나 링크의 방향은 흐름의 방향을 지정하지 않고 그저 흐름 flow의 방향을 고려하는 것을 나타내는 것이다.\n네트워크에서의 흐름 보존은 흐름이 노드와 간선을 통해 어떻게 이동하는지를 설명하며, 각 노드로 들어오는 총 흐름이 노드에서 나가는 총 흐름과 같음을 보장한다.\n네트워크 구조를 나타내는 \\(G_{n \\times m}\\)를 사용하여\n\\(y = Gx\\)는 각 노드로 들어오는 순흐름을 나타내는 \\(n\\)-벡터이다.\n\\(y_{i}\\)는 \\(i\\)-노드로 들어오는 총 흐름에서 \\(i\\)-노드에서 나가는 총 흐름을 뺀 값이다 즉, \\(i\\)-노드에서의 흐름 잉여 surplus이다.\n요약하면, \\(y = Gx\\)는 네트워크 이론에서의 흐름 보존 원칙을 요약한 것으로, 각 요소 \\(y_{i}\\)는 노드 \\(i\\)에서의 순 흐름 균형을 나타내며 모든 들어오는 흐름과 나가는 흐름을 고려한다.\n만약 \\(Gx = 0\\)인 상태를 각 노드에서 총 들어오는 흐름과 총 나가는 흐름이 일치하기 때문에 흐름 보존이 일어난다고 말한다.\n\n\n\n\n\n위의 그래프에 의해 나타낸 네트워크에서 \\(x = (1, - 1,1,0,1)\\)이다. 소스는 source 노드에서 네트워크로 들어오거나 나가지만, 간선을 따라 흐르지는 않습니다. 위 그림에서 보여지는 것처럼 이러한 흐름들은 5-벡터 4소스로 나타낸다. \\(s_{i}\\)를 노드 \\(i\\)에서 외부에서 네트워크로 들어오는 흐름으로 생각할 수 있다. 즉, 어떤 간선을 통해서도 들어오지 않는 것이다. \\(s_{i} &gt; 0\\)일 때 외부흐름은 소스라고 부르며 \\(s_{i} &lt; 0\\)일 때 외부흐름은 싱크라고 부른다.\n소스 포함된 흐름 보전 : \\(Ax + s = 0\\)\n\n\n5. 선형함수 모델 \\(Ax = b\\)\n필드에서 발생하는 많은 함수나 변수 간의 관계는 선형 또는 아핀 함수로 근사될 수 있는데, 두 변수 집합 간의 선형 함수를 모형(model) 또는 근사(approximation) 값으로 정의한다.\n\n(1) 수요의 가격 탄력성(Price elasticity of demand)\n가격이 n개의 상품(서비스)에 의해 결정되는 n-벡터 p로 주어지고, 상품에 대한 수요가 n-벡터 d로 주어진다. n-벡터 \\(\\delta^{price}\\)를 가격변화 벡터라 하면 \\(\\delta^{price} = \\frac{(p_{i}^{new} - p_{i})}{p_{i}}\\)라 하자(\\(p^{new}\\)는 새로운 가격 n-벡터). n-벡터 \\(\\delta^{dem}\\)를 수요변화 벡터라 하면 \\(\\delta^{dem} = \\frac{(d_{i}^{new} - d_{i})}{d_{i}}\\)라 하자. \\(\\delta^{dem} = E^{d}\\delta^{price}\\), \\(E^{d}\\)는 (\\(n \\times n\\)) 수요 탄력성 행렬이다.\n\\(E_{11}^{d} = - 0.4\\), \\(E_{21}^{d} = 0.2\\) 가정해 보자. 이는 첫 번째 상품의 가격이 1% 증가할 때, 다른 가격은 동일한 상태에서 첫 번째 상품의 수요가 0.4% 감소하고, 두 번째 상품의 수요가 0.2% 증가할 것임을 의미한다. 두 번째 상품은 첫 번째 상품의 부분 대체품으로 작용하고 있다.\n\n\n(2) 탄성 변형 Elastic deformation\nf 를 구조물에 작용하는 특정 위치(및 방향)에 대한 힘(하중)을 나타내는 n-벡터라고 합시다. 구조물은 하중으로 인해 약간 변형될 것입니다. d는 하중으로 인해 구조물의 m개 지점에서 발생하는 변위(특정 방향으로)를 나타내는 m-벡터입니다. 변위와 하중 사이의 관계는 선형으로 잘 근사된다. d= Cf 여기서 C 는 m × n 컴플라이언스(compliance) 행렬이고 C 의 항목의 단위는 m/N입니다.\n\n\n(3) 테일러 근사\n함수 \\(f:R^{n} \\rightarrow R^{n}\\)이 1차 미분이 가능하다고 하면 테일러 근사는 \\(\\widehat{f}(x)_{i} = f_{i}(z) + \\triangledown f_{i}(z)^{T}(x - z)\\), 단 n-벡터 \\(z\\)는 n-벡터 \\(x\\)와 가까운 값이다.\n\\(\\widehat{f}(x) = f(z) + Df(z)(x - z)\\), 단.\\(Df(z)_{ij} = \\frac{\\partial f_{i}}{\\partial x_{i}}(z),i = 1,...,m,j = 1,...,n\\)\n\n\n(4) 회귀모형\n표본 크기 \\(N\\), 예측변수 벡터 \\(x^{(1)},x^{(2)},...,x^{(N)}\\)이다. \\(i\\)-개체의 예측치는 \\({\\widehat{y}}^{(i)} = (x^{(i)})^{T}\\beta + v,i = 1,2,...,N\\)이다. 그리고 \\(X\\)는 예측변수 행렬, \\(y\\)는 목표변수 벡터이다.\n\n잔차는 \\(r^{(i)} = y^{(i)} - {\\widehat{y}}^{(i)}\\).\n절편 없는 회귀모형 : \\({\\widehat{y}}^{d} = X^{T}\\beta + v1\\)\n절편 회귀모형 : \\({\\widehat{y}}^{d} = \\left\\lbrack \\begin{array}{r}\n1^{T} \\\\\nX\n\\end{array} \\right\\rbrack^{T}\\left\\lbrack \\begin{array}{r}\nv \\\\\n\\beta\n\\end{array} \\right\\rbrack\\)\n\n\n\n\n6. 선형 동적 시스템\n시간에 따라 변하는 상태 벡터의 선형 관계를 설명하는 모델로 시스템의 현재 상태가 다음 상태를 예측할 수 있는 간단한 수학적 구조이다. \\(x_{t}\\)가 현재 상태인 \\(x_{1},x_{2},\\cdots\\) n-벡터 시계열이라 하자. 예를 들면, \\((x_{5})_{3}\\) 3번째 포트폴리오의 5일째 주가가 된다.\n\n(1) 입력이 포함된 선형 동적 시스템\n\\[x_{t + 1} = A_{t}x_{t} + B_{t}u_{t},t = 1,2,...\\]\n\\(u_{t}\\) 는 시간 t 에서의 입력벡터이고 .B 는 입력행렬로, 입력 \\(u_{t}\\)(외생 변수라고도 함)가 상태 벡터 \\(x_{t}\\)에 미치는 영향을 설명한다.\n\n\n(2) \\(K\\)-Markov 모형\n\\[x_{t + 1} = A_{1}x_{t} + \\cdots + A_{K}x_{t - K + 1},t = K,K + 1,...\\]\n\n상태 State : 시스템이 존재할 수 있는 모든 가능한 상태들의 집합. 예를 들어, 날씨 예측 모델에서 상태는 ”맑음”, ”흐림”, ”비” 등이 될 수 있다. 시스템이 가질 수 있는 모든 상태들의 집합을 상태 공간 \\(S\\)라 한다.\n상태 전이 State Transition : 한 상태에서 다른 상태로의 전이. 상태 전이는 확률적으로 이루어지며 \\(P_{i}\\)는 초기상태 확률분포이다.\n전이 확률 Transition Probability : 현재 상태에서 다음 상태로 전이될 확률을 나타낸다. 이는 \\(P(x_{t + 1} = s_{j}|x_{t} = s_{i})\\)로 표현되며, 현재 상태 \\(i\\)에서 다음 시점에 상태 \\(j\\)로 전이될 확률이다.\n\n# Markov model\nimport numpy as np\n# 전이 행렬 정의\nP = np.array([[0.8, 0.2],[0.4, 0.6]])\n# 초기 상태 분포 정의\npi_0 = np.array([0.6, 0.4])\n# 상태 이름 정의\nstates = [\"Sunny\", \"Rainy\"]\n# 시뮬레이션을 위한 시간 단계 수\nnum_steps = 10\n# 초기 상태 선택\ncurrent_state = np.random.choice(states, p=pi_0)\nprint(f\"Day 0: {current_state}\")\n# 시뮬레이션 시작\nfor t in range(1, num_steps + 1):\n    if current_state == \"Sunny\":\n        next_state = np.random.choice(states, p=P[0])\n    else:\n        next_state = np.random.choice(states, p=P[1])\n    print(f\"Day {t}: {next_state}\")\n    current_state = next_state\n\n\n\n\n\n\n\n\n7. 인구 동태\n100-벡터 \\((x_{t})_{i}\\)는 \\(t\\) 시점의 \\((i - 1)\\)세 인구이다. 100- 벡터 \\(b\\)의 \\(b_{i}\\)는 \\((i - 1)\\)의 평균 출생율이다. 가임 연령을 고려하면 벡터 b의 원소는\\(b_{I} = 0fori &lt; 13ori &gt; 50\\)이다. 만약 사망, 이민 없다고 가정하면 내년 0세 인구는 \\((x_{t + 1})_{1} = b^{T}x_{t}\\)이다.\n나이 \\(i\\)세 \\((t + 1)\\) 시점의 인구수는 다음과 같다. \\(d_{i}\\)는 \\(i\\)세 사망자수이다.\\((x_{t + 1})_{i + 1} = (1 - d_{i})(x_{t})_{i},i = 1,2,\\cdots,99\\). 최종적으로 인구 동태 모형은 \\(x_{t + 1} = Ax_{t},t = 1,2,\\cdots\\)이다.\n전이행렬 \\(A\\)\n\\[A = \\begin{bmatrix}\nb_{1} & b_{2} & b_{3} & \\cdots & b_{98} & b_{99} & b_{100} & \\\\\n1 - d_{1} & 0 & 0 & \\cdots & 0 & 0 & 0 & \\\\\n0 & 1 - d_{2} & 0 & \\cdots & 0 & 0 & 0 & \\\\\n\\cdots & \\cdots & \\cdots & \\cdots & \\cdots & \\cdots & \\cdots & \\\\\n0 & 0 & 0 & \\cdots & 1 - d_{98} & 0 & 0 & \\\\\n0 & 0 & 0 & \\cdots & & 0 & 1 - d_{99} & 0\n\\end{bmatrix}\\]\n이민을 고려한 인구 동태 모형\n\\(x_{t + 1} = Ax_{t} + u_{t},t = 1,2,\\cdots\\), 벡터 \\((u_{t})_{i}\\)는 t-시점에 나이 \\((i - 1)\\)세의 순이민자수이다.\n간단한 인구동태 방정식\n\\[P_{t + 1} = P_{t} + (B_{t} - D_{t}) + M_{t}\\]\n\\(P_{t}\\) : \\(t\\) 시점의 인구수, \\(B_{t}\\) : \\(t\\) 시점의 출생자수, \\(D_{t}\\) : \\(t\\) 시점의 사망자수, \\(M_{t}\\) : \\(t\\) 시점의 순 이민자수\n# 인구동태모형\nimport numpy as np\nimport matplotlib.pyplot as plt\n# 초기 인구와 파라미터 설정 미국 23년 기준\ninitial_population = 330_000_000\nbirth_rate = 12.4 / 1000\ndeath_rate = 8.9 / 1000\nannual_net_migration = 1_000_000\nyears = 10\n# 인구 예측을 위한 배열 초기화\npopulation = np.zeros(years + 1)\npopulation[0] = initial_population\n# 연도별 인구 예측\nfor t in range(1, years + 1):\n    births = population[t - 1] * birth_rate\n    deaths = population[t - 1] * death_rate\n    population[t] = population[t - 1] + births - deaths + annual_net_migration\n# 결과 출력\nfor t in range(years + 1):\n    print(f\"Year {2023 + t}: {population[t]:,.0f}\")\n【결과】 Year 2024: 332,155,000 Year 2025: 334,317,542 Year 2026: 336,487,654 Year 2027: 338,665,361 Year 2028: 340,850,689 Year 2029: 343,043,667 Year 2030: 345,244,320 Year 2031: 347,452,675 Year 2032: 349,668,759Year 2033: 351,892,600\n\n\n8. 전염병 동태\n전염 역할 모델른 전염병의 전파와 확산을 연구하는 분야로, 이는 질병의 전염 방식과 전파 속도를 이해하고 예측하는 데 중점을 둔다.\n\\(SIRD\\) 모델 상태\n\\(x_{t} = (S,I,R,D),whereS + R + I + D = 1\\)\n\n감염 가능성 Susceptible (S): 현재는 비감염이지만 내일에는 질병에 감염될 수 있는 사람들\n감염 Infected (I): 현재 질병에 감염된 사람들.\n회복 Recovered (R): 질병을 회복하고 면역을 획득한 사람들.\n사망 Deceased (D): 질병으로 사망한 사람들.\n\n약학 모델 동력학\n\\(\\beta\\) : 감염 가능성에서 감염으로 전환될 감염율, \\(\\gamma\\) : 감염에서 회복으로 전화되는 회복율 \\(\\mu\\) : 감염에서 사망으로 전환되는 사망율이라면\n\\[\\begin{matrix}\n& \\frac{dS}{dt} = - \\beta SI,\\frac{dI}{dt} = - \\beta SI - \\gamma I\\mu I \\\\\n& \\frac{dR}{dt} = - \\gamma I,\\frac{dD}{dt} = \\mu I\n\\end{matrix}\\]\n사례연구\n만약 t기의 SIRD 벡터가 \\(x_{t} = (0.99,0.01,0,0)\\)라 하자. 그리고 감염 가능성 있는 인구 중 30%(\\(\\beta = 0.3\\))는 전염되고 전염자의 2%(\\(\\mu = 0.02\\))는 사망하고 회복율은 10%(\\(\\gamma = 0.1)\\)이라 하자. 그러므로 전염 상태로 남아 있는 전염자는 88%이다.\n\\(x_{t + 1} = Ax_{t}\\) 모형에서 \\(A = \\begin{bmatrix}\n0.99 & 0.1 & 0 & 0 \\\\\n0.01 & 0.88 & 0 & 0 \\\\\n0 & 0.1 & 1 & 0 \\\\\n0 & 0.02 & 0 & 1\n\\end{bmatrix}\\)\n# 전염병 동태모델 사례\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\n# 초기 조건\nS0 = 0.99   # 초기 감수성 인구 비율\nI0 = 0.01   # 초기 감염 인구 비율\nR0 = 0.0    # 초기 회복 인구 비율\nD0 = 0.0    # 초기 사망 인구 비율\ninitial_conditions = [S0, I0, R0, D0]\n# 파라미터\nbeta = 0.3   # 전염율\ngamma = 0.1  # 회복율\nmu = 0.02    # 사망율\n# SIRD 모델 미분 방정식\ndef sird_model(y, t, beta, gamma, mu):\n    S, I, R, D = y\n    dS_dt = -beta * S * I\n    dI_dt = beta * S * I - gamma * I - mu * I\n    dR_dt = gamma * I\n    dD_dt = mu * I\n    return [dS_dt, dI_dt, dR_dt, dD_dt]\n# 시간 벡터 (일 단위)\nt = np.linspace(0, 160, 160)\n# ODE 풀기\nsolution = odeint(sird_model, initial_conditions, t, args=(beta, gamma, mu))\nS, I, R, D = solution.T\n# 결과 그래프 출력\nplt.figure(figsize=(10, 6))\nplt.plot(t, S, label='Susceptible')\nplt.plot(t, I, label='Infected')\nplt.plot(t, R, label='Recovered')\nplt.plot(t, D, label='Deceased')\nplt.xlabel('Time (days)')\nplt.ylabel('Proportion of Population')\nplt.legend()\nplt.title('SIRD Model')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nchapter 4. 고유치와 고유벡터\n\n1. 기초\n\n(1) 개념\n고유치는 행렬의 선형변환에서 중요한 특성을 나타내는 값이다. 특정 벡터(고유벡터)가 행렬 \\(A\\)에 의해 변환될 때, 방향은 변하지 않고 크기만 일정 비율로 변한다면, 이 비율을 고유치라고 한다.\n\n\n\n\n\n위 그래프는 행렬 \\(A = \\begin{bmatrix}\n3 & 1 \\\\\n0 & 2\n\\end{bmatrix}\\)의 고유치(\\(\\lambda = 3,2\\))와 고유벡터의 변환을 시각적으로 보여준다.\n\n빨간색 화살표: 첫 번째 고유벡터 \\(\\mathbf{v}_{1}\\)\n투명 빨간색 화살표: 첫 번째 고유벡터가 행렬 \\(A\\)에 의해 변환된 결과로, 고유치 \\(\\lambda_{1} = 3\\)에 의해 크기만 3배로 늘어난다.\n파란색 화살표: 두 번째 고유벡터 \\(\\mathbf{v}_{2}\\).\n투명 파란색 화살표: 두 번째 고유벡터가 행렬 A 에 의해 변환된 결과로, 고유치 \\(\\lambda_{2} = 2\\)에 의해 크기만 2배로 늘어난다.\n\n고유벡터의 방향은 행렬 변환 후에도 유지되며, 크기만 고유치 값에 따라 변한다. 이를 통해 고유치와 고유벡터의 개념을 시각적으로 이해할 수 있다.\n\n\n(2) 통계학 활용\n고유치 분석을 통해 얻을 수 있는 통계적 통찰은 다음과 같다.\n\n데이터의 분산 설명: 공분산 행렬의 고유치는 각 축의 분산 크기를 나타내며, 데이터가 어떤 축에서 더 많은 정보를 가지고 있는지 보여준다.\n중요한 변수 식별: PCA나 LDA에서 고유치를 사용해 데이터를 가장 잘 설명하는 주성분이나 판별 방향을 찾는다.\n데이터의 차원 축소: 가장 큰 고유치를 가진 축만 선택함으로써 데이터의 복잡성을 줄이고, 분석의 효율성을 높는다.\n시각화: MDS, PCA를 활용해 고차원 데이터를 저차원으로 투영하여 시각화할 수 있는다.\n\n주성분 분석(PCA, Principal Component Analysis)\nPCA는 데이터의 고차원 공간을 낮은 차원으로 축소하면서 데이터의 주요 정보를 보존하는 방법이다.\n\n데이터의 공분산 행렬에서 고유치를 계산하여 주성분의 중요도를 평가한다.\n가장 큰 고유치는 데이터의 분산을 가장 많이 설명하는 방향(주성분)을 나타낸다.\n예: 변수 100개로 구성된 데이터를 분석할 때, 고유치를 계산하여 주요한 2~3개의 주성분만 선택해 데이터 차원을 축소할 수 있다.\n\n선형 판별 분석(LDA, Linear Discriminant Analysis)\nLDA는 여러 클래스 간의 분산을 극대화하면서 각 클래스 내의 분산을 최소화하는 투영 방향을 찾는 방법이다.\n클래스 간 분산 행렬과 클래스 내 분산 행렬의 비율로 구성된 행렬의 고유치를 계산하여 최적의 분리 축을 결정한다.\n다차원 척도법(MDS, Multidimensional Scaling)\nMDS는 데이터 간의 거리 행렬을 기반으로 저차원 공간에 데이터를 시각화하는 방법이다.\n\n거리 행렬을 고유치 분해하여 데이터를 저차원 공간에 배치한다.\n가장 큰 고유치를 가진 방향이 데이터 구조의 주요 변화를 설명한다.\n\n공분산 행렬 및 상관 행렬 분석\n공분산 행렬이나 상관 행렬의 고유치는 데이터의 선형 독립성과 분산 구조를 분석하는 데 사용된다.\n\n고유치가 큰 방향은 데이터의 분산이 큰 축(정보가 많이 분포된 축)을 나타낸다.\n고유치가 0에 가까운 경우 변수들 간의 선형 종속성을 암시한다.\n\n행렬 분해 및 차원 축소\n고유치와 고유벡터는 행렬 분해 방법(예: 특이값 분해(SVD), 고유분해(Eigendecomposition))의 핵심이다.\n\n차원 축소, 데이터 압축, 노이즈 제거 등에 사용된다.\n예: 특이값 분해(SVD)는 추천 시스템이나 텍스트 분석(Latent Semantic Analysis, LSA)에서 널리 사용된다.\n\n시계열 데이터 분석 Autoregressive 모델(AR)\n시계열 모델에서 안정성을 분석할 때, 고유치를 통해 시스템의 특성을 평가한다. 예: 고유치가 1보다 크면 시스템이 불안정함을 나타낸다.\n\n\n\n2. 고유치, 고유벡터 구하기\n대칭행렬 \\(A_{n \\times n}\\)에 대하여 고유치 \\(\\lambda\\), 고유벡터 \\(\\underset{¯}{v}\\)는 다음 방정식이 성립한다. \\(A\\underset{¯}{v} = \\lambda\\underset{¯}{v}\\)\n\n(1) 고유치 eigenvalue 구하기\n\\(det(A - \\lambda I) = 0\\)을 만족하는 \\(\\lambda\\)를 고유치라 한다.\n고유치는 행렬 \\(A\\)의 차수만큼 존재한다. \\(\\lambda_{1},\\lambda_{2},...,\\lambda_{n}\\)\n\n\n(2) 고유벡터 eigenvector 구하기\n\\(A\\underset{¯}{v_{i}} = \\lambda_{i}\\underset{¯}{v_{i}}\\) 을 만족하는 벡터(\\(\\underset{¯}{v}\\))를 고유벡터라 한다.\n\\(det(A - \\lambda I) = 0\\)(singlular)가 성립하므로 고유벡터는 무수히 많이 존재한다.\n고유벡터 중 Norm(\\(\\underset{¯}{v}'\\underset{¯}{v} = 1\\))이 1인 고유 벡터를 주성분분석에서 사용한다.\n\n\n\n3. 고유치 활용\n\n(1) 고유치 분해 eigenvalue decomposition\n정방행렬 \\(A_{n \\times n}A\\)의 고유치(\\(\\lambda_{i}\\))를 대각원소로 하는 대각행렬 \\(\\Lambda\\), 고유벡터(\\(\\underset{¯}{v_{i}}\\))로 이루어진 직교 orthogonal 행렬 \\(Q\\)라 하면 행렬 \\(A\\)는 다음과 같이 고유치 분해 된다. \\(A = Q\\Lambda Q^{- 1}\\)\n\n\n(2) 주성분분석\n데이터 행렬 : \\(X_{n \\times p} = \\begin{bmatrix}\nx_{11} & x_{12} & \\cdots & x_{1p} \\\\\nx_{21} & x_{22} & \\cdots & x_{2p} \\\\\n\\cdots & \\cdots & \\cdots & \\cdots \\\\\nx_{n1} & x_{n2} & \\cdots & x_{np}\n\\end{bmatrix}\\) (변수 개수 \\(p\\))\n\n\\(\\underset{¯}{y} = P\\underset{¯}{x}\\) : 원 변수의 선형결합(선형계수 행렬은 고유벡터)으로 주성분변수를 만든다.\n\\(X'X\\) 고유치분해 : \\(X'X = (Q\\Lambda Q^{- 1})'(Q\\Lambda Q^{- 1}) = Q\\Lambda Q^{- 1}\\)\n\\(X\\)의 공분산행렬(측정 단위가 다른 경우 상관계수 행렬)로부터 고유치와 고유벡터(Norm=1인 정규고유벡터)를 구하여 서로 독립인 차원으로 변환한다.\n공분산행렬에 대한 고유치, 고유벡터 : \\(COV_{p \\times p}\\underset{¯}{v} = \\lambda\\underset{¯}{v}\\)\n공분산 행렬은 양의 정부호 행렬이므로 변수의 차수만큼의 고유치, 그에 대응하는 고유벡터가 존재한다.\n고유벡터는 원변수를 직교 축을 갖는 주성분 변수로 변환한다. 그러므로 차수는 줄어들지 않으나 모든 차원에서 관측값은 직교(독립)이다.\n주요 2~3개 차원만으로 \\(p\\)차원의 원변수 변동(정보)를 축약한다. 이를 주성분분석이라 한다.\n\n\n\n\n\n\n\n\n(3) 특이값 분해 Singular Value Decomposition\n\n\n\n\n\n\n직교행렬 \\(U\\)(\\(UU' = I\\)) : \\(AA'\\)의 고유벡터\n직교행렬 \\(V'\\)(\\(V'V = I\\)) : \\(A'A\\)의 고유벡터\n대각행렬 \\(\\Sigma\\)의 대각원소 : \\(AA'\\), \\(A'A\\)의 고유치분해 대각원소의 제곱근 값을 대각원소로 한다.\n\n\n\n(4) Cholesky factorization\n대칭행렬 \\(A\\)가 양의 정부호 행렬일 경우 사용되는 분해방법이다.\n\\(A = LL^{T}\\), \\(L\\) : 대각원소가 양이 하단 삼각행렬\n【활용】 최소제곱추정과 같은 최적해를 구할 때 사용하면 빠른 연산이 가능하다. \\(A\\underset{¯}{x} = \\underset{¯}{b}\\) (연립방정식) \\(\\underset{¯}{x} = A^{- 1}\\underset{¯}{b}\\) ➠ \\(LL^{T}\\underset{¯}{x} = \\underset{¯}{b}\\) 이것을 풀면 연산이 더 간편하다. \\(\\underset{¯}{x} = (LL^{T})^{- 1}\\underset{¯}{b} = (L^{- 1})'L^{- 1}\\underset{¯}{b}\\)\n#고유치, 고유벡터\nimport numpy as np\nA=np.array([[1,2,3], [4,5,7],[8,9,10]])\nimport numpy.linalg as la\nval,vec=la.eig(A)\nval,vec\n【결과】 (array([17.71571559, -1.44163052, -0.27408507]), array([[-0.21078452, -0.49872133, 0.47929184], [-0.52147269, -0.47685414, -0.81047488], [-0.82682291, 0.7238005 , 0.33676373]]))\n#고유벡터 분해\nimport numpy as np\nA=np.array([[1,2,3], \n  [4,5,7],\n  [8,9,10]])\nimport numpy.linalg as la\nval,vec=la.eig(A)\nS=np.diag(val); P=vec\nP@S@la.inv(P)\n【결과】 array([[ 1., 2., 3.], [ 4., 5., 7.], [ 8., 9., 10.]])\n#SVD decomposition\nu, s, vh = np.linalg.svd(A, full_matrices=True)\nu,s,vh\n【결과】 (array([[-0.19462586, -0.6193003 , -0.76064966], [-0.5071685 , -0.6002356 , 0.61846369], [-0.83958376, 0.50614657, -0.19726824]]), array([18.62202941, 1.46779937, 0.25609691]), array([[-0.48007495, -0.56284671, -0.67285334], [ 0.70100172, 0.21497525, -0.67998694], [ 0.52737523, -0.79811604, 0.29135228]]))\n#Cholesky decomposition\nimport numpy as np\nA=np.array([[25,15,-5], \n  [15,18,0],\n  [-5,0,11]])\nimport numpy.linalg as la\nnp.linalg.cholesky(A)\n【결과】 array([[ 5., 0., 0.], [ 3., 3., 0.], [-1., 1., 3.]])\n#확인 LL'\nnp.linalg.cholesky(A)@np.linalg.cholesky(A).T\n【결과】 array([[25., 15., -5.], [15., 18., 0.], [-5., 0., 11.]])\n\n\n\n\nchapter 5. 행렬미분\n\n1. 미분 공식\n\n(1) 벡터미분\n상수벡터 : \\({\\underset{¯}{a}}_{n} = \\left\\lbrack \\begin{array}{r}\na_{1} \\\\\na_{2} \\\\\n... \\\\\na_{n}\n\\end{array} \\right\\rbrack\\) 확률변수 벡터 : \\({\\underset{¯}{x}}_{n} = \\left\\lbrack \\begin{array}{r}\nx_{1} \\\\\nx_{2} \\\\\n... \\\\\nx_{n}\n\\end{array} \\right\\rbrack\\)\n확률변수 \\(x_{i} \\sim (iid)f(x)\\)는 확률표본이다.\n\\(\\frac{\\partial(\\underset{¯}{a}'\\underset{¯}{x})}{\\partial\\underset{¯}{x}} = \\underset{¯}{a}\\), \\(\\frac{\\partial(\\underset{¯}{x}'\\underset{¯}{a})}{\\partial\\underset{¯}{x}} = \\underset{¯}{a}\\)\n\n\n(2) 이차형식 미분\n\\(\\frac{\\partial(\\underset{¯}{x}'A\\underset{¯}{x})}{\\partial\\underset{¯}{x}} = (A + A')\\underset{¯}{x}\\) 만약 A가 대칭행렬이면) \\(2A\\underset{¯}{x}\\)\n\n\n\n2. 이차형식\n\n(1) 이차형식 정의\n정방행렬 : \\(A_{n \\times n} = \\begin{bmatrix}\na_{11} & a_{12} & \\cdots & a_{1n} \\\\\na_{21} & a_{22} & \\cdots & a_{2n} \\\\\n\\cdots & \\cdots & \\cdots & \\cdots \\\\\na_{n1} & a_{n2} & \\cdots & a_{nn}\n\\end{bmatrix}\\)\n이차형식 : \\(Q(x_{1},x_{2},...,x_{n}) = \\underset{¯}{x}'A\\underset{¯}{x}\\)\n\n2차형식의 경우 대칭행렬인 \\(A\\)는 적어도 한 개는 존재한다.\n\n\n\n(2) 이차형식 종류\n대칭행렬 \\(A\\), 이차형식 \\(Q(x_{1},x_{2},...,x_{n}) = \\underset{¯}{x}'A\\underset{¯}{x}\\)에 대하여\n모든 \\(x \\neq 0\\)에 대하여 \\(Q &gt; 0\\)이면 양의 정부호 positive definite\n모든 \\(x \\neq 0\\)에 대하여 \\(Q \\geq 0\\)이면 양의 반부호 positive semidefinite\n\n\n(3) 주축정리 The Principal Axes Theorem\n이차형식 \\(\\underset{¯}{x}'A\\underset{¯}{x}\\)을 교차항이 없는 이차형식 \\(\\underset{¯}{y}'D\\underset{¯}{y}\\)으로 변환하는 직교변환 \\(\\underset{¯}{x} = P\\underset{¯}{y}\\) 존재한다. \\(P\\)를 주축행렬이라 하고 대칭행렬 \\(A\\)의 고유벡터로 이루어져 있다.\n\n교차항이 없는 이차형식은 주축 변량에 대칭이다.\n\n\n\n\n\n\n\n\n(4) 이차형식과 고유치 관계\n\n이차형식 \\(Q = \\underset{¯}{x}'A\\underset{¯}{x}\\)이 양의 정부호이면 모든 고유치는 0보다 크다.\n양의 정부호 행렬의 역행렬도 양의 정부호 행렬이다.\n공분산 행렬은 양의 정부호 행렬이다.\n\n\n\n\n3. 이차형식 만들기\n\\[Q(x) = x_{1}^{2} + 2x_{2}^{2} - 7x_{3}^{2} - 4x_{1}x_{2} + 8x_{1}x_{3}\\]\n\n이차형식으로 만들면 다음과 같다. 제곱항은 그대로 대각원소로 하고 교차항은 1/2로 하여 각 셀에 배분한다.\n\n\\[Q(x) = \\begin{bmatrix}\nx_{1} & x_{2} & x_{3}\n\\end{bmatrix}\\begin{bmatrix}\n1 & - 2 & 4 \\\\\n- 2 & 2 & 0 \\\\\n4 & 0 & - 7\n\\end{bmatrix}\\left\\lbrack \\begin{array}{r}\nx_{1} \\\\\nx_{2} \\\\\nx_{3}\n\\end{array} \\right\\rbrack = \\underset{¯}{x}'A\\underset{¯}{x}\\]\n\n\\(\\underset{¯}{x} = P\\underset{¯}{y}\\), 주축행렬 \\(P\\)는 대칭행렬 \\(A\\)의 고유벡터이다.\n\\(A\\)의 교유치를 대각원소로 하는 행렬 \\(D = diag(\\lambda_{1},\\lambda_{2},\\lambda_{3})\\)를 이용하여 교차항이 없는 이차형식으로 변형한다.\n이렇게 되면 주축 변환된 이차형식의 변수 간에는 교차항이 없으므로 두 변수간에는 서로 독립이 된다.\n\\(Q(x) = \\underset{¯}{x}'A\\underset{¯}{x}\\) ⇢ \\(Q(y) = \\underset{¯}{y}'D\\underset{¯}{y}\\) (\\(\\underset{¯}{x} = P\\underset{¯}{y}\\))\n\n\n\n4. 선형 회귀모형\n\n(1) 데이터 구조\n목표변수 1개, \\(p\\)개 예측변수, 표본크기 n인 데이터를 가정하면 선형 회귀모형은 다음과 같다. \\(\\underset{¯}{y} = X\\underset{¯}{\\beta} + \\underset{¯}{e}\\)\n\\(\\left\\lbrack \\begin{array}{r}\ny_{1} \\\\\ny_{2} \\\\\n\\cdots \\\\\ny_{n}\n\\end{array} \\right\\rbrack\\)=\\(\\begin{bmatrix}\n1 & x_{11} & x_{12} & \\cdots & x_{1p} \\\\\n1 & x_{21} & x_{22} & \\cdots & x_{2p} \\\\\n\\cdots & \\cdots & \\cdots & \\cdots & \\\\\n1 & x_{n1} & x_{n2} & \\cdots & x_{np}\n\\end{bmatrix}\\left\\lbrack \\begin{array}{r}\na \\\\\nb_{1} \\\\\n\\cdots \\\\\nb_{p}\n\\end{array} \\right\\rbrack\\)+\\(\\left\\lbrack \\begin{array}{r}\ne_{1} \\\\\ne_{2} \\\\\n\\cdots \\\\\ne_{n}\n\\end{array} \\right\\rbrack\\)\n\n\n(2) 예측변수 데이터 행렬/벡터\n\\(X_{n \\times p} = \\begin{bmatrix}\nx_{11} & x_{12} & \\cdots & x_{1p} \\\\\nx_{21} & x_{22} & \\cdots & x_{2p} \\\\\n\\cdots & \\cdots & \\cdots & \\cdots \\\\\nx_{n1} & x_{n2} & \\cdots & x_{np}\n\\end{bmatrix}\\), \\(X_{n \\times p} = \\begin{bmatrix}\n{\\underset{¯}{x}}_{1} & {\\underset{¯}{x}}_{2} & \\cdots & {\\underset{¯}{x}}_{p} &\n\\end{bmatrix}\\)\n(데이터 벡터) \\({\\underset{¯}{x}}_{k} = \\left\\lbrack \\begin{array}{r}\nx_{1k} \\\\\nx_{2k} \\\\\n\\cdots \\\\\nx_{nk}\n\\end{array} \\right\\rbrack\\)\n\n\n(3) 확률변수 벡터, 평균벡터, 공분산행렬\n\\(\\underset{¯}{x} = \\left\\lbrack \\begin{array}{r}\nx_{1} \\\\\nx_{2} \\\\\n\\cdots \\\\\nx_{p}\n\\end{array} \\right\\rbrack\\), \\(x_{i}\\)는 확률변수이고 \\(E(x_{i}) = \\mu_{i},V(x_{i}) = \\sigma_{ii}\\),\n(두 변수의 공분산) \\(COV(x_{i},x_{j}) = \\sigma_{ij}\\)\n(평균벡터) \\(E(\\underset{¯}{x}) = \\underset{¯}{\\mu} = \\left\\lbrack \\begin{array}{r}\n\\mu_{1} \\\\\n\\mu_{2} \\\\\n\\cdots \\\\\n\\mu_{p}\n\\end{array} \\right\\rbrack\\)\n(공분산행렬) \\(COV(\\underset{¯}{x}) = \\Sigma = \\begin{bmatrix}\n\\sigma_{11} & \\sigma_{12} & \\cdots & \\sigma_{1p} \\\\\n\\sigma_{21} & \\sigma_{22} & \\cdots & \\sigma_{2p} \\\\\n\\cdots & \\cdots & \\cdots & \\cdots \\\\\n\\sigma_{p1} & \\sigma_{p2} & \\cdots & \\sigma_{pp}\n\\end{bmatrix}\\)\n상수벡터 : \\(\\underset{¯}{a} = \\left\\lbrack \\begin{array}{r}\na_{1},a_{2},\\cdots a_{p}\n\\end{array} \\right\\rbrack\\)\n\\(\\underset{¯}{a}'\\underset{¯}{x}\\)의 평균 : \\(E(\\underset{¯}{a}'\\underset{¯}{x}) = \\underset{¯}{a}'\\underset{¯}{\\mu}\\), 분산 \\(V(\\underset{¯}{a}'\\underset{¯}{x}) = \\underset{¯}{a}'\\underset{¯}{\\Sigma}\\underset{¯}{a}\\)\n\n\n(4) 선형 회귀모형\n\\(\\underset{¯}{y} = X\\underset{¯}{b} + \\underset{¯}{e}\\), \\(\\underset{¯}{e} \\sim N(\\underset{¯}{0},\\sigma^{2}I)\\)\n최소제곱법 추정\n\\[min_{a,b_{1},b_{2},...,b_{p}}\\sum e_{i}^{2} = min_{\\underset{¯}{b}}\\underset{¯}{e}'\\underset{¯}{e}\\]\n\\[Q(\\underset{¯}{b}) = \\underset{¯}{e}'\\underset{¯}{e} = (\\underset{¯}{y} - X\\underset{¯}{b})'(\\underset{¯}{y} - X\\underset{¯}{b}) = \\underset{¯}{y}'\\underset{¯}{y} + \\underset{¯}{b}'X'X\\underset{¯}{b} - 2\\underset{¯}{y}'X\\underset{¯}{b}\\]\n\\(\\frac{\\partial Q}{\\partial\\underset{¯}{b}} = 2X'X\\underset{¯}{b} - 2X'\\underset{¯}{y} = 0\\) ⇢ \\(\\widehat{\\underset{¯}{b}} = (X'X)^{- 1}X'\\underset{¯}{y}\\)\n적합치 fitted values 와 잔차 residuals\n적합치 : \\(\\widehat{\\underset{¯}{y}} = X\\widehat{\\underset{¯}{b}} = X(X'X)^{- 1}X'\\underset{¯}{y} = H\\underset{¯}{y}\\),\n\\(H = X(X'X)^{- 1}X'\\) hat 행렬이라 하고 대칭행렬이고 멱등행렬이다. \\(HH = H,H' = H\\)\n잔차 : \\(\\widehat{\\underset{¯}{e}} = \\underset{¯}{y} - \\widehat{\\underset{¯}{y}} = (I - H)\\underset{¯}{y}\\) \\(H\\)가 멱등행렬이면 \\((I - H)\\)도 멱등행렬이다.\n잔차의 분포 \\(\\widehat{\\underset{¯}{e}} \\sim N(\\underset{¯}{0},\\sigma^{2}I)\\)\n오차의 가정 : \\(\\underset{¯}{e} \\sim N(\\underset{¯}{0},\\sigma^{2}I)\\) ⇢ \\(\\underset{¯}{y} \\sim N(X\\underset{¯}{b},\\sigma^{2}I)\\)\n그러므로 \\(E(\\widehat{\\underset{¯}{e}}) = (I - H)E(\\underset{¯}{y}) = (I - H)(X\\underset{¯}{b}) = (X\\underset{¯}{b} - HX\\underset{¯}{b}) = \\underset{¯}{0}V(\\widehat{\\underset{¯}{e}}) = V((I - H)\\underset{¯}{y}) = (I - H)\\sigma^{2}I(I - H)' = \\sigma^{2}I\\)\n목표변수 분해\n\\(\\underset{¯}{y} = H\\underset{¯}{y} + (I - H)\\underset{¯}{y}\\)=(설명하는 변동) + (설명하지 못하는 변동)\n\n\n\n\n\n높이를 최소화 하는 \\(\\underset{¯}{b}\\)를 구하는 것이 최소제곱추정법이다.\n추정치 분포\n\\(\\widehat{\\underset{¯}{b}} = (X'X)^{- 1}X'\\underset{¯}{y}\\)이고 \\(\\underset{¯}{y} \\sim N(X\\underset{¯}{b},\\sigma^{2}I)\\)이므로\n\\[E(\\widehat{\\underset{¯}{b}}) = (X'X)^{- 1}X'E(\\underset{¯}{y}) = (X'X)^{- 1}X'X\\underset{¯}{b} = \\underset{¯}{b}\\]\n\\[V(\\widehat{\\underset{¯}{b}}) = \\sigma^{2}(X'X)^{- 1}\\]\n\\(\\widehat{\\underset{¯}{b}} \\sim N(\\underset{¯}{b},\\sigma^{2}(X'X)^{- 1})\\), \\({\\widehat{\\sigma}}^{2} = SSE\\)\n변동 분해 ANOVA\n총변동 Total Sum of Squares : \\(SST = \\sum(y_{i} - \\overline{y})^{2}\\)\n\\(SST = \\sum y_{i}^{2} - \\frac{(\\sum y_{i})^{2}}{n} = \\underset{¯}{y}'\\underset{¯}{y} - (\\frac{1}{n})\\underset{¯}{y}'J_{n \\times n}\\underset{¯}{y}\\), \\(J\\)는 1행렬\n\\[SST = \\underset{¯}{y}'(I - (\\frac{1}{n})J)\\underset{¯}{y}\\]\n오차변동 Error Sum of Squares\n\\[SSE = \\sum(y_{i} - \\widehat{y_{i}})^{2}\\]\n\\[SSE = (\\underset{¯}{y} - X\\underset{¯}{b})'(\\underset{¯}{y} - X\\underset{¯}{b}) = \\underset{¯}{y}'\\underset{¯}{y} - \\underset{¯}{b}'X'\\underset{¯}{y} = \\underset{¯}{y}'(I - H)\\underset{¯}{y}\\]\n회귀변동 Regression Sum of Squares\n\\(SSR = \\sum(\\widehat{y_{i}} - \\overline{y})^{2}\\), \\(SSR = \\underset{¯}{y}'(H - (\\frac{1}{n})J)\\underset{¯}{y}\\)\n\\[SSR = SST - SSE = \\underset{¯}{b}X'\\underset{¯}{y} - (\\frac{1}{n})\\underset{¯}{y}'J\\underset{¯}{y}\\]\n결정계수\n\\(R^{2} = \\frac{SSR}{SST} = 1 - \\frac{SSE}{SST}\\) : 모형의 총변동 설명 비중\nSSE, SSR 분포 및 \\(\\sigma^{2}\\) 추정량\n\\(\\underset{¯}{x} \\sim N(\\underset{¯}{\\mu},\\Sigma)\\) 이면 이차형식 \\(\\underset{¯}{x}'A\\underset{¯}{x}\\)의 평균은\n\\(E(\\underset{¯}{x}'A\\underset{¯}{x}) = tr(A\\Sigma) + \\mu'A\\mu\\)이다.\n\\(\\underset{¯}{x} \\sim N(\\underset{¯}{\\mu},\\sigma^{2}I)\\) 이면 이차형식 \\(\\underset{¯}{x}'A\\underset{¯}{x}\\)(\\(A\\) 대칭행렬이고 멱등행렬이면)에 대하여 \\(\\frac{\\underset{¯}{x}'A\\underset{¯}{x}}{\\sigma^{2}} \\sim \\chi^{2}(df = rank(A))\\)이다.\n\\(SSE = \\underset{¯}{y}'(I - H)\\underset{¯}{y}\\), 이차형식이고 \\((I - H)\\)는 멱등행렬\n\\(rank(I - H) = n - p - 1\\)이므로 \\(\\frac{SSE}{\\sigma^{2}} \\sim \\chi^{2}(n - p - 1)\\)이다.\n오차 분산의 추정량: \\(\\widehat{\\sigma^{2}} = MSE\\).\n\\(\\frac{SSR}{\\sigma^{2}} \\sim \\chi^{2}(p)\\), \\(F = \\frac{SSR/p}{SSE/(n - p - 1)} \\sim F(p,n - p - 1)\\)\n분산분석 표\n\n\n\n\n\n\n\n\n\n\n변동\n제곱변동\n자유도\n평균제곱\nF\n\n\n\n\n회귀\n\\[SSR\\]\n\\[p\\]\n\\[MSR = \\frac{SSR}{p}\\]\n\\[\\frac{MSR}{MSE}\\]\n\n\n오차\n\\[SSE\\]\n\\[n - p - 1\\]\n\\[MSE = \\frac{SSE}{n - p - 1}\\]\n\n\n총변동\n\\[SST\\]\n\\[n - 1\\]\n\\[{E(MSE) = \\sigma^{2}\n}{E(MSR) = \\sigma^{2} + b_{1}^{2}\\sum(x_{i} - \\overline{x})^{2}}\\]"
  },
  {
    "objectID": "notes/survey/questionnaire.html",
    "href": "notes/survey/questionnaire.html",
    "title": "조사방법론. 4. 설문지",
    "section": "",
    "text": "chapter 1. 설문지 작성 개요\n설문조사는 응답자에 대한 다양한 정보를 수집하기 위해 여러 방식을 활용한다. 이 중 가장 일반적인 방법은 설문지를 사용하는 것이다. 설문지는 일정한 순서로 제시되는 표준화된 질문들로 구성되며, 대부분 고정된 선택지를 포함하고 있다. 이를 통해 응답자로부터 일관된 데이터를 얻을 수 있다.\n오늘날 설문지는 점점 전자적인 형태로 변화하고 있다. 컴퓨터 프로그램이 설문지를 조사원에게 제공하거나, 응답자에게 직접 보여주는 방식이 증가하고 있다. 그러나 설문 방식이 종이이든 전자이든, 조사원이 있든 없든 대부분의 설문조사는 여전히 응답자가 정해진 질문을 해석하고 그에 맞는 정보를 제공하는 구조에 의존하고 있다.\n모든 설문조사가 응답자에게 질문에 대한 답변을 직접 구성하도록 요구하는 것은 아니다. 예를 들어, 기업이나 기관을 대상으로 한 설문은 주로 기록에서 정보를 추출하며, 이 경우 설문지는 인터뷰 대본이라기보다 데이터 기록 양식에 가깝다. 면접자는 실제 응답자가 아닌 기록과 상호 작용하면서 필요한 정보를 수집할 수 있다.\n교육 관련 설문에서는 학생의 성적 기록이 설문 데이터를 보완할 수 있고, 건강 관련 조사는 의료 기록을 활용함으로써 응답자의 진술에만 의존하는 것을 피할 수 있다. 이러한 경우에도 응답자는 기록에 접근할 수 있도록 협조하거나, 조사 담당자가 필요한 정보를 찾도록 도와주는 역할을 한다.\n일부 조사는 사전에 관련 기록을 준비하도록 요청함으로써 보다 정확한 응답을 유도하기도 한다. 예를 들어, 건강 관련 조사를 앞두고 응답자에게 진료비 영수증이나 의료비 기록을 준비하도록 안내하면, 인터뷰 중 더 정확한 답변을 이끌어낼 수 있다. 다만 어떤 가정에서는 일상 지출을 체계적으로 기록하지 않기 때문에, 필요한 정보가 아예 존재하지 않을 수도 있다.\n설문지는 응답자로부터 일관된 정보를 수집하는 데 핵심적인 역할을 하며, 설문조사의 가장 기본적인 도구로 사용된다. 동일한 질문을 모든 응답자에게 같은 방식으로 제시함으로써 비교 가능성을 높이고, 결과의 신뢰성을 확보할 수 있다. 닫힌 질문과 열린 질문을 적절히 구성함으로써, 응답자의 사고방식을 반영하고 정량적 또는 정성적 분석이 가능하도록 돕는다.\n설문지는 면접 조사에서 조사원이 질문을 일관되게 제시할 수 있도록 안내 역할을 하며, 자기 기입식 조사에서는 응답자가 혼자서도 쉽게 이해하고 답변할 수 있도록 구성된다. 응답 내용을 체계적으로 기록하고 보관하는 기능도 수행하며, 디지털 설문지는 이 과정을 더욱 효율적으로 만들어준다.\n또한, 응답자가 과거 경험을 회상할 수 있도록 특정 사건이나 시점을 제시하는 등 기억을 보조하는 역할도 수행한다. 의료비 지출과 같은 주제를 다룰 때는, 관련 기록을 참고하게 함으로써 보다 정확한 응답을 유도할 수 있다. 이외에도 설문지는 사람들의 행동이나 태도, 의견을 정량적으로 측정하는 데 사용된다. 리커트 척도와 같은 방식은 응답자의 주관적인 평가를 수치화하여 비교 분석을 가능하게 한다.\n설문지는 면접 조사, 우편 설문, 온라인 조사, 전화 조사 등 다양한 방식으로 적용되며, 조사 방식에 따라 질문 순서나 난이도, 응답 인터페이스 등이 달라지기도 한다.\n결국 설문지는 단순한 질문지를 넘어, 응답자의 반응을 유도하고 연구자가 원하는 정보를 효과적으로 수집하는 도구로 기능한다. 설문지 설계의 질은 전체 조사 결과의 신뢰성과 타당성을 결정짓는 중요한 요소가 된다.\n\n\nchapter 2. 좋은 질문지 작성\n좋은 설문지 작성 지침은 응답자의 부담을 줄이면서도 정확하고 신뢰할 수 있는 데이터를 확보하는 데 큰 도움이 된다. 이러한 데이터는 이후 연구, 정책 수립, 비즈니스 의사결정 등에서 보다 효과적인 결과를 도출하는 기반이 된다.\n우선, 설문 조사는 응답 과정에서 다양한 오류가 발생할 수 있다. 질문이 모호하거나 복잡하면 응답자가 정확하게 이해하지 못하고 엉뚱한 답을 하거나, 기억에 의존해 부정확하게 응답하는 일이 생긴다. 때로는 사회적으로 바람직한 방향으로 응답하려는 경향도 나타난다. 좋은 설문지 지침은 이러한 오류를 줄이고, 응답의 일관성과 정확성을 높이는 데 기여한다.\n설문 설계의 품질이 높아지면 수집되는 데이터의 신뢰성과 타당성도 향상된다. 질문이 명확하고 체계적으로 구성되면, 응답자는 자신의 경험이나 생각을 보다 정확하게 반영할 수 있다. 이로 인해 연구자는 실제 현상을 왜곡 없이 분석할 수 있고, 결과 해석의 정확도도 높아진다.\n응답자의 입장에서 보면, 질문이 명확하고 간결할수록 설문을 보다 수월하게 작성할 수 있다. 반대로 질문이 길거나 복잡하면 응답 피로도가 높아지고, 설문을 끝까지 완료하지 않거나 무성의한 답변을 하게 될 위험이 커진다. 잘 구성된 설문지는 응답 부담을 낮추고, 자연스럽게 높은 응답률을 유도할 수 있다.\n응답률이 높아지면 결과의 대표성도 향상된다. 이는 곧 전체 모집단을 보다 정확하게 반영하는 데이터 확보로 이어진다. 반면, 난해하거나 민감한 질문이 많을 경우 응답자가 중도에 설문을 포기할 수 있으므로, 질문 구성과 배열에도 세심한 주의가 필요하다.\n설문으로 수집된 자료는 다양한 분석과 의사결정에 활용된다. 그러나 질문이 잘못 설계되면 데이터가 왜곡되고, 결과적으로 잘못된 판단이나 정책으로 이어질 수 있다. 따라서 질문은 연구 목적에 부합하도록 설계되어야 하며, 타당하고 신뢰할 수 있는 해석이 가능하도록 구성되어야 한다.\n또한 설문 문항의 성격에 따라 적절한 접근 방식이 필요하다. 예를 들어, 행동을 묻는 질문은 구체적인 시점이나 상황을 제시해야 하며, 태도를 측정하는 질문은 명확한 척도와 함께 제시되어야 한다. 민감한 주제를 다룰 경우에는 응답자의 익명성과 프라이버시를 충분히 고려해야 한다. 질문 유형에 따라 각각 다른 원칙과 기법을 적용해야 하며, 이를 위해 명확한 설문지 작성 지침이 필요하다.\n설문조사는 종종 연구 결과나 정책 제안서, 또는 기업 보고서에 인용된다. 따라서 설문 설계가 과학적이고 체계적이지 않다면 결과의 신뢰성이 떨어지고, 해당 결과를 활용하는 다양한 이해관계자들에게 부정적인 영향을 미칠 수 있다. 설문지 작성 지침은 단순히 문항을 구성하는 기술적 매뉴얼을 넘어, 설문 연구의 품질을 결정짓는 핵심 요소라 할 수 있다.\n\n1. 행동문항과 태도 문항\n개념적 차이\n\n\n\n\n\n\n\n\n구분\n행동 behavior 문항\n태도 attitude 문항\n\n\n정의\n응답자의 실제 경험이나 행동을 측정하는 질문\n응답자의 신념, 가치관, 감정, 의견 등을 측정하는 질문\n\n\n목적\n특정 행동을 수행한 빈도, 시기, 방식 등을 파악\n특정 주제에 대한 태도나 선호도를 측정\n\n\n측정 대상\n객관적이고 구체적인 행동(실제 경험)\n주관적인 인식, 감정, 의견\n\n\n기록 방식\n응답자가 직접 보고한 행동(예: 구매경험, 운동빈도 등)\n응답자의 심리적 상태, 선호도 등을 측정\n\n\n\n측정방법 차이\n\n\n\n\n\n\n\n\n측정 방법\n행동 문항\n태도 문항\n\n\n자기보고\n응답자가 직접 자신의 행동을 보고\n응답자가 자신의 의견을 보고\n\n\n행동 기록\n응답자가 일정 기간 동안 행동을 기록 (예: 음식섭취 일기)\n해당 없음\n\n\n관찰법\n연구자가 직접 응답자의 행동을 관찰 (예: 실제 투표 여부 확인)\n연구자가 응답자 태도를 직접 측정할 수 없음\n\n\n반응 척도\n행동 횟수, 빈도를 정량적으로 측정 (예: '한 달에 5회 이상')\nLikert 척도, 시각적 아날로그 척도 등을 사용하여 태도를 정량적으로 측정\n\n\n\n활용방안\n\n\n\n\n\n\n\n\n연구 목적\n행동 문항\n태도 문항\n\n\n실제 행동 측정\n응답자가 특정 행동을 수행했는지 확인할 때\n해당 없음\n\n\n정책 평가\n정책이 실제 행동 변화에 영향을 미쳤는지 측정할 때\n정책에 대한 인식을 평가할 때\n\n\n소비자 조사\n제품 구매 빈도, 사용 습관 측정\n브랜드 선호도, 만족도 평가\n\n\n건강 연구\n운동, 식습관, 흡연여부 조사\n건강에 대한 인식, 위험에 대한 태도 측정\n\n\n\n설문 조사에서 행동 문항과 태도 문항은 서로 다른 목적과 특성을 지니며, 응답 방식이나 인식에도 차이가 있다. 행동 문항은 응답자의 실제 경험이나 행위를 측정하는 데 중점을 두며, 객관적인 데이터를 수집하는 데 적합하다. 반면 태도 문항은 특정 주제에 대한 신념, 감정, 의견을 평가하는 데 활용되며, 응답자의 주관적인 인식을 파악하는 데 유리하다.\n행동 문항은 특정 행동이 언제, 얼마나 자주, 어떤 방식으로 이루어졌는지를 묻는 것이 일반적이다. 예를 들어, “지난 한 달 동안 커피를 몇 번 구매하셨습니까?“와 같은 질문은 실제 경험을 기반으로 한 응답을 이끌어내기 위한 전형적인 행동 문항이다. 이에 비해, “당신은 커피를 마시는 것이 건강에 좋다고 생각하십니까?“는 응답자의 생각이나 판단을 묻는 태도 문항에 해당한다.\n행동 문항은 실재 경험에 기초하기 때문에 응답의 객관성이 상대적으로 높을 수 있지만, 응답자가 모든 경험을 정확히 기억하지 못할 가능성도 고려해야 한다. 예를 들어, “지난 6개월 동안 술을 얼마나 자주 마셨습니까?“와 같은 질문에서는 과거나 현재의 행동을 과장하거나 축소해 응답하는 경향이 나타날 수 있다. 반대로, 태도 문항은 응답자의 감정 상태나 환경적 요인에 따라 동일한 질문에도 답변이 달라질 수 있다. “술을 마시는 것이 사회적 관계에 도움이 된다고 생각하십니까?“라는 질문은 개인의 가치관에 따라 매우 다른 반응이 나올 수 있다.\n두 문항 유형은 질문 구성 방식에서도 차이를 보인다. 행동 문항은 구체적인 시간 범위와 빈도를 포함해야 응답자가 명확하게 답할 수 있다. 예를 들어, “최근에 운동한 적이 있습니까?“는 다소 모호한 반면, “지난 7일 동안 30분 이상 운동한 날이 며칠입니까?“는 보다 구체적인 정보를 요구하여 응답의 정확성을 높일 수 있다. 태도 문항은 주로 Likert 척도와 같은 평가 척도를 활용하여 응답자의 생각이나 입장을 수치화할 수 있도록 설계된다. 예를 들어, “당신은 정부의 환경 보호 정책을 얼마나 지지하십니까?“라는 문항은 5점 또는 7점 척도를 통해 응답을 정량화할 수 있다.\n행동 문항을 설계할 때는 응답자가 기억하기 쉬운 시간 기준을 사용하는 것이 중요하다. “지난 1년 동안 해외여행을 몇 번 다녀오셨습니까?“보다 “2024년 1월 이후 해외여행을 몇 번 다녀오셨습니까?“와 같이 명확한 시점을 제시하면 보다 정확한 응답을 유도할 수 있다. 또한, 행동 문항의 신뢰도를 높이기 위해 영수증, 일정표 등 실제 자료를 참조하도록 안내하는 것도 좋은 방법이다.\n태도 문항에서는 사회적 바람직성 편향을 줄이는 것이 중요하다. 예를 들어, “당신은 환경 보호를 중요하게 생각하십니까?“와 같은 질문은 응답자가 사회적으로 바람직한 방향으로 답할 가능성이 높다. 이때, “최근 6개월 동안 환경 보호를 위해 어떤 행동을 하셨습니까?“와 같이 구체적인 행동을 확인할 수 있는 보조 문항을 추가하면 응답의 신뢰도를 높일 수 있다. 또한, 태도 문항은 앞뒤 문항의 영향을 받을 수 있으므로, 설문지의 흐름과 문항 배열에도 주의를 기울여야 한다.\n행동 문항과 태도 문항은 연구 목적에 따라 적절히 선택하여 사용해야 한다. 행동 문항은 실제 행위를 파악하는 데 적합하여 정책 효과 분석, 소비 패턴 연구, 건강 행동 연구 등에 활용된다. 예를 들어, “지난 선거에서 투표를 하셨습니까?“와 같은 문항은 실제 참여 여부를 측정할 수 있다. 반면, 태도 문항은 개인의 가치관이나 인식을 이해하는 데 유용하며, 사회 문제 인식 조사나 브랜드 이미지 조사 등에 자주 사용된다. 예를 들어, “당신은 선거 참여가 중요하다고 생각하십니까?“는 정치적 태도를 분석하는 데 적합한 문항이다.\n이처럼 행동 문항과 태도 문항은 각기 다른 역할을 수행하며, 상황에 맞게 잘 설계되었을 때 설문조사의 타당성과 신뢰도를 크게 높일 수 있다.\n\n\n2. 행동문항: 민감하지 않은 질문\n민감하지 않은 질문이라 하더라도, 응답자의 기억력에 한계가 있을 수 있기 때문에 보다 정확하고 신뢰성 높은 데이터를 얻기 위해서는 설문 설계 시 세심한 전략이 필요하다. 특히, 응답자가 질문을 혼동하지 않도록 질문을 구체적이고 명확하게 제시하고, 필요한 경우 과거의 기억을 떠올릴 수 있도록 돕는 자극 요소를 함께 제공하는 것이 효과적이다.\n예를 들어, 특정 시기나 사건을 기준으로 삼아 질문을 제시하거나, 응답자가 참고할 수 있는 일정표, 영수증, 가계부 등과 같은 보조 자료를 활용하도록 유도하면 기억에 의존한 응답의 정확도를 크게 높일 수 있다. 이처럼 응답자의 회상을 돕는 다양한 도구와 설계 기법을 적용함으로써, 사소하거나 잊기 쉬운 정보에 대해서도 신뢰할 수 있는 응답을 이끌어낼 수 있다.\n폐쇄형 질문에서는 모든 합리적인 가능성을 응답 보기에 포함할 것\n폐쇄형 질문(closed-ended questions)은 응답자가 자유롭게 서술하기보다, 미리 제시된 선택지 중에서 가장 적절하다고 생각되는 답을 고르도록 설계된 질문 유형이다. 이러한 질문은 응답 결과를 정량적으로 분석하기 용이하다는 장점이 있으며, 조사자 간의 해석 차이나 데이터 정제 과정의 오류를 줄이는 데도 유리하다.\n하지만 응답자가 자신의 경험과 가장 일치하는 선택지를 찾을 수 있도록, 가능한 모든 합리적 응답 옵션이 빠짐없이 포함되어야 한다. 예를 들어, “지난 한 달 동안 외식한 횟수는?”이라는 질문을 제시할 때, 보기로는 0회, 1–2회, 3–4회, 5회 이상과 같이 모든 응답 범주를 포괄할 수 있어야 하며, 누락되거나 겹치는 구간이 없어야 한다. 이렇게 구성된 질문은 응답자의 선택을 쉽게 하고, 결과 해석의 명확성도 높여준다.\n질문을 가능한 한 구체적으로 만들 것\n질문이 모호하게 제시되면, 응답자는 각자의 경험과 기준에 따라 질문을 다르게 해석하게 되고, 그 결과 응답의 일관성과 비교 가능성이 떨어질 수 있다. 예를 들어, “운동을 얼마나 자주 하십니까?”라는 질문은 매우 일반적이고 추상적인 표현이기 때문에, 어떤 사람은 일주일에 한두 번 하는 것을 ’자주’라고 생각할 수 있고, 또 다른 사람은 하루에 한 번 이상 해야 ’자주’라고 느낄 수 있다. 이처럼 해석의 기준이 응답자마다 다를 경우, 수집된 데이터의 정확성과 신뢰성이 저하될 수 있다.\n따라서 질문은 응답자가 같은 기준으로 이해하고 답변할 수 있도록 구체적이고 명확하게 설계하는 것이 중요하다. 예컨대, “지난 7일 동안 30분 이상 신체 활동을 한 날은 며칠입니까?”처럼 시간 범위와 활동 기준을 함께 제시하면, 응답자는 자신의 경험을 보다 정확하게 회상하고 일관된 기준에 따라 응답할 수 있다. 이와 같은 질문 설계는 응답 해석의 차이를 줄이고 데이터 품질을 높이는 데 효과적이다.\n거의 모든 응답자가 이해할 수 있는 단어를 사용할 것\n설문 문항에 전문 용어나 지나치게 어려운 단어가 포함되면, 응답자가 질문의 의미를 정확히 이해하지 못하고 의도와 다른 답변을 할 가능성이 높아진다. 이는 특히 일반 대중을 대상으로 한 조사에서 자주 발생할 수 있으며, 데이터의 신뢰도와 해석의 정확성을 크게 떨어뜨릴 수 있다.\n예를 들어, “귀하는 주간 단위로 주거 이동을 하나요?”라는 문장은 일부 응답자에게 생소하거나 난해하게 느껴질 수 있다. 반면, 같은 내용을 보다 쉽게 표현한 “한 주 동안 다른 곳에서 머문 적이 있나요?”라는 문장은 일상적인 언어를 사용해 응답자가 질문을 명확히 이해하고 답할 수 있도록 돕는다.\n또한, 문화적 배경에 따라 다르게 해석될 수 있는 단어나 표현은 가급적 피해야 한다. 특정 지역이나 계층에서만 통용되는 표현은 설문 대상자 전체에게 일관된 이해를 제공하기 어렵기 때문이다. 따라서 모든 응답자가 비슷한 방식으로 해석할 수 있도록, 쉬운 언어로 표현하고 문화적 중립성을 유지하는 것이 설문 문항 설계의 기본 원칙 중 하나이다.\n기억을 향상시키기 위해 기억 단서를 추가하여 질문을 길게 만들 것\n응답자가 과거의 특정 사건을 정확히 기억해내기 어려운 경우, 질문에 기억을 자극하는 단서를 함께 제공하면 응답의 정확성을 높일 수 있다. 사람들은 일상적으로 경험한 사건이라 하더라도 시간이 지나면 세부 내용을 잊어버릴 수 있으며, 특히 빈도가 낮거나 중요도가 높지 않은 사건일수록 그 경향이 뚜렷하다.\n예를 들어, “지난 6개월 동안 해외여행을 다녀온 적이 있습니까?”라는 질문은 포괄적으로 보일 수 있으나, 응답자가 기억하지 못한 경험을 빠뜨릴 가능성이 있다. 이때 “업무 출장, 가족여행, 친구와의 여행, 유학 등 포함”과 같이 다양한 유형의 여행 사례를 함께 제시하면, 응답자가 자신의 경험을 더 쉽게 회상할 수 있고, 누락 없이 답변할 가능성이 높아진다.\n이러한 방식은 질문을 보다 구체적이고 현실적인 맥락 안에서 이해하도록 도와주며, 결과적으로 설문 데이터의 질을 향상시키는 데 기여한다.\n잊어버릴 가능성이 높을 때는 도움 회상을 사용할 것\n사람들은 일상에서 다양한 경험을 하며, 그중 일부는 시간이 지나면서 자연스럽게 잊혀질 수 있다. 특히 자주 발생하지 않거나 특별히 주의를 기울이지 않았던 사건에 대해서는 기억이 흐릿해지기 쉽다. 이러한 경우, 설문에서 정확한 정보를 얻기 위해서는 응답자의 기억을 돕는 회상 기법을 적절히 활용하는 것이 필요하다.\n예를 들어, “지난 3개월 동안 병원에 방문한 적이 있습니까?”라는 질문에 응답자가 확실하게 기억하지 못하는 상황이 있을 수 있다. 이럴 때 “가족 병원 방문, 정기 건강검진, 치과 진료, 응급실 방문 포함”과 같이 구체적인 사례나 유형을 제시하면, 응답자가 해당 경험을 떠올리는 데 도움이 되며, 그 결과 더 정확하고 신뢰할 수 있는 응답을 얻을 수 있다.\n이러한 회상 자극은 응답 누락이나 부정확한 답변을 줄이는 데 효과적이며, 설문조사 데이터의 품질을 높이는 중요한 전략 중 하나로 활용될 수 있다.\n빈번하지만 크게 중요하지 않은 경우, 응답자가 일지를 작성 유도\n일상에서 자주 일어나지만 중요도가 낮아 쉽게 잊히는 행동이나 사건에 대해서는, 설문 시 응답의 정확성을 확보하기가 쉽지 않다. 예를 들어, 간식 섭취, 대중교통 이용, 소액 지출 등은 자주 일어나지만 응답자가 구체적으로 기억하지 못할 가능성이 크다. 이런 경우에는 사전에 기록을 남기도록 안내함으로써, 설문 시 보다 정확한 정보를 제공받을 수 있다.\n예를 들어, 조사 시작 전 일정 기간 동안 응답자에게 간단한 일지나 체크리스트를 작성하도록 요청하면, 특정 행동에 대한 기억을 체계적으로 보존할 수 있다. 매일 섭취한 음식, 사용한 교통수단, 지출한 항목 등을 기록하게 하면, 설문조사 시 응답자는 이를 참고해 보다 정확한 응답을 제공할 수 있으며, 조사 결과의 신뢰성과 정밀도도 함께 향상된다.\n이러한 사전 기록 활용은 조사 대상의 특성에 따라 유연하게 적용할 수 있으며, 특히 생활습관, 소비행동, 건강 관련 조사의 정밀도를 높이는 데 유용한 방법이다.\n긴 회상 기간이 필요한 경우, 생애 사건 달력을 사용 권장\n조사에서 긴 기간에 걸친 기억을 회상해야 할 때는, 응답자의 기억이 흐릿해져 정확한 응답을 기대하기 어려운 경우가 많다. 예를 들어, 지난 1년간의 의료 이용 횟수처럼 시간적 범위가 길고 사건의 발생 시점이 분산된 경우, 응답자는 정확한 시기를 떠올리기 어려울 수 있다. 이런 경우에는 생애 사건 달력(life event calendar)과 같은 도구를 활용하여 응답자의 기억을 자극하는 것이 효과적이다.\n예를 들어, “작년 초에 병원에 간 적이 있나요?”처럼 막연한 시기를 제시하기보다는 “설 연휴 이후, 여름휴가 기간, 추석 이후에 병원에 방문한 적이 있나요?”처럼 사회적으로 널리 인식되는 기준 시점을 활용하면, 응답자가 과거 경험을 특정 시점에 연결해 더 정확하게 회상할 수 있다.\n이러한 방식은 단순한 시간 기준보다 현실적인 단서를 제공하기 때문에, 장기 회상이 필요한 설문조사에서 응답 오류를 줄이고, 데이터의 정확성과 신뢰성을 높이는 데 효과적인 전략이 될 수 있다.\n망원경 오류를 줄이기 위해 응답자가 가계 기록을 사용\n망원경 오류는 사람들이 실제 사건이 발생한 시기를 정확히 기억하지 못하고, 과거의 일을 더 최근의 일로 기억하거나, 반대로 최근에 일어난 일을 오래전에 있었던 일로 착각하는 현상을 의미한다. 이러한 오류는 특히 회상 기간이 길거나 사건이 반복적으로 발생했을 때 자주 나타나며, 응답 데이터의 시점 정확도를 떨어뜨릴 수 있다.\n이러한 오류를 줄이기 위해서는 응답자가 자신이 경험한 사건의 시점을 보다 명확히 인식할 수 있도록 도와주는 전략이 필요하다. 예를 들어, 설문 응답 시 영수증, 일정표, 가계부 등과 같은 실제 기록을 참고하도록 유도하면, 응답자가 막연한 기억에 의존하지 않고 보다 구체적인 정보를 제공할 수 있게 된다.\n또한, 명확한 시간 기준을 제시하는 경계 회상 기법을 함께 활용하면 효과적이다. “올해 1월 1일 이후”나 “2024년 7월 이후”와 같은 기준점을 제공하면, 응답자는 해당 시점을 중심으로 기억을 정리하고 보다 정확한 시기 판단을 할 수 있어, 전체적인 응답 오류를 줄이는 데 도움이 된다.\n비용이 문제가 되는 경우, 대리 응답자를 활용할 것\n설문조사에서 응답자의 기억이 부정확하거나, 조사 비용과 시간을 절감할 필요가 있을 때는 해당 정보를 더 잘 알고 있는 대리 응답자(proxy respondent)를 통해 답변을 받는 방법을 사용할 수 있다. 이는 특히 가구 단위 조사나 조직 내부 조사의 경우에 효과적인 전략으로, 일부 응답자가 세부적인 내용을 정확히 기억하지 못할 때 유용하게 활용된다. 예를 들어, 가계 소비 조사에서 가족 구성원이 자신의 지출 내역을 잘 기억하지 못할 경우, 가계 예산을 실제로 관리하고 있는 가족 구성원이 다른 구성원을 대신해 응답함으로써 전체적인 소비 정보를 보다 정확하게 수집할 수 있다.\n하지만 대리 응답 방식은 정보의 정확성을 담보하지 않는 한계도 함께 내포하고 있다. 대리 응답자가 실제로 얼마나 정확한 정보를 알고 있는지를 검토하는 과정이 병행되어야 하며, 경우에 따라 보완 질문이나 확인 절차가 필요할 수 있다. 만약 대리 응답자가 본인의 추측에 근거해 답변하거나 일부 정보만 알고 있는 상태라면, 수집된 데이터의 신뢰성과 타당성이 낮아질 수 있다. 따라서 대리 응답은 신중하게 적용되어야 하며, 응답의 품질을 확보하기 위한 장치도 함께 고려해야 한다.\n\n\n3. 행동문항: 민감한 질문\n민감한 질문을 포함하는 설문조사에서는 응답자의 심리적 불편함이나 저항감을 최소화하는 것이 매우 중요하다. 응답자가 부담을 느끼거나 불안감을 갖게 되면 질문에 대해 회피하거나 왜곡된 정보를 제공할 가능성이 높아지기 때문이다. 이러한 문제를 줄이기 위해, 질문을 보다 중립적인 언어로 표현하거나, 간접적인 방식으로 묻는 전략을 사용할 수 있다. 또한, 응답의 익명성과 비밀 보장이 철저히 이루어진다는 점을 사전에 안내하면, 응답자가 보다 솔직하게 자신의 생각이나 경험을 공유할 가능성이 높아진다.\n이와 함께, 응답의 신뢰도를 높이기 위한 다양한 보완 기법을 활용하는 것도 중요하다. 예를 들어, 민감한 문항을 설문지 후반부에 배치하거나, 자기기입 방식 또는 전산화된 응답 시스템을 도입하면 응답자가 심리적 부담 없이 답할 수 있는 환경을 조성할 수 있다. 이러한 전략을 적절히 적용하면 민감한 주제에 대해서도 보다 정밀하고 신뢰할 수 있는 데이터를 수집할 수 있으며, 이는 궁극적으로 연구의 타당성과 정책 수립의 실효성을 높이는 데 기여할 수 있다.\n민감한 행동의 빈도를 파악할 때 개방형 질문을 사용할 것\n민감한 행동에 대해 질문할 때, 응답자에게 정해진 선택지를 고르게 하기보다 스스로 자유롭게 경험을 서술할 수 있는 기회를 제공하면, 응답의 진실성과 정확성을 높일 수 있다. 폐쇄형 질문은 응답자의 민감함을 자극하거나 방어적인 태도를 유발할 수 있지만, 개방형 질문은 보다 편안한 분위기에서 자신의 경험을 표현하게 하여 왜곡 가능성을 줄여준다.\n예를 들어, “지난 6개월 동안 몇 번 음주했습니까?”라고 직접적으로 횟수를 묻는 대신, “지난 6개월 동안 음주한 경험에 대해 설명해 주세요.”와 같이 질문을 보다 개방적이고 서술적으로 제시하면, 응답자는 스스로 기억을 떠올리며 자신의 상황에 맞게 보다 자연스럽고 솔직한 답변을 할 가능성이 높다. 이러한 방식은 특히 민감하거나 사적인 영역의 행동을 조사할 때 유용하며, 응답의 신뢰도를 높이는 데 도움이 된다.\n짧은 질문보다는 긴 질문을 사용할 것\n짧고 간단한 질문은 응답자의 이해를 돕는 데 효과적일 수 있지만, 경우에 따라 오해를 불러일으키거나 질문의 의도를 제대로 전달하지 못할 위험도 함께 존재한다. 특히 민감하거나 구체적인 행동을 묻는 경우, 질문이 지나치게 간단하면 응답자가 질문의 범위나 맥락을 정확히 이해하지 못해 부정확한 답변을 할 가능성이 높아진다.\n이런 경우에는 보다 긴 문장을 사용해 질문의 맥락과 내용을 구체적으로 설명하는 것이 바람직하다. 예를 들어, 단순히 “마약을 사용한 적이 있습니까?”라고 묻는 것보다, “지난 12개월 동안 의사의 처방 없이 마약(예: 코카인, 대마초, 헤로인 등)을 사용한 적이 있습니까?”처럼 질문의 범위, 기간, 예시를 명확히 제시하면, 응답자는 질문을 보다 정확하게 이해하고 신중하게 답할 수 있다. 이는 설문 데이터의 신뢰성과 해석 가능성을 높이는 데도 도움이 된다.\n민감한 행동을 설명할 때 익숙한 단어를 사용할 것\n설문 문항을 작성할 때는 응답자가 쉽게 이해할 수 있는 일상적인 단어를 사용하는 것이 기본이다. 전문 용어나 생소한 표현은 혼란을 줄 수 있고, 특히 민감한 주제의 경우 단어 선택이 응답자의 심리적 저항을 유발할 수 있다. 따라서 가능하면 응답자가 익숙하게 받아들일 수 있는 언어로 질문을 구성해야 한다.\n예를 들어, “음주 습관”이라는 표현은 다소 공식적이고 평가적인 뉘앙스를 줄 수 있지만, “술을 마신 경험”이라는 표현은 보다 자연스럽고 부담 없이 받아들여질 수 있다. 마찬가지로, “불법 약물 사용”이라는 표현은 응답자에게 심리적 압박을 줄 수 있는 반면, “기분 전환을 위한 약물 복용”처럼 완화된 표현을 사용하면 보다 솔직한 응답을 유도하는 데 도움이 된다. 이러한 언어적 배려는 응답자의 거부감을 줄이고, 설문 응답의 질을 높이는 데 중요한 역할을 한다.\n허위 응답을 줄이기 위해 의도적으로 질문을 구성할 것\n민감한 주제를 다룰 때는 응답자가 정직하게 답할 수 있도록 질문을 신중하게 구성하는 것이 매우 중요하다. 질문이 너무 직설적이거나 판단적인 어투를 담고 있으면, 응답자는 심리적으로 위축되거나 방어적인 태도를 보일 수 있으며, 이로 인해 정확한 정보를 얻기 어려워질 수 있다.\n예를 들어, “당신은 불법적으로 마약을 사용한 적이 있습니까?”처럼 직접적이고 비판적으로 들릴 수 있는 질문보다는, “많은 사람들이 스트레스 해소를 위해 마약을 사용합니다. 당신은 지난 6개월 동안 마약을 사용한 경험이 있습니까?”처럼 사회적 낙인을 완화하는 문구를 함께 제시하면, 응답자는 자기 행동에 대해 덜 비난받는다고 느끼고 보다 솔직하게 답변할 가능성이 높아진다. 이러한 접근은 민감한 정보의 응답률과 정확도를 높이는 데 효과적인 전략이 된다.\n과거의 먼 시점을 먼저 질문할 것\n민감한 주제를 다룰 때는 질문의 순서를 전략적으로 구성하는 것이 응답자의 부담을 줄이는 데 도움이 된다. 특히 최근의 행동이나 경험을 곧바로 묻는 것보다는, 비교적 덜 민감하게 느껴질 수 있는 과거의 경험부터 질문을 시작하는 것이 효과적이다. 이를 통해 응답자는 민감한 주제에 대해 심리적으로 준비할 시간을 갖고, 점진적으로 질문에 익숙해질 수 있다.\n예를 들어, “지난 1년 동안 도박을 한 적이 있습니까?”라고 바로 묻기보다는, “어릴 때 가족이나 친구들과 함께 카지노나 내기 게임을 한 경험이 있습니까?”와 같이 과거의 경험을 먼저 묻는 방식이 응답자의 방어심을 낮추는 데 도움이 된다. 이렇게 점진적인 질문 흐름을 구성하면, 이후 보다 민감한 질문에 대해서도 응답자가 부담을 덜 느끼고 정직하게 답변할 가능성이 높아진다.\n민감한 질문을 다른 민감한 항목들 사이에 포함\n민감한 질문을 설문에 포함시킬 때는, 응답자가 해당 질문을 특별히 부담스럽게 느끼지 않도록 질문의 배치 순서와 문맥을 신중하게 설계하는 것이 중요하다. 민감한 문항이 갑작스럽게 등장하면 응답자가 방어적인 태도를 보이거나 응답을 회피할 수 있으므로, 주변 질문들과의 자연스러운 연결을 통해 해당 문항이 눈에 띄지 않도록 하는 전략이 필요하다.\n예를 들어, 음주에 관한 질문을 직접적으로 제시하기보다 “평소에 즐겨 마시는 음료는 무엇인가요?”, “지난 한 달 동안 커피를 얼마나 자주 마셨습니까?”와 같은 일반적인 음료 소비 질문들과 함께 배치하고, 그 중 하나로 “지난 한 달 동안 술을 얼마나 자주 마셨습니까?”를 포함시키면, 응답자는 해당 질문을 덜 민감하게 느끼고 자연스럽게 답변할 가능성이 높아진다. 이러한 배치는 설문 흐름의 부드러움을 유지하면서도 응답의 신뢰도를 높이는 데 도움이 된다.\n자기기입 방식 또는 유사한 방법을 사용할 것\n민감한 주제를 다루는 설문에서는 응답 환경이 응답의 정확도에 큰 영향을 미친다. 특히 조사원이 직접 질문을 제시하는 면접 방식에서는, 응답자가 타인의 시선을 의식해 솔직하게 답변하지 않거나, 사회적으로 바람직한 방향으로 응답을 왜곡할 가능성이 높다. 이러한 경우 조사 방식 자체가 심리적 장벽이 되어 응답의 질을 저하시킬 수 있다.\n이러한 문제를 줄이기 위해, 응답자가 스스로 질문에 답하는 자기기입 방식이 효과적으로 활용된다. 예를 들어, 온라인 설문조사, 컴퓨터를 이용한 자기기입식 조사(CASI), 종이 설문지를 활용한 자기기입식 방식 등은 조사원과의 직접적인 대면이 없기 때문에, 응답자가 보다 편안한 환경에서 자신의 경험이나 생각을 솔직하게 표현할 수 있게 해준다. 결과적으로 이러한 방식은 민감한 문항에 대한 응답률과 정확도를 높이는 데 유리하다.\n데이터를 수집할 때 일기 형식을 고려할 것\n민감한 행동에 관한 질문은 응답자가 의도적으로 왜곡된 정보를 제공하거나, 정확히 기억하지 못해 잘못된 응답을 하는 경우가 많다. 특히 음주, 흡연, 약물 사용, 성행동 등과 같이 사회적 평가와 관련된 주제는 응답자가 자신의 행동을 축소하거나 과장해서 보고할 가능성이 높다. 이로 인해 설문 데이터의 정확성과 신뢰도가 떨어질 수 있으며, 결과 해석에도 한계가 생긴다.\n이러한 문제를 보완하기 위한 방법으로, 응답자에게 일기 형식의 기록을 요청하는 전략이 효과적이다. 예를 들어, 음주 행동을 조사할 때 설문 이전 일정 기간 동안 매일 마신 술의 종류와 양을 직접 기록하도록 안내하면, 단 한 번의 회상에 의존하는 방식보다 훨씬 더 정밀하고 신뢰도 높은 정보를 확보할 수 있다. 이러한 방식은 특히 반복적이고 일상적인 행동을 측정할 때 유용하며, 민감한 주제에 대한 응답의 왜곡 가능성을 줄이는 데도 큰 도움이 된다.\n설문지의 끝부분에 응답 민감 항목에 대한 추가 문항 구성\n응답자가 설문에 답하는 과정에서 어떤 문항을 특히 민감하게 느꼈는지를 확인하는 것은, 전체 응답의 신뢰도를 높이고 설문 도구의 완성도를 향상시키는 데 도움이 된다. 민감한 질문에 대해 응답자가 실제로 어떤 수준의 불편함을 느꼈는지를 파악함으로써, 향후 설문 설계 시 해당 문항의 표현 방식이나 위치, 방식 등을 개선할 수 있는 근거 자료를 확보할 수 있다.\n예를 들어, 설문 마지막에 “설문에서 가장 대답하기 어려웠던 질문은 무엇이었습니까?”, “이 설문에서 불편함을 느낀 부분이 있다면 자유롭게 적어주세요”와 같은 질문을 추가하면, 응답자의 심리적 반응에 대한 피드백을 직접 수집할 수 있다. 이러한 정보를 바탕으로 민감도를 높이는 요소를 조정하거나 응답 환경을 개선하면, 이후 조사에서는 보다 솔직하고 신뢰성 높은 응답을 이끌어낼 수 있다.\n검증 데이터를 수집할 것\n설문조사를 통해 수집된 응답이 실제 행동이나 사실을 정확하게 반영하고 있는지를 확인하기 위해, 추가적인 검증 데이터를 함께 수집하는 것이 중요하다. 응답자는 무심코 기억을 잘못하거나, 사회적 압박으로 인해 의도적으로 사실을 왜곡할 수도 있기 때문에, 단지 설문 응답에만 의존하는 것은 데이터의 신뢰성을 저하시킬 위험이 있다.\n예를 들어, 음주 습관에 관한 조사를 실시할 때 응답자가 보고한 음주 빈도나 종류와 실제 구입 내역(예: 술 구매 영수증)을 비교하면, 응답의 정확성을 검토할 수 있다. 이러한 검증 절차는 조사 과정에서 발생할 수 있는 응답 오류나 왜곡을 줄이는 데 도움이 되며, 전체 조사 결과의 신뢰도와 타당성을 한층 높여준다. 경우에 따라 기록 자료, 관찰 데이터, 제3자의 보고 등 다양한 방식으로 보완 자료를 확보하는 것도 효과적인 전략이 될 수 있다.\n\n\n4. 태도문항\n태도의 대상을 명확하게 지정할 것\n태도 문항을 설계할 때는 응답자가 어떤 대상이나 상황에 대해 자신의 의견을 표현하는지 명확하게 이해할 수 있도록 질문을 구체적으로 구성하는 것이 중요하다. 질문이 모호하거나 지나치게 포괄적이면, 응답자는 각기 다른 해석을 바탕으로 답하게 되어 응답 간 비교가 어려워지고, 설문 결과의 타당성이 낮아질 수 있다.\n예를 들어, “환경 보호 정책에 대해 어떻게 생각하십니까?”라는 질문은 환경 문제 전반에 대한 광범위한 해석을 유도할 수 있어 응답자의 인식 차이를 제대로 반영하기 어렵다. 대신, “정부의 일회용 플라스틱 사용 제한 정책에 대해 어떻게 생각하십니까?”처럼 구체적인 정책이나 행동을 명시하면, 응답자는 보다 명확한 판단 기준에 따라 의견을 표현할 수 있게 된다. 이는 태도 측정의 정확도와 응답 해석의 일관성을 높이는 데 도움이 된다.\n이중 질문을 피할 것\n이중 질문(double-barreled question)은 하나의 문항에 두 개 이상의 서로 다른 개념이나 주제가 포함되어 있어, 응답자가 하나의 명확한 답변을 하기 어렵게 만드는 질문을 의미한다. 이러한 질문은 응답자의 의도를 정확히 파악하기 어렵게 만들고, 결과적으로 데이터의 신뢰성과 해석력을 떨어뜨리는 요인이 된다. 특히 응답자가 두 개의 주제에 대해 상반된 태도를 가지고 있을 경우, 어떤 부분에 대해 긍정 또는 부정을 표시했는지 명확히 알 수 없게 된다.\n예를 들어, “귀하는 정부의 환경 보호 정책과 경제 성장 전략을 지지하십니까?”라는 질문은 환경 보호 정책에는 찬성하지만 경제 성장 전략에는 반대하는 응답자에게 혼란을 줄 수 있다. 이 경우, “귀하는 정부의 환경 보호 정책을 지지하십니까?”와 “귀하는 정부의 경제 성장 전략을 지지하십니까?”처럼 각 개념을 별도의 문항으로 분리해 묻는 것이 바람직하다. 이를 통해 응답자는 각 항목에 대해 보다 정확하게 자신의 입장을 표현할 수 있으며, 조사자는 더 신뢰도 높은 자료를 확보할 수 있다.\n필요하다면 개별 문항을 사용하여 태도의 강도를 측정할 것\n태도 조사를 보다 정밀하게 수행하려면, 단순히 찬성이나 반대 여부만을 묻는 이분법적인 질문 방식에서 벗어나, 응답자의 태도 강도를 세분화하여 측정할 수 있는 척도를 사용하는 것이 중요하다. 찬성과 반대는 방향만을 나타낼 뿐, 그 정도나 확신의 수준을 반영하지 못하므로, 응답자의 입장을 충분히 해석하는 데 한계가 있을 수 있다.\n예를 들어, “귀하는 이 정책에 찬성하십니까?”처럼 단순하게 묻는 대신, “귀하는 이 정책을 얼마나 강하게 찬성 또는 반대하십니까?”와 같은 질문을 제시하고, ‘매우 찬성’, ‘약간 찬성’, ‘중립’, ‘약간 반대’, ‘매우 반대’ 등으로 구성된 리커트 척도를 활용하면, 응답자의 태도를 더 구체적이고 정량적으로 파악할 수 있다. 이러한 방식은 정책 수립이나 여론 분석 시 보다 섬세한 해석과 비교를 가능하게 하며, 태도 연구의 질을 높이는 데 기여한다.\n주요 정보를 놓칠 가능성이 있는 경우 제외하고 양극 항목을 사용할 것\n양극 항목(bipolar scale)은 응답자가 긍정적인 평가와 부정적인 평가 중에서 자신의 생각에 가장 가까운 선택지를 고를 수 있도록, 양쪽 극단을 모두 포함하는 응답 척도를 의미한다. 이러한 척도는 응답자의 태도 강도와 방향을 함께 파악할 수 있다는 점에서 유용하며, 태도의 분포나 변화 정도를 정밀하게 분석하는 데 적합하다. 예를 들어, “귀하는 정부의 환경 보호 정책을 얼마나 효과적이라고 생각하십니까?”라는 질문에 대해 ‘매우 효과적이다’, ‘효과적이다’, ‘보통이다’, ‘효과적이지 않다’, ’전혀 효과적이지 않다’처럼 긍정에서 부정까지 연속적인 범위를 제공하면, 다양한 응답자의 입장을 반영할 수 있다.\n그러나 모든 상황에서 양극 항목이 반드시 적절한 것은 아니다. 특정 문항에서는 응답자가 명확하게 긍정적인 방향에서만 평가하도록 유도하거나, 중립적인 선택지가 불필요한 경우도 있을 수 있다. 반대로, 중립적 입장을 유지하고자 하는 응답자를 위해 ‘보통이다’ 혹은 ’잘 모르겠다’와 같은 응답 옵션을 제공하는 것이 적절할 때도 있다. 따라서 척도의 구성은 조사 목적과 문항의 성격에 따라 신중하게 조정되어야 하며, 응답자가 자신의 의견을 왜곡 없이 표현할 수 있도록 돕는 방향으로 설계해야 한다.\n응답 보기는 응답 가능한 선택을 모두 포함하고 있어야 한다.\n설문에서 제시하는 응답 옵션은 응답자의 선택에 직접적인 영향을 미치기 때문에, 옵션의 구성은 질문의 신뢰성과 타당성을 좌우하는 중요한 요소가 된다. 응답자가 자신의 상황에 맞는 선택지를 찾지 못하면, 임의로 가장 가까운 항목을 선택하거나 응답을 포기할 수 있으며, 이는 데이터의 왜곡이나 누락으로 이어질 수 있다. 따라서 응답 항목은 가능한 현실적인 대안을 충분히 반영하도록 신중하게 설계되어야 한다.\n예를 들어, “귀하는 주로 어떤 교통수단을 이용합니까?”라는 질문에 ’자전거 — 버스 — 지하철 — 자동차’만 제시된다면, 실제로 기차나 도보를 주로 이용하는 사람은 자신의 경험과 일치하는 응답을 선택하기 어렵다. 이런 경우를 대비해 가능한 교통수단을 포괄적으로 포함하거나, “기타 (직접 입력)” 항목을 함께 제공하면, 응답자의 다양성을 반영하고 데이터의 완전성을 높이는 데 도움이 된다. 응답 옵션 설계 시 응답자의 입장에서 선택 가능성을 충분히 고려하는 것이 바람직하다.\n시간에 따른 변화를 측정할 때는 매번 동일한 질문을 사용할 것\n시간의 흐름에 따른 태도 변화를 측정할 때는, 동일한 질문에 대해 시점만 다르게 반복해 물어야 비교가 가능한 데이터가 수집된다. 질문의 문구나 표현 방식이 달라지면, 응답자는 각 질문을 다르게 해석할 수 있고, 그로 인해 실제 태도 변화가 아닌 질문 형식의 차이로 인해 응답 결과가 달라질 수 있다. 이는 설문조사의 신뢰성과 해석 가능성을 떨어뜨리는 주요한 원인이 된다.\n예를 들어, “지난해 환경 보호 정책에 대한 귀하의 태도는 어땠습니까?”와 “올해 환경 보호 정책에 대한 귀하의 태도는 어떻습니까?”는 내용상 유사해 보이지만, 질문의 표현 방식이나 문장 구조가 달라지면 응답자가 미묘하게 다르게 이해할 수 있다. 따라서 시계열 조사나 반복 조사에서는 질문의 문구를 가능한 한 동일하게 유지해야 하며, 시점 외에는 다른 요소를 바꾸지 않도록 주의함으로써 신뢰도 높은 비교가 가능하도록 해야 한다.\n일반적인 질문을 구체적인 질문보다 먼저 제시할 것\n응답자의 인식을 보다 체계적으로 평가하기 위해서는 질문의 흐름을 논리적이고 점진적으로 구성하는 것이 중요하다. 특히 태도나 가치관과 관련된 질문에서는, 일반적인 개념에 대한 인식을 먼저 확인한 후 점차 구체적인 사례나 정책으로 좁혀가는 방식이 효과적이다. 이러한 구조는 응답자가 자신의 생각을 정리하고, 보다 일관된 기준에 따라 질문에 답하도록 유도하는 데 도움이 된다.\n예를 들어, “귀하는 환경 보호가 중요하다고 생각하십니까?”와 같은 일반적인 질문을 먼저 제시한 다음, “귀하는 정부의 일회용 플라스틱 제한 정책에 대해 어떻게 생각하십니까?”처럼 특정 정책이나 사례에 대한 질문으로 이어지면, 응답자는 자연스러운 사고 흐름에 따라 자신의 입장을 보다 명확히 표현할 수 있다. 이와 같은 질문 배치는 응답의 품질을 높이고, 조사 결과의 해석력과 타당성을 향상시키는 데 기여한다.\n여러 항목을 질문을 할 때는 가장 덜 인기 있는 항목부터 시작할 것\n응답자가 설문에서 여러 주제에 대해 연속적으로 답변해야 하는 경우, 항목의 제시 순서가 응답의 집중도와 내용에 영향을 줄 수 있다. 특히 항목 간 중요도나 관심도의 차이가 클 경우, 응답자는 처음 제시된 항목에만 주의를 집중하고 뒤에 나오는 항목에는 상대적으로 덜 신중하게 답할 수 있다. 이를 방지하고 전체 응답 품질을 높이기 위해서는 일반적으로 중요도가 낮거나 덜 알려진 항목을 먼저 제시하는 것이 바람직하다.\n예를 들어, “귀하는 환경 보호 정책 중 어떤 부분을 가장 중요하다고 생각하십니까?”라는 질문에서 응답 항목을 ‘재생 에너지 확대 — 일회용 플라스틱 금지 — 자동차 배출가스 규제’ 순서로 제시하면, 첫 번째 항목이 자동적으로 주목을 받을 가능성이 높다. 반면, 중요도가 상대적으로 낮은 항목부터 제시하면 응답자는 전체 선택지를 더 고르게 검토하게 되며, 이는 응답의 신중함과 정확도를 높이는 데 도움이 된다. 이처럼 항목 배열 순서 또한 설문 설계에서 고려해야 할 중요한 요소 중 하나이다.\n태도를 측정할 때는 폐쇄형 질문을 사용할 것\n설문조사에서 응답자의 의견을 보다 체계적으로 분석하고자 할 때는, 응답 내용을 정량화할 수 있는 폐쇄형 질문을 사용하는 것이 효과적이다. 폐쇄형 질문은 미리 정해진 선택지 중 하나를 고르게 함으로써, 응답 결과를 수치로 변환하고 통계적으로 처리하기 용이하다. 특히 응답 항목이 표준화되어 있기 때문에, 여러 응답자의 답변을 비교하거나 집단 간 차이를 분석하는 데 유리하다.\n예를 들어, “귀하는 정부의 환경 보호 정책을 어떻게 생각하십니까?”라는 질문을 자유롭게 서술하도록 하면 개별 응답의 맥락은 풍부하게 파악할 수 있지만, 이를 정리하고 분석하는 데 시간이 많이 들고 주관적인 해석이 개입될 수 있다. 반면, 같은 질문에 대해 ’매우 찬성 — 찬성 — 중립 — 반대 — 매우 반대’와 같은 리커트 척도를 활용한 폐쇄형 질문으로 구성하면, 응답을 정량적으로 수집할 수 있어 전체적인 태도 경향을 쉽게 파악하고, 연구 결과의 일관성과 분석 효율성을 높일 수 있다.\n5점/7점 척도의 응답 척도를 사용하고, 모든 척도에 라벨을 붙일 것\n태도 문항의 응답을 정량적으로 측정하기 위해서는 적절한 척도를 사용하는 것이 중요하며, 일반적으로 5점 또는 7점 척도가 가장 널리 사용된다. 이러한 척도는 응답자의 세부적인 입장을 반영할 수 있을 만큼 충분한 선택지를 제공하면서도, 혼란을 주지 않을 정도로 간결한 구조를 유지할 수 있다는 장점이 있다. 척도의 간격이 너무 적으면 태도의 강도를 충분히 반영하지 못하고, 너무 많으면 응답자가 선택에 어려움을 느낄 수 있다.\n또한 각 점수에 의미 있는 라벨(설명)을 명확히 제시하는 것이 매우 중요하다. 예를 들어, 1점에는 ‘전혀 동의하지 않음’, 7점에는 ’매우 동의함’이라는 식으로 각 점수의 의미를 구체적으로 표현하면, 응답자는 자신의 태도에 가장 가까운 선택지를 정확히 고를 수 있다. 라벨이 불분명하거나 생략될 경우 응답자가 척도를 자의적으로 해석할 가능성이 있어, 응답 일관성과 데이터의 신뢰도가 떨어질 수 있다. 따라서 태도 측정 척도는 구조뿐만 아니라 설명의 명확성까지 고려하여 설계해야 한다.\n인기 없는 문항을 먼저 배치하지만, 설문의 성격에 따라 조정이 필요\n설문지의 문항 배치 순서는 응답자의 몰입도와 응답 품질에 영향을 미칠 수 있기 때문에 전략적으로 설계할 필요가 있다. 일반적으로는 덜 인기 있거나 상대적으로 중요도가 낮은 문항을 앞부분에 배치하고, 응답자의 관심이 높은 인기 있는 문항은 후반부에 배치하는 것이 권장된다. 이러한 구성은 응답자가 점차 문항에 익숙해지도록 돕고, 후반부의 주요 문항에 더 집중할 수 있는 기반을 마련해 준다.\n그러나 반드시 모든 경우에 이 원칙이 적용되는 것은 아니다. 설문 초반에 흥미를 유도하거나 설문 참여를 이어가게 하기 위해서는 응답자가 관심을 가질 만한 쉬운 문항을 앞부분에 제시하는 것이 더 효과적일 수 있다. 특히 반드시 응답이 필요한 핵심 문항이 있는 경우에는, 응답 이탈 전에 해당 문항을 먼저 배치하는 것이 유리하다. 따라서 최적의 전략은 응답자의 흥미와 집중도를 고려하여, 초반에는 가볍고 직관적인 문항으로 시작하고, 점차 세부적이고 분석적인 문항으로 자연스럽게 전환하는 방식이 바람직하다.\n모든 대안을 한눈에 볼 수 있는 경우에만 순위 매기기를 사용할 것\n응답자가 여러 대안 중에서 우선순위를 판단하거나 순위를 매겨야 하는 경우에는, 모든 선택지를 한눈에 비교할 수 있도록 제시하는 것이 중요하다. 응답자가 전체 대안을 동시에 검토하지 못하면, 일부 항목에 편중되거나 앞에 나온 항목에 영향을 받아 일관되지 않은 응답을 할 가능성이 높다. 따라서 우선순위 판단을 요구하는 질문에서는 시각적으로 명확한 배열과 균형 있는 제시 방식이 응답의 신뢰도를 높이는 데 도움이 된다.\n만약 모든 대안을 한 화면이나 페이지에서 제시하기 어렵거나, 항목 간 비교가 복잡한 경우에는 쌍대 비교(pairwise comparison) 방식을 활용하는 것이 적절하다. 이 방법은 각 대안을 두 개씩 짝지어 반복적으로 비교하게 하여, 응답자가 상대적인 중요도를 더 명확하게 판단할 수 있도록 돕는다. 쌍대 비교는 특히 항목 수가 많거나 선택 기준이 모호할 때 유용한 접근 방식이며, 보다 정밀한 선호도 분석에 적합하다.\n다중 선택 문항보다는 개별문항 리커트 척도 평가방법 사용\n설문에서 여러 항목에 대해 응답자의 선호나 평가를 수집할 때, 단순히 체크박스 방식으로 해당 항목을 모두 선택하게 하는 방식은 응답의 정밀도가 떨어질 수 있다. 체크박스는 특정 항목의 선택 여부만을 파악할 수 있어, 어떤 항목을 더 선호하거나 중요하게 여기는지를 비교하기 어렵고, 항목 간 상대적인 차이를 반영하기에도 한계가 있다.\n이러한 한계를 보완하기 위해, 각 항목에 대해 개별적으로 평점을 부여하도록 하는 방식이 더 적절하다. 예를 들어, ‘관심도’, ‘중요도’, ‘만족도’ 등을 기준으로 각 항목에 1점에서 5점 또는 7점 사이의 점수를 매기도록 하면, 응답자는 자신의 인식을 보다 세밀하게 표현할 수 있다. 이 방식은 항목 간 우선순위나 차이를 정량적으로 분석할 수 있도록 해주며, 더 정밀하고 유용한 데이터를 수집하는 데 도움이 된다.\n\n\n\nchapter 3. 질문지 평가\n질문 평가는 크게 두 가지 핵심 요소로 구성된다. 첫 번째는 질문이 응답자에게 얼마나 잘 이해되는지, 그리고 답변하는 데 얼마나 어려움이 따르는지를 평가하는 것이다. 이러한 요소들은 질문이 응답 과정에서 인지적 부담을 얼마나 유발하는지를 판단하는 기준이 되며, 궁극적으로 측정의 질에 직접적인 영향을 미친다. 설문 조사 연구자들은 주로 사람들이 질문을 읽고 해석하며 답변하는 전 과정을 관찰하거나, 응답자의 반응을 정성적으로 분석함으로써 질문의 이해도, 기억 회상의 난이도, 표현 방식의 모호성 등을 평가한다. 기본적인 가정은, 명확하게 이해되고 인지적으로 부담이 적은 질문일수록 응답자가 더 정확하게 반응할 수 있으며, 그 결과 측정 오류가 줄어든다는 것이다.\n두 번째 요소는 질문을 통해 수집된 응답이 실제로 우리가 측정하고자 하는 개념을 얼마나 정확하게 반영하고 있는지를 평가하는 과정이다. 이는 곧 측정 오류를 직접적으로 추정하는 작업으로, 설문 문항이 연구자가 의도한 개념과 일치하는지를 검증하는 것이다. 이를 위해 설문 방법론자들은 설문 응답 결과를 외부의 객관적인 자료와 비교하거나 동일한 질문을 반복 측정하는 방식을 활용한다. 외부 자료와의 비교는 주로 타당성(construct validity)이나 응답 편향(social desirability bias)과 같은 문제를 분석하는 데 사용되며, 측정 반복은 신뢰성(reliability)이나 응답 분산(response variability)을 평가하는 데 활용된다. 이처럼 질문 평가는 설문조사의 품질을 높이기 위한 핵심 과정으로, 설계 단계부터 체계적으로 고려되어야 한다.\n모든 설문 질문은 다음의 세 가지 명확한 기준을 충족해야 한다.\n내용 content 기준: 적절한 정보를 수집하는지를 평가하는 기준\n\n분석 관점: 문항이 연구 목적에 부합하는 데이터를 수집하는지 확인해야 한다. 이를 위해 분석가나 주제 전문가의 평가가 필요하다.\n응답 가능성: 질문이 실제로 응답자가 답할 수 있는 내용인지 평가해야 한다. 응답자의 답변이 신뢰할 만한 수준의 정확성을 가지려면, 질문을 이해하고 일관되게 응답할 수 있어야 한다. 이를 확인하기 위해 포커스 그룹 및 인지 인터뷰가 유용하다. 초점 집단은 응답자들이 특정 주제에 대해 어떤 지식을 가지고 있는지 평가하는 데 효과적이며, 인지 인터뷰는 특정 질문이 일관되게 응답될 수 있는지 분석하는 데 활용된다.\n\n인지 cognitive 기준: 응답자가 문항을 올바르게 이해하고 답변할 수 있는지를 평가하는 기준\n\n포커스 그룹 인터뷰: 이해되지 않는 용어나 모호한 개념을 파악할 수 있다.\n전문가 검토: 응답자가 답변하기 어려운 문항을 사전 탐지할 수 있다.\n행동 코딩: 사전조사 과정에서 응답자가 혼란을 느끼는 문항을 식별할 수 있다.\n\n사용성 usability 기준: 설문 도구가 실제 조사에서 원활하게 활용될 수 있는지를 평가하는 기준\n설문조사를 본격적으로 실시하기 전에, 문항의 타당성과 사용성을 점검하기 위한 절차로 전문가 검토를 실시하는 것이 중요하다. 전문가들은 설문 문항이 응답자에게 혼란을 주거나, 면접관이 질문을 제시하고 응답을 수집하는 과정에서 문제가 될 수 있는 요소들을 사전에 식별할 수 있다. 이를 통해 문항의 표현 방식, 내용의 민감성, 질문 흐름상의 논리적 오류 등을 조정하여, 설문이 원활하게 작동할 수 있도록 한다.\n특히 자기기입식(self-administered) 설문에서는 사용성 테스트가 핵심적인 검토 절차 중 하나로 간주된다. 실험실 환경이나 실제 조사 환경에서 테스트를 진행하면, 응답자가 문항을 이해하고 처리하는 방식, 특정 문항에서 혼란을 겪는 지점, 응답 오류가 발생하는 가능성 등을 직접 관찰할 수 있다. 컴퓨터 기반 설문에서는 응답자의 키 입력 시간, 문항 간 이동 패턴, 비정상적 입력 감지 등 다양한 디지털 데이터를 활용하여 사용성을 평가할 수 있다. 물론 실험실 테스트가 현장의 복잡한 변수들을 모두 반영하지는 못하지만, 실제 조사가 진행되기 전에 발생 가능한 문제를 미리 식별하고 개선할 수 있는 매우 유용한 방법이다.\n\n1. 전문가 검토\n설문조사에서 질문의 질을 평가하는 과정에서, 주제 전문가와 설문지 설계 전문가의 사전 검토는 필수적인 절차로 간주된다. 설문지 설계 전문가는 질문의 형식, 흐름, 문장 구조 등 기술적인 요소를 정교하게 다듬는 역할을 수행하며, 조사 도구의 완성도를 높이는 데 핵심적인 기여를 한다. 동시에, 설문이 연구의 분석 목적과 이론적 틀에 부합하는 내용을 포함하고 있는지를 검토하기 위해서는 해당 분야의 주제 전문가가 반드시 참여해야 한다. 주제 전문가의 관점은 수집되는 데이터가 실제 연구 목적에 맞게 활용 가능한지를 판단하는 데 중요한 기준이 된다.\n전문가 검토는 문항의 표현 방식, 질문 순서, 응답 보기의 구성, 조사원을 위한 지침, 설문 흐름 규칙 등 설계 전반에 걸쳐 진행되며, 응답자가 질문을 명확히 이해하고 일관된 방식으로 응답할 수 있도록 돕는 데 중점을 둔다. 이러한 검토는 설문 도구의 오류를 사전에 발견하고 수정함으로써 전체 조사 과정의 신뢰성과 타당성을 높이는 데 기여한다. 다만, 전문가의 평가만으로는 응답자의 실제 이해 과정과 반응을 완전히 예측하기 어렵기 때문에, 이후 논의될 추가 평가 방법들과 병행하여 실시해야 한다. 따라서 전문가 검토는 설문 설계 초기 단계에서 문항의 질을 향상시키는 핵심적인 절차이며, 이를 체계적으로 수행하기 위한 다양한 도구와 방법론이 꾸준히 개발되고 있다.\n\n\n2. 포커스 그룹 focus group\n포커스 그룹은 설문 도구를 개발하기 전, 특정 주제에 대한 응답자들의 인식과 반응을 깊이 있게 이해하기 위해 활용되는 질적 조사 방법이다. 일반적으로 6~10명 정도의 소규모 집단을 구성하여, 중재자의 진행 하에 자유로운 토론이 이루어진다. 참여자들은 서로의 의견을 듣고 상호작용하면서 자신의 생각을 확장하게 되며, 이를 통해 연구자는 특정 주제에 대해 사람들이 어떻게 생각하고 있는지, 어떤 표현이 혼란을 줄 수 있는지, 문항의 구조나 개념이 응답자들에게 어떻게 해석되는지를 구체적으로 파악할 수 있다.\n포커스 그룹은 특히 설문 설계의 초기 단계에서 유용한 도구로, 응답자들이 주제에 대해 가진 배경지식, 용어에 대한 이해, 관심의 정도 등을 사전에 탐색하는 데 효과적이다. 이러한 과정을 통해 설문 문항을 보다 응답자 친화적으로 조정할 수 있으며, 향후 조사에서 발생할 수 있는 오류를 줄이는 데 도움이 된다. 다만 포커스 그룹의 결과는 참여자의 수가 적고 비확률 표본이기 때문에 일반화에 한계가 있으며, 이를 보완하기 위해 개별 심층 인터뷰나 파일럿 테스트 등 다른 평가 방법과 병행해 사용하는 것이 바람직하다.\n\n(1) 포커스 그룹의 역할과 장점\n응답자의 지식 및 인식 구조 분석\n연구자는 포커스 그룹을 통해 응답자들이 조사 주제에 대해 어떤 지식과 경험을 가지고 있는지, 그리고 그 정보를 어떤 방식으로 인식하고 조직화하는지를 심층적으로 탐색할 수 있다. 예를 들어, 건강보험 관련 조사를 준비할 경우, 포커스 그룹 논의를 통해 응답자들이 알고 있는 보험 유형은 무엇인지, 각 유형을 어떻게 이해하고 있는지를 파악할 수 있으며, 이 과정에서 용어나 개념에 대한 오해 가능성도 확인할 수 있다. 또한 응답자들이 어떤 요소를 중요하게 여기고, 어떤 요소는 상대적으로 관심이 적은지 구분하는 데에도 유용하여, 설문 문항 설계 시 초점을 어디에 둘지 결정하는 데 실질적인 도움을 준다.\n용어 및 개념 정교화\n포커스 그룹은 설문에서 사용될 단어나 표현이 응답자에게 어떻게 받아들여지는지를 분석하는 데 매우 효과적인 도구이다. 연구자는 이 과정을 통해 응답자들이 일상적으로 사용하는 용어나 개념, 특정 표현에 대한 선호도와 이해 수준을 직접 관찰할 수 있다. 이를 바탕으로 설문 문항의 언어를 보다 명확하고 직관적으로 조정할 수 있으며, 응답자의 혼란이나 오해를 최소화하는 데 기여한다. 결과적으로 포커스 그룹은 응답자 중심의 설문 설계를 가능하게 하여, 전체 조사의 품질과 응답의 신뢰도를 높이는 데 중요한 역할을 한다.\n질문 설계의 현실성 확보\n포커스 그룹은 연구자가 특정 개념에 대해 응답자가 어떻게 인식하고, 어떤 경험과 사고 과정을 바탕으로 답변을 구성하는지를 이해하는 데 유용한 방법이다. 이러한 과정을 통해 연구자는 설문 문항이 단순히 이론적 개념에 기반한 것이 아니라, 실제 응답자의 경험과 감각에 맞닿아 있는지를 점검할 수 있다. 결과적으로, 설문 내용이 응답자의 현실과 더 잘 연결되도록 문항을 조정함으로써, 보다 신뢰할 수 있고 의미 있는 데이터를 수집할 수 있는 기반이 마련된다.\n\n\n(2) 포커스 그룹의 운영 방식\n포커스 그룹은 일반적으로 조용하고 집중할 수 있는 환경에서 진행되며, 연구진이 관찰할 수 있도록 단방향 거울이 설치되거나 오디오·비디오 녹화가 이루어지기도 한다. 경우에 따라 필기 노트나 토론 기록지를 활용해 토론 내용을 분석하고, 녹화된 영상은 편집하여 주요 내용을 요약하는 데 쓰이기도 한다.\n포커스 그룹에서 중재자는 개방적이고 편안한 분위기를 조성하면서도 논의가 연구 주제에서 이탈하지 않도록 유도하는 핵심적인 역할을 맡는다. 중재자는 다음과 같은 원칙을 지켜야 한다. 첫째, 모든 참가자가 적극적으로 참여할 수 있도록 유도하고, 내성적인 참가자의 의견도 이끌어내며 특정인의 발언 독점을 방지해야 한다. 둘째, 참가자들의 의견을 경청하고, 새로운 아이디어가 등장하면 다른 참가자의 반응을 관찰하며 조율한다. 셋째, 미리 준비된 질문지(script)에만 의존하지 않고, 연구 목표를 고려한 유연하고 자연스러운 방식으로 논의를 이끌어야 한다.\n또한 포커스 그룹은 조사 주제에 따라 유사한 특성을 가진 응답자들로 구분해 운영할 수 있다. 예를 들어, 취업 관련 조사의 경우 정규직 근로자와 시간제 근로자를 나누어 별도로 논의하거나, 다양한 하위 집단을 가진 조사에서는 각 집단에 대한 포커스 그룹을 따로 구성하여 보다 정교한 분석이 가능하도록 한다.\n\n\n(3) 포커스 그룹의 한계점\n대표성 부족\n포커스 그룹은 소규모의 참여자들이 특정 주제에 대해 깊이 있는 의견을 나누는 데 중점을 두기 때문에, 참가자들이 전체 조사 모집단을 통계적으로 대표한다고 보기 어렵다. 이로 인해 포커스 그룹 결과만으로 일반적인 결론이나 전체 인구에 대한 추정을 도출하는 데는 한계가 있다. 따라서 포커스 그룹은 전반적인 경향을 파악하거나 문항 개발을 위한 탐색적 도구로 활용하고, 일반화 가능한 결론은 보다 대표성 있는 양적 조사에서 도출해야 한다.\n설문 문항 평가의 한계\n포커스 그룹은 응답자의 전반적인 인식과 개념에 대한 이해를 도모하는 데 유용하지만, 특정 설문 문항의 문구가 얼마나 명확한지, 또는 응답자가 질문을 어떻게 해석하고 답변을 구성하는지에 대한 정밀한 분석에는 적합하지 않다. 이러한 문항 수준의 타당성과 이해도 평가는 집단 토론보다는 개별 면담을 통해 수행되는 1:1 인지 면접(cognitive testing) 방식이 훨씬 효과적이다. 인지 면접은 응답자의 사고 과정을 추적할 수 있어, 문항 해석의 차이나 오해의 가능성을 더 정확하게 파악할 수 있다.\n결과의 신뢰성 문제\n포커스 그룹에서 얻어진 정보는 주로 질적 데이터에 기반하기 때문에, 표준화된 분석이 어렵고, 연구자의 해석에 따라 결과가 달라질 가능성이 크다. 같은 토론 내용을 두고도 해석이 다양할 수 있어, 객관성과 일관성을 확보하는 데 한계가 있다. 또한, 포커스 그룹은 참가자 구성이나 토론 흐름에 따라 결과가 달라질 수 있기 때문에 동일한 연구를 반복하더라도 일관된 결과를 얻기 어렵다는 재현성(replicability)의 문제도 수반된다. 이러한 이유로, 포커스 그룹은 설문 설계 초기의 보조적 수단으로 활용하되, 주요 결론 도출의 단독 근거로 삼기에는 신중함이 요구된다.\n\n\n\n3. 인지 인터뷰 cognitive interviewing\n인지 인터뷰(Cognitive Interviewing)는 설문 문항이 응답자에게 어떻게 이해되고 해석되는지를 분석하기 위한 질적 조사 기법이다. 이 방법은 설문 문항이 의도한 바와 실제 응답자가 받아들이는 방식 간의 불일치를 확인하고, 문항의 개선 가능성을 탐색하는 데 중점을 둔다.\n인지 인터뷰의 핵심 방법론은 프로토콜 분석(protocol analysis)으로, 응답자가 문제를 해결하는 과정을 소리 내어 말하도록 요청하는 방식이다. 이는 원래 심리학에서 문제 해결 과정을 분석하기 위해 개발된 기법이며, 이후 설문 문항의 인지적 처리 과정을 이해하는 데 활용되었다. 대표적인 기법은 다음과 같다.\n\n동시적 사고 구술 (Concurrent Think-Alouds): 응답자가 질문을 읽고 답하는 과정에서 자신의 사고 과정을 실시간으로 소리 내어 설명하도록 유도한다. 회고적 사고 구술 (Retrospective Think-Alouds): 응답자가 질문에 답변한 이후, 그 응답을 도출하는 과정에서 어떤 생각을 했는지를 설명하게 한다.\n자신감 평가 (Confidence Rating): 응답자가 자신의 답변에 대해 어느 정도 확신이 있는지를 표현하게 한다.\n패러프레이징 (Paraphrasing): 응답자가 주어진 질문을 자신의 말로 다시 진술하게 함으로써, 문항 이해도를 평가한다.\n정의 제공 (Definition Probing): 질문 내 핵심 용어나 개념에 대해 응답자가 자신의 이해를 설명하도록 유도한다.\n추가 질문 (Probing Questions): 응답자가 어떤 전략이나 기준으로 답을 결정했는지 파악하기 위한 후속 질문을 제시한다.\n\n이러한 기법들은 설문 문항이 응답자에게 의도한 바대로 정확하고 일관되게 전달되는지를 점검하는 데 활용되며, 설문지의 신뢰성과 타당성을 높이는 데 매우 유용한 자료를 제공한다.\n인지 인터뷰는 일정한 절차가 고정된 정형화된 방식이라기보다는, 연구 목적과 상황에 따라 유연하게 설계되는 질적 접근 방법이다. 일반적으로 응답자는 일정한 보상을 제공받는 자원봉사자 형태로 모집되며, 인터뷰는 조사 연구자뿐만 아니라 인지 심리학자, 설문 조사 방법론 전문가 등 다양한 배경을 가진 면접자가 수행할 수 있다.\n연구 기관이나 조사 목적에 따라 인지 인터뷰의 운영 방식은 다소 상이할 수 있다. 예를 들어, 어떤 기관은 면접자가 사전 구성된 후속 질문(probes)을 중심으로 진행하는 반면, 다른 기관은 응답자의 자연스러운 사고 구술(thinking aloud)에 보다 초점을 맞추어 인터뷰를 이끈다. 또한, 인터뷰 결과는 비디오 녹화, 오디오 녹음, 필기 노트 등 다양한 방식으로 기록되며, 분석 방법 역시 연구 환경이나 목적에 따라 차이가 있다.\n이처럼 인지 인터뷰는 설문 문항의 인지적 적합성(cognitive validity)을 평가하는 핵심 도구로 자리 잡고 있으며, 특히 문항이 응답자에게 어떻게 해석되고 반응되는지를 실제로 검증할 수 있다는 점에서 중요한 역할을 한다. 다만, 이러한 기법의 결과를 보다 체계적으로 활용하고, 연구자 간 해석의 일관성을 확보하기 위해서는 방법론적 표준화와 추가적인 검증 연구가 지속적으로 요구된다.\n\n\n4. 사전조사와 행동코딩\n사전조사(pretests)는 본격적인 설문 조사에 앞서 소규모로 실시되는 리허설로, 설문 도구의 설계와 데이터 수집 절차의 적절성을 검토하는 데 목적이 있다. 주로 소수의 응답자와 면접관을 대상으로 진행되며, 설문 문항이 의도대로 작동하는지, 응답 과정에서 어떤 문제가 발생하는지를 사전에 점검할 수 있는 표준적인 절차로 널리 활용된다.\n사전조사에서 활용되는 대표적인 방법 중 하나는 면접관 피드백 수집이다. 사전조사에 참여한 응답자들을 대상으로 포커스 그룹을 운영하거나 인터뷰를 실시해, 응답자가 설문을 수행하면서 느낀 불편이나 이해하기 어려웠던 부분을 수집한다. 이 과정에서 면접관 역시 설문 절차를 단순화하거나 문항 구성을 개선할 수 있는 실질적인 제안을 제공할 수 있다.\n또한, 사전조사를 통해 수집된 응답 데이터를 정량적으로 분석하여 문항의 품질을 평가할 수도 있다. 연구자들은 누락된 응답의 비율, 논리적 불일치, 범위 밖의 응답 등 다양한 지표를 통해 설문 문항의 문제점을 진단하고, 분산이 지나치게 낮아 유의미한 구분이 어려운 문항은 삭제하거나 수정할 수 있다. 이러한 정량 분석은 문항의 타당성과 응답 가능성을 높이는 데 중요한 역할을 한다.\n행동 코딩(behavior coding)은 면접관과 응답자 간의 상호작용을 분석하여 설문 문항의 이해도와 전달 효과를 평가하는 기법이다. 면접 과정을 녹음한 후, 면접관이 질문을 반복하거나 수정하는 빈도, 응답자의 주저나 ‘모름’ 응답 비율 등을 코드화하여 분석함으로써 문항이 실제로 어떻게 작동하는지를 평가할 수 있다. 이는 응답자가 문항을 이해하는 데 어려움이 있었는지를 간접적으로 파악하는 데 매우 유용하다.\n실제로 행동 코딩의 신뢰도는 비교적 높은 편이다. 예를 들어, 동일한 질문을 서로 다른 조사팀이 평가했을 때, 행동 코딩 결과 간의 상관계수가 0.75에서 0.90에 이를 정도로 일관성이 있다는 연구도 있다. 이는 설문 문항의 구조적 문제가 특정 응답자나 면접관에 국한되지 않고 보다 보편적으로 발생할 수 있음을 보여주는 결과이며, 설문 도구를 수정하는 근거로 활용될 수 있다.\n\n\n\nchapter 4. 질문지 평가 통계적 접근\n설문 조사 연구에서 ’품질’을 측정할 때 사용되는 용어는 아직까지 완전히 표준화되어 있지 않지만, 전통적으로 두 가지 주요 접근법이 존재한다. 하나는 심리측정(psychometrics)의 관점이고, 다른 하나는 표본통계(survey statistics)의 관점이다.\n첫 번째 접근법인 심리측정은 개별 응답자의 반응에 초점을 맞추며, 문항이 측정하고자 하는 개념을 얼마나 정확하게 반영하는지를 뜻하는 타당성(validity)과, 동일한 조건에서 일관된 결과를 도출할 수 있는지를 의미하는 신뢰성(reliability)이라는 개념을 중심으로 품질을 평가한다.\n반면, 두 번째 접근법은 설문 응답을 종합하여 전체 집단을 대표하는 통계치를 도출하는 과정에서의 편향(bias)과 분산(variance)을 중심으로 설문 품질을 평가한다. 이는 각 응답의 정합성보다는 추정치의 정확성과 일관성에 중점을 둔 통계적 접근이라고 할 수 있다.\n이처럼 설문 조사 품질을 평가하는 개념은 분석의 초점에 따라 서로 다른 용어와 기준이 사용되며, 각각의 접근은 조사 목적과 분석 수준에 따라 적절히 선택되어야 한다.\n\n1. 타당도\n타당도는 설문 문항이 측정하고자 하는 구성 개념(construct)을 얼마나 정확하게 반영하고 있는지를 나타내는 개념이다. 즉, 응답자가 문항에 답한 결과가 연구자가 의도한 속성이나 태도를 실제로 잘 측정하고 있는지를 평가한다.\n타당도는 설문 조사에서 매우 중요한 개념으로, 다음과 같은 주요 유형으로 나뉜다: - 내용 타당도 (Content Validity): 문항이 측정하고자 하는 개념의 모든 중요한 측면을 충분히 포괄하고 있는지를 평가한다. 전문가 평가 등을 통해 판단된다. - 기준 타당도 (Criterion Validity): 설문 결과가 외부의 객관적 기준(예: 행동, 실적 등)과 얼마나 잘 부합하는지를 본다. 예컨대, 직무 적성 검사의 점수가 실제 업무 성과와 상관관계가 높다면 기준 타당도가 높다고 할 수 있다. - 구성 타당도 (Construct Validity): 문항이 이론적으로 정의된 개념을 제대로 측정하고 있는지를 평가한다. 주로 요인분석, 상관분석 등을 통해 통계적으로 검증된다.\n따라서, 타당도는 단순히 문항이 잘 만들어졌는지를 넘어서, 이 문항이 과연 내가 측정하고자 하는 ’그것’을 제대로 측정하고 있는가에 대한 핵심적인 질문이라 할 수 있다.\n\n(1) 내용 content 타당도\n전문가 검토(Expert Review)\n내용(content) 타당도는 설문 문항이 측정하고자 하는 개념의 모든 핵심 요소를 포괄하고 있는지를 평가하는 개념이다. 가장 일반적인 평가 방법은 전문가 검토(Expert Review)로, 해당 분야의 전문가들이 설문 문항을 검토하여 설문이 연구 목적과 개념을 충분히 반영하고 있는지를 판단한다. 이 과정에서 전문가들은 문항이 적절한지를 평가하고, 누락된 내용이나 불필요한 요소가 있는지를 지적하며 수정 사항을 제안한다. 이러한 절차를 통해 문항이 연구 주제를 충분히 반영하고 있는지를 확인하고, 설문의 내용 타당도를 향상시킬 수 있다.\n내용 타당도 지수 content validity index, CVI\n내용 타당도 지수(Content Validity Index, CVI)는 설문 문항이 측정하고자 하는 연구 개념을 얼마나 잘 반영하는지를 정량적으로 평가하는 지표이다. 이 방법은 전문가 패널이 각 문항의 적절성을 4점 척도(예: 1 = 적절하지 않음, 2 = 다소 적절하지 않음, 3 = 적절함, 4 = 매우 적절함)로 평가한 후, 문항별 또는 전체 문항의 평균 점수를 산출하는 방식으로 진행된다. 일반적으로 CVI 값이 0.80 이상이면 해당 문항 또는 설문 전체가 높은 내용 타당도를 가진 것으로 간주한다. 이 지수는 설문지의 내용 타당성을 수치적으로 나타내어 문항의 적절성 여부를 보다 명확하게 판단할 수 있도록 도와준다.\n내용 타당도 비율 content validity ratio, CVR\nLawshe(1975)가 제안한 정량적 평가 방법으로, 설문 문항이 연구 개념 측정에 필수적인지를 전문가 집단을 통해 판단하는 데 사용된다. 이 방법에서는 각 전문가에게 특정 문항이 “필수적이다”, “유용하지만 필수는 아니다”, “불필요하다” 중 하나로 평가하게 한 뒤, “필수적이다”라고 응답한 전문가의 수를 기준으로 다음과 같은 공식을 사용해 CVR을 계산한다:\n\\(\\text{CVR} = \\frac{n_{e} - (N/2)}{N/2}\\)\n여기서 \\(n_e\\) 는 해당 문항을 “필수적”이라고 평가한 전문가 수, N은 전체 전문가 수이다.\n계산된 CVR 값은 Lawshe가 제시한 임계값 이상이어야 해당 문항이 내용 타당성을 갖춘 것으로 인정된다. 예를 들어, 전문가 수가 8명일 경우 CVR 값이 최소 0.75 이상이어야 하며, 전문가 수가 10명이라면 0.62 이상이어야 한다. 이 방식은 문항의 타당성을 보다 객관적으로 판단할 수 있는 기준을 제공한다.\n문항 분석\n파일럿 테스트(사전조사)를 통해 응답자들이 각 문항에 어떻게 반응하는지를 체계적으로 분석하여, 설문지의 품질을 향상시키기 위한 과정이다. 이 분석은 문항의 이해도, 반응 일관성, 응답 분포 등을 종합적으로 고려하여 수행된다.\n주로 문항 간 상관관계, 문항-전체 점수 상관(item-total correlation), 응답 분산 등을 통해 특정 문항이 전체 개념 측정에 기여하는 정도를 평가하며, 그 결과 타당도가 낮거나 혼란을 유발하는 문항은 제거하거나 수정된다. 이러한 분석은 문항의 내용 타당도를 간접적으로 평가하고, 설문 구성의 논리성과 신뢰성을 강화하는 데 매우 유용하다.\n포커스 그룹\n설문 문항을 본격적으로 적용하기 전에, 잠재적 응답자들을 소규모 집단(보통 6~10명)으로 모아 자유롭게 토론하도록 하여 문항의 적절성과 이해도를 평가하는 질적 조사 방법이다. 이 과정에서 연구자는 응답자들이 특정 문항을 어떻게 해석하는지, 문항에 대해 어떤 반응을 보이는지, 혼란을 느끼거나 불편함을 표현하는 부분이 있는지를 파악할 수 있다.\n포커스 그룹을 통해 수집한 피드백은 설문 문항을 보다 명확하고 응답자 친화적으로 다듬는 데 중요한 근거가 된다. 이 방법은 특히 민감하거나 복잡한 개념을 다루는 설문에서, 질문이 응답자들에게 의도한 의미로 전달되는지를 사전에 확인하고 개선할 수 있는 유용한 절차로 활용된다.\n\n\n(2) 기준 criterion 타당도\n기준 타당도(Criterion Validity)는 설문 문항이 측정하고자 하는 속성이 실제 외부의 객관적 기준과 얼마나 밀접하게 관련되어 있는지를 평가하는 개념이다. 다시 말해, 특정 문항이나 척도가 이미 검증된 외부 지표(기준 변수)와 어느 정도의 상관관계를 가지는지를 검토함으로써 그 타당성을 확인한다.\n예를 들어, 스트레스 수준을 측정하는 설문이 있다면, 해당 설문 점수와 생리적 지표(예: 코르티솔 수치) 혹은 임상 평가 결과와의 상관관계를 분석하여 기준 타당도를 평가할 수 있다. 기준 타당도는 일반적으로 동시 타당도(concurrent validity)와 예측 타당도(predictive validity)로 나뉘는데, 전자는 현재 시점에서의 상관성을, 후자는 미래 행동이나 성과를 예측하는 능력을 평가한다.\n동시 concurrent 타당성\n설문 도구가 현재 시점에서 존재하는 외부 기준 변수(객관적인 지표)와 얼마나 강한 상관관계를 가지는지를 평가하는 방식이다. 이는 측정 도구의 정확성을 검증하는 방법 중 하나로, 설문 결과와 이미 검증된 외부 평가나 측정 지표를 동시에 비교함으로써 평가된다.\n예를 들어, 새로 개발한 우울증 척도가 기존에 널리 사용되며 검증된 우울증 척도와 높은 상관관계를 보인다면, 해당 척도는 동시 타당성이 높다고 볼 수 있다. 또 다른 예로, 한 기업에서 직무 만족도를 측정하는 설문을 실시했을 때, 그 결과가 현재의 상사 평가나 인사 고과 점수와 밀접하게 연관되어 있다면, 해당 설문 도구는 높은 동시 타당성을 가진 것으로 평가된다. 이처럼 동시 타당성은 기존의 신뢰할 수 있는 기준과 비교하여 새로운 측정 도구의 신뢰성을 간접적으로 검증하는 데 유용하다.\n예측 predictive 타당성\n설문을 통해 측정된 값이 미래의 특정 결과나 행동을 얼마나 정확하게 예측하는지를 평가하는 방식이다. 이는 설문 도구가 단순히 현재 상태를 반영하는 것을 넘어, 장기적으로 의미 있는 결과와 연결될 수 있는지를 검증하는 데 사용된다.\n예를 들어, 대학 입학 시험 점수가 입학 이후의 평균 학점(GPA)과 유의미한 상관관계를 보인다면, 해당 시험은 학업 성취도를 예측하는 데 타당한 도구로 간주된다. 마찬가지로, 어떤 기업에서 실시한 성격 검사가 향후 직원의 업무 성과와 높은 연관성을 나타낸다면, 해당 검사는 예측 타당성이 높은 것으로 평가할 수 있다. 이처럼 예측 타당성은 설문 결과가 미래 행동이나 성과를 얼마나 잘 설명하고 예측할 수 있는지를 판단하는 데 필수적인 기준이 된다.\n상관 분석\n기준 타당성을 평가할 때 가장 기본적으로 사용되는 통계 기법이다. 이는 설문 문항이 측정하고자 하는 개념이 실제 외부 기준 변수와 얼마나 일관되게 연관되어 있는지를 확인하는 데 초점을 둔다.\n가장 일반적으로 사용되는 지표는 피어슨 상관계수(Pearson’s r)로, 두 변수 간의 선형 상관관계를 수치로 표현한다. 예를 들어, 직무 만족도 설문 점수와 실제 이직률 사이에 r 값이 -0.70이라면, 만족도가 높을수록 이직률이 낮다는 강한 음의 상관관계를 의미한다. 일반적으로 r 값이 0.70 이상이면 강한 상관관계, 0.50 이상이면 중간 정도의 상관관계로 해석된다. 이러한 분석 결과는 설문 도구가 외부의 객관적인 기준과 얼마나 밀접하게 연결되어 있는지를 판단하는 데 유용한 근거를 제공한다.\n회귀 분석\n설문 문항의 기준 타당성, 특히 예측 타당성을 평가하는 데 매우 유용한 통계 기법이다. 이 방법에서는 외부의 기준 변수를 종속 변수로, 설문 문항 또는 척도 점수를 독립 변수로 설정하여, 설문 결과가 기준 변수를 얼마나 잘 설명하거나 예측할 수 있는지를 분석한다.\n회귀 분석의 결과에서 회귀 계수(coefficient)가 통계적으로 유의미하고, 결정계수(R²) 값이 높을수록 설문 문항의 예측력이 뛰어나다고 판단할 수 있다. 예를 들어, 직무 만족도 설문 점수가 향후 이직 여부(0=재직, 1=이직)를 유의하게 예측할 수 있다면, 해당 설문의 기준 타당성이 높다고 평가된다. 이처럼 회귀 분석은 설문 도구의 실제적인 예측 가능성과 설명력을 계량적으로 평가하는 데 핵심적인 역할을 한다.\nROC 곡선 Receiver Operating Characteristic Curve\n설문 문항이나 척도가 기준 변수에 따라 이분형 결과(예: 질병 유무, 합격 여부)를 얼마나 잘 분류할 수 있는지를 평가하는 데 사용된다. 이 방법은 특히 진단 도구나 예측 척도의 기준 타당성을 평가할 때 널리 활용된다.\nROC 곡선은 민감도(sensitivity)와 특이도(1-specificity)의 관계를 시각화한 곡선이며, 이 곡선 아래 면적인 AUC (Area Under the Curve) 값을 통해 분류 성능을 정량적으로 평가할 수 있다.\n\nAUC = 0.5이면 무작위 추측 수준과 동일한 성능을 의미하고,\nAUC ≥ 0.80이면 높은 분류 정확도, 즉 높은 기준 타당성을 의미한다.\n\n예를 들어, 우울증 설문 점수를 기준으로 우울증 진단 여부를 정확히 예측할 수 있는지를 ROC 분석을 통해 확인할 수 있으며, AUC가 0.85라면 해당 설문은 높은 기준 타당성을 가진다고 평가할 수 있다.\n카이제곱 검정\n설문 결과와 기준 변수가 범주형(categorical) 데이터일 때, 이들 간의 독립성 또는 연관성을 검증함으로써 기준 타당성(criterion validity)을 평가하는 데 사용된다. 예를 들어, 설문에서 수집한 직무 만족도 수준(예: “만족”, “보통”, “불만족”)과 실제 직무 성과 평가 결과(예: “우수”, “보통”, “미흡”)가 서로 독립적인지 아닌지를 카이제곱 검정을 통해 확인할 수 있다.\n\n검정 결과가 유의미하면(p &lt; .05), 두 변수 간 통계적으로 유의한 연관성이 있다고 판단하며,\n이는 해당 설문 문항이 기준 변수(실제 성과)를 잘 설명하거나 예측한다는 점에서 기준 타당성이 높다고 평가할 수 있다.\n\n이 검정은 범주형 변수 간의 관계를 분석하는 데 적합하며, 특히 명목 척도 또는 순서 척도 문항의 기준 타당성을 검증할 때 효과적이다.\n\n\n(3) 구성 construction 타당성\n설문 문항이 이론적으로 정의된 추상적인 개념(구성 개념, construct)을 얼마나 잘 측정하고 있는지를 평가하는 개념이다. 각 설문 측정은 개념적으로 무한한 실험(trials)의 집합 중 하나의 실현으로 볼 수 있다. 즉, 특정 응답자가 특정 질문에 대해 제공하는 응답은 이론적으로 가능한 수많은 측정 중 하나에 해당하며, 동일한 구성 개념에 대한 측정이 반복적으로 이루어진다고 가정할 수 있다.\n이러한 맥락에서 구성 타당성은 단순히 문항의 적절성 여부를 넘어서, 측정하고자 하는 개념과 설문 문항 간의 이론적 연관성을 종합적으로 검증하는 절차를 포함한다. 예를 들어, 설문을 통해 ’사회적 불안’을 측정하고자 할 때, 그 문항들이 실제로 사회적 불안이라는 심리적 구성 개념을 반영하는지를 검증하는 것이 바로 구성 타당성을 평가하는 과정이다.\n구성 타당성을 확보하기 위해서는 통계적 분석뿐 아니라 이론적 정당성과 관련 문헌 기반의 논리적 타당성 확보가 병행되어야 하며, 일반적으로 요인분석, 수렴 및 판별 타당도 분석, 가설 검증 등을 통해 평가된다.\n단일 문항 구성 타당성 척도\n\\(\\mu_{i}\\): \\(i\\) 번째 응답자의 실제 구성 개념 값\n\\(Y_{it}\\): \\(i\\) 번째 응답자가 \\(t\\) 번째 실험에서 제공한 응답\n\\(\\epsilon_{it}\\): \\(i\\) 번째 응답자의 실제 개념 값과 응답 값 간의 편차\n설문에서 특정 구성 개념, \\(\\mu_{i}\\)에 대한 질문이 \\(i\\) 번째 응답자에게 주어졌을 때 응답자는 실제 값 \\(\\mu_{i}\\)를 그대로 응답하는 것이 아니라 다음과 같이 표현되는 측정값 \\(Y_{it} = \\mu_{i} + \\epsilon_{it}\\)을 응답하게 된다. 편차 \\(\\epsilon_{it}\\)는 측정 과정에서 발생할 수 있는 변동성이다.\n구성 타당성은 위 식에서 나타낸 측정값, \\(Y_{it}\\)과 실제 개념 값, \\(\\mu_{i}\\) 간의 상관계수로 측정된다. 구성 타당성은 0.0에서 1.0 사이의 숫자로 표현되며, 값이 클수록 타당성이 높음을 의미한다.0.7 이상이면 높은 타당성을 가진다고 판단한다.\n구성 타당도: \\(\\text{Validity}(Y) = \\frac{\\sum_{i,t}(Y_{it} - \\overline{Y})(\\mu_{i} - \\overline{\\mu})}{\\sqrt{\\sum_{i,t}(Y_{it} - \\overline{Y})^{2}\\sum_{i}(\\mu_{i} - \\overline{\\mu})^{2}}}\\)\n응답자의 실제 값 \\(\\mu_{i}\\)은 기록 데이터나 외부 자료를 활용하거나 응답자에게 다른 질문을 통하여 얻은 참 값을 사용한다. 일반적으로 설문 문항의 응답을 외부 자료와 비교하는 것이 이상적이다.\n외부 기준이 없는 경우\n외부 기준이 없는 경우에도 구성 타당성을 평가할 수 있는 방법들이 있다. 첫째, 설문 응답 간 상관관계 분석은 이론적으로 관련이 있어야 할 문항들이 실제로 높은 상관관계를 보이는지를 통해 설문이 제대로 구성 개념을 측정하고 있는지를 평가한다. 예를 들어, “나는 경제가 앞으로 좋아질 것이라고 생각한다”는 문항이 “나는 소비 지출을 늘릴 계획이다”와 높은 상관을 보인다면, 해당 문항들이 동일한 구성 개념(예: 경제에 대한 낙관적 기대)을 측정하고 있을 가능성이 높다고 판단할 수 있다.\n둘째, 집단 간 비교를 통해 구성 타당성을 간접적으로 검증할 수 있다. 측정하고자 하는 구성 개념이 실제로 다른 집단 간에 응답 차이가 유의미하게 나타나는지를 평가하는 방식이다. 예를 들어, 고소득층과 저소득층은 경제 전망에 대해 다른 인식을 가질 가능성이 있으므로, 두 집단의 응답 차이를 비교하여 문항이 해당 구성 개념을 잘 반영하고 있는지 검토할 수 있다.\n셋째, 대체 문항 또는 자료 수집 방법 간 비교도 활용된다. 동일한 응답자를 대상으로 문항 형식을 약간 바꾸거나 다른 방식으로 자료를 수집한 후 결과를 비교함으로써 일관성 있는 측정이 이루어졌는지를 평가한다. 예컨대, “향후 12개월 동안 경제 상황이 나아질 것이라고 생각하십니까?”와 “향후 12개월 동안 본인의 가계 경제가 나아질 것이라고 생각하십니까?”라는 문항을 비교하면, 유사하지만 범위가 다른 문항에 대한 반응을 분석함으로써 구성 개념이 일관되게 측정되고 있는지를 점검할 수 있다.\n하위 문항 구성 타당도\n\n\n\n\n\n탐색적 요인 분석에서는 요인 적재값이 0.40 이상이면 수용 가능, 0.70 이상이면 강한 구성 타당성을 가진다고 평가한다.\n확인적 요인 분석에서는 구조 방정식 모델의 적합도 지수를 활용하여 구성 타당성을 평가한다. (수용가능 지표) 비교 적합 지수 (Comparative Fit Index)-≥ 0.90 (권장: ≥ 0.95), 표준화된 SRMR (Standardized Root Mean Square Residual)-≤ 0.08 (이상적: ≤ 0.05), 튜커-루이스 지수(Tucker-Lewis Index)-≥ 0.90 (권장: ≥ 0.95)\n\n\n(4) 응답 편향 response bias\n설문 문항과 관련된 오류와 관련하여 가장 흔히 발생하는 개념적 혼란 중 하나는 ”타당성”과 ”편향” 간의 관계이다. 타당성은 응답과 실제 값 간의 상관관계의 함수이다. 따라서, 타당성은 개별 응답의 속성으로 정의될 수 있다. 그러나, 응답이 실제 값에서 체계적으로 벗어나는 경우는 어떻게 될까?\n예를 들어, 사회적으로 바람직하지 않은 특성에 대한 응답이 체계적으로 과소 응답되는 현상을 보인다. 이러한 체계적인 과소 응답과 실제 값 간의 상관관계를 반드시 감소시키는 것은 아니다. 예를 들어, 모든 응답자가 실제 체중보다 5파운드 적게 보고한다면, 응답 값과 실제 값 간의 상관관계는 1.0으로 유지될 것이다. 그러나, 이 경우 응답 값의 평균은 실제 값의 평균보다 5파운드 낮게 나타나는 편향이 발생하게 된다.\n스플릿-발롯 split-ballot 접근법을 활용한 편향 검증\n\n비교된 두 가지 질문, Sudman과 Bradburn(1982)\n술을 마시는 날, 보통 몇 잔을 마십니까? 1잔, 2잔, 3잔 이상?\n술을 마시는 날, 보통 몇 잔을 마십니까? 1-2잔, 3-4잔, 5-6잔, 7잔 이상?\n실험 절차 및 결과\n\n\n응답자들은 위 두 질문 중 무작위로 하나를 배정받아 응답했다.\n연구 결과, 질문 (b)에 응답한 사람들이 질문 (a)에 응답한 사람들보다 3잔 이상 마신다고 응답할 가능성이 훨씬 높았다.\n연구자들은 응답자들이 실제 음주량을 과소 응답하는 경향이 있다고 확신했다.\n이 가정을 바탕으로, 연구자들은 두 번째 질문(b)의 응답이 첫 번째 질문(a)보다 더 타당하다고 결론지었다.\n\n설문 통계에서의 편향\n\\(Y_{it} = \\mu_{i} + \\epsilon_{it}\\). 즉, 응답 값(\\(Y_{it}\\))은 실제 값(\\(\\mu_{i}\\))과 오차(\\(\\epsilon_{it}\\))의 합으로 구성된다. 만약 오차 항(\\(\\epsilon_{it}\\))이 체계적인 성분을 포함하고 있다면, 오차의 기대값이 0이 아닐 것이다.\n편향은 설문응답(\\(Y_{it}\\)) 기대값과 실제 값(\\(\\mu_{i}\\))이 다를 때 발생한다. 즉, 응답 값과 실제 값 간의 체계적인 편차가 존재할 때 편향이 발생한다.\n편향: \\(Bias(Y_{it}) = E_{i}\\left\\lbrack E_{t}(Y_{it}) - \\mu_{i} \\right\\rbrack\\)\n편향 추정치: \\(Bias(\\overline{Y}) = E_{t}\\left( \\frac{\\sum_{i}^{}Y_{it}}{N} - \\frac{\\sum_{i}^{}\\mu_{i}}{N} \\right)\\) 응답 값의 평균이 실제 값의 평균에 대한 편향된 추정치임을 의미한다. 첫 번째 항(\\(\\sum_{i}Y_{it}/N\\))은 모든 실험에서 응답 값의 기대값을 나타낸다. 편향은 응답 값의 평균이 실제 값의 평균과 체계적으로 다를 때 발생한다.\n타당성 평가와 편향 측정\n타당성 평가와 편향 측정의 유사성\n\n타당성 평가와 유사하게 연구자가 ”진실”에 대해 일정한 가정을 해야만 편향을 측정할 수 있음을 의미한다.\n기록 시스템을 활용해 설문 응답을 비교하는 경우, 연구자는 기록 데이터가 오류 없이 측정되었다는 가정을 하게 된다.\n\n타당성과 편향의 차이\n\n편향의 개념은 실제 값(\\(\\mu_{i}\\))의 존재 여부에 따라 정의된다.\n타당성은 \\(\\mu_{i}\\)의 변동성에 따라 달라진다.\n즉, 편향은 절대적인 기준(진실된 값)이 존재해야 정의될 수 있지만, 타당성은 응답 값이 얼마나 일관되게 측정되는지를 평가하는 개념이다.\n\n\n\n\n2. 신뢰도\n신뢰도란 반복적인 개념적 실험에서 응답 값의 변동성을 측정하는 개념이다. 신뢰도는 응답자가 일관되게 또는 안정적으로 응답하는지 여부를 평가한다. 따라서, 신뢰도는 응답 분산 성분을 기준으로 정의되며 이는 응답 값(\\(Y_{it}\\))의 오차 항(\\(\\epsilon_{it}\\)) 변동성을 포함한다.\n\\[Reliability(Y_{it}) = \\frac{E_{i}(\\mu_{i} - \\overline{\\mu})^{2}}{E_{i}(\\mu_{i} - \\overline{\\mu})^{2} + E_{i,t}(\\epsilon_{it} - \\overline{\\epsilon})^{2}}\\]\n\\[= \\frac{\\text{실제 값의 분산 (Variance of true values)}}{\\text{보고된 값의 분산 (Variance of reported values)}}\\]\n\n(1) 신뢰도의 해석\n응답 오차의 분산(\\(E_{i,t}(\\epsilon_{it} - \\overline{\\epsilon})^{2}\\))이 작으면 신뢰도 계수는 1에 가까워진다. 신뢰도는 어떤 설문 문항이나 측정 도구가 일관된 결과를 제공하는 정도를 나타낸다. 통계적으로는 전체 변동성 중에서 진짜 값(실제 측정하고자 하는 개념)의 분산이 차지하는 비율로 해석되며, 이 값이 1에 가까울수록 신뢰도가 높다는 의미이다.\n응답 오차의 분산이 작을수록, 즉 반복된 측정에서 응답 결과가 일정할수록 신뢰도는 높아진다. 이때 신뢰도 계수는 1에 가까워지며, 해당 측정이 안정적이고 일관된 정보를 제공한다고 판단할 수 있다. 반대로, 반복된 실험이나 조사에서 응답 결과가 크게 달라진다면, 이는 응답 오차의 분산이 크다는 뜻이며, 신뢰도 계수는 0에 가까워진다.\n결론적으로 신뢰도는 측정된 값의 총 변동성 중 실제 값이 차지하는 비율을 나타낸다. 신뢰도가 높다는 것은, 동일한 응답자에게 반복해서 질문했을 때 측정값이 재현 가능하고 변동이 적다는 의미이며, 이는 좋은 설문 도구의 핵심 요건 중 하나이다.\n\n\n(2) 개별 문항 신뢰도 측정\n참값을 알고 있을 때\n\\(R = \\frac{\\sigma_{T}^{2}}{\\sigma_{T}^{2} + \\sigma_{E}^{2}}\\), 여기서 \\(\\sigma_{T}^{2}\\)은 실제 값의 분산, \\(\\sigma_{E}^{2}\\)은 오차 분산, \\(\\sigma_{T}^{2} + \\sigma_{E}^{2}\\)은 총 분산이다. 이 식을 사용하려면 ”참값”을 직접 알아야 한다. 그러나, 현실에서는 참가자들의 ”실제 심리 상태”나 ”실제 능력”을 정확히 측정할 수 없기 때문에 현실에서는 참 값을 모르는 경우가 대부분이므로 계산할 수 없다.\n참값을 알지 못하는 경우\n같은 응답자를 대상으로 반복 면접을 실시하는 방식은 설문 문항의 신뢰도(일관성)를 평가하는 데 효과적인 방법이다. 이 접근법에서는 동일한 문항을 일정한 시간 간격을 두고 동일한 응답자에게 다시 제시하여, 두 응답 간의 차이를 분석함으로써 측정의 안정성을 평가한다.\n이러한 반복 측정이 유의미하려면 몇 가지 기본적인 가정이 전제되어야 한다.\n첫째, 응답자의 실제 속성 또는 태도(구성 개념)가 두 번의 면접 사이에서 변하지 않아야 한다. 즉, 측정 간에 실제 변화가 없어야 오차만 분석할 수 있다. 둘째, 조사 환경과 측정 조건이 동일해야 한다. 질문의 표현, 면접 방식, 응답 방식 등이 같아야 비교가 가능하다. 셋째, 기억 효과(memory effect)가 없어야 한다. 응답자가 첫 번째 면접 내용을 기억하고 두 번째에 영향을 받으면, 독립적인 응답이 되지 않기 때문이다.\n이러한 조건이 충족되면, 반복 면접을 통해 얻은 결과는 응답의 일관성과 측정 도구의 안정성을 신뢰성 있게 평가하는 데 사용될 수 있다.\n검사 재검사 신뢰도 Test-Retest Reliability\n같은 응답자에게 시간 간격을 두고 동일한 설문을 반복 측정하여 신뢰도를 평가한다. 두 번의 측정 값 간 상관관계를 계산하여 신뢰도를 추정한다.\n설문 도구의 시간에 따른 일관성을 평가하는 대표적인 방법이다. 동일한 응답자에게 동일한 문항을 시간 간격을 두고 두 번 제시하고, 그 두 번의 측정값 간의 상관계수를 계산함으로써 신뢰도를 추정한다.\n수식으로 표현하면 다음과 같다. \\(R = r(\\text{Time1, Time2})\\), 여기서 r은 첫 번째 측정값과 두 번째 측정값 간의 피어슨 상관계수를 의미한다.\n이 신뢰도가 높다는 것은, 시간의 흐름에도 불구하고 설문 문항이 응답자의 태도나 속성을 안정적으로 측정하고 있다는 의미이며, 일반적으로 r 0.70이면 수용 가능한 수준으로 본다. 단, 시간 간격이 너무 짧으면 기억 효과가 생기고, 너무 길면 실제 태도 변화가 반영될 수 있으므로 적절한 간격 설정이 중요하다.\n평행 검사 신뢰도 Parallel Forms Reliability\n동일한 개념을 측정하지만 문항의 구성이나 표현이 서로 다른 두 형태(Form A, Form B)의 설문지를 개발하여, 두 검사의 결과 간 상관관계를 통해 신뢰도를 평가하는 방법이다. 이 방법의 핵심은 두 검사가 내용적으로 동등하고 통계적으로 유사한 속성을 가져야 한다는 점입니다. 즉, A형과 B형이 서로 다른 문항을 사용하더라도, 측정하고자 하는 심리적·사회적 개념이 같아야 한다.\n\\(R = r(\\text{Form A}, \\text{Form B})\\)\n여기서 r은 동일한 응답자 집단이 두 형태의 설문에 응답했을 때의 점수 간 상관계수를 의미한다. 높은 상관계수는 두 형태 모두 일관된 측정 결과를 낸다는 것을 의미하며, 이는 설문 도구의 신뢰도를 뒷받침 한다. 이 방법은 기억 효과를 최소화할 수 있는 장점이 있지만, 문항을 두 세트로 개발해야 하므로 설계와 타당성 확보에 더 많은 노력이 필요하다.\n\n\n(3) 다수 하위 문항 신뢰도 측정\n다수의 하위 문항을 이용한 신뢰도 측정에서는 몇 가지 중요한 가정이 전제되어야 한다. 첫째, 모든 문항은 동일한 구성 개념을 반영하는 지표로서, 기대값이 동일해야 한다. 둘째, 모든 문항의 응답 편차는 일정해야 하며, 즉 단순 응답 분산이나 신뢰도가 일정해야 한다. 셋째, 각 문항의 측정값은 독립적이어야 하며, 하나의 문항에 대한 응답이 다른 문항의 응답에 영향을 미쳐서는 안 된다.\n이러한 가정을 만족하는 경우, 동일한 개념을 측정하는 여러 문항을 통해 신뢰도를 보다 정밀하게 평가할 수 있으며, 이는 문항 간의 내적 일관성(internal consistency)을 측정하는 데 중요한 역할을 한다.\n대표적인 신뢰도 측정 방법으로는 크론바흐 알파(Cronbach’s Alpha)가 있으며, 이는 다중 문항 척도의 신뢰도를 평가하는 데 널리 사용된다. 일반적으로 알파 값이 0.70 이상이면 수용 가능한 수준의 신뢰도를 가진 것으로 간주되며, 값이 높을수록 문항 간 일관성이 강하다는 것을 의미한다.\n\\(\\alpha = \\frac{k}{k - 1}\\left( 1 - \\frac{\\sum\\sigma_{Y_{i}}^{2}}{\\sigma_{Y}^{2}} \\right)\\), 여기서 \\(k\\)는 문항 개수, \\(\\sigma_{Y_{i}}^{2}\\)은 각 문항의 분산, \\(\\sigma_{Y}^{2}\\)은 총 점수의 분산이다.\n\\(\\alpha = \\frac{k\\overline{r}}{1 + (k - 1)\\overline{r}}\\), \\(\\overline{r}\\)은 문항 간 평균 상관관계이다.\n문항 간 상관이 높거나 문항 수가 많을수록 신뢰도는 증가하는 경향이 있다. 이는 크론바흐 알파 계수의 수학적 특성이며, 문항 간 일관성이 클수록 전체 척도의 내적 일관성 또한 높아진다는 것을 의미한다.\n알파 값이 0.90을 초과하는 경우, 신뢰도가 지나치게 높은 것으로 간주되어 주의가 필요하다. 이는 문항들이 거의 동일한 내용을 반복하여 측정하고 있을 가능성을 시사하며, 중복성이 높아져 설문지의 효율성을 저해할 수 있다. 이런 경우 일부 문항을 제거함으로써 척도를 간결하고 효율적으로 다듬는 것이 바람직하다.\n알파 값이 0.70에서 0.90 사이에 위치할 경우, 일반적으로 적절한 신뢰도를 가진 것으로 평가된다. 특히 심리학이나 교육학 분야에서는 0.80 이상이면 양호한 신뢰도를 나타내는 것으로 간주한다.\n다만, 문항 수가 적은 경우에는 알파 계수가 낮게 나올 수 있으며, 이는 척도의 신뢰도가 낮기 때문이 아니라 문항 수가 적어서 나타나는 현상일 수 있다. 반대로, 문항 수가 많더라도 문항 간 상관관계가 낮다면 신뢰도는 높아지지 않는다. 따라서 신뢰도를 높이기 위해서는 단순히 문항 수를 늘리는 것보다는 문항 간의 개념적 일관성과 상관관계를 높이는 것이 더 효과적이다."
  },
  {
    "objectID": "notes/survey/survey_intro.html",
    "href": "notes/survey/survey_intro.html",
    "title": "조사방법론. 1. 조사방법론 개요",
    "section": "",
    "text": "chapter 1. 개요\n\n1. 조사란?\n조사는 특정 집단, 즉 표본으로부터 정보를 수집하여, 그 집단이 속한 더 큰 모집단의 특성을 수치적으로 설명하고자 하는 체계적인 방법이다. 조사를 통해 얻어진 통계는 특정 요소 집합에 대한 관찰 결과를 요약한 수치적 표현이며, 이는 크게 두 가지 유형으로 구분된다. 이러한 통계는 사회의 다양한 모집단이 가진 특성이나 경험을 이해하고 설명하는 데 중요한 도구로 활용된다.\n첫째, 기술통계는 모집단 내 다양한 특성의 수준과 분포를 설명한다. 예를 들어, 사람들의 평균 교육 연수, 병원에 있는 총 환자 수, 대통령을 지지하는 사람들의 비율 등이 이에 해당한다.\n둘째, 분석통계는 두 개 이상의 변수 간 관계를 측정한다. 예를 들어, 소득 수준과 교육 연수 간의 관계를 설명하는 회귀계수, 혹은 지난 1년 동안 읽은 책의 수와 교육 수준 간의 상관관계 등이 이에 속한다.\n조사는 사회과학에서 사회의 작동 방식이나 행동 이론을 검증하는 데 가장 널리 사용되는 방법 중 하나이며, 다양한 형태로 수행된다. 본 강의에서는 그중 특정 유형의 조사를 중심으로 다룰 예정이며, 정보는 주로 사람들에게 질문을 통해 수집된다.\n정보 수집 방식은 조사자가 직접 질문하고 응답을 기록하거나, 응답자가 스스로 질문을 읽거나 들은 뒤 답을 작성하는 방식으로 이루어진다. 일반적으로 정보는 모집단 전체가 아닌, 기술된 모집단의 일부인 표본으로부터 수집된다.\n조사방법론은 조사 과정에서 발생하는 다양한 오류의 원인을 분석하고, 조사 결과로 얻어진 수치가 가능한 한 정확하게 모집단을 반영하도록 하기 위한 연구 분야이다. 여기서 ’오류’란 원하는 결과에서 벗어난 편차나 이탈을 의미하며, 통계적 오류는 단순한 실수가 아닌, 모집단의 실제 값과 조사로 얻은 추정값 사이의 차이를 설명하기 위해 사용된다.\n\n\n2. 조사목적\n조사는 특정 현상을 이해하고 분석하기 위해 체계적으로 데이터를 수집하고 해석하는 활동으로, 다양한 목적에 따라 설계된다. 조사 과정에서 가장 중요한 두 가지 질문은 “무엇을 발견할 것인가?“와 “가장 효과적인 방법은 무엇인가?“이다. 이러한 질문을 바탕으로, 대부분의 조사는 다음 세 가지 주요 목적을 중심으로 수행된다.\n첫째, 탐구는 관심 있는 집단이나 현상을 보다 깊이 이해하기 위한 예비적 조사로, 잘 알려지지 않은 영역이나 새로운 주제를 다룰 때 활용된다. 이는 조사 설계와 연구 방향 설정의 기초를 마련하며, 예를 들어 새로운 사회적 트렌드나 특정 인구 집단의 행동 패턴을 파악하기 위한 사전 연구가 이에 해당한다. 탐구적 조사는 주로 인터뷰나 포커스 그룹과 같은 정성적 방법을 사용하여 초기 데이터를 수집한다.\n둘째, 서술은 조사 대상 집단의 특성을 수치적 또는 질적 데이터로 기술하는 데 목적을 둔다. 이는 대상 집단의 상태를 명확히 규명하고, 그 결과를 일반화할 수 있는 기반을 제공한다. 예를 들어 실업률, 인구 구조, 산업 동향과 같은 국가 통계나 시장 조사 등이 이에 해당한다. 서술적 조사에서는 데이터의 품질과 일반화 가능성이 핵심이며, 이를 위해 엄격한 표본추출과 신뢰도 검증이 요구된다.\n셋째, 설명은 특정 현상의 원인과 결과를 실증적으로 밝히는 것을 목표로 한다. 이는 변수 간의 관계를 탐구하거나, 특정 행동이나 태도의 원인을 설명하기 위해 설계된다. 예를 들어 “왜 노년층은 보수적인 정치 성향을 보이는가?“와 같은 질문에 답하기 위해 설문조사와 통계 분석을 통해 인과 관계를 추론하는 방식이 이에 해당한다. 설명적 조사는 대체로 정량적 데이터를 바탕으로 가설 검정과 통계 분석을 수행한다.\n조사의 목적을 명확히 하기 위해서는 누구를 대상으로, 어떤 방법으로, 어떤 내용을 조사할 것인지가 분명히 정의되어야 한다. 이를 위해 조사 대상 집단을 규정하고 적절한 표본 프레임을 설정한 뒤, 수집하고자 하는 정보에 기반하여 설문 항목을 신중히 설계해야 한다.\n조사 목적은 연구의 가설 설정과 직결되며, 이 가설을 바탕으로 설문지가 구성된다. 단, 설문조사 결과를 분석한 후에 가설을 설정하거나, 조사의 목적을 설정할 때부터 결론을 미리 정하는 것은 바람직하지 않다. 이러한 방식은 조사 결과를 왜곡시킬 가능성이 있으므로 피해야 한다.\n조사 목적이 분명히 설정된 이후에는 이해관계자 또는 관련 전문가로 구성된 포커스 그룹이나 컨센서스 패널을 통해 설문지를 검토하고 개선할 필요가 있다. 또한, 유사한 주제를 다룬 기존 조사 문헌을 분석함으로써 설문지의 완성도를 높이는 것이 바람직하다.\n\n\n\nchapter 2. 조사에서의 추론과 오류\n조사는 설계 단계에서 출발하여 실행 과정을 거쳐, 궁극적으로 모집단의 통계적 특성을 설명하는 데 목적을 둔다. 조사의 출발점은 응답자가 제시하는 답변이며, 이 답변을 바탕으로 응답자의 개별적인 특성을 추론하게 된다. 이후 이러한 개인 수준의 정보는 통계적 계산을 통해 표본의 특성으로 통합되며, 다시 이를 기반으로 전체 모집단의 특성을 추론하는 과정으로 이어진다.\n즉, 조사는 응답자의 답변에서 시작하여 개인의 특성을 도출하고, 이를 표본 수준으로 확장한 뒤, 다시 모집단 수준으로 일반화하는 일련의 추론 과정을 포함한다. 이 과정에서 두 가지 핵심 조건이 충족되어야 한다.\n첫째, 응답자가 제공한 답변이 실제로 그 사람의 특성을 정확하게 반영해야 한다.\n둘째, 조사에 참여한 표본이 모집단 전체의 특성을 대표할 수 있어야 한다.\n이 두 조건 중 하나라도 충족되지 않으면 오류가 발생할 수 있다. 여기서 말하는 오류는 단순한 실수가 아니라, 의도한 결과와 실제 결과 사이의 편차를 의미한다. 예를 들어, 측정 오류는 질문에 대한 응답이 실제 측정하고자 하는 속성과 일치하지 않을 때 발생하며, 비관찰 오류는 표본으로부터 추정한 통계량이 모집단의 실제 값과 차이를 보일 때 나타난다.\n조사방법론은 이러한 오류를 체계적으로 분류하고 분석하며, 오류를 최소화하기 위해 조사 설계, 표본추출, 자료 수집 등 모든 단계에서 신중한 계획이 요구된다.\n\n1. 조사 주기(조사 설계 관점)\n조사를 바라보는 데에는 두 가지 주요 관점이 있다. 하나는 설계 관점이며, 다른 하나는 품질 관점이다. 설계 관점에서는 조사 설계를 추상적인 아이디어를 구체적인 실행 단계로 전환하는 과정으로 이해한다. 반면, 품질 관점에서는 조사 설계가 조사 통계에 영향을 미치는 다양한 오류의 근원으로 작용할 수 있음을 강조한다.\n조사는 설계 단계에서 출발하여 실행 단계로 이어진다. 적절한 설계 없이는 신뢰할 수 있는 조사 결과를 얻기 어렵다. 설계에서 실행으로 초점이 이동함에 따라 조사 작업은 추상적인 구상에서 실제적인 실행으로 전환된다. 이후 조사 결과를 해석하고 모집단에 대한 추론을 수행하는 과정에서는 다시 추상적인 수준의 사고가 요구된다.\n조사의 핵심은 측정 차원과 표현 차원이라는 두 가지 틀을 통해 설명할 수 있다. 측정 차원은 표본 내 관찰 단위에서 수집되는 데이터, 즉 “무엇에 관한 조사인가?“에 해당하며, 표현 차원은 조사에서 다루는 모집단, 즉 “누구에 관한 조사인가?“에 초점을 둔다.\n\n측정 과정\n조사의 측정 과정은 먼저 조사에서 측정하고자 하는 개념이나 구성 요소를 정의하는 것으로 시작된다. 이를 바탕으로 구체적인 측정 도구와 질문이 설계되고, 응답자는 이에 대한 답변을 제공한다. 수집된 응답은 검토 및 편집 과정을 통해 오류나 불일치가 수정되며, 정제된 데이터를 기반으로 통계가 산출된다.\n\n\n표현 과정\n표현 과정은 조사 대상이 되는 모집단을 명확히 정의하는 것으로 시작된다. 이후, 해당 모집단의 특정 부분을 대상으로 하는 표본 프레임이 설정되고, 이로부터 표본이 추출된다. 표본으로 선정된 응답자가 실제로 조사에 참여하게 되며, 조사 이후에는 필요에 따라 보정 작업이 이루어진다. 이렇게 수집된 자료는 전체 모집단을 대표하는 통계로 일반화된다.\n\n\n(1) 구성 요소 constructs\n구성 요소는 연구자가 조사에서 얻고자 하는 정보의 내용을 의미한다. 예를 들어, 고용 통계 조사는 특정 월의 근로자 수나 일자리 개수를 측정하고자 하며, 교육 성취도 평가는 학생들의 지식을 평가하는 데 목적이 있다. 전국 범죄 피해 조사는 지난 1년 동안 발생한 범죄 피해 사건의 수를 파악하려는 조사이다. 이처럼 구성 요소는 조사 목적에 따라 다양하지만, 종종 추상적이며 정확하게 측정하기 어려운 특성을 지닌다.\n예를 들어, 범죄 피해자의 정체성을 명확히 정의하는 것은 경우에 따라 모호할 수 있다. 공공장소에 낙서가 그려진 경우, 피해자를 누구로 간주할 수 있는가? 특정 수준의 범죄가 실제로 처벌의 대상이 되는 기준은 어디에 있는가? 이러한 질문들은 단순한 서술 수준의 개념을 실제 측정 가능한 항목으로 전환하는 과정에서 발생한다.\n구성 요소의 추상성은 주제에 따라 달라질 수 있다. 예를 들어, 소비자 신뢰도 조사는 개인의 재정 상태에 대한 단기적인 낙관적 태도를 측정하는데, 이는 매우 주관적이며 사람마다 인식의 차이가 크다. 반면, 전국 약물 사용 및 건강 조사는 지난달의 맥주 소비량처럼 비교적 구체적이고 관찰 가능한 행동을 측정한다. 이 경우에는 맥주로 간주되는 음료의 범위를 어떻게 정의할 것인지와 같은 실질적인 문제를 해결하는 것이 중요하다. 이처럼 소비자 신뢰도는 맥주 소비량에 비해 훨씬 더 추상적인 구성 요소라 할 수 있다.\n\n\n(2) 측정 measurement\n측정은 구성 요소보다 한층 더 구체적인 개념이다. 조사에서 ’측정’은 특정 구성 요소에 대한 정보를 수집하는 방법을 의미한다. 조사의 측정 방식은 매우 다양하며, 조사 주제에 따라 물리적 측정, 행동 관찰, 또는 질문을 통한 정보 수집 등 여러 형태로 나타난다.\n예를 들어, 유독물질 오염에 관한 조사에서는 표본 가구의 마당에서 흙 샘플을 채취할 수 있고, 건강 조사에서는 혈압을 측정할 수 있으며, 교통 조사에서는 센서를 활용해 차량 흐름을 전자적으로 기록할 수 있다. 한편, 많은 조사는 응답자에게 질문을 던져 그들의 인식이나 행동에 대한 정보를 수집하는 방식으로 이루어진다. 예를 들어, “지난 6개월 동안 본인이 범죄라고 생각한 사건과 관련해 경찰에 신고한 적이 있습니까?“와 같은 질문이 포함될 수 있다.\n측정 과정에서 가장 중요한 과제는 측정하고자 하는 구성 요소를 충실히 반영할 수 있는 질문을 설계하는 것이다. 질문이 부정확하거나 모호할 경우, 수집된 정보는 실제 구성 요소를 제대로 대변하지 못할 수 있다.\n이러한 질문은 전화 인터뷰나 대면 조사 방식으로 제시될 수 있으며, 종이 설문지나 컴퓨터를 이용한 자가 응답 방식으로도 제공될 수 있다. 경우에 따라서는 조사자가 직접 관찰을 통해 정보를 수집해야 하는 상황도 있다.\n\n\n(3) 응답 response\n조사에서 생성된 데이터는 조사 측정을 통해 수집된 정보에서 비롯되며, 응답의 성격은 사용된 측정 방법에 따라 달라진다. 질문이 측정 도구로 사용되는 경우, 응답자는 기억을 되살리거나 주관적 판단을 통해 답을 생성하거나, 기록을 참고하거나, 때로는 타인의 도움을 받아 응답할 수 있다.\n예를 들어, 소비자 신뢰도 조사에서는 “앞으로 1년 후 본인과 가족의 경제적 상황이 더 나아질 것 같은지, 더 나빠질 것 같은지, 아니면 비슷할 것 같은지”와 같은 질문이 제시된다. 반면, 고용 통계 조사에서는 고용주가 직원 기록을 확인하여 특정 주간의 비관리직 직원 수를 보고하는 방식으로 이루어진다.\n측정 방식에 따라 응답 형식도 달라진다. 어떤 경우에는 선택지가 제공되어 응답자가 해당 범주 중 하나를 선택하면 되며, 다른 경우에는 질문만 주어지고 응답자가 자신의 언어로 자유롭게 답을 작성해야 하는 경우도 있다.\n\n\n(4) 편집된 응답 edited response\n일부 데이터 수집 방식에서는 초기 측정 데이터를 다음 단계로 넘기기 전에 사전 검토 과정을 거친다. 컴퓨터를 이용한 조사에서는 정량적 응답에 대해 범위 검사를 수행하여, 허용된 한계를 벗어난 답변을 자동으로 감지하고, 후속 질문을 통해 응답의 정확성을 확인한다. 예를 들어, 출생 연도를 묻는 질문에 1890년 이전의 숫자가 입력되었거나, 한 응답자가 자신의 나이를 14세라고 답하면서 동시에 다섯 명의 자녀가 있다고 응답한 경우, 이러한 불일치를 확인하고 수정을 유도하는 후속 질문이 제시된다.\n종이 설문지의 경우에는 조사자가 설문지를 수기로 검토하여, 읽기 어려운 답변이나 누락된 항목을 찾아 보완하는 작업이 이루어진다. 이는 현장 조사자가 수행하는 1차적인 오류 점검 단계라 할 수 있다.\n모든 응답자의 답변이 수집된 이후에도 데이터에 대한 추가적인 편집 과정이 진행될 수 있다. 이 과정에서는 전체 응답 분포를 검토하고, 비정상적인 응답 패턴이나 불일치 사례를 탐지하여 이상치를 식별한다. 경우에 따라 특정 설문지나 응답자의 응답을 보다 면밀히 검토해야 할 수도 있다.\n이러한 데이터의 검토와 편집 과정은 조사 결과의 신뢰성과 정확성을 확보하기 위한 핵심적인 절차로 간주된다.\n\n\n(5) 조사 대상 모집단 target population\n조사 대상 모집단은 조사의 대상이 되는 단위들의 집합을 의미한다. 예를 들어, 가구 조사의 경우 성인을 조사 대상 모집단으로 정의할 수 있다. 그러나 이와 같은 정의는 몇 가지 세부 사항이 명확히 설정되지 않으면 해석의 여지를 남기게 된다. 조사 시점을 특정하지 않거나, 전통적인 가구 형태에 속하지 않는 사람들(예: 노숙인, 시설 거주자 등)을 포함할지 여부를 명시하지 않는다면 모집단의 범위는 모호해질 수 있다. 또한, 최근 성인이 된 사람들을 포함할 것인지, 국내 거주 상태를 어떤 기준으로 판단할 것인지 등이 명확히 정의되지 않으면, 모집단의 일관성과 재현 가능성에 문제가 발생할 수 있다.\n조사 대상 모집단은 일반적으로 유한한 규모의 개인들로 구성되며, 이들은 조사의 분석 대상이 된다. 예를 들어, 경제활동인구조사는 만 15세 이상이면서 현재 군 복무를 하지 않고, 병원·교도소·기숙사와 같은 시설이 아닌 일반 주거지에 거주하는 사람들을 모집단으로 정의한다. 모집단의 시간적 범위는 보통 특정 월이나 주로 고정되며, 이 시점에 표본으로 선정된 사람이 해당 거주지에 실제로 거주하고 있어야 한다.\n\n\n(6) 표본 프레임 모집단 frame population\n표본 프레임 모집단은 조사 표본에 선택될 가능성이 있는 대상 모집단의 구성원 집합을 의미한다. 단순한 경우에는 표본 프레임이 대상 모집단의 모든 단위(예: 개인, 고용주 등) 목록으로 구성된다. 그러나 현실에서는 표본 프레임이 대상 모집단과 완전히 일치하지 않거나, 일부 단위만을 포함하는 경우도 많다.\n예를 들어, 소비자 신뢰도 조사의 대상 모집단은 성인 가구이며, 이때 전화번호 목록이 표본 프레임으로 사용될 수 있다. 이는 각 사람을 자신이 속한 가구의 전화번호와 연결할 수 있다는 전제에 기반한다. 그러나 실제로는 전화가 없는 가구도 존재하며, 하나의 가구가 여러 개의 전화번호를 보유하고 있는 경우도 있어, 이러한 전제가 항상 성립하지 않으며 표본 프레임의 복잡성이 발생할 수 있다.\n건강 조사의 경우, 행정구역별 거주지 목록이 표본 프레임으로 활용된다. 이 목록은 각 주택 단위를 특정 시군구와 연결시키며, 일반적으로 15세 이상의 성인이 거주하는 주택을 조사 대상으로 설정한다. 그러나 고정된 거주지가 없는 사람, 혹은 복수의 거주지를 가진 사람과 같이 표본 프레임에서 다루기 어려운 사례도 존재한다.\n\n\n(7) 표본 sample\n표본은 표본프레임에서 선택된다. 이 표본은 측정을 통해 데이터를 수집할 대상 그룹이다. 표본은 표본 프레임의 매우 작은 부분만을 차지한다.\n\n\n(8) 응답자 respondents\n대부분의 조사에서는 선택된 표본 사례를 모두 성공적으로 측정하기 어렵다. 조사에 성공적으로 응답한 사례는 ‘응답자’로 분류되며, 반대로 전혀 응답하지 않은 사례는 ‘무응답자’ 또는 ’단위 무응답’으로 간주된다.\n그러나 어떤 사례를 응답자로 분류할지, 무응답자로 간주할지를 판단하는 일은 종종 명확하지 않다. 일부 응답자는 조사에서 요구되는 정보 중 일부만을 제공하는 경우가 있으며, 이 경우 응답 상태의 구분이 애매해질 수 있다. 이러한 사례에 대해 데이터를 구축할 때는, 불완전한 응답을 포함할지 아니면 해당 응답자를 분석 파일에서 제외할지를 결정해야 한다.\n한편, ‘항목 결측’ 또는 ’항목 무응답’이라는 용어는 응답자가 전체적으로는 조사에 참여했지만, 특정 질문에 대한 응답이 누락된 경우를 지칭한다. 즉, 단위 무응답이 전체 사례에 대한 응답 실패를 의미한다면, 항목 무응답은 일부 질문에 대한 응답 누락을 의미한다.\n\n\n(9) 조사 후 조정 (Postsurvey Adjustments)\n모든 응답자가 데이터를 제공하고 해당 데이터 기록이 완성된 이후에도, 조사로부터 도출된 추정치의 품질을 향상시키기 위해 추가적인 절차가 진행되는 경우가 많다. 이는 무응답 문제나, 표본 프레임과 실제 대상 모집단 간의 불일치와 같은 커버리지 문제로 인해, 응답자 기반 통계가 전체 모집단의 통계와 차이를 보일 수 있기 때문이다.\n이러한 차이를 이해하기 위해, 조사 단계에서는 서로 다른 하위 집단에 대한 단위 무응답 패턴을 분석한다. 예를 들어, 도시 지역의 응답률이 농촌 지역보다 낮은 경우, 도시 거주자가 표본에서 과소 대표되고 있을 가능성을 시사한다. 이와 유사하게, 표본 프레임 자체에 포함되지 않은 단위 유형에 대한 정보를 분석하면, 모집단 내 특정 유형이 아예 조사 대상에서 누락되었음을 확인할 수 있다.\n이후 과정에서, 과소 대표된 집단의 영향을 보정하기 위해 가중치를 조정함으로써 전체 추정치를 개선할 수 있다. 또한, 응답하지 않은 항목은 ’결측 대체(imputation)’라 불리는 절차를 통해 추정된 값으로 대체할 수 있다.\n이러한 가중 조정과 결측 대체 방법은 다양하게 존재하며, 모두 조사 후 조정(post-survey adjustment)에 해당하는 절차로 분류된다.\n\n\n\n2. 조사 주기(조사 품질 관점)\n조사 방법론에서 흔히 사용하는 품질 개념을 추가적으로 표시한 타원형을 볼 수 있다. 이 개념들은 조사 과정의 연속적인 단계 사이에서 발생하는 불일치를 나타내며, 대부분 \"오류\" 라는 단어를 포함하고 있다. 조사 설계자의 역할은 설계 및 추정 선택을 통해 이러한 오류를 최소화하여 조사 통계의 품질을 높이는 것이다.\n\n\n\n\n\n\n\\(\\mu_{i}\\): 모집단에서 \\(i\\) 번째 사람의 참 값\n\\(Y_{i}\\): \\(i\\) 번째 표본 사람의 측정값\n\\(y_{i}\\): \\(i\\) 번째 표본 측정 응답값(조사 질문에 대한 응답)\n\\(y_{ip}\\): 편집 및 추가 처리 과정을 거친 \\(i\\) 번째 표본 데이터값\n\n결론적으로, 측정하려는 기본 목표 속성은 \\(\\mu_{i}\\)이지만, 실제로는 측정 오류로 인해 목표에서 벗어난 불완전한 지표 \\(y_{ip}\\)를 사용한다.\n\n(1) 타당성 validity\n구성 요소의 타당성 validity은 측정값이 근본적인 구성 요소와 관련된 정도를 나타낸다. 반면, 타당하지 않음은 타당성이 달성되지 않은 정도를 설명하는 데 사용되는 용어다. 통계적으로, 타당성의 개념은 개별 응답자 수준에서 적용된다. 이는 구성 요소가 관찰되지 않거나 쉽게 관찰될 수 없는 경우에도, 모집단에서 \\(i\\) 번째 사람과 관련된 일부 값을 가지며, 이는 전통적으로 \\(\\mu_{i}\\)(구성 요소의 참값)로 표시된다. 특정 측정값 \\(Y_{i}\\)의 결과는 \\(\\mu_{i}\\)가 아닌 \\(Y_{i} = \\mu_{i} + \\varepsilon_{i}\\)가 된다.\n이 식에서 \\(\\varepsilon_{i}\\)는 진짜 값에서의 편차를 나타내며, 타당성 개념의 기초를 형성한다. 또한, 측정 타당성을 이해하려면 한 번의 측정이 아닌 여러 번의 반복적인 측정을 고려해야 한다. 같은 측정이 \\(i\\) 번째 사람에게 여러 번 적용될 경우 각 결과는 달라질 수 있으며, 이를 고려해 식이 \\(Y_{it} = \\mu_{i} + \\varepsilon_{it}\\)로 확장된다. 여기서 \\(t\\)는 측정 시도의 번호를 나타낸다. 결국, 타당성은 측정값과 참값 간의 상관 관계로 정의된다. 이는 측정값 \\(Y\\)와 구성 요소 \\(\\mu\\)간의 관계가 높을수록 타당성이 높은 것으로 간주된다.\n\n\n(2) 측정 오류 measurement error\n측정 오류는 측정값이 실제 값, 즉 참값에서 벗어나는 현상을 의미한다. 예를 들어, 국민건강조사에서 “코카인을 한 번이라도 사용한 적이 있습니까?“라는 질문이 있다고 가정해보자. 연구에 따르면, 응답자가 부정적으로 인식하는 행동에 대해서는 과소 보고하는 경향이 있다. 따라서 실제로는 “예”라고 응답해야 하는 사람이 자신의 약물 사용 사실이 드러나는 것을 우려해 “아니요”라고 응답할 수 있다. 이처럼 특정 질문에 대한 응답이 반복적으로 왜곡된다면, 응답값의 평균과 모집단의 실제 평균 사이에 차이가 발생하게 된다.\n통계적으로는 특정 응답자 i에 대해, 측정값과 참값 사이의 체계적 편차를 \\((y_₁ - Y_₁)\\) 로 나타낼 수 있다. 이러한 차이가 일정한 방향으로 발생하면 이를 응답 편향이라고 한다. 예를 들어, 응답자가 자신의 약물 사용이나 범죄 피해 경험을 일관되게 과소 보고하는 경우가 이에 해당한다. 이 편향은 조사 결과가 실제보다 낮거나 높게 나타나는 경향을 유발한다.\n한편, 응답 행동의 불안정성은 또 다른 유형의 오류를 야기할 수 있다. 예를 들어, “현재 사업 환경이 1년 전보다 나아졌습니까, 아니면 나빠졌습니까?“와 같은 질문에 대해 응답자는 질문의 내용뿐 아니라 앞선 질문의 맥락이나 측정 환경의 자극 등 다양한 요소에 영향을 받아 응답할 수 있다. 이러한 자극은 예측하기 어려우며, 동일한 질문을 여러 차례 반복해도 응답이 일관되지 않을 수 있다. 다시 말해, 기대값 \\(E(y_i)\\) 가 참값 \\(Y_\\) 와 일치하지 않을 수 있다.\n응답 분산은 동일한 사람에게 동일한 질문을 여러 번 했을 때 매번 다른 응답이 나타나는 현상을 의미한다. 이는 응답 편향과 구별되며, 보통 신뢰도가 낮은 측정에서 발생한다. 설문 조사에서는 이러한 응답 분산이 추정값의 불안정성을 높이는 주요 원인 중 하나로 간주된다.\n\n\n(3) 처리 오류 processing error\n데이터가 수집된 이후, 추정 단계에 들어가기 전까지 발생할 수 있는 오류에는 여러 가지가 있다. 대표적인 예로 편집 오류와 코딩 오류가 있다.\n편집 단계에서는 응답값의 신뢰성과 일관성을 검토하면서, 명백히 이상해 보이는 값을 누락 처리하거나 수정할 수 있다. 예를 들어, 한 응답자가 “매일 여러 차례 폭행을 당했다”고 보고한 경우, 이는 직관적으로 믿기 어려운 보고로 간주되어 자동 편집 규칙에 따라 결측 처리될 수 있다. 그러나 만약 해당 응답자가 술집의 보안요원이라는 추가 정보가 제공된다면, 응답 내용이 실제 상황을 반영하고 있을 가능성이 높아진다. 이처럼 측정하려는 구성 요소의 맥락에 따라 응답을 수정하거나 유지할지 여부를 판단하는 과정에서 처리 오류가 발생할 수 있다.\n또한, 코딩 단계에서도 오류가 발생할 수 있다. 텍스트 응답을 분류할 때, 동일한 응답이라 하더라도 코딩하는 사람에 따라 다르게 해석될 수 있다. 이러한 차이는 결과의 변동성을 유발하며, 코딩 시스템의 구조나 코더 간 일관성 부족에서 기인한다. 이를 흔히 코딩 분산이라 부른다. 특히 훈련이 부족한 코더는 모호한 언어나 응답자의 설명을 일관되게 해석하지 못해 잘못된 범주로 분류할 수 있으며, 이는 코딩 편향을 초래하게 된다.\n결국, 편집과 코딩 단계 모두에서 발생하는 오류는 측정 이후 데이터 품질에 영향을 미치며, 추정 단계에서의 통계적 결과에도 왜곡을 가져올 수 있다.\n통계적 표기법으로 표현하면, 예를 들어 소득과 같은 변수를 고려할 때, 처리 효과는 제공된 응답과 편집된 응답 간의 차이로 정의될 수 있다. \\(y_{i}\\)는 조사 질문에 대한 응답을, \\(y_{ip}\\)는 편집된 응답을 나타낸다. 따라서, 처리 편차는 \\((y_{ip} - y_{i})\\)로 나타낼 수 있다.\n\n\n(4) 포함오류 coverage error\n포함 오류는 모집단과 표본 프레임 간의 차이에서 발생한다. 예를 들어, 표본 프레임이 모집단의 일부를 포함하지 못한 경우를 포함 부족(undercoverage)이라고 하며, 반대로 표본 프레임에 모집단에 속하지 않는 요소가 포함된 경우는 과잉 포함(overcoverage)이라고 한다.\n통계적으로 볼 때, 표본 평균에서 발생하는 포함 편향은 두 가지 요소에 의해 결정된다. 첫째는 표본 프레임에 포함되지 않은 모집단 구성원의 비율이고, 둘째는 프레임에 포함된 구성원과 포함되지 않은 구성원 간의 특성 차이이다. 즉, 포함되지 않은 비율이 높고, 포함된 구성원과 포함되지 않은 구성원 간에 측정하고자 하는 변수의 평균 차이가 클수록 포함 편향은 커지게 된다.\n\\({\\overline{Y}}_{C} - \\overline{Y} = \\frac{U}{N}({\\overline{Y}}_{C} - {\\overline{Y}}_{U})\\), 여기서 \\(\\overline{Y}\\)는 목표 모집단 전체의 평균, \\({\\overline{Y}}_{C}\\)는 표본 프레임에 포함된 모집단의 평균, \\({\\overline{Y}}_{U}\\)는 표본 프레임 밖 모집단의 평균을 나타낸다. \\(N\\)은 목표 모집단의 총 구성원 수, \\(C\\)는 표본 프레임에 포함된 적격 구성원의 총수, 그리고 \\(U\\)는 표본 프레임에 포함되지 않은 적격 구성원의 총수이다.\n예를 들어, 전화 조사를 통해 가구의 평균 교육 연수를 측정한다고 가정하자. 전화가 없는 가구는 표본에서 제외되므로 이들의 평균 교육 연수는 낮아질 가능성이 있다. 전화가 있는 가구의 평균 교육 연수가 14.3년이고, 전화가 없는 가구의 평균 교육 연수가 11.2년이라면, 전체 모집단 평균에 대한 편향은 다음과 같이 계산될 수 있다(단, 전화 없는 가구 비율을 5%라 가정하자).\n\\({\\overline{Y}}_{C} - \\overline{Y} = 0.05(14.3 - 11.2) = 0.16\\text{년}\\).\n즉, 전화가 없는 가구를 포함하지 않은 표본 프레임은 모집단 평균보다 약 0.16년 더 높은 평균 교육 연수를 보여줄 것이다. 결론적으로, 표본 프레임의 포괄 오류는 표본 평균 추정값에 영향을 미치며, 이는 모집단 평균이 아닌 표본 프레임 평균을 반영하게 된다.\n\n\n(5) 표본 오류 sampling err0r\n표본 설문조사에서는 비용과 시간의 제약으로 인해, 표본 프레임 내 모든 구성원을 조사하는 것이 현실적으로 어렵다. 따라서 전체 중 일부만을 선택하여 조사하고, 나머지는 제외하는 방식이 일반적으로 채택된다. 이러한 선택적 측정으로 인해 발생하는 통계적 차이를 표본 오류라고 한다.\n표본 오류는 크게 두 가지 유형으로 구분된다. - 표본 편향(sampling bias)은 표본 프레임의 일부 구성원이 표본으로 선택될 기회를 갖지 못하거나, 선택될 가능성이 상대적으로 낮을 때 발생한다. 예를 들어, 특정 표본 설계가 체계적으로 일부 그룹을 항상 제외하도록 구성되어 있다면, 그 결과로 도출된 통계치는 실제 프레임 모집단의 통계와 차이를 보일 수 있다. - 표본 분산(sampling variance)은 동일한 방법으로 표본을 반복 추출할 경우, 각 표본이 서로 다른 응답을 포함하게 되어 조사 통계가 반복마다 달라질 수 있는 현상을 의미한다. 이는 표본 선택이 확률적일 때 자연스럽게 발생하는 오차로, 표본의 수나 분포에 따라 크기가 달라질 수 있다. 표본 선택의 여러 가능성을 개념적으로 반복한 결과, 표본 분산의 개념이 만들어진다. 표본 분산은 동일한 설계에서 얻어진 여러 표본 평균이 얼마나 변동하는지를 나타낸다.\n\n\\({\\overline{Y}}_{s}\\): 특정 표본 추출의 표본 평균, 표본 \\(s;s = 1,2,\\ldots,S\\)\n\\({\\overline{Y}}_{C}\\): 표본 프레임에서의 모든 요소의 총평균\n\\(\\overline{Y}_s = \\frac{\\sum_{i=1}^{n_s} y_{si}}{n_s},\\ \\overline{Y}_C = \\frac{\\sum_{i=1}^{C} Y_i}{C}\\)\n표본 분산: \\(\\frac{\\sum_{s = 1}^{S}({\\overline{Y}}_{s} - {\\overline{Y}}_{C})^{2}}{S}\\)\n\n\n\n(6) 응답률 오류 nonresponse error\n모든 표본 구성원을 설문조사에서 완전히 측정하는 것은 현실적으로 어렵다. 특히 사람을 대상으로 하는 조사에서는 이러한 상황이 자주 발생한다. 이로 인해 발생하는 오류를 응답률 오류라고 하며, 이는 실제 응답한 사람들의 통계 값이 전체 표본을 기준으로 했을 때의 통계 값과 다를 때 나타난다.\n예를 들어, 수행평가 당일 결석한 학생들이 수학적 또는 언어적 능력이 낮은 경향이 있다면, 이들이 측정에서 제외됨으로써 전체 수행평가 점수가 과대평가될 수 있다. 즉, 응답자의 평균 점수가 전체 표본의 진정한 평균보다 체계적으로 높아지는 결과가 나타난다. 이러한 오류는 응답률이 낮을수록 그 영향이 커지며, 조사 결과의 왜곡 가능성도 더욱 심각해질 수 있다.\n응답률 편향: \\({\\overline{y}}_{r} - {\\overline{y}}_{s} = \\frac{m_{s}}{n_{s}}({\\overline{y}}_{r} - {\\overline{y}}_{m})\\)\n\n\\({\\overline{y}}_{s}\\): 선택된 특정 표본의 전체 평균,\n\\({\\overline{y}}_{r}\\): 𝑠번째 표본의 응답자 평균, \\({\\overline{y}}_{m}\\): 𝑠번째 표본의 비응답자 평균\n\n𝑛𝑠: 𝑠번째 표본의 총 구성원 수, 𝑟𝑠: 𝑠번째 표본의 응답자 수, 𝑚𝑠: 𝑠번째 표본의 비응답자 수\n따라서 표본 평균에 대한 응답률 편향은 응답률(데이터가 수집되지 않은 표본 구성원의 비율)과 응답자와 비응답자 평균 간의 차이의 곱으로 나타난다. 이는 높은 응답률만으로는 반드시 품질 지표가 아님을 나타낸다. 응답률이 높은 설문조사에서도 비응답자가 조사 변수에서 매우 독특할 경우, 높은 응답률 편향이 나타날 수 있다. 이 문제를 방지하는 가장 좋은 방법은 높은 응답률을 유지하여 응답률 편향의 위험을 줄이는 것이다.\n\n\n(7) 보정 오류 adjustment error\n조사에서 발생하는 비관측 오류를 줄이기 위한 마지막 단계는 조사 후 보정이다. 이 보정은 표본 추정치를 개선하기 위해 시행되며, 포함 오류, 표본 오류, 무응답 오류와 같은 오류를 줄이는 것을 목표로 하며, 보정 과정은 개별 응답에 대한 수정 단계와 유사한 역할을 한다.\n보정은 대상 모집단 또는 표본 프레임에 대한 정보와 응답률 데이터를 활용하여 과소 대표된 표본 사례에 더 큰 가중치를 부여함으로써 데이터의 균형을 맞춘다. 예를 들어, A지역의 응답률이 85%인 경우 해당 지역 응답자에게 \\(w_{i} = 1/0.85\\)의 가중치를 부여하여 특정 응답자의 영향을 평균 계산에서 확대한다.\n조정된 평균은 이러한 가중치를 적용해 계산되며, 조정된 표본 평균(\\(\\overline{y}nw = \\frac{\\sum_{i = 1}^{r}w_{i}y_{si}}{\\sum_{i = 1}^{r}w_{i}}\\))과 모집단 평균과 간의 차이는 \\(({\\overline{y}}_{nw} - \\overline{Y})\\) 로 나타난다. 이러한 보정은 통계적 편향을 줄이는 데 기여하지만, 경우에 따라 오류를 오히려 증가시킬 수도 있으므로 설계와 실행 단계에서 세심한 주의가 필요하다.\n\n\n\n\nchapter 3. 목표모집단, 표본프레임, 포함오류\n표본 설문조사는 명확히 정의된 모집단을 설명하거나, 그로부터 통계적 추론을 도출하는 과정이다. 이때 모집단을 구성하는 기본 단위는 ‘요소’ 또는 ’조사단위’로 불리며, 이 요소들이 전체 모집단을 형성한다. 예를 들어, 가구 조사의 경우 요소는 개별 가구원일 수 있으며, 학교 조사의 경우에는 학생이, 비즈니스 조사의 경우에는 사업체나 시설이 요소가 된다. 하나의 설문조사 내에서도 다양한 유형의 요소가 존재할 수 있다. 가구 조사의 경우, 조사 대상은 사람일 수도 있지만, 주거 단위나 거주 커뮤니티 등과 같은 더 넓은 단위로 확장될 수도 있다.\n설문조사에서 모집단 정의는 조사 설계와 결과 해석의 출발점이자 핵심이다. 모집단을 어떻게 정의하느냐에 따라 데이터의 대표성과 신뢰성이 결정되며, 이는 추론의 정확도와 직결된다. 다음은 설문조사에서 모집단 정의가 중요한 이유를 설명하는 네 가지 측면이다.\n설문의 주요 목적\n설문조사의 핵심 목적은 특정 모집단의 특성을 통계적으로 설명하거나, 그 모집단에 대해 일반화된 결론을 도출하는 것이다. 모집단이 명확히 정의되지 않으면, 조사 결과의 정확성과 대표성이 저하될 수 있다. 모집단 정의는 조사 결과가 어떤 집단을 설명하고 있는지를 분명히 밝히는 역할을 한다.\n조사의 설계 및 표본 추출\n설문조사는 모집단으로부터 표본을 추출하고, 이를 통해 모집단 전체에 대한 추정치를 산출한다. 모집단 정의가 불명확하면 표본 추출 과정에 왜곡이 생기고, 결과적으로 표본이 모집단을 제대로 대표하지 못하게 된다. 따라서 모집단 정의는 표본 설계의 출발점으로서 반드시 선행되어야 한다.\n다양한 단위와 요소 처리\n하나의 조사에서도 사람, 가구, 기업 등 다양한 요소들이 존재할 수 있다. 이러한 요소들의 범위와 성격이 명확히 정의되지 않으면, 데이터 해석 과정에서 혼란이 발생할 수 있으며, 잘못된 결론으로 이어질 위험도 존재한다.\n다른 연구와의 차별성\n실험 연구와 같이 자극과 반응 간의 인과관계를 규명하는 데 초점을 맞춘 연구에서는 모집단 정의가 상대적으로 부차적인 요소일 수 있다. 반면, 설문조사는 모집단 전체의 특성을 설명하고 해석하는 것을 궁극적인 목표로 삼기 때문에, 모집단 정의는 조사 전 과정에서 가장 중요한 요소 중 하나로 간주된다.\n\n1. 모집단과 프레임\n목표 모집단(target population)은 조사 결과를 일반화하고자 하는, 즉 표본 통계를 통해 추론하고자 하는 요소들의 집합을 의미한다. 목표 모집단은 다음과 같은 조건을 충족해야 한다:\n\n크기가 유한해야 한다. 이론적으로라도 개별 요소들을 셀 수 있어야 한다.\n시간적으로 정의되어야 한다. 특정 시점 또는 시기 내에서 존재하는 집단이어야 한다.\n관찰 가능해야 한다. 즉, 실제로 접근하여 조사할 수 있어야 한다.\n\n목표 모집단을 정의할 때는 두 가지 요소를 명확히 해야 한다. 첫째, 어떤 단위를 모집단의 요소로 간주할 것인가(예: 사람, 가구, 시설). 둘째, 어떤 시간적 범위를 설정할 것인가. 예를 들어, 가구 조사의 경우 조사 대상은 일반적으로 경제활동인구에 해당하는 만 15세 이상의 성인으로, 주택 단위에서 거주하는 사람들을 포함한다. 이때 ’가구’는 집, 아파트, 이동식 주택, 방 그룹 또는 독립된 방처럼 거주를 목적으로 마련된 공간을 포함한다.\n모든 사람이 반드시 성인이거나 주택에 거주하는 것은 아니므로(예: 교도소 수감자, 군부대 거주자, 장기 요양시설 입소자 등), 이들이 목표 모집단에 포함될지 여부는 조사의 목적과 범위에 따라 달라질 수 있다. 어떤 조사는 특정 지역(예: 특광역시)으로 모집단을 한정하기도 하며, 어떤 조사는 시설 거주자를 포함하기도 한다.\n모집단은 고정된 것이 아니라 시간에 따라 변할 수 있기 때문에, 조사 시점 역시 모집단 정의의 중요한 요소이다. 예를 들어, 가구 조사가 며칠 혹은 몇 주에 걸쳐 이루어질 경우, 그 조사 기간 중 해당 주택에 거주하는 사람이 모집단에 포함된다. 실무에서는 첫 번째 접촉 시점에서 거주자가 누구인지를 기준으로 모집단을 “고정”하는 방식을 자주 사용한다.\n그러나 실제로 조사 데이터를 수집할 때는, 조사 방법 자체가 모집단을 더 좁은 범위로 제한하는 경우가 많다. 예를 들어, 목표 모집단이 ’대한민국에 거주하는 만 18세 이상 성인’이라 하더라도, 전화 조사는 실제로 전화번호를 가진 사람들만 조사할 수 있다. 이처럼 실질적으로 조사가 이루어진 집단을 조사 모집단(survey population)이라 하며, 이는 원래 목표 모집단과 다를 수 있다.\n조사를 설계하기 위해서는 표본 프레임(sample frame)이 필요하다. 표본 프레임은 모집단 요소를 식별할 수 있는 자료 집합으로, 요소들의 명부(예: 회원 명단, 주소록)나 요소가 존재하는 지역·시설·시점의 목록일 수 있다. 예를 들어, 특정 전문 협회 회원 명단, 특정 지역 내 사업체 목록 등이 이에 해당한다.\n그러나 실제 조사에서는 단일한 표본 프레임이 존재하지 않는 경우도 많다. 예를 들어, 서울 지역 모든 초중고등학생의 명단이나, 교정시설 수감자 전체 명단은 현실적으로 존재하지 않거나 접근이 어렵다. 이 경우 조사자는 두 가지 선택지를 고려할 수 있다.\n\n표본 프레임에 맞게 목표 모집단을 재정의한다.\n원래 모집단을 유지하되, 포함 오류(coverage error)의 가능성을 인정한다.\n\n예를 들어, 전화 조사를 설계할 때 목표 모집단이 미국의 모든 성인이라 하더라도, 실제 표본 프레임은 전화번호를 보유한 성인으로 제한될 수 있다. 모집단을 전화가 있는 성인으로 재정의하는 것은 모집단과 프레임 간의 불일치를 해결하는 방식이지만, 원래 모집단을 그대로 유지할 경우에는 전화가 없는 성인이 누락되어 포함 오류가 발생한다.\n마지막으로, 표본 프레임 없이 조사를 수행해야 하는 경우도 있다. 이때는 확률 표집이 어려우므로, 눈덩이 표집(snowball sampling)이나 특정 지역을 설정한 현장 조사와 같은 비확률 표집(nonprobability sampling) 방식이 활용되기도 한다.\n\n\n2. 표본프레임의 포함 이슈\n조사에서 연구자들에게 중요한 통계적 관심은 표본 프레임(표본을 선택하기 위해 사용 가능한 자료)이 실제로 목표 모집단을 얼마나 잘 포함하고 있는가이다. 표본 프레임과 목표 모집단 간의 일치는 포함, 미포함(목표 모집단에 포함되어야 하지만 표본 프레임에 포함되지 않거나 포함될 수 없는 요소), 비적격(목표 모집단에 속하지 않지만 표본 프레임에 포함된 단위) 단위를 포함한 세 가지 잠재적 결과를 초래할 수 있다.\n표본 프레임이 완벽하다는 것은 프레임 요소와 목표 모집단 요소 간에 일대일 매핑이 있다는 것을 의미한다. 실제로는 완벽한 프레임이 존재하지 않으며, 일대일 매핑을 방해하는 문제가 항상 발생한다.\n프레임의 적합성을 논의할 때 포함 오류와 비적격 단위 문제이외 프레임 단위가 존재하고 목표 모집단의 요소와 매핑되지만 그 매핑이 고유하지 않을 때 발생하는 문제도 논의 되어야 한다. ”중복”은 여러 프레임 단위가 목표 모집단의 단일 요소에 매핑될 때 사용된다.\n”군집화”는 여러 목표 모집단 요소가 동일한 단일 프레임 요소와 연결될 때 사용되는 용어다. 표본 크기(요소 수로 측정)는 선택된 군집에 따라 클 수도 있고 작을 수도 있다. 또한 여러 프레임 단위가 여러 목표 모집단 요소와 매핑되는 경우(다대다 매핑)도 있다.\n\n(1) 미포함 undercoverage\n미포함 정의\n미포함는 조사 통계에서 특정 모집단 부분이 포함되지 않아 발생하는 오류를 뜻한다. 예를 들어, 전화 가구 조사는 모든 가구의 사람들을 대상으로 하지만, 전화 프레임에는 전화가 없는 가구가 포함되지 않아 미포함이 발생한다. 세계 여러 국가에서 전화 사용이 지속적인 비용을 요구하기 때문에 경제적으로 어려운 계층이 비율적으로 더 많이 제외된다. 또한, 휴대전화가 고정전화 서비스를 대체하는 국가에서는 젊은 사람들이 새로운 기술을 더 빨리 수용하기 때문에 고정전화 기반 프레임에서 제외될 가능성이 높다.\n미포함 문제의 원인\n미포함 문제는 표본 프레임 생성 과정에 따라 발생한다. 이 과정은 조사 설계에 의해 통제될 수도 있고, 외부 출처에서 프레임을 얻을 때는 조사 외부 요인에 의해 결정될 수도 있다. 예를 들어, 가구 조사의 경우, 조사 표본은 초기 지역 목록(시군구 등)에서 시작하여 시군구 내의 주택 목록으로 세분화되고, 최종적으로 가구 내 거주자 목록으로 연결된다. 이러한 샘플링 과정은 지역 샘플로 불린다.\n문제의 수준\n\n지리적 경계: 도로, 강, 철도 등 물리적 경계는 상대적으로 쉽게 구별되지만, 자연 경계선(산등성이, 능선 등)은 해석에 따라 차이가 발생할 수 있다. 경계 해석 오류로 인해 특정 가구가 목록에서 누락될 가능성이 있다.\n가구 정의: 가구는 독립된 입구를 갖춘 물리적 구조로 정의되지만, 추가가구나 숨겨진 입구가 있는 경우 누락될 가능성이 있다.\n특수 사례: 공동체 생활(공동 주방 사용 등)이나 제도적 시설(교도소, 병원 등)의 경우, 거주 단위를 정의하고 포함 여부를 결정하는 규칙이 필요하다.\n\n주민 등록 규칙의 문제\n조사에서 거주자는 일반적으로 ”일반 거주” 규칙에 따라 정의된다. 이 규칙은 거주 단위에서 통상적으로 거주하는 사람을 포함하도록 한다. 하지만, 여행하는 직업(트럭 운전사, 항공 조종사 등)을 가진 사람들의 경우 거주지 정의가 모호할 수 있다. 또한, 부모와 떨어져 살거나 복잡한 가족 구조를 가진 아동도 미포함이 발생할 수 있다.\n사업체 조사에서의 Undercoverage\n사업체 조사는 사업체의 생성, 병합, 종료로 인해 미포함이 발생할 가능성이 높다. 특히 대규모 또는 소규모 사업체는 표본 프레임에 포함되지 않을 수 있다. 새로운 사업체는 행정적 기록의 지연으로 프레임에서 누락되거나, 복잡한 사업체 구조는 데이터 정리 과정에서 오류를 일으킬 수 있다.\n\n\n(2) 부적격 단위 ineligible units\n표본 프레임에는 때로 목표 모집단에 속하지 않는 요소들이 포함될 수 있다. 예를 들어, 전화번호 프레임에는 작업 또는 비거주 전화번호가 많이 포함될 수 있는데, 이는 가구 모집단을 대상으로 하는 프레임의 사용을 복잡하게 만든다. 지역 확률 조사에서는 종종 지도 자료에 목표 지리적 영역 외부의 단위가 포함될 수 있다. 조사원이 주택 단위를 나열하기 위해 표본 영역을 방문할 때, 때때로 점유되지 않았거나 주택 단위로 보이는 사업장 구조물을 포함시킬 수 있다.\n조사원이 주택 단위에서 가구 구성원의 목록을 작성할 때, 응답자가 생각하는 ”가구”의 개념과 조사에서 요구하는 정의가 다를 수 있다. 예를 들어, 집을 떠나 학교에 다니는 학생의 부모는 여전히 그들을 가구의 일부로 여길 수 있지만, 대부분의 조사에서는 이들을 대학생으로 분류하여 별도로 다룬다. 또한, 응답자는 같은 주택 내에서 방을 임대해 거주하는 사람이나 친족 관계가 없는 사람들을 가구 구성원으로 포함하지 않을 가능성이 높다. 이는 조사 결과에서 특정 가구 유형이나 가족 구성원의 불균형을 초래할 수 있다.\n프레임에서 선택 시작 전에 외부 단위가 식별되면 적은 비용으로 제거될 수 있다. 외부 단위의 비율이 소수라면 표본 크기를 줄이는 것과 같은 스크리닝 단계에서 이를 식별하고 표본에서 제외할 수 있다. 외부 단위의 발생률이 대략적으로라도 사전에 알려진 경우, 일부 외부 단위를 스크리닝할 것을 예상하며 추가 단위를 선택할 수 있다. 예를 들어, 전국 전화번호 명부 리스트의 약 15%가 더 이상 존재하지 않는 번호임을 알고 있는 경우, 100개의 전화 가구 표본을 얻기 위해 디렉토리에서 100/(1 - 0.15) = 118개의 항목을 선택할 수 있으며, 그 중 18개가 유효하지 않는 번호일 것이다.\n\n\n(3) 프레임 요소 내에서 목표 모집단 요소의 클러스터링\n프레임에서 모집단으로, 또는 모집단에서 프레임으로의 다중 매핑(클러스터링 또는 중복)은 표본 선택에서 문제를 일으킬 수 있다. 전화번호부를 표본 프레임으로 사용해 전화 가구에 거주하는 성인(목표 모집단)을 표본으로 삼는 경우 전화번호부에 나열된 가구에는 하나의 프레임 요소(전화번호)로 여러 성인이 포함될 수 있다.\n클러스터링 문제의 예\n홍길동 가족(홀길동, 홍길동 아내, 홀길동 부모)은 같은 가구에 살며 동일 전화번호를 공유한다. 이 전화번호는 표본 프레임 요소로 사용되며, 홀길동 가족 모두가 동일한 프레임 요소와 연결됩니다. 그러나 이들은 목표 모집단의 4 요소를 구성한다.\n클러스터링 문제 해결 방법\n클러스터링 문제를 해결하는 한 가지 방법은 선택된 프레임 요소(예: 전화번호)에 속한 모든 자격 요소(목표 모집단 요소)를 포함하는 것이다. 이러한 설계에서는 클러스터 내의 모든 요소에 동일한 선택 확률이 적용된다.\n클러스터링 문제의 중요성\n클러스터링은 종종 클러스터를 부분적으로 표본화 하게 되는 중요한 문제를 제기한다.\n\n첫째, 일부 경우 클러스터의 모든 요소에서 성공적으로 정보를 수집하기 어려울 수 있다. 예를 들어, 전화 가구 조사에서는 한 가구에서 여러 번 인터뷰를 시도하면 무응답 비율이 증가하는 경우가 있다.\n둘째, 인터뷰가 여러 시간대에 걸쳐 진행되어야 할 경우 초기 응답자가 나중 응답자에게 설문 내용을 논의하면서 답변에 영향을 줄 수 있다.\n셋째, 클러스터 크기가 다를 경우 표본 크기 통제가 어려워질 수 있다.\n\n클러스터 크기와 표본 왜곡\n큰 클러스터의 요소는 작은 클러스터 요소에 비해 선택될 확률이 낮다. 예를 들어, 전화번호가 표본으로 선택되었을 때 두 명의 자격 요소를 포함한 가구에서는 한 사람이 선택될 확률이 50%인 반면, 네 명의 자격 요소를 포함한 가구에서는 각각 25%의 확률을 갖게 된다. 이러한 샘플링의 결과로 소규모 가구의 구성원이 목표 모집단에 비해 과대표될 가능성이 있다. 예를 들어, 범죄 피해 조사에서 소규모 가구의 구성원이 범죄 피해를 입을 확률이 더 높은 경우, 클러스터 크기와 변수 간의 관계로 인해 표본 결과는 편향된 추정치를 제공할 수 있다.\n해결 방법\n이러한 편향을 제거하기 위해 분석 과정에서 보상 조치를 취해야 한다. 클러스터 내 자격 요소 수에 따라 가중치를 적용해 표본 추정치를 수정할 수 있다.\n\n\n(4) 표본 프레임에서 목표 모집단 요소의 중복\n프레임과 목표 모집단 사이의 또 다른 중복 매핑 유형은 ”중복”이다. 중복은 단일 목표 모집단 요소가 여러 프레임 요소와 연관된 경우를 의미한다. 전화 설문조사 예를 들어, 단일 전화 가구가 전화번호부에 여러 번 나열되는 경우가 있다. 홍길동 목표 모집단 구성원은 전화번호 두 개를 등록하여 두 개의 프레임 요소와 연관되어 있다고 하자. 이러한 프레임 문제는 클러스터링과 유사하다. 여러 프레임 단위를 가진 목표 모집단 요소는 선택될 확률이 높아져 모집단에 비해 과대 대표된다. 중복과 관심 변수 간의 상관관계가 있는 경우, 설문조사 추정치는 편향될 수 있다. 문제는 중복 여부와 중복과 조사 변수 간의 상관관계가 종종 알려지지 않는다는 점이다.\n중복으로 인한 편향 문제는 다양한 방식으로 해결할 수 있다. 첫 번째 방법은 표본 선택 전에 프레임에서 중복 항목을 제거하는 것이다. 예를 들어, 전자 전화번호부를 정렬하여 동일한 번호의 중복 항목을 삭제하는 방식이다. 두 번째 방법은 표본 선택 과정이나 데이터 수집 중에 중복된 프레임 단위를 식별하는 것이다. 이 경우, 간단한 규칙을 적용하여 중복 항목을 처리할 수 있다. 예를 들어, 디렉토리에 여러 항목이 있을 경우, 첫 번째 항목만 유효하다고 간주하는 규칙을 사용할 수 있다. 데이터 수집 중에는 조사원이 가구에 여러 디렉토리 항목이 있는지 확인한 뒤, 확인된 중복 항목 중 첫 번째 항목만 선택하고 나머지는 ”외부 단위”로 분류하여 제외할 수 있다. 이러한 접근 방식은 중복으로 인한 표본 편향을 줄이는 데 효과적이다.\n또 다른 해결책은 가중치를 부여하는 방법이다. 클러스터링의 경우와 유사하게, 중복된 프레임 요소의 개수를 기반으로 역수를 사용하여 가중치를 계산한다. 예를 들어, 한 전화 가구가 두 개의 전화선을 보유하고 있으며 디렉토리에 총 세 개의 항목(한 개 번호는 홍길동 처의 이름으로 중복 등록)이 등재되어 있다면, 이 가구는 표본 내에서 가중치 1/3을 받게 된다. 반면, 무작위 숫자 다이얼(RDD) 프레임에서는 해당 가구가 가중치 1/2을 받게 된다. 이러한 가중치 계산은 표본 내의 중복 문제를 보정하여 통계적 편향을 최소화하는 데 기여한다.\n표본 프레임과 목표 모집단 요소 간의 복잡한 매핑\n다수의 프레임 단위가 여러 모집단 요소에 매핑될 가능성도 있습니다. 예를 들어, 성인을 대상으로 한 전화 가구 조사에서는 디렉토리에 여러 항목이 포함된 여러 성인이 있는 가구를 만날 수 있습니다. 이러한 다대다 매핑 문제는 클러스터링과 중복의 조합입니다.\n예를 들어, 홍길동 가구는 두 개의 전화번호 프레임 요소를 가지고 있으며, 이는 두 개의 표본 프레임 요소에 매핑된 세 개의 목표 모집단 요소를 나타낼 수 있습니다. 이 문제에 대한 일반적인 해결책은 조사 결과에 가중치를 부여하여 두 문제를 동시에 처리하는 것입니다. 개별 수준 통계를 위한 보정 가중치는 가구의 성인(또는 적격자) 수를 해당 가구의 프레임 항목 수로 나눈 값으로 정의됩니다. 예를 들어, 홍길동 가구의 구성원에게 부여되는 가중치는 1/2이 됩니다.\n\n\n\n3. 목표모집단과 표본프레임 이슈\n\n(1) 가구와 개인\n가구를 대상으로 한 일반적인 표본 프레임에는 지역 프레임(인구조사 구역 또는 카운티와 같은 지역 단위 목록), 전화번호, 전화목록, 그리고 우편목록이 있다. 지역 프레임은 지리적 단위를 기반으로 하기 때문에, 사람이 해당 지역에 속한다는 것을 거주 연결 규칙을 통해 연관지어야 한다. 이러한 프레임은 개인을 표본으로 선택할 때 여러 단계를 요구한다. 먼저 지역 단위의 일부를 선택한 후, 해당 구역의 주소 목록을 작성해야 한다. 우수한 지도나 항공사진이 있는 경우, 이 프레임은 이론적으로 주거지의 완전한 범위를 제공할 수 있다. 그러나 선택된 지역 단위 내 주거지 목록에 일부 누락된 단위가 존재할 경우, 프레임은 불포함 오류를 겪게 된다. 한 사람이 두 개 이상의 거주지를 가지고 있는 경우에는 중복 문제가 발생하며, 여러 사람이 동일한 거주지에 거주하는 경우에는 개인을 표본으로 선택할 때 클러스터링 문제가 발생한다.\n또 다른 가구 모집단 프레임은 주택 내 유선전화 번호를 기반으로 한 프레임이다. 일부 가구는 여러 개의 전화번호를 보유하고 있어 과포함 문제가 발생할 수 있다. 이 프레임에는 사용되지 않는 전화번호와 비주거용 번호가 포함되어 있기 때문에, 이를 개인 수준의 표본으로 활용하려면 제거해야 한다.\n주거용 전화번호 목록 프레임은 전화번호 프레임보다 범위가 좁지만, 비작동 번호와 비주거용 번호가 대부분 제거되어 있어 가구 조사에서는 더 효율적이다. 이 목록은 상업적 기업이 전자 및 인쇄된 전화번호 디렉토리에서 얻으며, 대량 발송업자와 조사기관에 판매한다. 그러나 상당수의 주거용 번호가 디렉토리에 포함되지 않으며, 특히 도시 지역 거주자나 일시적인 거주자의 번호가 빠질 수 있다. 같은 번호가 여러 이름으로 등재되는 경우도 많아 중복 문제가 발생하기도 한다.\n웹 설문조사에 대한 관심이 높아지면서, 이메일 주소를 기반으로 한 가구 모집단 프레임 개발에 주목이 쏠리고 있다. 그러나 이메일 프레임은 전체 가구 모집단을 충분히 포함하지 못하며, 한 사람이 여러 이메일 주소를 보유하거나 여러 사람이 하나의 이메일을 공유하는 등의 이유로 중복 및 클러스터링 문제가 존재한다.\n모바일 또는 휴대전화는 많은 국가에서 유선 전화를 빠르게 대체하고 있다. 예를 들어, 핀란드에서는 1990년대 중반부터 유선 전화 가입자가 감소하고 휴대전화 가입자가 급격히 증가하였다. 이는 기존의 유선 전화 기반 프레임에서 휴대전화 번호가 누락됨에 따라, 프레임 손실이 발생했음을 의미한다. 특히 젊은 세대 중 독립적인 가구를 처음 형성하는 층에서 이러한 손실이 두드러졌다.\n더욱이 휴대전화는 유선전화와 달리 한 사람과 직접 연결되며, 전체 가구 단위와 연결되지 않는다. 따라서 전화 설문조사는 휴대전화 번호를 표본으로 사용할 수밖에 없으며, 이는 프레임과 표본 단위가 가구에서 개인으로 분리되는 것을 요구하게 된다. 현재로서는 유선전화와 휴대전화 번호의 병용에서 비롯된 클러스터링과 중복 문제 등 여러 프레임 관련 이슈가 해결되지 않은 상태이다.\n\n\n(2) 고객, 고용주 또는 조직 구성원\n표본 프레임은 전자 파일 또는 인쇄물 형식으로 구성된 개인 기록일 수 있으며, 이러한 시스템은 주기적인 업데이트 지연으로 인해 불포함 오류가 발생하거나, 조직을 이미 떠난 인물이 빠르게 제거되지 않아 부적격 요소를 포함할 수 있다. 예를 들어, 마지막 거래가 오래전에 이루어진 고객이 여전히 목록에 남아 있는 경우가 있으며, 계약직 직원처럼 조직과의 소속이 모호한 경우도 존재한다. 고객 기반 프레임에서는 거래 단위별로 동일한 고객이 여러 차례 기록되어 중복이 발생할 수 있으며, 이때 설문조사 연구자는 목표 모집단이 ’사람’인지, ’거래’인지, 혹은 둘 다인지를 신중히 판단해야 한다.\n설문조사 연구자는 대체 가능한 프레임을 평가할 때, 해당 목록이 어떤 방식으로 생성되고 수정되는지 파악해야 하며, 예컨대 급여 목록이나 보안 시스템 기록이 특정 직원 집단을 포함하거나 제외할 가능성도 함께 검토해야 한다. 특히 월급제와 주급제의 차이, 임시 결근, 장기 병가 등은 프레임의 포괄성과 대표성을 더욱 복잡하게 만들 수 있다. 따라서 각 설문조사에서는 프레임에 포함될 대상의 기준과 선택 절차를 명확히 정의하고, 그 적절성을 면밀히 검토하는 과정이 반드시 필요하다.\n\n\n(3) 기관\n기관을 대상으로 한 표본 프레임은 일반적으로 단위 목록으로 구성되며, 이 중 기업체는 아마도 설문조사에서 가장 빈번하게 설정되는 목표 모집단일 것이다. 기업 모집단은 고유한 프레임 문제를 수반한다.\n첫째, 기업 모집단의 중요한 특성 중 하나는 규모의 차이가 매우 크다는 점이다. 예를 들어, 소프트웨어 판매업체를 조사할 경우, 연매출이 매우 큰 NC소프트와 소규모 소매점을 모두 프레임에 포함해야 한다. 많은 기업 설문조사는 산업 내 전체 고용 규모나 매출과 같은 크기 관련 변수를 측정하기 때문에, 프레임의 포괄성 문제는 일반적으로 가장 작은 기업보다 가장 큰 기업을 포함하는 데 더 많은 주의를 기울이게 된다.\n둘째, 기업 모집단은 매우 역동적이다. 소규모 기업은 빠르게 설립되거나 폐업되며, 대규모 기업은 다른 회사를 인수하거나 합병하기도 하고, 반대로 분할되기도 한다. 따라서 프레임 모집단은 새로운 기업을 포함하고, 더 이상 존재하지 않는 기업을 제거함으로써 그 포괄성을 유지하기 위해 지속적인 업데이트가 필요하다.\n셋째, 기업 모집단은 법적으로 정의된 실체와 물리적 위치 간의 구분을 내포한다. 예를 들어, 다지점 또는 다국적 기업은 전 세계에 여러 개의 사업장을 운영하지만 본사는 하나뿐이다. 이에 따라 설문조사는 ‘기업’(법적 실체)을 대상으로 할 수도 있고, ‘시설’(물리적 단위)을 대상으로 할 수도 있다. 일부 기업은 물리적 위치 없이 운영되기도 하며(예: 재택 근무 기반의 컨설팅 회사), 반대로 여러 기업이 하나의 물리적 위치를 공유하기도 한다. 이러한 구조는 표본 프레임 설계 시 조사 단위의 정의를 더욱 중요하게 만든다.\n\n\n(4) 사건\n설문조사는 사건 모집단을 대상으로 하며, 여기에 포함되는 사건의 예로는 서비스나 제품 구매, 결혼, 임신, 출생, 실직, 우울증 사례, 범죄 피해 등이 있다. 이러한 사건에 대한 설문조사는 일반적으로 사람들을 대상으로 한 프레임에서 시작되며, 일부 사람들은 여러 사건을 경험하면서 사건 요소 간의 집단을 형성하게 된다.\n사건 표본추출의 또 다른 접근 방식은 시간 단위를 프레임으로 사용하는 것이다. 예를 들어, 동물원 방문 사례를 조사할 때 방문 시간을 기준으로 프레임을 구성하고, 일정한 시간 간격(예를 들어 5분 블록)을 선택하여 해당 시간에 방문한 사람들을 대상으로 질문하는 방식이 사용될 수 있다.\n일부 시간 사용 설문조사는 무작위로 선택된 시점에 전자 호출기를 통해 신호음을 발생시키는 방식을 사용한다. 신호가 울리면, 응답자는 그 시점에 자신이 무엇을 하고 있었는지를 보고하도록 되어 있다. 예를 들어, 사무실에서 일하고 있었는지, 텔레비전을 시청하고 있었는지, 혹은 쇼핑을 하고 있었는지를 기록하게 된다.\n사건을 대상으로 하는 설문조사는 경우에 따라 여러 모집단을 동시에 포함할 수 있다. 이러한 조사는 사건 자체에 대한 통계뿐만 아니라 그 사건을 경험한 사람들에 대한 통계에도 관심을 가진다. 이처럼 목적이 이중적인 경우, 표본 설계 과정에서 클러스터링과 중복과 같은 문제가 발생할 수 있다. 예를 들어, 가족에 의한 자동차 구매 사건을 조사하는 경우, 사건 요소는 구매 행위이지만, 사건을 경험한 사람으로는 법적 소유자, 모든 가족 구성원, 또는 차량을 운전할 가능성이 있는 사람 등 다양한 해석이 가능하다.\n\n\n(5) 희귀 모집단\n희귀 모집단은 연구자가 관심을 갖는 소규모 대상 집단을 지칭하는 용어로, 이들이 희귀하다고 판단되는 이유는 절대적인 규모보다는 사용 가능한 프레임 내에서의 상대적 크기 때문이다. 예를 들어, 전체 인구가 5천만 명이고 이 중 100만 명이 노인 복지 혜택을 받고 있다면, 이는 전체 인구의 약 2%에 해당하므로 희귀 모집단으로 간주될 수 있다. 이러한 모집단을 조사 대상으로 설정할 경우, 적절한 표본 프레임을 식별하는 데 여러 가지 어려움이 따른다.\n희귀 모집단을 위한 표본 프레임을 구축하는 방식에는 크게 두 가지 접근이 있다. 첫째는 희귀 모집단에 속하는 요소들의 목록을 직접 구성하는 방법이다. 예를 들어, 복지 수급자의 목록을 복지 사무소의 행정기록에서 얻을 수 있다. 다만 이러한 자료는 종종 기밀로 취급되거나, 단일 목록이 전체 모집단을 포괄하지 못하는 경우가 많아 여러 출처의 목록을 조합해야 할 수도 있다.\n둘째는 보다 일반적인 모집단 프레임을 설정하고, 그 안에서 희귀 모집단에 해당하는 요소들을 선별하는 방식이다. 예를 들어, 일반 가구 모집단을 대상으로 하여 그 안에서 복지 수급 가구를 찾아내는 방식이 여기에 해당한다. 만약 희귀 모집단의 모든 구성원이 더 큰 프레임 모집단의 하위 집합으로 포함된다면, 희귀 모집단에 대한 완전한 포괄이 가능하다.\n\n\n\n4. 포함 오류\n불포함은 해결하기 어려운 문제이며, 설문조사에서 중요한 포함 오류의 원인이 될 수 있다. 포함 오류는 표본 통계나 설문조사에서 도출된 추정치의 특성에 영향을 미친다. 하나의 통계는 포함 오류로 인해 크게 왜곡될 수 있는 반면, 동일한 설문조사에서 얻어진 다른 통계는 같은 오류에 거의 영향을 받지 않을 수도 있다. 설문조사 방법론에서는 불포함, 중복, 클러스터링 등을 포함 오류를 유발하는 표본 프레임의 구조적 문제로 본다. 포함 오류란 이러한 문제들이 조사 결과에 미치는 영향을 지칭하는 개념이다.\n\n포함 오류: \\({\\overline{Y}}_{C} - \\overline{Y} = \\frac{U}{N}({\\overline{Y}}_{C} - {\\overline{Y}}_{U})\\), 여기서 \\(\\overline{Y}\\)는 목표 모집단 전체의 평균, \\({\\overline{Y}}_{C}\\)는 표본 프레임에 포함된 모집단의 평균, \\({\\overline{Y}}_{U}\\)는 표본 프레임 밖 모집단의 평균을 나타낸다. \\(N\\)은 목표 모집단의 총 구성원 수, \\(C\\)는 표본 프레임에 포함된 적격 구성원의 총수, 그리고 \\(U\\)는 표본 프레임에 포함되지 않은 적격 구성원의 총수이다.\n\n따라서 프레임에 포함되지 않은 \\((N - c)\\) 개의 단위로 인해 발생하는 오류는, 전체 모집단에서 포함되지 않은 비율과 포함된 단위와 포함되지 않은 단위 간의 평균 차이에 따라 결정된다. 설문조사는 표본 크기와 무관하게 포함된 단위의 평균 \\({\\overline{Y}}_{C}\\) 만을 추정할 수 있다. 이때, 포함되지 않은 단위 U의 규모가 크거나, 포함된 단위와 포함되지 않은 단위 간의 특성 차이가 클수록 편향, 즉 포함 오류의 크기는 커지게 된다.\n포함되지 않은 비율은 모집단의 하위 계층에 따라 달라질 수 있다. 전체 모집단에서의 불포함 비율보다 특정 하위 그룹에서의 불포함 비율이 더 높을 수도 있다. 또한 포함 오류는 포함된 단위와 포함되지 않은 단위 간의 추정치 차이에 따라 결정되므로, 동일한 적격 단위 하위 계층을 기준으로 계산된 통계라 하더라도 각 통계별로 포함 오류의 정도는 다를 수 있다."
  },
  {
    "objectID": "notes/survey/survey_scale.html",
    "href": "notes/survey/survey_scale.html",
    "title": "조사방법론. 6. 문항 척도",
    "section": "",
    "text": "chapter 1. 문항 척도 개요\n설문조사는 연구자가 특정 주제에 대해 구조화된 방식으로 정보를 수집하고 분석하는 주요 연구 방법 중 하나이다. 이 과정에서 척도(scale)는 응답자의 태도, 인식, 행동을 수치화하여 측정하는 핵심 도구로 작용하며, 연구 결과의 신뢰도(reliability)와 타당도(validity)에 직접적인 영향을 미친다. 따라서 연구 목적에 부합하는 적절한 척도를 선택하고 이를 정확하게 활용하는 것은 설문 데이터의 품질을 높이고, 분석 결과의 객관성과 재현성을 확보하는 데 필수적인 절차라 할 수 있다.\n\n1. 척도 개념\n척도는 설문 응답을 수치화하여 체계적으로 정리하는 방식으로, 응답 결과를 정량적으로 비교하고 분석할 수 있도록 돕는다. 설문조사에서는 다양한 유형의 척도가 사용되며, 이는 단순한 의견 수집을 넘어 분석 가능하고 일관성 있는 데이터를 생성하는 데 기여한다.\n첫째, 응답의 표준화 기능을 통해 모든 응답자가 동일한 기준에서 문항을 해석하고 응답하도록 유도할 수 있다. 이는 결과의 객관성을 높이고, 응답 간의 비교 가능성을 확보하는 데 필수적이다.\n둘째, 신뢰성 향상에도 기여한다. 동일한 질문을 반복 측정했을 때 유사한 결과가 나타나는지를 확인할 수 있으며, 예를 들어 리커트 5점 또는 7점 척도와 같이 일관된 방식의 척도는 태도나 인식의 변화를 비교하는 데 유리하다. 신뢰도 높은 척도는 연구 결과의 재현성을 높이고 후속 연구에서도 동일한 틀을 유지할 수 있게 한다.\n셋째, 타당성 확보에 있어서는 연구자가 측정하고자 하는 개념을 정확히 반영하는 척도를 선택하는 것이 핵심이다. 예를 들어 ’소비자 만족’을 단순한 이분법(만족/불만족)으로 측정하는 것보다, 5점 또는 7점 척도를 사용하는 것이 미묘한 차이를 반영하는 데 유리하다.\n마지막으로, 척도는 통계적 분석 가능성을 확장시킨다. 명목 및 서열 척도는 빈도 분석이나 카이제곱 검정에 적합하며, 등간 및 비율 척도는 평균, 표준편차, 상관 및 회귀분석 등 다양한 수치 분석 기법을 적용할 수 있다. 이처럼 척도의 적절한 활용은 조사 데이터의 질적 수준을 높이고, 과학적 분석을 가능하게 한다.\n\n\n2. 척도의 유형과 선택의 중요성\n\n\n\n\n\n\n\n\n\n척도 유형\n설명\n예시\n주요 분석 방법\n\n\n명목 척도\n(Nominal Scale)\n단순한 분류와 명칭을 부여하는 방식\n성별(남/여), 종교(기독교/불교)\n빈도분석, 카이제곱 검정\n\n\n서열 척도\n(Ordinal Scale)\n순서를 구별할 수 있으나 간격이 일정하지 않음\n교육 수준(초등/중등/고등), 만족도(높음/보통/낮음)\n순위 분석, 카이제곱 검정\n\n\n등간 척도\n(Interval Scale)\n간격이 일정하지만 절대적인 0점이 없음\n온도(°C), 지능지수(IQ)\n평균, 표준편차, 상관분석\n\n\n비율 척도\n(Ratio Scale)\n절대적인 0점을 가지며, 비율 비교가 가능\n나이(세), 소득(만원), 키(cm)\n평균, 분산 분석, 회귀 분석\n\n\n\n설문 조사에서 척도를 적절히 설정하는 것은 매우 중요하다. 척도가 부적절하게 설계되면 응답자의 반응이 일관성을 잃고, 수집된 데이터의 해석에도 오류가 발생할 수 있다. 이는 궁극적으로 연구 결과의 신뢰도를 저하시켜, 의미 있는 분석과 일반화된 결론 도출을 어렵게 만든다.\n예를 들어, ’매우 만족–만족–보통–불만족–매우 불만족’과 같은 5점 척도를 사용하면 응답자의 태도 강도를 세분화해 파악할 수 있다. 반면, 이를 단순히 ’예/아니오’와 같은 이분법적 응답 방식으로 대체하면 태도 변화의 미묘한 차이를 반영하기 어렵고, 해석의 폭도 좁아질 수 있다. 따라서 질문의 목적과 분석 수준에 맞는 척도를 설정하는 것이 설문 설계의 핵심 요소라 할 수 있다.\n\n통계적 분석 가능성: 척도는 통계적 분석의 기반이 되며, 설문 응답을 정량화할 수 있도록 돕는다. 만약 모든 문항이 개방형으로 구성된다면, 응답 내용의 수치화가 어렵고 체계적인 분석이 제한될 수 있다. 반면, 폐쇄형 질문에 적절한 척도를 결합하면 응답을 수치로 변환하여 다양한 통계 기법을 적용할 수 있다. 예를 들어, 마케팅 조사에서 소비자의 브랜드 인식을 등간 척도로 측정하면, 분산 분석(ANOVA)이나 회귀 분석을 통해 보다 정교한 통계적 해석이 가능하다.\n결과의 재현성 확보: 또한, 척도가 명확하게 정의되어 있다면 동일한 연구를 다른 시점이나 환경에서 반복해도 유사한 결과를 도출할 수 있다. 이는 연구의 재현성을 확보하고, 결과의 일반화 가능성을 높이는 데 기여한다. 이러한 점에서 척도는 단순한 응답 수단을 넘어서 과학적 연구 설계의 핵심 요소로 작용한다.\n\n설문조사에서 척도는 단순한 응답 선택지를 넘어, 수집된 데이터의 품질과 연구 결과의 신뢰도를 좌우하는 핵심 요소이다. 적절한 척도를 선택하면 연구자는 응답자의 태도나 행동을 정밀하게 측정할 수 있으며, 통계적으로 타당한 분석을 통해 보다 신뢰성 있는 결론을 도출할 수 있다. 따라서 설문 설계 단계에서 연구 목적에 부합하는 척도를 신중히 선택하는 것이 중요하며, 이는 데이터의 일관성과 해석의 정밀도를 높여 의미 있는 연구 성과로 이어진다.\n\n\n\nchapter 2. 전통적인 척도\n\n\n\n\n\n\n\n\n\n\n구분\n명목 척도\n서열 척도\n등간 척도\n비율 척도\n\n\n측정값 간 순서\nX\nO\nO\nO\n\n\n측정값 간 차이 일정성\nX\nX\nO\nO\n\n\n덧셈, 뺄셈 연산 가능 여부\nX\nX\nO\nO\n\n\n비율(나눗셈) 계산 가능 여부\nX\nX\nX\nO\n\n\n예시\n성별, 혈액형, 국적\n학년, 학점, 만족도\n온도, IQ 점수\n키, 몸무게, 연봉, 나이\n\n\n\n\n1. 명목 척도\n명목 척도는 가장 기초적인 수준의 측정 척도로, 대상을 단순히 분류하거나 명명하는 역할을 한다. 이 척도에서 사용되는 숫자는 단순한 식별자 역할을 할 뿐, 수치적 의미를 가지지 않는다. 즉, 명목 척도에서 1과 2, 또는 A와 B는 단순히 서로 다른 범주를 의미할 뿐, 크기나 순서의 개념이 없다.\n예를 들어, 응답자의 성별을 측정하는 문항에서 \"남성\"을 1, \"여성\"을 2로 표시할 수 있다. 그러나 이는 단순히 남성과 여성을 구분하기 위한 코드일 뿐, '1이 2보다 크다'는 의미를 갖지 않는다.\n\n(1) 명목 척도 특징\n측정값 간 서열이 없음\n명목 척도는 측정값 간 서열이나 크기의 차이를 나타내지 않는다. 이는 단순히 각 범주를 구별하기 위한 코드로 사용될 뿐, 그 숫자 간에 어떤 순서나 우열도 존재하지 않는다. 예를 들어, 종교 항목에서 “기독교=1, 불교=2, 이슬람교=3, 무교=4”와 같이 숫자를 부여한다고 해도, 이는 편의상 구분을 위한 부호일 뿐 “무교(4)”가 “기독교(1)”보다 크거나 뒤에 있다는 의미는 없다. 따라서 명목 척도는 범주 간 비교는 가능하되, 서열 비교는 허용되지 않는다.\n값의 차이를 측정할 수 없음\n명목 척도는 범주 간의 차이나 간격을 수치적으로 해석할 수 없다. 예를 들어, 성별을 “남성=1, 여성=2”로 부호화했을 때, 이들 사이의 차이를 “2 - 1 = 1”이라고 수치적으로 해석하는 것은 의미가 없다. 이 숫자는 단순히 범주를 구분하기 위한 상징일 뿐, 수학적 연산(합, 차, 평균 등)에 사용될 수 있는 값이 아니다. 따라서 명목 척도에서는 범주 간의 차이나 비율을 측정하거나 비교하는 것은 부적절하며, 빈도나 비율 같은 비수치적 분석이 주로 활용된다.\n기본적인 연산이 불가능함\n명목 척도는 단순히 범주를 구분하는 역할만 하므로, 수치 간의 의미 있는 간격이나 순서가 존재하지 않는다. 이로 인해 평균이나 표준편차처럼 수학적 계산을 필요로 하는 연산은 수행할 수 없다. 예를 들어, “기독교=1, 불교=2, 천주교=3”으로 부호화된 종교 변수의 평균을 구하는 것은 의미가 없다. 대신, 명목 척도에서는 각 범주에 속하는 응답자의 빈도 수, 전체 응답자 대비 백분율, 가장 많이 선택된 범주인 최빈값(Mode) 등을 활용한 기술 통계 분석이 가능하다. 이러한 방식으로 집단의 특성을 요약하고 비교할 수 있다.\n데이터의 범주가 명확해야 함\n명목 척도를 설계할 때는 범주 간의 구분이 명확하고, 모든 가능한 선택지가 포함되어야 한다. 응답자가 자신의 속성이나 의견을 올바르게 선택할 수 있도록 서로 겹치지 않는 범주(disjoint categories) 를 제공해야 하며, 중요한 응답 선택지가 누락되지 않도록 포괄성도 확보해야 한다. 예를 들어, “좋아하는 색깔”을 묻는 문항에서 “빨강, 파랑, 노랑”만 제시하고 “녹색”이나 “기타” 선택지를 제공하지 않는다면, 응답자의 진의를 반영하지 못해 데이터의 왜곡이 발생할 수 있다. 따라서 명확하고 완전한 범주 구성이 필수적이다.\n\n\n\n\n\n\n\n변수\n예시 값\n\n\n성별\n남성(1), 여성(2)\n\n\n국적\n한국(1), 미국(2), 영국(3)\n\n\n혈액형\nA형(1), B형(2), O형(3), AB형(4)\n\n\n종교\n기독교(1), 불교(2), 이슬람교(3), 무교(4)\n\n\n학과\n경영학과(1), 심리학과(2), 공학과(3)\n\n\n\n\n\n(2) 명목 척도 분석 방법\n명목 척도는 기본적인 범주형 데이터 분석을 수행하는 데 적합하다. 주요 분석 방법은 다음과 같다.\n빈도 분석 frequency analysis\n명목 척도 데이터를 요약하는 데 가장 기본적이고 효과적인 방법이다. 각 범주별로 응답자의 수(빈도)를 세고, 전체 응답자 수 대비 비율(%)을 계산함으로써 자료의 분포와 구성 비율을 직관적으로 파악할 수 있다.\n예를 들어, 설문조사에서 혈액형을 묻는 질문에 대해 다음과 같은 결과가 나왔다면: A형: 30명 (30%), B형: 25명 (25%), O형: 35명 (35%), AB형: 10명 (10%) 이처럼 빈도와 백분율을 함께 제시하면 각 범주의 상대적 크기와 특성을 명확하게 비교할 수 있어, 조사 대상의 특성을 이해하는 데 유용하다. 막대그래프(bar chart)나 원형그래프(pie chart)로 시각화하면 더 효과적인 설명이 가능하다.\n최빈값 mode 분석\n명목 척도 데이터를 요약할 때 대표값을 제시하는 가장 적절한 방법이다. 명목 척도에서는 숫자 간의 순서나 간격이 없기 때문에 평균이나 중앙값을 계산하는 것이 무의미하며, 가장 많이 나타난 응답(최빈값)을 통해 데이터를 대표할 수 있다.\n예를 들어, 학과별 학생 수를 조사한 결과가 다음과 같다면: 경영학과: 50명, 심리학과: 30명, 컴퓨터공학과: 40명, 이 경우 최빈값(mode)은 ’경영학과’이며, 이는 해당 집단에서 가장 흔한(대표적인) 특성으로 해석된다. 명목형 자료에서는 이러한 최빈값 분석이 실제 현장의 특성을 단순하고 명확하게 설명하는 데 매우 유용하다.\n카이제곱 검정 Chi-Square test\n두 개 이상의 명목형 변수 간의 통계적 연관성을 분석할 때 사용된다. 이 검정은 관측된 빈도와 기대 빈도의 차이를 비교하여, 두 변수 간에 우연 이상의 연관성이 있는지를 판단한다.\n예를 들어, 설문조사에서 응답자의 성별(남성/여성)과 선호하는 브랜드(브랜드 A/B/C) 간의 관계를 알아보고자 할 때, 다음과 같은 질문이 가능하다: “성별에 따라 선호 브랜드가 달라지는가?”\n이때 실제 응답에서 나타난 성별-브랜드 분포(관측값)와, 성별과 브랜드가 독립이라고 가정했을 때의 기대값 간의 차이를 분석하여 유의미한 차이가 있는지를 검정한다.\n백분율 분석 percentage analysis\n백분율 분석은 각 범주가 전체 응답자 중에서 차지하는 비중을 계산하여, 데이터의 분포를 직관적으로 파악할 수 있도록 해주는 방법이다. 주로 명목 척도에서 사용되며, 다양한 범주 간의 상대적인 크기를 비교하거나, 특정 집단이 전체에서 얼마나 중요한 비율을 차지하는지를 나타낼 때 유용하다.\n예를 들어, 종교에 대한 설문 조사에서 응답자의 40%가 무교, 35%가 기독교, 15%가 불교, 10%가 기타 종교라고 응답한 경우, 백분율 분석을 통해 각 종교의 상대적인 분포를 명확하게 확인할 수 있다. 이처럼 백분율은 단순한 빈도 수치를 상대적인 수치로 변환하여, 다양한 집단 간 비교를 용이하게 하고, 조사 결과를 시각적으로 설명할 수 있도록 돕는다.\n\n\n(3) 명목 척도의 장점과 단점\n명목 척도는 조사 대상의 특성을 구분하거나 분류할 때 가장 기본적으로 사용되는 측정 도구로, 실생활에서 쉽게 관찰되는 성별, 종교, 국적 등과 같은 범주형 정보를 효과적으로 수집할 수 있다. 이 척도는 응답자가 쉽게 이해하고 선택할 수 있는 형태이기 때문에, 데이터 수집이 용이하고 해석도 간단하다는 장점이 있다. 또한 인구통계학적 조사, 시장 조사, 심리학 연구 등 다양한 분야에서 폭넓게 활용되며, 현실에서 사용되는 범주를 그대로 반영할 수 있다는 점에서 응답의 실효성을 높인다.\n그러나 명목 척도는 수치 간의 크기나 순서를 나타내지 않기 때문에 평균이나 표준편차와 같은 수학적 연산이 불가능하다. 단순 빈도나 백분율과 같은 기초적인 분석만 수행할 수 있으며, 그 이상의 정교한 통계 분석은 어렵다는 한계가 있다. 또한, 범주 설정이 명확하지 않거나 중복될 경우, 응답자의 혼란을 초래하고 데이터 해석에도 오류가 발생할 수 있다. 이러한 점에서 명목 척도는 정보량이 상대적으로 적으며, 분석의 깊이를 확보하는 데 제한이 있다.\n\n\n\n2. 서열 척도\n서열 척도는 조사 대상 간의 순서를 비교할 수 있도록 해주는 측정 방식으로, 예를 들어 어떤 대상이 더 높거나 낮은지, 더 선호되거나 덜 선호되는지를 나타낼 수 있다. 응답자의 태도, 만족도, 선호도와 같은 심리적 또는 주관적 평가를 측정할 때 주로 사용되며, 명목 척도보다 더 많은 정보를 담고 있다는 점에서 분석의 정밀도를 높여준다.\n서열 척도의 핵심 특징은 순위를 부여할 수 있다는 점이다. 예를 들어 대학 성적에서 A, B, C, D, F와 같은 등급이 있다면, A가 B보다 우수하다는 순위는 명확하지만 A와 B의 점수 차이와 C와 D의 점수 차이가 동일하다고 볼 수는 없다. 즉, 순서 정보는 제공하지만 간격 정보는 제공하지 않는다는 것이 서열 척도의 중요한 제한점이다.\n이러한 특성으로 인해 서열 척도는 빈도분석, 백분율, 중앙값, 사분위수와 같은 순위 기반 분석에는 적합하지만, 평균이나 표준편차를 사용하는 분석에는 주의가 필요하다. 평균을 계산하는 것이 불가능한 것은 아니지만, 간격이 일정하지 않다는 점에서 그 해석에 신중함이 요구된다. 따라서 서열 척도는 정보량이 많고 해석이 직관적이지만, 정량적인 분석에는 다소 제약이 따를 수 있다.\n\n(1) 서열 척도 예시\n설문조사 및 심리 척도\n\n만족도 조사: ”매우 만족 - 만족 - 보통 - 불만족 - 매우 불만족”\n중요도 평가: ”매우 중요 - 중요 - 보통 - 중요하지 않음 - 전혀 중요하지 않음”\n\n경쟁 및 순위 관련 데이터\n\n고객 선호 브랜드 순위: 1위, 2위, 3위…\n스포츠 경기 성적: 금메달, 은메달, 동메달\n\n교육 및 시험 결과\n\n학점: A, B, C, D, F\n시험 성적 등급: 상, 중, 하\n\n소득 및 계층 구분\n\n고소득 &gt; 중소득 &gt; 저소득\n사회계층: 상류층 &gt; 중산층 &gt; 서민층\n\n건강 및 의료 평가\n\n병의 심각도: 경증 &gt; 중등도 &gt; 중증\n환자의 통증 수준: 심한 통증 &gt; 중간 통증 &gt; 약한 통증 &gt; 없음\n\n\n\n(2) 서열 척도 특징\n순위(서열) 부여 가능: 서열 척도에서는 대상 간의 비교가 가능하며, 순서를 정할 수 있다. (예) 소득 수준: 고소득 &gt; 중소득 &gt; 저소득\n순위 간의 간격(interval)은 균등하지 않음: 측정값 사이의 차이가 동일한 크기를 의미하지 않는다. (예) 영화 평점(별점 1~5점)에서 5점과 4점 차이가 2점과 1점 차이보다 크거나 작을 수 있음.\n(예) 만족도 조사(매우 만족, 만족, 보통, 불만족, 매우 불만족)의 경우, ’보통(3)’에서 ’만족(4)’으로 변하는 것이 ’불만족(2)’에서 ’보통(3)’으로 변하는 것과 동일한 차이를 가진다고 보기 어려움.\n덧셈, 뺄셈 등의 수치적 연산이 불가능: 서열 척도에서는 측정값이 숫자로 표현될 수 있으나, 그 숫자는 단순히 순서를 나타낼 뿐 절대적인 수치적 의미를 가지지는 않는다. 예를 들어, 만족도 조사에서 “매우 만족 = 5”, “만족 = 4”, “보통 = 3”, “불만족 = 2”, “매우 불만족 = 1”처럼 숫자를 부여할 수 있지만, 이들 간의 간격이 동일하다고 볼 수 없다.\n따라서 평균을 계산하여 분석하는 것보다는, 중위값(Median) 또는 최빈값(Mode)처럼 순위를 기반으로 한 통계량을 사용하는 것이 더 적절하다. 이러한 방식은 서열 척도의 핵심인 순서 정보를 보존하면서도, 간격이 일정하지 않다는 특성을 고려한 해석을 가능하게 한다.\n비율 계산 불가능: ”A의 점수가 B의 점수의 2배다”와 같은 해석이 불가능하다. (예) 선호도 조사에서 1위(고객 100명)와 2위(고객 50명)의 차이가 2배라고 해서, 1위 브랜드가 2위보다 정확히 2배 더 선호된다고 볼 수 없음.\n\n\n(3) 서열 척도 통계 분석 방법\n서열 척도 데이터는 평균이나 표준편차 계산이 적절하지 않으며, 대신 다음과 같은 기법이 주로 사용된다.\n최빈값 및 중위값 사용: 평균은 서열 척도에 적절하지 않기 때문에 중위값이나 최빈값을 사용하여 데이터의 중심 경향을 분석한다.\n순위 기반 통계 기법 적용: 순위합 검정(Rank-Sum Test), 윌콕슨 부호순위 검정(Wilcoxon Signed-Rank Test), 크루스칼-월리스 검정(Kruskal-Wallis Test) 등. 이는 서열 척도의 특성을 고려하여 두 그룹 이상 간의 차이를 비교하는 비모수적 방법이다.\n상관분석 시 순위 기반 기법 사용: Spearman의 순위 상관계수 또는 Kendall의 순위 상관계수(Kendall’s tau)를 사용한다.\n로지스틱 회귀(Logistic Regression) 사용 가능: 예측변수(종속변수)가 서열 척도인 경우 서열 로지스틱 회귀(Ordinal Logistic Regression, Proportional Odds Model) 를 사용한다.\n\n\n(5) 서열 척도의 한계와 보완 방법\n서열 척도는 측정 대상 간의 순서를 알 수 있다는 점에서 유용하지만, 각 순위 간의 간격이 균등하지 않다는 한계를 가지고 있다. 예를 들어, 어떤 응답자가 ’매우 만족(5점)’을 선택하고, 다른 응답자가 ’만족(4점)’을 선택했다 하더라도, 그 차이가 ’보통(3점)’과 ‘불만족(2점)’ 간의 차이와 같다고 보장할 수는 없다. 이처럼 간격이 일정하지 않기 때문에 평균이나 표준편차 등의 수치 연산을 적용하기에는 주의가 필요하다.\n그러나 실제 연구에서는 서열 척도 중 일부, 특히 Likert 척도(예: 5점 척도, 7점 척도 등)에 대해, 응답 간격이 대체로 균등하다고 간주할 수 있는 경우에는 등간 척도로 변환하여 사용하는 방식이 널리 활용된다. 이 경우, 평균, 표준편차 등의 통계 분석을 정당화할 수 있으며, 보다 정밀한 수치 분석이 가능해진다. 단, 이러한 접근은 연구 목적과 응답자의 인식 특성에 대한 충분한 고려를 바탕으로 이루어져야 한다.\n\n\n(6) 리커트 척도는 서열척도\n리커트 척도(Likert Scale)는 1932년 렌시스 리커트(Rensis Likert)가 박사학위 논문에서 처음 고안한 측정 도구로, 응답자의 태도나 의견을 보다 정밀하고 객관적으로 수량화하기 위해 개발되었다.\n기존의 설문조사에서는 “예/아니오”나 “찬성/반대”와 같은 단순한 명목 척도 방식이 주로 사용되었으나, 이는 사람들의 복합적인 감정이나 태도를 충분히 포착하기 어려웠다. 리커트는 이러한 한계를 보완하고자, 단순한 선택을 넘어서 다양한 정도의 동의 수준을 표현할 수 있도록 서열형 응답 구조를 제안했다.\n리커트 척도는 일반적으로 “매우 그렇다”부터 “전혀 그렇지 않다”까지의 다섯 점 또는 일곱 점 척도를 사용하여, 응답자가 자신의 의견을 보다 세밀하게 표현할 수 있도록 돕는다. 이러한 방식은 설문 응답의 신뢰성과 민감도를 높이며, 통계적으로도 평균, 분산 등 다양한 분석을 가능하게 하는 장점이 있다.\n단순한 이분법적 질문의 한계 극복\n기존의 설문조사 방식은 “찬성/반대”와 같은 단순한 이분법적 질문 형식을 주로 사용해 왔지만, 이는 응답자의 태도나 감정을 정밀하게 측정하는 데 한계가 있었다. 이러한 방식에서는 의견의 강도나 미묘한 차이를 반영하기 어렵기 때문에, 조사 결과가 응답자의 실제 생각을 충분히 드러내지 못하는 문제가 발생한다.\n리커트 척도는 이러한 한계를 극복하기 위해, 단순한 찬반 여부를 넘어 응답자의 태도 강도를 함께 측정할 수 있도록 설계되었다. 예를 들어, “이 정책을 찬성합니까?“라는 기존의 질문이 단순히 “찬성” 또는 “반대”만을 선택하게 한다면, 리커트 방식은 “이 정책에 대해 어떻게 생각하십니까?“라는 질문에 대해 “매우 찬성(5)”, “찬성(4)”, “보통(3)”, “반대(2)”, “매우 반대(1)“와 같은 응답 선택지를 제공한다. 이를 통해 응답자는 자신의 태도를 보다 섬세하게 표현할 수 있고, 연구자는 응답자의 의견 강도를 수치화하여 분석할 수 있다. 이처럼 리커트 척도는 태도 측정의 정밀도를 높이는 데 중요한 역할을 한다.\n사회과학 연구에서 태도 및 인식 연구를 위한 표준화된 도구 제공\n사회과학 연구에서는 인간의 태도, 인식, 감정 등과 같은 주관적 요소를 정량적으로 측정하는 것이 매우 중요하지만 동시에 어려운 과제이기도 하다. 이러한 비가시적이고 주관적인 특성들은 단순한 숫자나 범주로 쉽게 표현되기 어렵기 때문이다. 리커트 척도는 이러한 측정의 어려움을 해결하기 위한 표준화된 도구로 널리 활용된다.\n예를 들어 “이 제품을 다시 구매할 의향이 있습니까?”라는 질문에 대해, 단순히 ‘예’ 또는 ’아니오’로 응답하는 것이 아니라, “매우 그렇다(5) – 그렇다(4) – 보통이다(3) – 아니다(2) – 전혀 아니다(1)”와 같이 응답자의 태도 강도를 표현할 수 있는 서열화된 선택지를 제공함으로써, 보다 정밀하고 신뢰도 높은 데이터 수집이 가능해진다. 이처럼 리커트 척도는 태도 및 인식 연구에서 객관성과 일관성을 높이기 위한 핵심적인 도구로 기능하며, 사회과학 연구 전반에서 중요한 표준 측정 방식으로 자리 잡고 있다.\n리커트 척도는 서열 척도이다.\n리커트 척도는 응답자의 태도나 의견을 측정할 때 널리 사용되는 도구로, 기본적으로 서열 척도(ordnal scale)로 간주된다. 그 이유는 각 응답 항목 사이에 순위가 존재하지만, 그 간격이 반드시 균등하다고 보장할 수 없기 때문이다.\n예를 들어, “매우 만족(5) - 만족(4) - 보통(3) - 불만족(2) - 매우 불만족(1)”이라는 5점 척도에서 응답자들은 각 항목을 순서대로 인식하지만, ‘만족’과 ‘보통’ 사이의 거리와 ‘불만족’과 ‘매우 불만족’ 사이의 거리가 동일하다고 단정할 수는 없다. 즉, 수치는 서열을 나타내는 데에는 유용하지만, 수치 간 간격이 심리적으로나 실제로 일정하다는 보장은 없다.\n따라서 리커트 척도는 원칙적으로 서열 척도로 분류되며, 평균이나 표준편차 같은 등간 척도 기반의 분석을 수행할 경우에는 연구 목적에 따라 간격의 동일성을 전제해야 함을 유의해야 한다. 이 같은 전제를 정당화하기 어렵다면, 중위값, 빈도, 범주별 분포 등 서열 데이터에 적합한 분석 기법을 사용하는 것이 바람직하다.\n등간 척도로 활용하는 이유\n리커트 척도는 본래 서열 척도로 분류되지만, 심리학·사회과학 분야의 연구에서는 등간 척도로 간주하여 활용하는 경우가 많다. 그 주된 이유는 분석의 실용성과 통계 지표의 활용도 때문이다.\n서열 척도로 엄격히 해석하면 평균, 표준편차와 같은 연산은 적절하지 않다. 그러나 현실의 연구에서는 응답 항목 간의 간격이 대체로 균등하다는 가정을 받아들이고, 리커트 척도를 등간 척도로 취급한다. 이를 통해 예를 들어 “매우 만족(5) - 만족(4) - 보통(3) - 불만족(2) - 매우 불만족(1)” 같은 5점 척도에서 응답 평균이 3.6점이라면, 비교적 긍정적인 평가로 해석할 수 있다.\n또한, 실험적 연구나 집단 비교 분석에서 평균, 표준편차, t-검정, 분산분석(ANOVA) 등 통계 분석 기법을 적용할 수 있어 분석의 폭이 넓어진다. 실제로 많은 연구자가 리커트 점수의 차이가 응답자의 태도나 인식의 차이를 어느 정도 반영한다고 보고 있으며, 등간 척도로서의 활용은 연구의 실용성과 해석력을 높이는 데 기여하고 있다.\n리커트 척도를 등간 척도로 간주할 때 척도의 신뢰성 검토 필요\n리커트 척도를 등간 척도로 간주하여 평균이나 표준편차 등의 통계 분석을 수행하려면, 그에 앞서 척도의 신뢰성과 일관성에 대한 검토가 반드시 필요하다. 모든 리커트 척도가 등간척도처럼 해석 가능한 것은 아니기 때문이다.\n이는 각 응답자가 척도 간의 간격을 동일하게 인식하지 않을 수 있기 때문이다. 예를 들어, 어떤 사람은 ’보통(3)’에서 ’만족(4)’으로의 차이를 크게 느끼는 반면, 다른 사람은 ’만족(4)’에서 ’매우 만족(5)’으로의 차이를 더 중요하게 여길 수 있다. 이처럼 응답 간 간격에 대한 인식 차이는 등간척도로서의 가정을 위협할 수 있다.\n따라서, 척도의 신뢰성과 구조적 타당성을 검토하는 과정이 선행되어야 하며, 대표적인 방법으로는 다음과 같은 분석이 활용된다.\n\n신뢰도 분석(Cronbach’s Alpha): 동일한 척도를 구성하는 문항 간의 일관성을 평가하여, 응답자들이 각 문항에 대해 일관되게 반응하는지를 검토한다.\n탐색적 요인 분석(EFA): 여러 문항이 하나의 요인(개념)을 측정하고 있는지를 분석하여 척도의 구조적 타당성을 확인한다.\n\n이러한 검토를 통해 척도의 내적 일관성과 구성 타당성이 확보된다면, 해당 리커트 척도를 등간 척도로 간주하여 통계 분석에 활용하는 것이 보다 타당하고 신뢰로운 해석으로 이어질 수 있다.\n\n\n\n3. 등간 척도\n등간척도는 변수 간의 차이를 수치적으로 측정할 수 있도록 설계된 척도로, 각 값들 사이의 간격이 일정하다는 점이 핵심적인 특징이다. 예를 들어, 섭씨 온도는 10도에서 20도로 올라간 변화와, 20도에서 30도로 올라간 변화가 동일한 간격(10도 차)을 의미하므로 등간척도로 간주된다.\n그러나 절대적 기준점(진정한 0점)이 존재하지 않는다는 점에서 비율척도와는 다르다. 예를 들어, 섭씨 0도는 ’온도의 부재’를 의미하지 않으며, 20도가 10도의 ’두 배 더 덥다’라고 해석하는 것도 옳지 않다. 이처럼 등간척도는 간격(차이)을 비교할 수는 있지만, 비율 비교나 배수 해석은 불가능하다.\n\n(1) 등간척도 특징\n순서 정보 제공: 변수 값의 크고 작음을 비교할 수 있다. (예) 온도(섭씨, 화씨), IQ 점수, 표준화 점수(Z-score)\n일정한 간격 유지: 측정값들 사이의 차이가 동일한 간격을 유지한다. (예) 섭씨 온도에서 20°C와 30°C 사이의 차이(10°C)는, 30°C와 40°C 사이의 차이(10°C)와 같다.\n절대적 0이 없음: 등간척도는 임의적으로 정한 0점을 사용하므로, ”절대적인 없음”을 의미하는 0점이 아니다. 예를 들어, 섭씨 0°C는 온도의 완전한 부재가 아니라, 물의 어는점을 기준으로 설정된 값이다. 따라서, 40°C가 20°C의 ”두 배”라고 할 수 없다.\n덧셈과 뺄셈이 가능하지만, 곱셈과 나눗셈(비율 비교)은 불가능: 차이(증감량)를 분석하는 데 유용하지만, 비율(몇 배 큰지) 분석은 의미가 없다. 예를 들면, IQ 점수 140이 70보다 두 배 높은 지능을 의미하지 않는다.\n\n\n(2) 등간척도 예시\n\n온도(섭씨, 화씨): 20°C와 30°C 사이의 차이는 10°C, 하지만 40°C가 20°C의 2배 더 뜨겁다고 할 수 없음.\nIQ 점수: 140점이 70점의 두 배의 지능을 의미하지 않음.\n시험 점수(표준화 점수): 예를 들어, 수능 점수가 300점에서 400점으로 증가한 것과 400점에서 500점으로 증가한 것은 동일한 차이를 나타냄.\n신용평점: 신용평점 800이 400보다 정확히 두 배의 신용도를 의미하는 것은 아님.\n리커트 척도: ”1=매우 불만족, 2=불만족, 3=보통, 4=만족, 5=매우 만족” 등 숫자가 등간성을 가질 수 있는 경우.\n\n\n\n(3) 등간 척도 통계 분석 방법\n산술평균과 표준편차: 등간척도는 산술평균을 계산할 수 있으며, 자료의 분산과 표준편차 분석이 가능하다. (예) 특정 시험에서 학생들의 평균 점수를 계산.\nt-검정 및 분산분석: 두 집단 이상에서 평균 차이를 비교할 때 사용된다. (예) 새로운 교육 방법이 기존 방법보다 효과적인지 확인할 때.\n상관관계 분석: 등간척도 데이터 간의 선형 관계를 분석하는 데 사용한다. (예) 학생들의 IQ와 학업 성취도 간의 상관관계 분석.\n회귀분석: 예측 모델을 만들기 위해 사용된다. (예) 기온이 소비자 구매 행동에 미치는 영향을 분석한다.\nZ-점수 변환: 등간척도 데이터는 표준화하여 비교가능하도록 변환할 수 있다. (예) 여러 시험에서 점수를 비교할 때 표준화 점수를 사용한다.\n\n\n(4) 등간척도의 한계와 고려 사항\n비율 비교 불가능: 섭씨 온도에서 40°C가 20°C의 두 배라고 할 수 없다. (해결 방법) 비율척도로 변환 가능할 경우 변환하여 분석 (예: 절대적 0이 있는 켈빈 온도를 사용하는 방법).\n정확한 간격 유지 여부 확인 필요: 일부 척도(예: 심리학 설문지)는 등간척도를 가정하고 있지만, 실제로는 완전한 등간성이 없는 경우가 많다.\n정규성 검정 필요: 등간척도 자료가 정규분포를 따르는지 여부에 따라 사용할 수 있는 통계 분석 기법이 달라진다.\n\n\n\n4. 비율 척도\n비율척도는 측정값들 간의 절대적 0이 존재하며, 덧셈·뺄셈뿐만 아니라 곱셈·나눗셈을 포함한 모든 산술 연산이 가능한 척도이다. 즉, 값들 간의 비율(배수 개념)이 의미를 갖는 척도이다.\n\n(1) 비율척도 특징\n순서 정보 제공: 값들의 크고 작음을 비교할 수 있다. (예) 키(170cm &gt; 160cm), 몸무게(70kg &gt; 50kg)\n일정한 간격 유지: 측정값들 사이의 간격이 일정하다. (예) 10kg와 20kg 사이의 차이(10kg)는, 30kg와 40kg 사이의 차이(10kg)와 같다.\n절대적 0 존재: 값이 ’0’일 때 해당 속성이 완전히 없는 상태를 의미한다. (예) 키 0cm, 몸무게 0kg, 연령 0세(출생 이전 없음), 수입 0원\n비율(배수 비교) 가능: 40kg이 20kg의 두 배임을 의미하며, 100cm는 50cm의 두 배 길이임을 의미함. 이는 등간척도(Interval Scale)에서는 불가능했던 비교이다. (예) ”50세는 25세의 두 배 오래 살았다”는 논리가 성립.\n모든 산술 연산 가능: 덧셈, 뺄셈, 곱셈, 나눗셈 연산이 모두 가능하다. (예) 평균, 비율, 표준 편차, 변동 계수 등 계산 가능.\n\n\n(2) 비율척도 예시\n\n신체 측정값: 키(cm), 몸무게(kg), 허리둘레(cm)\n시간 측정값: 반응 시간(초), 나이(년), 학습 시간(시간)\n소득 및 비용: 월급(원), 저축액(원), 소비액(원)\n거리 및 속도: 거리(km, m), 속도(km/h), 주행거리(km)\n수량 데이터: 판매량(개), 학생 수(명), 인구 수(명)\n\n\n\n(3) 비율척도 통계 분석 방법\n산술평균, 중앙값, 최빈값 계산 가능: 모든 기술통계가 적용 가능하다. (예) 평균 소득, 중앙값 소득, 최빈값 분석.\n표준편차와 분산 계산 가능: 데이터의 변동성을 분석할 수 있다. (예) 신체검사에서 키의 표준편차 분석.\nt-검정 및 분산분석: 집단 간 평균 차이 검정 가능하다. (예) 남성과 여성의 평균 키 차이 분석.\n회귀분석 및 상관분석: (1) 독립변수와 종속변수 간의 관계를 예측하는 데 사용된다. (예) 학습 시간과 시험 성적 간의 관계 분석. (2) 두 변수 간의 관계를 측정할 수 있다. (예) 소득과 소비 간의 관계 분석.\n비율 비교 가능: 데이터 간 비율(배수)을 이용한 분석이 가능하다. (예) A 지역의 평균 소득이 B 지역보다 1.5배 높다.\n\n\n(4) 비율척도의 한계와 고려 사항\n데이터의 정규성 검토 필요: 대부분의 통계 분석 기법(t- 검정, 분산분석, 회귀분석 등)은 정규분포를 가정하므로 데이터가 정규성을 만족하는지 확인해야 한다.\n이상치(Outliers) 문제: 비율척도 데이터는 절대적인 크기가 의미를 가지므로, 이상치(극단값)에 민감하다. (예) 평균 소득 분석 시, 억대 연봉자가 포함되면 평균값이 왜곡될 수 있음.\n비율척도의 단위 고려: 단위 변환 시 비율 비교가 달라질 수 있다. (예) 키를 cm에서 m로 변환하면 수치가 100배 차이가 나므로, 단위 해석에 주의해야 함.\n\n\n\n\nchapter 3. 심리적 행동적 척도\n\n1. 거트만 Guttman 척도\n\n(1) 거트만 척도 개요\n거트만 척도(Guttman Scale)는 누적척도의 한 형태로, 응답자의 태도나 행동이 위계적으로 구성된 문항에 대해 일관된 응답 패턴을 보이는지를 측정하는 척도이다. 이 척도는 상위 문항에 동의한 응답자는 반드시 그보다 낮은 수준의 문항에도 동의한다고 가정한다. 다시 말해, 특정 진술에 ’그렇다’고 응답한 사람은 그보다 덜 강한 진술에도 ’그렇다’고 응답해야 논리적으로 일관된 것으로 간주한다.\n거트만 척도는 응답자 간 점수의 단순 비교보다, 응답 패턴의 누적성과 일관성에 초점을 두는 방식이다. 응답 결과가 이상적인 누적 형태를 따를수록, 해당 척도의 신뢰성과 설명력이 높다고 평가한다.\n이 척도는 사회적 태도, 신념 구조, 행동 수용 정도 등과 같이 위계적 순서가 존재한다고 판단되는 개념을 측정하는 데 적합하다. 따라서 다음과 같은 분야에서 주로 활용된다.\n\n사회과학 연구: 성평등 인식, 정치적 이념 수용도, 편견 수준 등\n교육 연구: 학습 태도, 교육 내용 수용도 등\n마케팅 조사: 제품 구매 의향, 브랜드 충성도 등\n\n예를 들어, 정치적 참여에 대한 척도를 구성할 때 다음과 같이 문항을 배열할 수 있다. 1. 정치 뉴스를 읽는다. &lt; 2. 정치 토론에 참여한다. &lt; 3. 집회에 참석한 적이 있다. &lt; 4. 정치 기부를 한다. &lt; 5. 정당에 가입했다.\n이 경우, ’정당에 가입했다’는 응답자는 앞선 모든 문항에도 동의할 것으로 예상되며, 이러한 응답 구조가 거트만 척도의 전형적인 예시이다.\n\n\n(2) 거트만 척도 원리\n거트만 척도는 응답자의 태도나 행동이 계층적으로 배열된 문항을 통해 일관된 패턴을 보이는지 측정하는 방법이다. 이를 위해 거트만 척도는 네 가지 핵심 원칙을 따른다.\n(1) 위계적 구조(hierarchical structure)\n문항들은 강도의 순서에 따라 배열되며, 상위 문항에 동의한 사람은 하위 문항에도 반드시 동의해야 한다. 예를 들어, “난민을 이웃으로 받아들일 수 있다”는 문항에 동의한 사람은 “같은 국가에 사는 것은 괜찮다”는 문항에도 동의해야 한다는 구조이다.\n(2) 누적성 (Cumulativeness)\n척도에 포함된 문항들은 특정 주제나 태도에 대한 강도의 위계를 가지며 응답자는 자신의 태도 강도에 따라 논리적으로 일관된 답변을 해야 한다. 즉, 응답자가 가장 강한 수준의 문항(상위 문항)에 동의했다면, 그보다 약한 수준의 문항(하위 문항)에도 반드시 동의해야 한다. 반대로, 특정 문항에 동의하지 않는다면, 그보다 강한 수준의 문항에도 동의하지 않는 것이 일반적인 응답 패턴이 된다.\n예를 들어, 성평등에 대한 태도를 측정하는 거트만 척도에서 응답자가 ”여성도 전투병이 될 수 있다”는 문항에 동의했다면, 그보다 낮은 수준인 ”여성도 CEO가 될 수 있다”와 ”여성도 직업을 가질 수 있다”는 문항에도 동의해야 한다. 만약 이러한 논리가 지켜지지 않는다면(예: ”여성도 전투병이 될 수 있다”에 동의하지만, ”여성도 CEO가 될 수 있다”에 동의하지 않는 경우), 척도 구성의 오류가 발생할 수 있다.\n(3) 단일 차원성 (Unidimensionality)\n거트만 척도는 측정하고자 하는 태도나 속성이 단일 차원으로 구성되어야 한다. 응답자의 태도를 하나의 연속된 척도로 설명할 수 있어야 하며, 문항 간의 위계적 관계가 유지되어야 한다. 만약 문항들이 여러 개의 차원을 포함하고 있다면, 거트만 척도를 적용하기 어려워진다.\n예를 들어, ”정치적 이념”을 측정하는 경우, 경제적 이념(자유시장과 정부 개입)과 사회적 이념(개인주의와 공동체주의)이 동시에 고려된다면, 이 두 가지는 서로 다른 차원의 속성이므로 거트만 척도로 일관된 위계를 형성하기 어렵다.\n(4) 예측 가능성 (Predictability)\n거트만 척도에서는 응답자의 답변 패턴이 예측 가능해야 한다. 즉, 특정 문항에 대한 응답을 보면 그보다 낮은 수준의 문항에 대한 응답도 예측할 수 있어야 한다. 거트만 척도는 규칙적인 응답 패턴을 기반으로 하기 때문에, 만약 응답자가 예상되는 논리를 따르지 않는다면, 해당 응답이 척도의 신뢰성을 떨어뜨릴 가능성이 크다.\n예를 들어, 교육 수준에 따른 학력 태도를 측정할 때 다음과 같은 문항이 있다고 가정하자.\n1. 초등학교 교육은 모든 사람이 받아야 한다.\n2. 중학교 교육은 모든 사람이 받아야 한다.\n3. 고등학교 교육은 모든 사람이 받아야 한다.\n4. 대학교 교육은 모든 사람이 받아야 한다.\n만약 한 응답자가 ”대학교 교육은 모든 사람이 받아야 한다”고 응답했음에도 불구하고 ”고등학교 교육은 모든 사람이 받아야 한다”에 동의하지 않는다면, 이는 논리적으로 모순된 응답이 된다. 거트만 척도에서는 이러한 불일치가 최소화되어야 하며, 응답자가 한 문항에 동의하면 그보다 낮은 강도의 문항에도 동의할 것이라는 전제가 성립해야 한다.\n\n\n(3) 거트만 척도 사례\n거트만 척도에서는 응답자가 동의한 마지막(가장 높은) 문항의 번호를 기준으로 척도 점수를 부여한다. 즉, 응답자가 어느 수준까지 동의했는지를 측정하여 그 강도를 수량화한다. 이는 연구자가 응답자의 태도 수준을 정량적으로 비교할 수 있도록 도와준다. 예를 들어, 아래와 같은 거트만 척도가 있다고 가정하자.\n\n\n\n\n\n\n\n\n\n\n문항\n응답자 A\n응답자 B\n응답자 C\n응답자 D\n\n\n1. 여성도 일해야 한다\nO\nO\nO\nX\n\n\n2. 여성도 CEO가 될 수 있다\nO\nO\nX\nX\n\n\n3. 여성도 국방의 의무를 가져야 한다\nO\nX\nX\nX\n\n\n4. 여성도 전투병이 될 수 있다\nX\nX\nX\nX\n\n\n척도 점수\n3\n2\n1\n0\n\n\n\n\n\n\n(4) 거트만 척도 구성방법\n(1) 연구 목적 설정\n거트만 척도를 적용하기 전에 가장 먼저 고려해야 할 점은 연구 목적이 명확한가와 측정하고자 하는 태도나 행동이 단일 차원인지를 확인하는 것이다. 거트만 척도는 단일 차원의 위계적 구조를 기반으로 하기 때문에, 측정 대상이 여러 차원의 요소를 포함하는 경우에는 거트만 척도가 적절하지 않을 수 있다.\n예를 들어, 사회적 평등에 대한 태도를 측정하고자 할 때, 경제적 평등(소득 재분배)과 성별 평등(여성의 권리)과 같은 서로 다른 차원의 개념이 포함되면, 하나의 일관된 위계를 형성하기 어렵다. 연구자는 한 가지 차원에서 일관되게 정의될 수 있는 주제를 선정해야 한다.\n적절한 연구 주제: ”성평등에 대한 태도”, ”환경 보호에 대한 인식 수준”, ”정치적 개혁에 대한 수용도”\n부적절한 연구 주제: ”사회적 평등 (경제 + 성별 + 인종 차별)” → 여러 차원을 포함함\n(2) 문항 선정 및 계층적 배열\n연구 주제를 설정한 후에는, 해당 태도를 측정할 수 있는 위계적인 문항을 개발해야 한다. 거트만 척도의 가장 중요한 특징은 문항이 논리적인 강도(위계, Hierarchy)를 가지며, 응답자가 특정 문항에 동의하면 그보다 낮은 강도의 문항도 동의해야 한다는 점이다.\n이를 위해 연구자는 문항을 만들 때 경도에서 난도로 정렬해야 한다. 즉, 가장 많은 사람이 동의할 만한 일반적인 문항에서 시작하여, 점차 강한 입장을 나타내는 문항으로 발전해야 한다.\n\n\n\n\n\n\n\n문항 번호\n문항 내용\n\n\n1\n나는 재활용을 실천한다.\n\n\n2\n나는 환경 보호를 위해 일회용품 사용을 줄인다.\n\n\n3\n나는 대중교통을 적극적으로 이용한다.\n\n\n4\n나는 환경 보호 단체에 기부하거나 활동에 참여한다.\n\n\n5\n나는 환경 보호를 위해 추가적인 세금을 부담할 의향이 있다.\n\n\n\n이러한 문항 배열에서는 응답자가 5번 문항(세금 부담)에 동의한다면, 1~4번 문항(재활용, 일회용품 줄이기, 대중교통 이용, 환경 단체 활동)에도 동의할 가능성이 높다. 반대로, 1번 문항(재활용 실천)에조차 동의하지 않는다면, 상위 문항에도 동의하지 않을 가능성이 크다.\n이처럼, 연구자는 문항을 개발할 때 위계적으로 정렬된 문항을 만들고, 응답자가 강한 수준의 문항에 동의하면 약한 수준의 문항도 포함될 수 있도록 설계해야 한다.\n(3) 문항의 적합성 검증\n거트만 척도의 문항이 연구 목적에 맞게 구성되었는지 확인한 후에는, 척도가 실제로 누적적 구조를 따르는지 검증하는 과정이 필요하다. 이를 위해 연구자는 응답 데이터를 분석하여 응답 패턴이 논리적인 위계를 따르는지 평가해야 한다.\n가장 일반적인 검증 방법은 척도 재현성 계수(Scale Reproducibility Coefficient, R)를 계산하는 것이다. 이 계수는 응답자들의 패턴이 거트만 척도의 논리를 얼마나 충실히 따르는지를 평가하는 지표로 사용된다.\n척도 재현성 계수 계산 공식: \\(R = 1 - \\frac{\\sum e}{(n \\times k)}\\)\n\\(e\\): 오류 응답 개수 (예: 낮은 강도의 문항에 동의하지 않으면서 높은 강도의 문항에 동의한 경우)\n\\(n\\)= 응답자 수, \\(k\\)= 문항 수\n만약 응답자 10명, 문항 5개로 구성된 척도에서 오류 응답(예측 불가능한 응답)이 4개라면, \\(R = 1 - \\frac{4}{(10 \\times 5)} = 1 - \\frac{4}{50} = 0.92\\)\n\\(R \\geq 0.90\\) → 척도의 일관성이 매우 높음, 신뢰할 수 있음\n\\(0.80 \\leq R &lt; 0.90\\) → 척도 개선 가능성 있음\n\\(R &lt; 0.80\\) → 척도의 신뢰성이 낮음, 재구성이 필요\n만약 R 값이 낮다면, 이는 척도 문항이 적절한 위계를 형성하지 못하고 있거나, 응답자들이 일관된 논리를 따르지 않는다는 의미가 될 수 있다. 이러한 경우, 연구자는 문항을 재구성하거나, 응답 패턴을 분석하여 비일관적인 데이터를 보정해야 한다.\n\n\n\n2. 서스톤 Thurstone 척도\n서스톤 척도는 응답자의 태도를 정량적으로 평가하는 방법 중 하나로, 전문가 패널이 사전에 각 문항의 강도를 평가하여 점수를 부여한 후, 이를 바탕으로 응답자의 태도 점수를 계산하는 방식이다. 일반적으로 태도 측정에서는 응답자가 자신의 태도를 직접 수치화하는 방식(예: 리커트 척도)이 많이 사용되지만, 서스톤 척도는 전문가가 문항의 강도를 미리 점수화하기 때문에 보다 객관적이고 정밀한 태도 측정이 가능하다는 장점이 있다.\n이 척도는 사회과학 연구, 마케팅 조사, 심리학 연구 등에서 활용되며, 예를 들어 환경 보호, 정치적 성향, 종교적 신념, 제품 선호도 등과 같은 태도를 측정하는 데 사용될 수 있다.\n\n(1) 서스톤 척도 원리\n서스톤 척도는 세 가지 핵심 원칙을 따른다.\n전문가 패널을 통해 문항의 강도를 미리 평가한다.\n문항별 강도를 등간척도(Interval Scale) 형태로 점수화한다.\n응답자의 태도를 문항 점수를 기반으로 계산한다.\n먼저 연구자는 특정 태도를 측정하기 위한 다양한 문항을 개발한다. 이때 문항은 응답자의 태도 강도를 점진적으로 측정할 수 있도록 다양하게 구성되어야 한다. 그런 다음, 전문가 패널이 각 문항이 나타내는 태도의 강도를 평가하여 점수를 부여한다. 이 과정에서 전문가들은 일반적으로 1점(매우 약함)에서 11점(매우 강함)까지의 척도를 사용하며, 문항별로 점수를 매긴 후 중앙값이나 평균값을 산출하여 최종 문항 점수로 사용한다.\n이후 응답자는 문항을 읽고 자신이 동의하는 문항을 선택한다. 연구자는 응답자가 동의한 문항들의 점수를 평균 또는 중앙값으로 계산하여 응답자의 태도 점수를 결정한다. 이 태도 점수는 등간척도 값이므로, 평균 비교나 통계적 분석이 가능하다.\n\n\n(2) 서스톤 척도의 구성 방법 (Construction of Thurstone Scale)\n(1) 연구 목적 설정\n서스톤 척도를 적용하기 위해서는 먼저 연구의 목적을 명확하게 설정해야 한다. 이는 측정하고자 하는 태도나 신념이 하나의 연속적인 차원에서 설명될 수 있는지 확인하는 과정이다. 서스톤 척도는 태도의 강도를 측정하는 방법이므로, 연구자가 다차원적인 개념을 포함할 경우 척도의 적용이 어려울 수 있다.따라서, 단일 차원을 유지하는 것이 중요하다.\n예를 들어, 연구자가 환경 보호에 대한 태도를 측정한다고 가정하자. 이 경우, 환경 보호에 대한 태도를 긍정적 태도와 부정적 태도의 연속적인 개념으로 설정할 수 있다. 즉, 응답자가 환경 보호를 얼마나 중요하게 생각하는지를 강도에 따라 평가할 수 있도록 환경 보호에 대한 긍정적인 태도를 하나의 차원으로 정의할 수 있다.\n반면, ”환경 보호 태도”를 측정할 때 정책적 태도(환경 규제 찬성/반대), 행동적 태도(재활용 실천 여부), 감정적 태도(환경 문제에 대한 관심도) 등 여러 가지 차원이 혼합된다면, 서스톤 척도를 적용하는 것이 어려워질 수 있다.\n따라서, 연구 목적을 설정할 때는 응답자의 태도가 하나의 연속적인 척도로 측정될 수 있도록 명확한 개념 정의가 필요하며, 측정하고자 하는 속성이 단일 차원으로 구성되어 있는지 검토해야 한다.\n(2) 문항 개발 및 전문가 평가\n서스톤 척도를 구성하기 위해 연구자는 먼저 측정하고자 하는 태도나 신념과 관련된 다양한 강도의 문항을 개발해야 한다. 이때 문항은 응답자의 태도 강도를 점진적으로 측정할 수 있도록 구성되어야 하며, 너무 유사하거나 중복된 표현이 포함되지 않도록 주의해야 한다.\n문항이 개발된 후, 연구자는 전문가 패널(판정단)을 구성하여 각 문항이 나타내는 태도의 강도를 평가하도록 한다. 전문가들은 보통 11점 척도(또는 9점, 7점 등)를 사용하여 문항의 강도를 판단하며, 점수가 클수록 더 강한 태도를 나타내는 것으로 평가한다. 즉, 가장 낮은 점수의 문항은 태도가 가장 약한 진술을 의미하고, 가장 높은 점수의 문항은 태도가 가장 강한 진술을 의미하게 된다.\n이러한 전문가 평가 결과를 바탕으로 연구자는 각 문항에 대해 평균값 또는 중앙값을 계산하여 최종 문항 점수로 설정한다. 이 과정에서 특정 문항에 대한 전문가들의 의견이 크게 분산되는 경우, 연구자는 해당 문항을 수정하거나 제외할 수도 있다. 예를 들어, 환경 보호에 대한 태도를 측정하는 서스톤 척도의 경우, 전문가 패널이 다음과 같은 문항을 평가할 수 있다.\n”나는 가끔 재활용을 한다.” → 평균 점수: 2.5점 (낮은 수준의 환경 보호 태도)\n”나는 환경 보호를 위해 일회용품 사용을 줄인다.” → 평균 점수: 5.2점 (중간 수준의 환경 보호 태도)\n”나는 환경 보호 단체에 기부하거나 활동에 참여한다.” → 평균 점수: 7.8점 (높은 수준의 환경 보호 태도)\n”나는 환경 보호를 위해 추가적인 세금을 부담할 의향이 있다.” → 평균 점수: 10.3점 (매우 높은 수준의 환경 보호 태도)\n이처럼, 문항이 전문가 패널에 의해 점수화되면, 연구자는 점수 분포를 분석하여 강도가 균등하게 분포된 문항을 선정하고, 최종적인 서스톤 척도를 구성할 수 있다. 이후 응답자는 자신이 동의하는 문항을 선택하게 되며, 연구자는 해당 문항의 점수를 바탕으로 응답자의 태도를 정량적으로 평가할 수 있다.\n(3) 최종 문항 선정\n전문가 패널이 모든 문항을 평가한 후, 연구자는 응답자의 태도를 효과적으로 측정할 수 있도록 최종적으로 사용할 문항을 선정해야 한다. 이때 가장 중요한 것은 문항의 점수 분포가 균형 있게 배치되는지 확인하는 것이다.\n서스톤 척도의 핵심 원리는 태도 강도를 연속적인 척도로 측정하는 것이므로, 최종적으로 선택된 문항들이 너무 한쪽에 치우치지 않도록 강도가 균등하게 분포되도록 조정해야 한다. 예를 들어, 전문가 평가를 거친 후 점수가 1점, 3점, 5점, 7점, 9점으로 균등하게 분포된 문항을 선택하면, 응답자의 태도 강도를 보다 정밀하게 측정할 수 있다.\n만약 문항 점수가 특정 구간(예: 5점~9점)에 집중되어 있다면, 연구자는 1점~3점 범위의 문항을 추가하거나, 특정 문항을 수정하여 보다 균형 잡힌 척도를 구성할 필요가 있다. 이 과정을 통해 최종적으로 선택된 문항들은 응답자의 태도를 단계적으로 측정할 수 있는 기준이 되며, 이후 태도 점수를 계산하는 데 활용된다.\n(4) 응답자의 태도 점수 측정\n최종적으로 선정된 문항을 바탕으로 연구자는 응답자의 태도를 측정한다. 이 과정에서 응답자는 제공된 문항을 읽고, 자신이 동의하는 문항을 선택하게 된다.\n응답자가 선택한 문항들은 연구자가 사전에 설정한 강도 점수를 가지고 있으며, 연구자는 이를 기반으로 응답자의 태도 점수를 계산할 수 있다. 태도 점수는 일반적으로 응답자가 동의한 문항들의 평균 또는 중앙값으로 측정된다.\n예를 들어, 한 응답자가 환경 보호 태도를 측정하는 서스톤 척도에서 다음과 같은 문항에 동의했다고 가정하자.\n”나는 환경 보호를 위해 일회용품 사용을 줄인다.” (평균 점수: 5.2)\n”나는 대중교통을 적극적으로 이용한다.” (평균 점수: 6.5)\n이 경우, 응답자의 태도 점수는 \\((5.2 + 6.5)/2 = 5.85\\)이다. 즉, 응답자는 환경 보호에 대한 태도를 5.85점 수준으로 가지고 있다고 해석할 수 있다.\n이러한 방식으로 연구자는 응답자의 태도를 정량적으로 평가할 수 있으며, 개별 응답자뿐만 아니라 집단 간 태도를 비교하거나 통계적 분석을 수행할 수도 있다. 예를 들어, 연령대별 환경 보호 태도 차이를 분석하거나, 기업과 일반 소비자의 태도를 비교하는 연구에서도 서스톤 척도를 활용할 수 있다. 이와 같이, 서스톤 척도는 전문가 패널을 통해 사전에 평가된 문항 점수를 활용하여 응답자의 태도를 보다 정밀하게 측정할 수 있는 방법을 제공한다.\n\n\n(3) 서스톤 척도 장단점\n(1) 장점 (Advantages)\n첫째, 객관적인 태도 측정이 가능하다. 일반적인 태도 측정 방법(예: 리커트 척도)은 응답자가 자신의 태도를 직접 평가하는 방식이지만, 서스톤 척도는 전문가가 사전에 문항의 강도를 점수화하기 때문에 보다 객관적인 평가가 가능하다. 즉, 응답자의 주관적 해석이 개입될 여지가 줄어들며, 연구자가 미리 설정한 기준에 따라 태도를 수량화할 수 있다.\n둘째, 정확한 태도 점수를 제공할 수 있다. 응답자가 단순히 ”동의” 또는 ”비동의”와 같은 선택을 하는 것이 아니라, 전문가가 평가한 문항 점수를 기반으로 태도 강도를 측정할 수 있다. 따라서, 응답자의 태도를 정밀하게 측정할 수 있으며, 비교적 작은 차이도 감지할 수 있다. 예를 들어, 환경 보호에 대한 태도를 평가할 때, ”나는 가끔 재활용을 한다”와 ”나는 환경 보호를 위해 추가적인 세금을 부담할 의향이 있다”는 명확히 다른 수준의 태도를 나타낸다. 서스톤 척도는 이러한 차이를 정량화하여 태도 점수를 제공할 수 있다.\n셋째, 등간척도로 활용할 수 있어 통계적 분석이 용이하다. 서스톤 척도는 문항이 사전에 점수화되어 있어 등간척도로 간주될 수 있다. 따라서, 환경 보호 태도를 조사한 후, 특정 연령대별 평균 태도 점수를 비교하거나, 기업과 일반 소비자의 태도 차이를 분석하는 데 사용할 수 있다. 이러한 분석이 가능하기 때문에 사회과학 연구나 마케팅 조사에서 활용도가 높다.\n(2) 단점 (Disadvantages)\n첫째, 전문가 패널을 구성해야 하는 번거로움이 있다. 서스톤 척도를 사용하려면, 연구자가 문항을 개발한 후 해당 분야의 전문가 집단을 구성하여 문항을 평가받아야 한다. 이는 상당한 시간과 노력이 필요하며, 전문가 의견을 조정하는 과정에서 추가적인 논의와 검토가 필요할 수 있다. 특히, 전문가들의 평가가 일관되지 않을 경우 추가적인 조정이 필요하므로 연구 과정이 더욱 복잡해질 수 있다.\n둘째, 문항 선정 및 점수화 과정이 복잡하고 시간이 많이 소요된다.리커트 척도처럼 ”매우 동의 ~ 매우 반대”의 선택지를 제공하는 방식과 달리, 서스톤 척도는 문항을 개발한 후 각 문항의 강도를 평가하고 점수화하는 과정이 필요하다. 이 과정에서 연구자는 전문가 패널의 평가 점수를 수집하고, 이를 평균 또는 중앙값으로 변환하여 최종 문항 점수를 결정해야 한다. 따라서, 서스톤 척도는 문항 개발과 평가 과정이 복잡하여 연구를 신속하게 진행하기 어려운 경우가 많다.\n셋째, 응답자가 특정 문항을 선택하지 않으면 태도 점수 계산이 어려울 수 있다. 서스톤 척도는 응답자가 동의하는 문항을 선택하는 방식이므로, 만약 응답자가 어떤 문항도 선택하지 않는다면 그 응답자의 태도 점수를 계산하기 어렵다. 또한, 응답자가 중간 강도의 문항만 선택하거나, 극단적인 문항만 선택할 경우, 연구자가 의도한 대로 태도 강도가 균형적으로 측정되지 않을 가능성이 있다. 이러한 문제를 방지하기 위해 연구자는 문항을 신중하게 구성해야 하며, 응답자의 선택 패턴을 분석하여 연구 결과의 신뢰성을 평가할 필요가 있다.\n\n\n\n3. 의미분화 Semantic Differential 척도\n의미분화 척도는 응답자의 태도, 감정, 인식을 측정하기 위한 방법으로, 서로 반대되는 형용사 쌍을 이용하여 특정 개념을 평가하는 방식이다. 이 척도는 1950년대 찰스 오스굿(Charles Osgood)에 의해 개발되었으며, 주로 브랜드 이미지 평가, 제품 선호도 조사, 감정 분석, 사회적 태도 연구에 활용된다.\n응답자는 주어진 개념(예: 특정 브랜드, 제품, 서비스, 정치적 이슈 등)에 대해 양극적인 의미를 가지는 형용사 쌍(예: 혁신적이다 – 전통적이다, 친절하다 – 무뚝뚝하다, 고급스럽다 – 저렴하다 등)을 기준으로 평가한다. 이 척도는 보통 5점 또는 7점 척도를 사용하여, 응답자가 두 개의 형용사 중 어느 쪽에 더 가깝다고 느끼는지를 선택하게 한다. 이를 통해 연구자는 특정 개념에 대한 응답자의 인식과 감정을 수량화하여 비교 및 분석할 수 있다.\n\n(1) 의미분화 척도 구성 방법\n(1) 연구 목적 설정\n먼저, 연구자는 측정하려는 개념을 명확히 정의해야 한다. 이 척도는 인지적 평가(브랜드 이미지), 감정적 반응(감성 평가), 태도(사회적 이슈에 대한 인식) 등을 측정하는 데 효과적이다.\n예를 들어, 연구자가 소비자의 브랜드 인식을 조사하려는 경우, 혁신성, 신뢰성, 감성적 요소 등 다양한 측면에서 브랜드를 평가할 수 있도록 형용사 쌍을 선정해야 한다.\n(2) 적절한 형용사 쌍 선정\n의미분화 척도의 핵심은 양극적인 의미를 가지는 형용사 쌍을 선정하는 것이다. 형용사는 측정 대상과 관련성이 있어야 하며, 응답자가 쉽게 이해할 수 있어야 한다. 예를 들어, 스마트폰 브랜드를 평가하는 경우 다음과 같은 형용사 쌍을 사용할 수 있다.\n디자인 측면: 세련된 – 투박한\n성능 측면: 강력한 – 느린\n가격 대비 가치: 가성비 좋다 – 비싸기만 하다\n브랜드 이미지: 혁신적인 – 전통적인\n(3) 응답 척도 설정\n보통 5점 척도 또는 7점 척도를 사용하여 응답자가 각 형용사 쌍 사이에서 자신의 입장을 선택할 수 있도록 한다. 예를 들어, ”이 브랜드는 세련된가?” 라는 질문이 주어졌을 때, 응답자는 아래와 같이 선택할 수 있다.\n세련된 (1) – (2) – (3) – (4) – (5) 투박한\n이러한 방식으로 응답자는 특정 개념에 대해 자신이 인식하는 정도를 선택하게 된다.\n\n\n(2) 의미분화 척도 응답 결과 해석\n응답자가 평가한 점수를 분석하여 특정 개념(브랜드, 제품, 서비스 등)이 어떤 속성을 가지고 있는지 해석할 수 있다. 이를 통해 연구자는 브랜드 간 비교, 소비자 인식 분석, 마케팅 전략 수립 등에 활용할 수 있다. 예를 들어, 브랜드 이미지 평가에서 애플과 삼성을 비교한 결과가 다음과 같다고 가정하자.\n\n\n\n\n\n\n\n\n형용사 쌍\n애플\n삼성\n\n\n혁신적이다 – 전통적이다\n2.1\n4.3\n\n\n고급스럽다 – 저렴해 보인다\n2.5\n3.9\n\n\n감성적이다 – 실용적이다\n3.8\n2.2\n\n\n\n이 결과를 해석하면 다음과 같다.\n\n애플은 혁신적이고 고급스러우며 감성적인 브랜드로 인식된다.\n삼성은 실용적이지만 비교적 전통적이고 저렴한 브랜드로 평가된다.\n\n이러한 분석을 통해 기업은 자신들의 브랜드 포지셔닝 전략을 조정하거나, 소비자의 인식 변화를 모니터링하는 데 활용할 수 있다.\n\n\n(3) 의미분화 척도 장단점\n(1) 장점\n감성적·정성적 데이터를 수량화할 수 있음: 브랜드 이미지나 소비자 감정처럼 측정하기 어려운 개념을 숫자로 변환할 수 있다.\n심층적인 분석이 가능함: 다양한 속성을 동시에 비교할 수 있어 브랜드 전략, 소비자 인식 분석에 효과적이다.\n다양한 연구 분야에서 활용 가능: 마케팅, 심리학, 사회과학 등 여러 분야에서 적용할 수 있으며, 정량적 분석과 정성적 분석을 함께 수행할 수 있다.\n(2) 단점\n형용사 쌍 선정이 어렵다: 연구자가 적절한 형용사 쌍을 선정하지 못하면 신뢰성 있는 결과를 얻기 어려울 수 있다.\n주관성이 개입될 수 있음: 응답자가 동일한 척도를 다르게 해석할 가능성이 있으며, 개인적인 경험이나 문화적 배경에 따라 답변이 달라질 수 있다.\n통계적 분석이 어려울 수 있음: 개별 속성마다 다른 점수를 얻기 때문에, 전체적인 인식을 종합적으로 분석하는 것이 복잡할 수 있다.\n\n\n\n4. 보가더스 Bogardus Social Distance 척도\n보가더스 척도는 사회적 거리를 측정하기 위한 방법으로, 특정 집단에 대한 개인의 사회적 수용도를 평가하는 척도이다. 이 척도는 1925년 에멜 보가더스(Emory S. Bogardus)가 개발했으며, 주로 인종, 계층, 문화적 차이 등에 대한 태도를 분석하는 데 사용된다.\n\n(1) 보가더스 척도 개요\n보가더스 척도는 응답자가 특정 집단(예: 인종, 종교, 성별 등)에 대해 어떤 수준까지 사회적 관계를 허용할 수 있는지를 평가하는 방식이다. 이 척도는 사회적 거리의 개념을 기반으로 하며, 응답자의 태도 강도를 점진적으로 측정한다.\n보가더스 척도는 보통 다음과 같은 7단계(또는 변형된 5~10단계)의 진술문으로 구성된다. 응답자는 특정 집단에 대해 각 단계에서 자신의 수용 가능 여부를 표시해야 한다.\n\n\n(2) 보가더스 척도 구성 방법\n(1) 연구 목적 설정\n보가더스 척도는 특정 집단에 대한 사회적 거리감을 측정하는 것이 목적이다. 예를 들어, 연구자가 다문화 사회에서 특정 민족 집단에 대한 태도를 조사하려는 경우, 이 척도를 활용하여 응답자들이 해당 집단을 어느 정도까지 수용할 수 있는지를 측정할 수 있다.\n(2) 7단계 문항 구성\n보가더스 척도는 일반적으로 사회적 관계의 밀도(친밀성)에 따라 7단계로 구성된다. 응답자는 특정 집단(예: 난민, 외국인 노동자, 특정 인종 등)에 대해 다음의 관계 수준에서 수용 가능 여부를 선택한다.\n\n가족 구성원으로 받아들일 수 있다.\n개인적인 친구로 받아들일 수 있다.\n이웃으로 받아들일 수 있다.\n동료(직장, 학교)로 받아들일 수 있다.\n시민으로 받아들일 수 있다.\n관광객으로 받아들일 수 있다.\n완전히 거부한다.\n\n이러한 문항을 바탕으로 응답자는 자신이 허용할 수 있는 가장 높은 단계까지만 ’동의’를 선택하게 된다. 즉, 응답자의 최종 선택된 단계가 사회적 거리 점수로 계산된다.\n\n\n(3) 보가더스 척도 응답 결과 해석\n(1) 태도 강도 측정 및 사회적 거리 점수 계산\n보가더스 척도에서는 응답자가 허용할 수 있는 가장 높은(즉, 가장 친밀한) 단계를 기준으로 점수를 계산한다. 응답자가 특정 집단에 대해 가까운 관계를 허용할수록 사회적 거리는 짧고, 거부할수록 사회적 거리는 길어진다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n응답자\n가족 구성원\n친구\n이웃\n직장 동료\n시민권 허용\n관광객 허용\n완전 거부\n사회적 거리 점수\n\n\nA\nO\nO\nO\nO\nO\nO\nX\n6\n\n\nB\nX\nX\nO\nO\nO\nX\nX\n5\n\n\nC\nX\nO\nX\nO\nX\nX\nX\n4\n\n\n\n(2) 응답 집단 간 비교 분석\n보가더스 척도는 집단 간 태도를 비교하는 데 유용하다. 예를 들어, 연령별, 성별, 지역별로 특정 집단에 대한 사회적 거리를 비교할 수 있다.\n\n\n\n\n\n\n\n\n연령대\n평균 점수\n해석\n\n\n20대\n5.8\n난민 수용에 비교적 개방적\n\n\n40대\n4.2\n중립적 태도\n\n\n60대\n3\n난민 수용에 보수적\n\n\n\n\n\n\n(4) 보가더스 척도 장단점\n장점\n보가더스 척도는 특정 집단(예: 난민, 성소수자, 특정 인종 등)에 대한 사회적 거리감을 직관적으로 측정할 수 있는 장점을 지닌다. 이 척도는 응답자가 해당 집단을 얼마나 가까운 사회적 관계 속에서 수용할 수 있는지를 단계별로 평가하도록 설계되어 있어, 연구자는 응답자의 사회적 거리감과 수용도를 명확히 분석할 수 있다. 예를 들어, 어떤 응답자가 특정 집단을 직장 동료로는 허용하지만 가족 구성원으로는 받아들이기 어렵다고 응답했다면, 이는 해당 집단에 대해 일정한 거리감을 갖고 있음을 의미한다. 이러한 구조를 통해 보가더스 척도는 응답자의 태도를 체계적으로 측정하고, 사회적 거리 개념을 쉽게 해석할 수 있도록 한다.\n또한, 이 척도는 태도 변화 분석에도 유용하다. 난민, 이민자, 성소수자 등 논쟁이 되는 집단에 대한 사회적 거리 점수의 변화를 시계열적으로 분석함으로써, 사회적 태도가 더 개방적으로 변화했는지(점수 증가) 혹은 보수적으로 변화했는지(점수 감소)를 파악할 수 있다. 예컨대, 이민자 수용 정책이 바뀐 이후 대중의 사회적 거리 점수를 비교·분석함으로써, 해당 정책이 대중의 태도에 미친 영향을 측정할 수 있다.\n더 나아가, 보가더스 척도는 다양한 문화 및 사회 연구에 폭넓게 적용될 수 있다. 단순한 인종 차별 연구를 넘어, 성소수자(LGBTQ+), 난민, 이민자 등 특정 집단에 대한 사회적 거리 평가를 통해 차별과 수용의 정도를 정량적으로 분석할 수 있다. 예를 들어, 인종 차별 연구에서는 특정 인종 집단에 대한 거리감을 측정하고, 성차별 연구에서는 여성 및 성소수자에 대한 수용도를 평가하며, 장애인 연구에서는 장애인과 비장애인 간의 사회적 거리 차이를 분석할 수 있다. 이러한 방식으로 보가더스 척도는 다양한 사회적 관계 속에서 형성되는 거리감을 수치화하고, 사회적 통합과 차별을 이해하는 데 유용한 도구로 활용된다.\n단점\n보가더스 척도를 사용할 때 주의해야 할 한계 중 하나는 응답자의 사회적 바람직성 편향(social desirability bias) 가능성이다. 이는 응답자가 실제 태도보다 더 개방적이고 긍정적인 방향으로 답하려는 경향을 의미한다. 특히 인종, 성소수자, 난민과 같은 민감한 주제를 다룰 때 이러한 편향이 두드러지게 나타날 수 있다. 예를 들어, 공개된 설문조사 상황에서는 응답자가 인종차별적인 사람으로 보일까봐 특정 인종에 대해 실제보다 더 수용적인 태도를 보일 수 있으며, 성소수자에 대한 수용 태도 역시 사회 분위기를 의식한 긍정적인 응답으로 나타날 수 있다. 이러한 편향을 완화하기 위해 연구자는 익명성을 보장하거나, 보조 질문을 추가하여 응답의 일관성을 검토하는 등의 방법을 활용할 수 있다.\n또한 보가더스 척도는 응답자가 특정 집단에 대해 어느 정도 수용적인지를 수량화하는 데에는 효과적이지만, 그 이유나 동기를 설명하는 데에는 한계가 있다. 예를 들어, 어떤 응답자가 난민에 대해 높은 사회적 거리 점수를 보였다 하더라도, 그것이 정치적 신념 때문인지, 개인적인 경험이나 교육 수준 때문인지는 이 척도만으로는 파악할 수 없다. 따라서 연구자가 보가더스 척도를 사용할 경우, 응답자의 태도 형성 배경을 보다 깊이 이해하기 위해 개방형 질문, 면접(interview) 등의 질적 조사 방법을 병행하는 것이 바람직하다.\n마지막으로, 현대 사회의 다양한 사회적 관계를 보가더스 척도가 충분히 반영하지 못할 수 있다는 점도 고려해야 한다. 기존의 7단계 문항 구조는 ‘이웃’, ‘동료’, ‘결혼 상대’ 등 전통적인 관계 유형을 중심으로 구성되어 있다. 그러나 현대 사회에서는 SNS 친구, 온라인 커뮤니티 멤버, 동호회 파트너 등 다양한 비대면·비공식적 관계가 존재하며, 이러한 새로운 관계 유형은 기존 척도로는 포착하기 어렵다. 또한, 국제화된 사회에서는 ’관광객 허용’과 같은 문항이 구체적인 의미를 갖기 어렵고, 단지 관광객으로 오는 것을 허용한다고 해서 해당 집단을 실질적으로 수용하는 것은 아닐 수 있다. 따라서 연구자는 보가더스 척도를 활용할 때, 시대 변화에 맞춰 문항을 수정하거나 보완하여 보다 현실적이고 정교한 분석이 가능하도록 해야 한다.\n\n\n\n5. 기타 척도\n\n(1) 스테이플 척도\n스테이플 척도는 설문 응답자가 특정 속성에 대해 긍정적 또는 부정적인 정도를 평가할 수 있도록 설계된 단극형 척도이다. 이 척도는 R. Stapel에 의해 개발되었으며 마케팅 조사 및 소비자 태도 연구에서 자주 사용된다.\n스테이플 척도를 구성하기 위해서는 먼저 측정하려는 속성을 명확하게 정의하고, 이를 평가할 수 있는 단일 형용사를 선정해야 한다. 일반적으로 긍정적 또는 부정적 감정을 유발하는 형용사가 사용되며, 응답자가 해당 속성에 대해 얼마나 긍정적이거나 부정적인지 평가할 수 있도록 한다.\n스테이플 척도는 중립값(0)을 중심으로 -5에서 +5까지의 연속적인 점수를 제공하여, 응답자가 특정 속성에 대한 평가를 강한 부정(-5)부터 강한 긍정(+5)까지 표현할 수 있도록 한다. 0은 중립적인 태도를 의미하며, 응답자가 특정 속성에 대해 특별한 의견이 없거나 긍정과 부정이 동등하게 느껴질 경우 선택할 수 있다.\n응답자는 각 문항에서 제시된 형용사가 평가 대상(예: 제품, 브랜드, 서비스 등)에 얼마나 적절한지를 선택하며, 이를 통해 연구자는 특정 대상의 이미지나 특성을 수량화할 수 있다.\n예를 들어, 특정 스마트폰 브랜드에 대한 평가를 조사할 경우, ”고급스러운”, ”혁신적인”, ”신뢰할 수 있는” 등의 형용사를 제시하고 응답자가 -5에서 +5 사이에서 자신의 인식을 선택하도록 한다. 이때 응답자의 선택은 브랜드에 대한 감정적 태도를 직접적으로 반영하며, 평균 점수를 통해 특정 속성에 대한 전반적인 인식을 파악할 수 있다.\n\n\n\n\n\n\n\n\n\n척도 유형\n측정 방식\n주요 특징\n활용 예시\n\n\n리커트 척도\n5~7점 동의 수준 측정\n쉬운 응답 방식, 보편적으로 사용됨\n고객 만족도 조사\n\n\n의미분화 척도\n양극단의 형용사 선택\n감정적 태도 측정, 브랜드 이미지 분석\n브랜드 인식 조사\n\n\n스테이플 척도\n단일 형용사 긍정/부정 평가\n-5~+5 연속적 측정, 긍정/부정 감정 동시에 분석 가능\n제품 평가, 광고 효과 분석\n\n\n서스톤 척도\n전문가 패널이 문항 가중치 부여\n등간척도로 활용 가능, 신뢰도 높음\n감정 평가, 브랜드 선호도 조사\n\n\n\n\n\n(2) 맥콜스키 척도\n맥콜스키 McClosky 척도는 개인의 정치적 태도 및 민주주의에 대한 신념을 측정하기 위해 개발된 척도로, 보가더스 척도와 유사하게 사용되지만, 주로 정치적 태도를 평가하는 데 초점을 맞춘다는 점에서 차별성이 있다. 이 척도는 정치적 자유주의와 보수주의 사이에서 개인이 어디에 위치하는지를 분석하는 도구로 활용되며, 정치적 신념, 정부 개입에 대한 견해, 시민권 보호, 언론 자유, 법과 질서 등 다양한 정치적 개념을 평가하는 데 유용하다.\n리커트 척도 5점/7점 척도를 사용하여 응답자가 각 진술에 대해 ”강하게 반대(1)”에서 ”강하게 동의(5)”까지의 수준을 선택할 수 있도록 구성된다. 예를 들어, ”정부는 경제에 적극적으로 개입해야 한다.”라는 문항에 대해 응답자가 강하게 동의(5)를 선택한다면, 이는 해당 응답자가 정부 개입을 선호하는 자유주의적 경제 정책을 지지하는 경향이 있음을 나타낸다.\n반면, ”국가 안보를 위해 시민의 일부 자유를 제한할 수 있다.”라는 문항에 대해 강하게 반대(1)를 선택했다면, 이는 응답자가 개인 자유를 우선시하는 성향을 보인다고 해석할 수 있다. “언론의 자유는 어떠한 경우에도 제한되어서는 안 된다.”, “법과 질서를 유지하기 위해 강력한 정부 권력이 필요하다.” 문항도 동일하게 평가한다.\n이러한 방식으로 리커트 척도를 활용하면 개별 응답자의 정치적 태도를 수량적으로 평가할 수 있으며, 특정 집단(예: 연령별, 지역별, 교육 수준별)의 정치적 경향성을 비교하는 데 활용될 수 있다. 또한, 평균 점수를 계산하여 집단 간 차이를 분석하거나, 시간에 따른 태도 변화를 추적하는 연구에도 유용하게 적용할 수 있다.\n\n\n(3) 사전 확률 척도\n사전 확률 척도는 응답자가 특정 사건이 발생할 가능성을 직접 확률로 평가하도록 하는 척도이다. 이 척도는 0%에서 100%까지의 범위를 사용하여, 응답자가 얼마나 확신하는지를 수량적으로 표현할 수 있도록 설계되었다.\n전통적인 리커트 척도나 의미분화 척도와 달리, 사전 확률 척도는 응답자가 단순히 동의/반대 또는 강도를 선택하는 것이 아니라 특정 사건이 발생할 확률을 직접 입력하거나 선택할 수 있도록 한다.\n다음 질문에 대해, 해당 사건이 발생할 가능성을 0%에서 100% 사이에서 선택해 주세요.\n\"다음 선거에서 A 후보가 당선될 확률은 몇 %라고 생각하십니까?\"\n⬜ 0% ⬜ 10% ⬜ 20% ⬜ 30% ⬜ 40% ⬜ 50% ⬜ 60% ⬜ 70% ⬜ 80% ⬜ 90% ⬜ 100%\n\"내년 경제가 성장할 확률은 얼마나 된다고 생각하십니까?\"\n⬜ 0% ⬜ 10% ⬜ 20% ⬜ 30% ⬜ 40% ⬜ 50% ⬜ 60% ⬜ 70% ⬜ 80% ⬜ 90% ⬜ 100%\n\"내년 중 실업률이 증가할 가능성은 얼마나 된다고 생각하십니까?\"\n⬜ 0% ⬜ 10% ⬜ 20% ⬜ 30% ⬜ 40% ⬜ 50% ⬜ 60% ⬜ 70% ⬜ 80% ⬜ 90% ⬜ 100%\n\n\n(4) 피시바인-아즈젠 태도 모델 Theory of Reasoned Action)\n태도와 행동의 관계를 설명하는 이론적 모델로 특정 행동에 대한 개인의 태도가 행동 의도(Behavioral Intention)에 어떻게 영향을 미치는지를 분석하는 데 사용된다. 이 모델은 이성적 행동 이론의 핵심 개념을 기반으로 하며, 주로 소비자 행동, 건강 행동, 마케팅, 정책 연구 등에서 활용된다.\n피시바인-아즈젠 태도 모델의 수식\n\\[BI = (A)W_{1} + (SN)W_{2}\\]\n\nBI (Behavioral Intention): 행동 의도\nA (Attitude): 개인의 태도\nSN (Subjective Norms): 주관적 규범\nW₁, W₂: 태도와 주관적 규범의 상대적 중요도 가중치\n\n즉, 행동 의도는 개인의 태도(A)와 사회적 규범(SN)의 영향을 받아 형성되며 이 두 요소가 행동을 예측하는 중요한 변수로 작용한다.\n예시\n태도(A), 주관적 규범(SN), 행동 의도(BI)는 하나의 단순한 질문으로 완벽히 측정할 수 없는 복합적인 개념이다. 예를 들어, 태도(A)는 ”긍정적”인지 ”부정적”인지뿐만 아니라, ”유용성”, ”편리성”, ”비용” 등의 하위 요소로 구성될 수 있다. 다수의 리커트 척도(5점, 7점) 문항들로 구성하여 평균 점수를 이용한다.\n행동 의도(BI) 측정 문항\n목표: 응답자가 특정 행동(예: 전기차 구매)을 실제로 할 의향이 있는지를 평가\n”나는 앞으로 6개월 이내에 전기차를 구매할 의향이 있다.” (1 = 전혀 없음, 5 = 매우 높음\n”나는 전기차를 구매하는 것을 진지하게 고려하고 있다.” (1 = 전혀 그렇지 않다, 5 = 매우 그렇다)\n”전기차 구매를 위한 정보를 적극적으로 찾고 있다.” (1 = 전혀 그렇지 않다, 5 = 매우 그렇다)\n”내가 차량을 구매한다면, 전기차를 선택할 가능성이 높다.” (1 = 전혀 그렇지 않다, 5 = 매우 그렇다)\n태도(A) 측정 문항\n목표: 개인이 특정 행동(예: 전기차 구매)에 대해 어떤 감정을 가지고 있는지를 평가\n” 나는 전기차를 구매하는 것이 좋은 선택이라고 생각한다.” (1 = 매우 나쁜 선택, 5 = 매우 좋은 선택)\n”전기차는 환경 보호에 기여한다고 생각한다.” (1 = 전혀 그렇지 않다, 5 = 매우 그렇다)\n”전기차는 경제적으로 합리적인 선택이다.” (1 = 전혀 그렇지 않다, 5 = 매우 그렇다)\n”나는 전기차가 기존 내연기관 차량보다 성능이 더 좋다고 생각한다.” (1 = 전혀 그렇지 않다, 5 = 매우 그렇다)\n주관적 규범(SN) 측정 문항\n목표: 특정 행동(예: 전기차 구매)에 대해 주변 사람들(가족, 친구, 사회)이 어떻게 생각하는지 평가\n”내 가족은 내가 전기차를 구매하는 것을 지지할 것이다.” (1 = 전혀 지지하지 않음, 5 = 매우 지지함)\n”내 친구들은 전기차를 구매하는 것이 좋은 선택이라고 생각한다.” (1 = 전혀 그렇지 않다, 5 = 매우 그렇다)\n”주변 사람들이 나에게 전기차를 추천할 가능성이 높다.” (1 = 전혀 그렇지 않다, 5 = 매우 그렇다)\n”사회적으로 전기차를 구매하는 것이 긍정적으로 여겨진다.” (1 = 전혀 그렇지 않다, 5 = 매우 그렇다)\n가중치 추정: 관심 집단 응답자의 응답결과 데이터를 이용하여 회귀추정하여 얻는다.\n\\(W_{1} &gt; W_{2}\\) → 행동 의도에 대한 태도의 영향력이 더 큼\n\\(W_{1} &lt; W_{2}\\) → 행동 의도에 대한 사회적 규범의 영향력이 더 큼\n\\(W_{1} \\approx W_{2}\\) → 태도와 사회적 규범이 비슷한 영향을 미침\n\n\n(5) 감성 측정 척도\n감성 측정 Emotional Measuremen 척도는 응답자의 감정 상태나 특정 대상(브랜드, 제품, 광고, 서비스 등)에 대한 감성적 반응을 측정하는 방법이다. 감성은 단순한 긍정적/부정적 반응을 넘어 다양한 차원(예: 흥분, 즐거움, 불안, 신뢰, 공포 등)으로 세분화될 수 있다. 따라서, 감성 측정 척도는 응답자가 특정 경험을 통해 느끼는 감정을 정량적으로 평가할 수 있도록 설계된다.\n(1) 감성적 반응 척도 (Emotional Response Scale)\n응답자가 특정 경험—예를 들어 제품을 사용하거나, 광고를 시청하거나, 서비스를 이용한 후—그 경험을 통해 느낀 감정을 평가할 수 있도록 설계된 척도이다. 이 척도는 단순히 ’좋았다/나빴다’는 이분법적 판단을 넘어서, 경험이 유발한 감정의 종류와 강도를 수치화하여 정밀하게 측정할 수 있게 해준다.\n감성적 반응 척도는 특히 브랜드 이미지 조사나 UX/UI(User Experience/User Interface) 연구 등에서 자주 활용된다. 예를 들어 브랜드 이미지 조사의 경우, 소비자가 특정 브랜드를 접했을 때 느끼는 감정—예컨대 ‘신뢰’, ‘즐거움’, ‘불쾌감’—을 수치화함으로써, 브랜드가 어떤 정서적 인상을 남기는지를 파악할 수 있다.\n또한, UX/UI 분야에서는 사용자가 웹사이트나 앱을 사용할 때 느끼는 감정 변화를 측정하여, 인터페이스 설계가 긍정적인 사용자 경험을 유도하고 있는지 평가하는 데 활용된다. 예를 들어, 버튼의 위치나 색상, 페이지 이동 흐름이 사용자에게 혼란을 주었는지, 아니면 직관적이고 만족스러운 경험을 제공했는지 감성 반응을 통해 정량적으로 분석할 수 있다.\n이처럼 감성적 반응 척도는 소비자나 사용자의 ’감정’을 체계적으로 파악하여, 브랜드 전략, 제품 개선, 사용자 경험 디자인 등에 있어 보다 감성적이고 인간 중심적인 의사결정을 가능하게 해주는 중요한 도구이다.\n”이 브랜드를 접했을 때, 다음 감정을 얼마나 강하게 느끼셨습니까?”\n고급스럽다: 1(전혀 아님) ~ 7(매우 많이)\n세련되다: 1(전혀 아님) ~ 7(매우 많이)\n친근하다: 1(전혀 아님) ~ 7(매우 많이)\n(2) PANAS 척도 (Positive and Negative Affect Schedule)\n응답자가 특정 상황에서 느낀 긍정적 정서(Positive Affect)와 부정적 정서(Negative Affect)를 각각 독립적으로 측정할 수 있도록 설계된 심리 측정 도구이다.\n이 척도는 일반적으로 20개의 감정 항목(긍정적 감정 10개, 부정적 감정 10개)으로 구성되며, 각 항목에 대해 응답자는 자신이 느낀 감정의 빈도나 강도를 5점 또는 7점 리커트 척도를 이용해 평가하게 된다. 예를 들어 “기쁨”, “열정”, “긴장”, “불안” 등의 감정 단어에 대해 “전혀 느끼지 않았다”부터 “매우 강하게 느꼈다”까지 점수를 매기는 방식이다.\nPANAS 척도는 다음과 같은 분야에서 유용하게 활용된다.\n\n광고 및 마케팅 연구: 광고를 본 후 소비자가 경험한 긍정적 감정(예: 흥미, 기쁨)과 부정적 감정(예: 짜증, 지루함)을 측정함으로써 광고 메시지의 감정적 반응을 평가할 수 있다.\n고객 경험 분석: 서비스 이용 후 고객이 느낀 다양한 감정 상태를 분석하여, 단순한 만족도 이상으로 감정 기반의 고객 반응을 정량화할 수 있다. 예를 들어, 고객이 서비스 이후 ’짜증’을 느꼈다면 이는 단순한 불만족보다 더 즉각적인 개선이 필요한 지표로 해석될 수 있다.\n\nPANAS는 감정 상태를 분리해서 분석할 수 있기 때문에, 긍정적 감정이 높다고 해서 자동으로 부정적 감정이 낮다고 가정하지 않으며, 각각을 독립적으로 분석할 수 있다는 점에서 정서 분석의 정밀도를 높이는 데 기여한다. 이러한 특성 덕분에 심리학뿐만 아니라 마케팅, UX 디자인, 고객경험관리(CXM) 등 다양한 분야에서 활용되고 있다.\n”광고를 본 후, 다음 감정을 얼마나 강하게 느꼈습니까?”\n기쁨 😊: 1(전혀 아님) ~ 5(매우 많이)\n흥분 😃: 1(전혀 아님) ~ 5(매우 많이)\n짜증 😡: 1(전혀 아님) ~ 5(매우 많이)\n(3) SAM 척도 (Self-Assessment Manikin Scale)\n감정 측정을 위해 시각적인 아이콘(만화형 사람 그림)을 사용하는 방식으로, 언어에 대한 의존도를 최소화한 비언어적 감성 측정 도구이다. 이는 정서 반응을 세 가지 차원에서 평가한다.\n\n쾌-불쾌(valence): 얼마나 기분이 좋은지 또는 나쁜지를 나타냄\n각성(arousal): 얼마나 흥분되었는지 또는 평온한지를 나타냄\n지배감(dominance): 상황을 통제하고 있다고 느끼는 정도\n\n각 차원마다 시각적인 사람 형태의 그림이 점진적으로 변하며 표현되기 때문에, 글을 읽지 않고도 응답자가 자신의 감정을 선택할 수 있도록 설계되어 있다.\n주요 특징 및 활용\n\n언어 장벽 극복: 글을 해석할 필요가 없어 어린이, 비문해자, 다문화권 등 언어적 제약이 있는 대상에게 적합하다.\nUX/UI 디자인 평가: 사용자가 웹사이트나 애플리케이션을 사용할 때 느낀 감정 상태를 직관적으로 측정 가능하다. 예를 들어, 버튼 클릭 후 느낀 만족감이나 화면 구성에 대한 직관적 반응을 SAM 척도를 통해 정량화할 수 있다.\n제품 또는 서비스 만족도 조사: 소비자가 제품 사용 후 느낀 감정을 시각적으로 평가함으로써 감정 기반 만족도를 파악할 수 있다. 텍스트로 표현하기 어려운 감정 반응을 직관적이고 구체적으로 측정할 수 있다는 장점이 있다.\n\nSAM 척도는 특히 정서 반응을 정확하고 간편하게 수집해야 하는 경우에 매우 유용하며, 정량적 분석은 물론 감성디자인, 감정 기반 마케팅, 인터랙션 디자인 평가 등 다양한 분야에서 활용되고 있다.\n”이 제품을 사용한 후 기분은?”\n😃 😐 😢 (행복 → 슬픔)\n⚡ 🔋 💤 (흥분 → 차분)\n(4) Plutchik’s 감정 휠 (Plutchik’s Emotion Wheel)\n심리학자 로버트 플러칙(Robert Plutchik)이 제안한 감정 이론으로, 인간의 감정을 8가지(기쁨, 신뢰, 공포, 놀람, 슬픔, 혐오, 분노, 기대) 기본 감정으로 구분하고 이들 간의 관계를 시각적인 원형 구조로 표현한 모델이다.\n이 감정들은 서로 반대되는 쌍으로 구성되어 있으며, 감정 간의 혼합과 강도 변화를 통해 복합적인 감정 상태를 설명할 수 있다. 예를 들어,\n\n기쁨 + 신뢰 → 사랑\n공포 + 놀람 → 경외감(Awe)\n분노 + 혐오 → 경멸(Contempt) 등\n\n소비자 심리 연구: 광고, 브랜드, 패키징 등 소비자가 어떤 감정을 느끼는지를 감정 휠을 통해 분석할 수 있다. 브랜드가 유발하는 감정이 구매 행동에 어떤 영향을 미치는지 파악하는 데 유용하다.\n정신 건강 연구: 스트레스, 불안, 우울감 등의 감정 변화를 감정 휠 구조 내에서 시각적으로 추적할 수 있어, 심리치료, 상담, 감정일기 분석 등에서 활용된다.\n교육 및 자기이해 도구: 학습자나 환자가 자신의 감정을 더 정교하게 인식하고 표현할 수 있도록 돕는다.\n플러칙의 감정 휠은 복합적이고 동적인 감정 상태를 구조적으로 이해할 수 있게 해 주며, 감정 분석, 정서 인공지능, 감정 기반 마케팅 등의 분야에서 활용되고 있다.\n”이 브랜드를 접했을 때, 어떤 감정을 느꼈습니까?”\n➡️ 선택: 기쁨 😊 / 신뢰 🤝 / 기대감 😍 / 실망 ☹️"
  },
  {
    "objectID": "consult.html",
    "href": "consult.html",
    "title": "통계상담",
    "section": "",
    "text": "📋 통계상담 안내\n데이터 분석, 통계 해석, 설문 설계 등 상담이 필요하신 분은 아래 폼을 제출해 주세요.\n👉 상담 신청하기\n\n온라인/비대면 상담 가능합니다."
  },
  {
    "objectID": "cardnews/news002.html",
    "href": "cardnews/news002.html",
    "title": "출산율 감소",
    "section": "",
    "text": "👶 출산율 감소, 바닥을 뚫다\n\n\n\n출산\n\n\n\n2023년 합계출산율: 0.72명\n전 세계 최저\n지방소멸 → 학교 폐교 → 일자리 축소의 악순환\n\n\n데이터가 보여주는 출산의 현실"
  },
  {
    "objectID": "cardnews/news004.html",
    "href": "cardnews/news004.html",
    "title": "전공별 취업률 격차",
    "section": "",
    "text": "title: “전공별 취업률 격차” format: html page-layout: full —"
  },
  {
    "objectID": "cardnews/news004.html#왜-이런-차이가-날까",
    "href": "cardnews/news004.html#왜-이런-차이가-날까",
    "title": "전공별 취업률 격차",
    "section": "💡 왜 이런 차이가 날까?",
    "text": "💡 왜 이런 차이가 날까?\n\n산업 수요와의 불균형\n졸업 후 진로 다양성, 인프라 차이\n지역 대학일수록 격차 더 큼"
  },
  {
    "objectID": "cardnews/news004.html#졸업생-1인의-목소리",
    "href": "cardnews/news004.html#졸업생-1인의-목소리",
    "title": "전공별 취업률 격차",
    "section": "💬 졸업생 1인의 목소리",
    "text": "💬 졸업생 1인의 목소리\n\n“취업률 통계는 높지만,\n실제로는 계약직, 인턴이 대부분이에요.”\n(사회계열 졸업생 인터뷰 중)"
  },
  {
    "objectID": "cardnews/news004.html#통계의-해석은-숫자-너머",
    "href": "cardnews/news004.html#통계의-해석은-숫자-너머",
    "title": "전공별 취업률 격차",
    "section": "📚 통계의 해석은 숫자 너머",
    "text": "📚 통계의 해석은 숫자 너머\n통계는 단순 수치보다 맥락과 경험을 함께 살필 때 의미를 갖습니다.\n\n전공 선택이 삶 전체에 어떤 영향을 주는가,\n그 통계로 함께 이야기해야 합니다."
  }
]