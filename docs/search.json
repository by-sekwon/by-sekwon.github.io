[
  {
    "objectID": "cardnews/index.html",
    "href": "cardnews/index.html",
    "title": "📰 카드뉴스 모음",
    "section": "",
    "text": "통계를 주제로 한 다양한 카드뉴스를 주제별로 모았습니다.\n클릭하면 자세한 내용을 보실 수 있어요 😊\n\n\n\n\n\n #### 고령화 속도 65세 이상 비율이 역대 최고!\n자세히 보기 ▶\n\n\n #### 출산율 감소 합계출산율 0.72명의 의미는?\n자세히 보기 ▶\n\n\n\n\n\n\n\n\n #### 청년 고용률 청년 고용의 구조적 문제\n자세히 보기 ▶\n\n\n #### 전공별 격차 전공 따라 취업률이 이렇게나!\n자세히 보기 ▶"
  },
  {
    "objectID": "cardnews/index.html#인구와-사회",
    "href": "cardnews/index.html#인구와-사회",
    "title": "📰 카드뉴스 모음",
    "section": "",
    "text": "#### 고령화 속도 65세 이상 비율이 역대 최고!\n자세히 보기 ▶\n\n\n #### 출산율 감소 합계출산율 0.72명의 의미는?\n자세히 보기 ▶"
  },
  {
    "objectID": "cardnews/index.html#청년과-고용",
    "href": "cardnews/index.html#청년과-고용",
    "title": "📰 카드뉴스 모음",
    "section": "",
    "text": "#### 청년 고용률 청년 고용의 구조적 문제\n자세히 보기 ▶\n\n\n #### 전공별 격차 전공 따라 취업률이 이렇게나!\n자세히 보기 ▶"
  },
  {
    "objectID": "cardnews/news001.html",
    "href": "cardnews/news001.html",
    "title": "고령화 속도",
    "section": "",
    "text": "👵 고령화 속도, 세계 최고\n\n\n\n고령화\n\n\n\n2024년 한국 65세 이상 인구: 18.4%\n고령사회(14%) 기준 이미 초과\n초고령사회(20%) 진입도 눈앞\n\n\n📌 정책은 얼마나 따라가고 있을까?"
  },
  {
    "objectID": "cardnews/news003.html",
    "href": "cardnews/news003.html",
    "title": "청년 고용률",
    "section": "",
    "text": "청년 고용률\n\n\n2023년 기준, 15~29세 청년 고용률은 45.4%\n코로나 이후 회복 중이지만 여전히 회복세는 느림.\n\n\n\n\n청년층 일자리 중 단기 계약직, 인턴 비중이 높음\n\n정규직 진입률은 10년 전보다 낮아진 상태\n\n\n🔍 “취업했다”는 통계 뒤에 숨은 고용의 질 문제를 들여다봐야 합니다.\n\n\n\n\n\n\n일자리 찾기 → 계약직 → 재취업 준비 → 불안정 반복\n이직까지 평균 1.5년 소요\n\n\n\n\n\n\n\nNote\n\n\n\n📌 통계청 자료 기준: 2023 경제활동인구조사 청년 부문\n\n\n\n\n\n\n\n청년 고용률 수치만 보는 게 아니라\n고용의 질, 지속성, 업종 다양성을 함께 살펴야 합니다."
  },
  {
    "objectID": "cardnews/news003.html#정규직-비중은-여전히-낮아",
    "href": "cardnews/news003.html#정규직-비중은-여전히-낮아",
    "title": "청년 고용률",
    "section": "",
    "text": "청년층 일자리 중 단기 계약직, 인턴 비중이 높음\n\n정규직 진입률은 10년 전보다 낮아진 상태\n\n\n🔍 “취업했다”는 통계 뒤에 숨은 고용의 질 문제를 들여다봐야 합니다."
  },
  {
    "objectID": "cardnews/news003.html#반복되는-패턴",
    "href": "cardnews/news003.html#반복되는-패턴",
    "title": "청년 고용률",
    "section": "",
    "text": "일자리 찾기 → 계약직 → 재취업 준비 → 불안정 반복\n이직까지 평균 1.5년 소요\n\n\n\n\n\n\n\nNote\n\n\n\n📌 통계청 자료 기준: 2023 경제활동인구조사 청년 부문"
  },
  {
    "objectID": "cardnews/news003.html#정책이-나아가야-할-방향은",
    "href": "cardnews/news003.html#정책이-나아가야-할-방향은",
    "title": "청년 고용률",
    "section": "",
    "text": "청년 고용률 수치만 보는 게 아니라\n고용의 질, 지속성, 업종 다양성을 함께 살펴야 합니다."
  },
  {
    "objectID": "notes/survey/nonresponse.html",
    "href": "notes/survey/nonresponse.html",
    "title": "조사방법론. 3. 무응답과 대체",
    "section": "",
    "text": "chapter 1. 무응답 개요\n설문조사에서 무응답(nonresponse)은 표본으로 선정된 일부 응답자가 질문에 답하지 않는 현상을 의미한다. 이러한 무응답이 발생하면, 추정값이 편향될 수 있으며 표본이 모집단을 제대로 대표하지 못하게 되어 분석 결과의 신뢰성이 떨어질 가능성이 높다.\n무응답자가 응답자와 다른 특성을 가진다면, 응답자만을 대상으로 계산한 추정값은 모집단 전체의 실제 값과 차이를 보일 수 있다. 특히 무응답이 일정한 방향이나 경향성을 가지는 경우, 이는 단순한 오류를 넘어서 설계 전체에 체계적인 편향을 초래할 수 있으며, 이를 무응답 편향(nonresponse bias)이라고 한다.\n무응답이 특정 집단에 집중될 경우, 표본이 모집단의 다양한 특성을 충분히 반영하지 못하게 된다. 예를 들어, 소득이 높은 사람이나 바쁜 직장인처럼 일정한 특성을 가진 집단의 응답률이 낮다면, 이들의 의견은 과소 대표되거나 완전히 누락될 수 있다. 그 결과 표본의 대표성이 손상된다.\n또한 무응답이 무작위로 발생한다면 통계적으로 큰 문제가 되지 않을 수 있지만, 현실에서는 특정 문항이나 주제에 따라 일관된 응답 회피가 발생하는 경우가 많다. 예를 들어 정치적 성향에 대한 질문에서 특정 지지층이 응답을 회피한다면, 결과는 특정 방향으로 왜곡될 수 있다.\n무응답으로 인해 유효한 응답 수가 줄어들면, 전체 표본의 크기가 감소하게 되어 통계 추정의 분산이 커지고 표본 오차가 증가한다. 이는 결과의 정확성을 떨어뜨리고, 신뢰구간을 넓혀 결과 해석에 불확실성을 더하게 된다.\n결과적으로 무응답이 많을수록 조사 결과를 일반화하기 어려워지고, 정책 결정이나 연구 활용 시 신뢰할 수 없는 정보를 제공하게 될 가능성이 커진다. 따라서 설문조사에서 무응답을 최소화하고, 발생한 무응답을 적절히 보정하는 절차가 중요하다.\n\n단위 무응답 unit nonresponse\n무응답이 발생하는 방식 중 하나는 단위 무응답(unit nonresponse)으로, 이는 표본으로 선정된 사람이 조사에 전혀 응답하지 않는 경우를 의미한다. 이 경우, 조사 대상자는 모든 질문에 답하지 않기 때문에 해당 응답자는 전체적으로 누락된다. 예를 들어 어떤 조사 대상자가 전화를 받자마자 “나는 설문조사에 절대 참여하지 않는다. 다시 전화하지 말라”고 말하며 응답을 거부하는 경우, 이는 전형적인 단위 무응답에 해당한다.\n\n\n항목 무응답 item nonresponse\n무응답이 전체 문항이 아닌 일부 질문에서만 발생하는 경우를 항목 무응답(item nonresponse)이라고 한다. 이는 응답자가 특정 질문에 대해서만 답변을 하지 않거나 회피하는 상황을 말한다.\n예를 들어 조사자가 “작년 총 가구 소득이 얼마였습니까?”라고 묻자, 응답자가 “모르겠다. 아내가 그런 기록을 관리한다”고 답하며 해당 항목에 대한 응답을 유보하는 경우, 이는 항목 무응답에 해당한다.\n\n\n\nchapter 2. 단위 무응답 유형\n무응답은 여러 가지 이유로 발생할 수 있으며, 크게 세 가지 유형으로 구분할 수 있다.\n첫째, 조사 요청 전달 실패는 조사자가 표본으로 선정된 대상자에게 조사 요청을 전달하지 못하는 경우를 의미한다. 이는 조사 대상자를 물리적으로 찾지 못하거나, 우편으로 보낸 설문지가 반송되는 상황 등이 포함된다. 이러한 경우에는 조사 자체가 이루어지지 않으므로 단위 무응답으로 처리된다.\n둘째, 응답 거부는 조사 대상자가 조사 요청을 인지했음에도 불구하고 설문 참여를 명확히 거절하는 경우에 해당한다. 전화나 방문을 통해 접촉이 이루어졌지만, 개인적인 이유, 조사에 대한 불신, 시간 부족 등의 이유로 응답을 거부하는 경우가 여기에 포함된다.\n셋째, 응답 불가능은 조사 대상자가 설문 문항을 이해하지 못하거나, 인지적 또는 신체적인 이유로 응답할 수 없는 경우를 의미한다. 예를 들어 고령자나 언어적 장벽이 있는 사람이 질문의 의미를 제대로 파악하지 못해 답변을 제공하지 못하는 상황이 해당된다.\n\n1. 조사 요청 전달 실패로 인한 단위 무응답\n비접촉 또는 조사 요청 전달 실패로 인한 무응답은 조사 대상자가 특정한 데이터 수집 방식으로는 접근이 어려운 경우에 발생한다. 이와 같은 상황에서 중요한 개념은 접근 가능성이며, 이는 조사자가 표본으로 선정된 대상자에게 실제로 연락하거나 조사를 수행할 수 있는지를 의미한다. 조사 대상자의 연락처 정보가 부정확하거나, 반복적인 접촉 시도에도 불구하고 연결되지 않는 경우, 설문 참여 여부와 무관하게 조사가 이루어지지 않게 된다.\n\n가구 설문조사에서 접근 가능성 문제\n조사자가 응답자가 집에 머무는 시간을 알고 있다면, 단 한 번의 시도로도 성공적으로 접촉할 수 있다. 그러나 실제 조사에서는 표본 대상자의 접근 가능한 시간이 사전에 알려져 있는 경우가 드물다. 이로 인해 조사자는 동일한 대상자에게 여러 차례 연락을 시도해야 하며, 이는 조사 비용과 시간이 증가하는 원인이 되기도 한다.\n\n\n접근이 어려운 사례\n조사 요청 전달이 실패하는 주요 원인 중 하나는 물리적인 접근의 제한이다. 이는 외부인의 접촉을 차단하는 환경에서 자주 발생하며, 예를 들어 출입이 통제된 아파트 건물이나 자동 응답 전화 시스템이 설치된 경우 조사자가 대상자에게 직접 접근하기 어렵다.\n우편을 통한 설문조사에서는 설문지가 대상자에게 도달하더라도, 발신자를 알 수 없는 우편물을 열어보지 않고 폐기하는 사람들은 응답에서 자연스럽게 누락될 가능성이 높다.\n전화 조사에서도 비슷한 문제가 발생한다. 예를 들어 집에 머무는 시간이 거의 없는 사람들은 조사자가 여러 차례 전화를 시도하더라도 연결되지 않을 가능성이 크다. 또한 발신자 번호를 차단하거나 필터링하는 서비스를 이용하는 경우, 조사원의 연락 시도 자체가 인지되지 않아 응답으로 이어지지 않을 수 있다.\n\n\n첫번 째 시도에서 조사 성공률이 가장 높다.\n성공적인 연락률은 통화 시도 횟수가 늘어날수록 점차 감소하는 경향이 있으며, 이러한 감소는 종종 지수적인 형태를 따른다. 특히 가구를 대상으로 한 설문조사에서는 첫 번째 접촉을 성사시키기 위해 몇 차례의 전화 시도가 필요한지를 결정하는 데 다음과 같은 두 가지 요인이 주요하게 작용한다.\n첫째, 통화가 이루어지는 시간대는 응답률에 영향을 미친다. 일반적으로 저녁 시간이나 주말에 걸려온 전화는 평일 낮 시간에 비해 응답률이 더 높은 것으로 나타난다. 이는 많은 사람들이 해당 시간대에 집에 머물 가능성이 높기 때문이다.\n둘째, 모집단의 특성에 따라 접근 가능성이 다르게 나타날 수 있다. 예를 들어 직업, 생활 패턴, 주거 형태 등에 따라 어떤 모집단은 조사자와의 연락이 상대적으로 더 용이한 반면, 또 다른 모집단은 접근이 더 어려울 수 있다. 이러한 차이는 조사 설계와 연락 전략에 반영될 필요가 있다.\n\n\n우편, 이메일, 웹 설문조사\n인터뷰어가 직접 접촉하지 않는 방식의 조사는, 조사 요청이 표본 대상자에게 지속적으로 노출될 수 있도록 설계되어야 한다. 예를 들어 우편 설문조사의 경우, 설문지가 일단 가구에 도착하면 응답 여부와 관계없이 일정 기간 동안 가구 내에 그대로 남아 있게 된다. 이로 인해 가구 구성원은 자신이 원하는 요일이나 시간대에 설문에 응답할 수 있다.\n이러한 방식에서는 전화나 방문 조사와 달리, 조사자가 능동적으로 접촉을 시도하지 않더라도 응답이 이루어질 가능성이 생긴다. 따라서 직접적인 접촉을 필요로 하는 조사 방식과는 달리, 표본 단위가 첫 접촉에 이르기까지 필요한 시도 횟수나 시간의 분포가 서로 다른 양상을 보인다.\n\n\n\n2. 응답거부로 인한 단위 무응답\n설문조사의 성공 여부는 응답자가 낯선 조사자의 요청에 자발적으로 응할 의사가 있는지에 크게 좌우된다. 응답자가 설문에 참여하기 위해서는 몇 가지 심리적 조건이 충족되어야 한다.\n우선, 조사자로부터 신체적 또는 경제적 피해를 입을 것이라는 두려움이 없어야 한다. 응답자는 자신에게 어떠한 해도 가해지지 않을 것이라는 확신을 가져야 한다.\n또한, 응답 과정에서 자신의 평판이 손상될 가능성을 걱정하지 않아야 하며, 조사 참여가 사회적 이미지에 부정적인 영향을 미치지 않을 것이라고 느껴야 한다.\n설문 참여로 인해 심리적 스트레스를 겪을 수 있다는 불안도 응답을 가로막는 요인이 될 수 있다. 따라서 조사는 응답자에게 부담을 주지 않는 방식으로 진행되어야 한다.\n기밀 보장에 대한 신뢰 역시 중요한 요소이다. 응답자는 조사자가 제공한 정보 보호 약속을 믿을 수 있어야 하며, 자신의 응답 내용이 외부로 유출되지 않을 것이라는 확신을 가져야 한다.\n마지막으로, 응답자는 자신의 의견을 자유롭게 표현할 수 있으며, 솔직한 정보를 제공하더라도 불이익을 받거나 위험에 처하지 않을 것이라고 믿을 때 비로소 진정한 응답이 이루어진다. 이러한 심리적 안정이 확보되어야만 응답자는 설문조사에 적극적으로 참여하게 된다.\n\n\n(1) 설문조사와 타 조사의 차이\n설문조사 요청은 사람들이 일상생활에서 경험하는 다양한 외부 요청들과 비교해볼 수 있으며, 이러한 비교는 설문 응답 행태를 이해하는 데 중요한 시사점을 제공한다. 대중이 낯선 사람으로부터 받는 요청은 일반적으로 판매 전화, 업무 또는 서비스 관련 연락, 기부 요청, 정치 활동, 그리고 설문조사 등으로 나눌 수 있다. 이들은 여러 측면에서 서로 다른 특성을 보인다.\n첫째, 사람들의 경험 빈도는 접촉 방식에 따라 달라진다. 과거에는 방문 판매가 흔했으나, 최근에는 텔레마케팅이 그 자리를 대신하고 있다. 이로 인해 낯선 사람으로부터 걸려오는 전화나 우편, 이메일 메시지는 설문조사보다는 상품이나 서비스 판매를 목적으로 하는 경우가 훨씬 더 많다. 이러한 경험의 불균형은 응답자가 설문조사 요청을 다른 상업적 요청과 혼동할 가능성을 높인다.\n둘째, 대중의 인식 수준에서도 차이가 나타난다. 기업이나 널리 알려진 자선단체, 정치 단체의 경우 많은 사람들이 해당 조직의 이름에 익숙할 수 있다. 반면, 설문조사를 실시하는 주체가 대학이나 정부 기관인 경우에도 일부 응답자는 사전에 해당 기관을 인식하고 있을 수 있지만, 그렇지 않은 경우에는 요청자가 낯설게 느껴질 수 있다.\n셋째, 인센티브의 제공 여부도 다르다. 설문조사는 응답에 대한 감사의 표시로 소정의 금전적 보상이나 선물을 제공하는 경우가 있으나, 판매나 서비스 요청에서는 일반적으로 이러한 유인책이 제공되지 않는다. 이는 설문 응답 동기를 유도하는 중요한 차별점이 될 수 있다.\n넷째, 연락의 지속성 측면에서 판매 및 모금 요청은 대체로 반복적인 시도를 하지 않는 경향이 있다. 망설이는 대상자를 설득하기보다는 새로운 대상을 찾는 것이 더 효율적이기 때문이다. 이에 반해, 설문조사 특히 확률 표본조사는 표본의 대표성을 확보해야 하므로 동일 가구에 대해 여러 차례 연락을 시도하는 경우가 많다.\n다섯째, 요청의 성격에서도 차이가 있다. 판매는 일반적으로 상품이나 서비스에 대한 금전적 지불을 요구하지만, 설문조사는 응답자의 시간과 정보를 제공받는 것이 목적이다. 설문은 응답자의 자발적인 참여가 아닌 조사자의 접근으로 시작되기 때문에, 응답자는 설문 참여보다는 자신의 원래 활동으로 돌아가는 것을 더 중요하게 여길 수 있다.\n이러한 반복적인 경험은 사람들로 하여금 설문 요청에 대해 일정한 반응을 형성하게 만든다. 즉, 응답자의 반응은 과거의 유사한 경험에서 비롯된 습관적인 대응일 수 있다. 설문 요청이 상업적 전화와 혼동되어 거절되는 경우도 자주 발생하는데, 이를 해결하기 위해서는 반복적인 연락을 통해 조사 목적을 명확히 설명하는 것이 중요하다. 또한 신뢰할 수 있는 기관이 주관하는 조사라면, 조사원이 해당 기관의 이름을 강조함으로써 상업적 목적이 아님을 분명히 할 수 있다.\n\n\n(2) 응답거절 단위 무응답 발생 요인\n설문조사에서 응답률을 높이고 무응답 편향을 줄이기 위해서는 응답 거절로 인한 단위 무응답 발생 요인을 이해하는 것이 중요하다. 이러한 요인은 조사자가 통제할 수 없는 요인과 조정 가능한 요인으로 나눌 수 있다.\n먼저, 조사자가 조정하기 어려운 요인으로는 사회적 환경과 개인 수준의 특성이 있다. 예를 들어, 대도시 지역에서는 가구 단위 설문에서 응답 거절 비율이 상대적으로 높게 나타난다. 이는 도시 생활의 익명성, 바쁜 생활 패턴, 낯선 사람에 대한 경계심 등이 영향을 줄 수 있다. 또한, 가구 구성원이 여러 명인 가정은 1인 가구보다 응답에 협조할 가능성이 높으며, 이는 집단 내의 의견 조율이나 설문 참여에 대한 심리적 부담이 분산되기 때문이다. 개인 수준에서는 남성이 여성보다 설문에 응하지 않을 가능성이 더 높은 경향이 관찰된다.\n한편, 조사자가 조정할 수 있는 요인도 있다. 대표적인 예로는 조사원 개인의 능력과 설문 설계 방식이 있다. 경험이 풍부한 조사원은 응답자의 반응에 능숙하게 대응하고 신뢰를 구축하는 데 유리하므로, 경험이 적은 조사원보다 더 높은 응답 협조율을 이끌어낼 수 있다. 또한, 응답자에게 소정의 인센티브를 제공하는 것은 응답률을 높이는 데 효과적이며, 이는 설문 참여에 대한 긍정적인 동기를 부여하는 역할을 한다.\n이와 같은 요인들을 종합적으로 고려하여 설문조사를 설계하고 실행한다면, 단위 무응답을 줄이고 보다 신뢰성 있는 결과를 얻을 수 있다.\n\n\n(3) 응답거절 관련 이론적 가설\n응답 거절을 설명하는 데 활용되는 이론적 가설은 설문조사의 응답률과 무응답 편향을 이해하는 데 중요한 통찰을 제공한다. 다음의 네 가지 가설은 응답자의 행동을 설명하는 대표적인 이론적 틀로 제시된다.\n첫째는 기회비용 가설이다. 이 가설에 따르면 바쁜 사람일수록 인터뷰나 설문조사 참여를 거부할 가능성이 높다. 이들은 일상에서 다른 활동에 할애할 시간이 부족하므로, 설문 참여를 시간 낭비로 인식하거나 부담스럽게 느낀다.\n둘째는 사회적 고립 개념이다. 이는 사회경제적 계층의 양극단에 위치한 사람들이 설문 요청에 응하지 않을 가능성이 높다는 주장이다. 지나치게 부유하거나 매우 빈곤한 계층의 경우, 사회적 제도나 기관과의 관계가 약해 설문 요청 자체를 거부하거나 무관심하게 대할 수 있다.\n셋째는 주제 관심 가설이다. 이 가설은 특정 주제에 대해 관심이 있는 사람들만이 설문에 적극적으로 응하면서, 표본이 해당 주제에 편향된 집단으로 구성될 가능성이 있다는 점을 지적한다. 이러한 경우 통계적 결과에 무응답 오류가 발생할 수 있으며, 이는 전체 모집단을 반영하지 못하는 왜곡된 결과로 이어질 수 있다.\n넷째는 과도한 설문조사 개념이다. 반복적이고 빈번한 설문 요청은 응답자의 피로도를 높이고, 결과적으로 설문 참여를 꺼리게 만드는 요인이 될 수 있다. 이는 특히 동일한 대상자에게 유사한 설문이 반복적으로 도달하는 상황에서 더욱 두드러진다.\n이러한 가설들은 설문조사 과정에서 나타나는 응답 거절 현상을 보다 정교하게 이해하고, 이를 줄이기 위한 설계 전략을 수립하는 데 유용하게 활용될 수 있다.\n\n\n(4) 레버리지-현저성 이론 leverage-salience theory\n레버리지-현저성 이론(leverage-salience theory)은 사람들이 설문 요청의 여러 속성을 서로 다르게 중요하게 여긴다는 점에 주목한다. 설문 주제, 인터뷰에 소요되는 시간, 후원 기관, 수집된 데이터의 활용 목적 등이 이에 해당하며, 응답자는 각 속성을 긍정적으로 평가할 수도 있고 부정적으로 받아들일 수도 있다.\n조사자는 사전에 어떤 속성이 응답자에게 중요한지를 알기 어렵지만, 설문이 진행되는 과정에서 특정 속성이 강조되면 응답자의 응답 여부에 영향을 미칠 수 있다. 즉, 강조된 요소가 응답자의 가치관이나 관심과 부합하면 설문에 응할 가능성이 높아지며, 반대로 불편함이나 거부감을 유발하는 경우에는 응답을 거절할 가능성이 높아진다.\n예를 들어, 첫 번째 응답자는 설문 주제에 높은 관심을 가지지만 시간이 많이 걸리는 점을 부담스럽게 느낄 수 있고, 두 번째 응답자는 주제에는 관심이 없지만 제공되는 인센티브에 긍정적인 반응을 보일 수 있다. 이때 조사자가 설문의 후원 기관이나 보상에 대해 강조한다면, 각 응답자에게 해당 요소가 설문 참여 여부를 결정짓는 기준으로 작용할 수 있다. 이러한 상황에서는 주제에 긍정적인 첫 번째 응답자가 설문에 응할 가능성이 더 높아질 수 있다.\n이 이론이 주는 주요 시사점은 설문조사에서 응답자의 다양성을 고려한 맞춤형 접근이 필요하다는 것이다. 응답자가 설문 요청을 수락하거나 거절하는 이유는 사람마다 다르고, 조사자는 이러한 이유를 조사 초기에는 파악하기 어렵다. 따라서 단일한 접근 방식만으로는 다양한 응답자의 요구와 우려를 효과적으로 해결하기 어렵다. 대신, 응답자가 긍정적으로 인식할 수 있는 속성을 파악하고 이를 적절히 강조하는 전략을 통해 응답률을 높이는 것이 효과적이다.\n\n\n3. 요청된 데이터를 제공할 수 없는 경우의 단위 무응답\n단위 무응답은 응답자가 설문에 응할 의사가 있음에도 불구하고, 요청된 데이터를 제공할 수 없는 경우에도 발생할 수 있다. 이러한 상황은 표본 대상자와의 접촉이 성공적으로 이루어졌더라도, 다양한 제약으로 인해 응답이 불가능한 경우를 포함한다.\n예를 들어, 일부 응답자는 설문이 제공되는 언어를 전혀 이해하지 못하거나, 질문의 내용을 이해하거나 기억에서 필요한 정보를 불러오는 것이 어려울 수 있다. 정신적인 부담이나 인지적 제약이 있는 경우도 여기에 해당된다. 또한, 건강 문제로 인해 응답이 어려운 경우도 있으며, 문해력에 제한이 있어 설문지를 읽거나 해석하는 데 어려움을 겪는 경우도 무응답으로 이어질 수 있다. 기업을 대상으로 한 조사에서는 조사 형식이 적절하지 않거나 조사에 할애할 시간이 부족하여 필요한 정보를 제공하지 못하는 경우가 발생하기도 한다.\n이와 같이 응답 불가능의 원인이 다양하기 때문에, 단위 무응답이 통계 분석에 미치는 영향도 상황에 따라 달라진다. 예를 들어, 인구의 건강 상태를 조사하는 설문에서는 건강상의 이유로 응답이 이루어지지 않는 경우가 무응답 편향을 유발할 수 있다. 건강이 좋지 않은 사람들이 조사에서 빠지게 되면, 전체 인구의 건강 수준이 실제보다 더 양호하게 추정될 가능성이 있다. 반면, 동일한 조사에서 정치적 태도나 사회적 인식을 측정하는 경우에는 같은 무응답이 결과에 미치는 영향이 상대적으로 작을 수 있다.\n따라서 이러한 유형의 무응답은 단순한 데이터 누락 이상의 의미를 가지며, 조사 주제와 분석 목적에 따라 그 영향을 면밀히 평가하고 보정할 필요가 있다.\n\n\n\nchapter 3. 응답률 계산\n\n1. 무응답이 통계 품질에 미치는 영향\n무응답으로 인해 발생하는 편향은 무응답의 원인이 조사 대상이 되는 통계적 특성과 연관될 때 더욱 심각해진다. 예를 들어, 혼자 사는 가구의 비율을 조사하는 경우를 생각해보면, 1인 가구는 집에 머무는 시간이 상대적으로 짧아 조사자가 연락을 시도했을 때 접촉이 어려울 수 있다. 이 경우 단 한 번의 연락 시도만으로는 해당 가구가 표본에서 누락될 가능성이 높으며, 결과적으로 혼자 사는 사람의 비율이 실제보다 낮게 추정될 수 있다. 반면, 반복적인 연락 시도를 통해 이러한 가구를 조사에 포함시키면 오히려 과도하게 반영되어 실제보다 높은 추정값이 나올 수도 있다. 이는 무응답이 가구의 거주 시간과 밀접하게 관련되어 있기 때문이다.\n이와 달리, 정치적 관심도와 같은 주제를 조사하는 경우에는 무응답이 통계에 미치는 영향이 상대적으로 작을 수 있다. 따라서 무응답이 초래하는 통계적 편향은 조사 주제와 무응답의 원인 간의 관련성에 따라 달라질 수 있다.\n거절 무응답 오류는 응답자가 설문에 응하지 않는 이유가 해당 통계와 관련이 있을 때 발생한다. 예를 들어, 어떤 설문조사에서 특정 인센티브가 특정 집단의 응답률을 높이는 데는 효과적일 수 있으나, 동시에 응답자의 구성이나 특성에 영향을 주어 조사 결과 자체에 변화를 일으킬 가능성도 있다.\n무응답 편향이 발생하는지를 판단하기 위해서는 응답 여부에 영향을 미치는 인과 메커니즘을 고려해야 한다. 어떤 경우에는 무응답의 원인이 조사 대상과 직접적인 관련이 없어 통계적으로 큰 문제가 되지 않기도 한다. 예를 들어, 가구의 전기 사용량을 조사할 때 집에 머무는 시간이 응답 성향에는 영향을 줄 수 있지만, 이 성향이 전기 사용량과 직접적인 관련을 가지지 않는다면 무응답은 비교적 무해한 것으로 간주할 수 있다.\n반면, 무시할 수 없는 인과 메커니즘이 작용하는 경우도 있다. HIV 유병률 조사에서는 응답자의 감염 여부 자체가 설문 참여 여부에 영향을 줄 수 있다. 이러한 경우 무응답은 단순한 비응답이 아닌 통계의 과소추정을 초래하는 심각한 편향 요인이 될 수 있다. 실제로 미국에서 HIV 유행 초기 공중보건 당국은 혈액 채취를 포함한 전국적 유병률 조사를 실시하고 금전적 보상까지 제공했으나, HIV 감염자들의 응답률은 여전히 낮았다. 기록 대조 연구에 따르면 이는 사회적 낙인으로 인해 감염자들이 설문 참여를 기피했기 때문이며, 그 결과 조사된 HIV 감염률이 실제보다 낮게 추정되는 과소추정이 발생한 것으로 나타났다.\n무응답의 영향은 조사 주제와 맥락에 따라 다르게 나타난다. 어떤 조사에서는 무응답률이 높든 낮든 결과에 큰 차이를 주지 않는 경우도 있으며, 이로 인해 일부 연구자들은 무응답률을 중요하지 않다고 간주하기도 한다. 이는 무응답률이 반드시 조사 결과의 질을 저해한다는 가정이 항상 성립하지는 않는다는 점을 보여준다.\n그러나 무응답의 원인이 조사 대상 속성과 밀접하게 연관된 경우에는 통계적 추정에 심각한 왜곡을 초래할 수 있다. 문제는 대부분의 경우 연구자가 무응답이 어떤 특성과 연관되어 발생하는지를 명확히 파악하기 어렵다는 데 있다. 이러한 불확실성 속에서 무응답의 영향을 정확히 측정하거나, 최적의 응답률을 판단하는 것은 현실적으로 쉽지 않다. 따라서 대부분의 연구에서는 조사 예산이 허용하는 범위 내에서 가능한 한 높은 응답률을 확보하려는 전략이 일반적으로 사용된다.\n\n\n2. 응답률 계산\n\n\n(1) 무응답 편향 계산 공식\n무응답 편향nonresponse bias 계산식: \\({\\overline{y}}_{r} - {\\overline{y}}_{s} = \\frac{m_{s}}{n_{s}}({\\overline{y}}_{r} - {\\overline{y}}_{m})\\)\n\n\\({\\overline{y}}_{s}\\): 특정 표본에서 선택된 전체 응답의 평균\n\\({\\overline{y}}_{r}\\): 해당 표본 내 응답자의 평균\n\\({\\overline{y}}_{m}\\): 해당 표본 내 무응답자의 평균\n\\(n_{s}\\): 해당 표본의 총 표본 수\n\\(r_{s}\\): 해당 표본 내 응답자의 수\n\\(m_{s}\\): 해당 표본 내 무응답자의 수\n\n무응답자의 평균, \\({\\overline{y}}_{m}\\)을 알 수 없으나 확률적인 특성을 가질 수 있으므로 이를 반영한 보다 일반적인 편향 공식은 다음과 같다.\n\\[bias({\\overline{y}}_{r}) = \\text{Cov}(r_{i},Y_{i}) + E\\left\\lbrack \\left( \\frac{m_{s}}{n_{s}} \\right)({\\overline{y}}_{r} - \\overline{Y}) \\right\\rbrack\\]\n응답 확률(\\(r_{i}\\))과 관심 변수(\\(Y_{i}\\)) 간의 공분산: 이는 응답자가 될 확률과 조사 대상 변수 간의 상관관계를 의미하며, 응답자가 될 가능성이 높은 사람이 특정한 특성을 가질 경우 편향이 발생할 수 있다.\n기대 무응답률과 전체 평균의 차이: 두 번째 항은 기대 무응답률 \\(\\frac{m_{s}}{n_{s}}\\)과 응답자 평균(\\({\\overline{y}}_{r})\\) 과 모집단 평균(\\(\\overline{Y}\\))의 차이의 곱이다. 이는 무응답자의 특성이 전체 모집단과 다를 경우 발생하는 편향을 나타낸다.\n무응답자의 특성이 더욱 뚜렷해지고 무응답률이 낮아지더라도, 무응답 오류가 반드시 감소하는 것은 아니다. 이는 무응답자의 특성이 전체 모집단과 크게 다를 경우, 단순히 응답률을 높이는 것만으로는 통계적 편향을 효과적으로 줄이기 어렵다는 점을 시사한다. 다시 말해, 응답률이 개선되었다고 하더라도 응답하지 않은 집단의 특성이 여전히 표본에서 제대로 반영되지 않는다면, 결과적으로 무응답 편향은 여전히 존재하거나 오히려 심화될 수도 있다. 따라서 단순한 응답률 향상보다는, 무응답자의 특성과 응답자의 차이를 파악하고 적절한 보정 방법을 병행하는 노력이 필요하다.\n\n\n(2) 응답율 계산 주요 이슈\n무응답률을 단순히 \\(\\frac{m_s}{n_s}\\) 의 비율로 계산하는 방식은 그 계산에 내포된 복잡성을 감추는 결과를 낳을 수 있다. 무응답률은 무응답 오류를 구성하는 주요 요소 중 하나이며, 때로는 조사 결과의 신뢰도를 높여 보이기 위해 의도적으로 무응답률을 낮게 산정하려는 경향도 나타난다. 하지만 무응답률의 정확한 계산에는 여러 가지 실질적인 문제가 존재한다.\n첫째, 표본 프레임에는 조사 대상이 아닌 단위가 포함될 수 있기 때문에, 조사 대상자의 적격성을 사전에 선별하는 과정이 필요하다. 예를 들어, 가구를 대상으로 하는 전화 조사에서 표본 프레임에 업무용 전화번호가 포함되어 있는 경우, 해당 번호의 수신자가 조사 대상에 해당하는지를 확인하기 어렵다. 이로 인해 응답률 계산 시 분모에 어떤 대상을 포함할 것인지에 대한 기준이 불확실해질 수 있다.\n둘째, 일부 표본은 클러스터 단위로 구성되어 있어, 표본 추출 단계에서 개별 조사 대상자의 수를 알기 어려운 경우가 있다. 예를 들어, 학교를 표본 단위로 설정한 후 그 안에서 학생을 조사하는 경우, 전체 클러스터가 무응답으로 분류될 때 실제 몇 명이 응답하지 않은 것인지 명확히 알기 어렵다. 이는 무응답률 산정 시 분자의 해석에 불확실성을 더한다.\n셋째, 표본 프레임에 포함된 요소들이 동일한 선택 확률을 갖지 않는 경우, 응답률 계산에 가중치를 반영해야 하는지 여부에 대한 고민이 필요하다. 예를 들어, 특정 소수 민족 집단을 초과 표집한 경우, 응답률 산정 시 이들의 과대표집 비율을 그대로 반영할 것인지 아니면 가중치를 조정할 것인지에 대한 기준이 모호할 수 있다.\n이러한 이유로 인해 응답률은 단순한 비율 수치 이상의 의미를 가지며, 무응답률의 해석과 활용에 있어 보다 세심한 접근이 요구된다.\n\n\n(3) 응답률 계산\n첫 번째와 두 번째 이슈를 해결하는 방법 중 하나는 분모의 값을 추정하는 것이다. 이때 외부 정보 또는 다른 사례에서 얻은 정보를 활용할 수 있으므로 응답률은 다음과 같이 계산될 수 있다.\n\\(\\frac{I}{I + R + NC + O + e(UH + UO)}\\), 여기서 \\(I\\)은 조사 완료자 수, \\(R\\)은 거절 및 중단, \\(NC\\)은 미접촉, \\(O\\)은 기타 적격 사례, \\(UH\\)은 조사대상자 여부가 불분명한 사례, \\(UO\\)은 기타 적격 여부가 불분명한 사례, \\(e\\)은 적격 여부가 불분명한 사례 중 적격으로 추정되는 비율이다. 변수 \\(e\\)의 추정치는 현재 진행 중인 설문조사에서 얻을 수 있다.\n\\[e = \\frac{I + R + NC + O}{I + R + NC + O + \\text{샘플에 포함된 부적격 사례}}\\]\n만약 \\(e\\)에 대한 신뢰할 수 있는 추정치를 얻을 수 없다면 \\((UH + UO)\\)을 계수 없이 분모를 사용하거나 분모에서 이를 제외하는 방식이다.\n응답률을 추정할 때 선택 확률이 불균등한 경우, 단순한 계산 방식만으로는 정확한 응답률을 산정하기 어렵다. 예를 들어, 행정 서비스에 대한 사회조사를 실시하면서 저소득층 거주 지역을 다른 지역에 비해 두 배 높은 비율로 표본추출한 경우를 생각해보자. 이와 같은 설계에서는 응답률과 관련해 다음과 같은 두 가지 주요 문제가 발생할 수 있다.\n첫째는 층별 응답률 비교이다. 저소득층 지역과 비저소득층 지역 간의 응답률을 각각 구해 비교하는 것은 일반적인 접근 방식이며, 두 집단 간의 평균 차이를 분석하는 데 유용하다. 이 경우에는 각 층 내에서의 응답률을 별도로 계산하고, 단순 비교를 통해 응답 특성을 이해할 수 있다. 이러한 분석에서는 앞서 설명한 표준적인 응답률 계산 방식이 적용 가능하다.\n둘째는 전체 표본의 응답률을 계산하는 경우이다. 만약 분석의 초점이 전체 모집단의 평균에 있다면, 응답률을 계산할 때 표본 추출 시의 불균등한 선택 확률을 반영해야 한다. 즉, 각 표본 요소의 선택 확률에 따라 가중치(\\(w_i\\))를 부여한 후 이를 활용하여 전체 응답률을 산정해야 한다. 이러한 가중 응답률 계산은 전체 표본이 모집단을 얼마나 잘 대표하는지를 보다 정확히 평가할 수 있도록 도와준다.\n이처럼 불균등 표집 설계에서는 응답률 계산 시 분석 목적에 따라 적절한 방법을 선택해야 하며, 층별 비교와 전체 평균 추정에서 서로 다른 계산 방식이 요구된다.\n\n다양한 응답률 지표의 활용\n응답률을 해석하고 활용할 때는 조사 목적과 구조에 따라 적절한 지표를 선택하는 것이 중요하다. 단순한 전체 응답률 외에도 다양한 유형의 응답률 지표가 존재하며, 이는 조사 설계와 분석 목적에 따라 다르게 적용될 수 있다.\n우선, 거절률은 설문 요청을 받은 대상자 중에서 응답을 거부한 비율을 의미하며, 일반적으로 \\(R / (I + R)\\) 의 공식으로 계산된다. 여기서 \\(R\\) 은 거절 수, \\(I\\)는 실제 응답 수를 나타낸다. 또한, 처음에는 응답을 거절했지만 이후에 설문에 참여한 경우를 반영하는 거절 변환율도 함께 고려할 수 있다. 이러한 지표는 조사 접근 방식의 효과성을 평가하는 데 유용하다.\n다음으로, 포괄률은 특히 기업을 대상으로 한 조사에서 사용되며, 전체 조사 대상 집단 중 실제 응답한 단위가 차지하는 비율을 의미한다. 이는 예를 들어 생산량이나 고용 규모와 같은 정보를 추정할 때 중요하게 고려된다. 이때 대형 유통업체인 이마트가 응답하지 않는 것과, 소규모 동네 편의점이 빠지는 경우는 조사 결과에 미치는 영향이 다르기 때문에 단순한 개수 기준의 응답률보다 포괄률이 더 적절한 지표가 될 수 있다.\n또한, 복합 응답률은 수행평가조사와 같이 다단계 표본추출이 이루어지는 구조에서 활용된다. 예를 들어, 학교와 학생이라는 두 수준에서 각각 무응답이 발생하는 경우, 이들 각 수준의 응답률을 결합하여 전체 응답률을 계산하는 방식이다. 이는 조사 참여가 여러 단계를 거치는 설계에서 보다 정확한 응답 수준을 반영할 수 있도록 한다.\n결론적으로, 응답률은 단일한 개념으로 이해하기보다는, 조사 대상, 설계 구조, 분석 목적에 따라 다양한 형태로 정의되고 활용될 수 있으며, 상황에 맞는 지표를 적절히 선택하는 것이 중요하다.\n\n\n\n\nchapter 4. 항목 무응답\n\n1. 항목 무응답 정의\n항목 무응답은 설문조사에서 응답자가 전체 설문에 참여하였음에도 불구하고 특정 질문에 대해서만 응답하지 않는 경우를 의미한다. 예를 들어, 소비자 조사의 응답자가 대부분의 문항에 성실히 응답하였더라도, 조사자가 지난 1년간의 가족 소득을 묻는 질문에 대해서는 답변을 거부할 수 있다. 항목 무응답은 단위 무응답과 마찬가지로 통계에 편향을 일으킬 수 있으나, 그 영향은 해당 항목의 데이터를 활용한 통계에만 국한된다.\n항목 무응답이 발생하는 원인은 단위 무응답과는 성격이 다를 수 있다. 단위 무응답은 설문 참여 여부를 결정하는 초기 단계에서 발생하는 반면, 항목 무응답은 설문이 진행되는 도중 개별 문항에 대한 응답 결정 과정에서 나타난다.\n항목 무응답의 주요 원인에는 다음과 같은 요인이 포함된다. 첫째, 응답자가 질문의 의도를 충분히 이해하지 못할 경우 답변을 생략할 수 있다. 둘째, 질문에 대한 정보를 기억해내기 어렵거나, 정확한 수치를 제공하기 어려운 상황도 무응답으로 이어질 수 있다. 셋째, 응답자가 질문 내용이 민감하다고 느끼거나, 정보를 공개할 동기나 의지가 부족한 경우에도 응답을 거부할 가능성이 있다.\n또한, 일부 응답자는 자신이 제공할 수 있는 답변이 정확하지 않다고 판단할 때 해당 항목을 생략하기도 한다. 이러한 상황에서는 질문의 형식을 조정하여 응답률을 개선할 수 있다. 예를 들어, 소득을 구체적인 금액이 아니라 범위로 제시하면, 응답자가 보다 부담 없이 응답할 수 있어 항목 무응답을 줄이는 데 도움이 될 수 있다.\n\nBeatty-Herrmann 모델\nBeatty-Herrmann 모델은 항목 무응답이 발생하는 과정을 인지적 측면과 응답 경로의 차이에 따라 설명하는 이론적 틀이다. 이 모델은 응답자가 필요한 정보를 얼마나 쉽게 접근할 수 있는지를 기준으로 네 가지 인지 상태를 제시하며, 각 상태에서 응답이 이루어질 가능성과 오류 발생 가능성을 함께 설명한다.\n첫 번째는 가용한 정보 상태이다. 이는 응답자가 질문에 필요한 정보를 쉽게 회상할 수 있는 경우를 의미한다. 이 상태에서는 대부분 정확한 응답이 이루어지며, 응답 오류가 발생할 가능성도 매우 낮다.\n두 번째는 접근 가능한 정보 상태이다. 이 경우, 응답자가 정보를 즉시 기억해내지는 못하지만, 약간의 인지적 노력이나 조사원의 유도에 의해 기억을 떠올릴 수 있다. 이러한 상황에서도 응답은 대체로 이루어지며, 정확성도 비교적 높은 편이지만, 일부 오류가 포함될 수 있다.\n세 번째는 추정 가능한 정보 상태이다. 응답자가 직접적인 기억은 없지만, 유사한 경험이나 논리적 추론을 통해 정보를 생성할 수 있는 경우에 해당한다. 이때 제공되는 응답은 어느 정도 일관성을 가질 수 있지만, 오류가 발생할 가능성이 높으며, 응답자가 스스로 신뢰하지 못해 응답을 포기할 경우 무응답으로 이어질 수 있다.\n마지막으로, 추정 불가능한 정보 상태는 응답자가 해당 질문에 대한 정보를 전혀 기억하지 못하고, 이를 유추할 수 있는 근거조차 없는 경우를 말한다. 이 상태에서는 대부분 응답이 이루어지지 않으며, 항목 무응답으로 직접 연결된다.\n이 모델은 항목 무응답을 단순한 의사결정 결과가 아니라, 응답자의 인지적 정보 처리 과정의 산물로 이해할 수 있도록 도와주며, 질문 설계와 조사 전략 수립에 유용한 시사점을 제공한다.\n\n\n\n2. 항목 무응답 줄이기 위한 설계적 요소\n\n\n(1) 응답 과정\n응답 과정은 설문조사에서 응답이 이루어지기까지의 일련의 단계로 구성되며, 일반적으로 접촉 단계, 초기 결정 단계, 그리고 최종 결정 단계의 세 단계로 구분된다. 각 단계는 응답률과 조사 품질에 중요한 영향을 미치며, 단계별로 다양한 요인이 작용한다.\n접촉 단계에서는 응답자와의 접촉이 가능한지를 판단하며, 이는 조사 성공의 첫 번째 조건이 된다. 이 단계에서는 다음과 같은 요소들이 고려된다. 우선, 자료 수집 기간이 길수록 응답자가 설문 요청을 인지하고 응답할 기회를 가질 가능성이 높다. 또한, 면접자에게 과도한 업무량이 배정되면 개별 응답자와 충분히 접촉하기 어려워져 응답률이 낮아질 수 있다. 면접자의 관찰 능력도 중요한데, 가구의 특성을 빠르게 파악하고 응답 가능성을 예측하는 능력은 조사 효율을 높이는 데 기여한다. 아울러, 통화 시도 횟수와 시점 역시 응답자와의 연결 가능성에 영향을 미치므로, 적절한 시간대에 여러 차례 연락하는 전략이 효과적이다.\n초기 결정 단계는 응답자가 설문 참여 여부를 판단하는 시점으로, 다양한 심리적·환경적 요인이 영향을 미친다. 먼저, 사전 통지는 응답자가 조사에 대한 신뢰를 갖고 사전에 준비할 수 있도록 하여 응답률을 높이는 데 도움을 준다. 금전적 보상이나 선물 등의 인센티브는 설문 참여에 대한 동기를 부여하며, 설문이 지나치게 길거나 인지적 부담이 큰 경우에는 오히려 응답률이 낮아질 수 있다. 가구 내 응답자 선택 규칙이 유연할수록 무응답 가능성이 줄어들며, 면접자가 응답자와 신뢰 관계를 형성할 수 있을 경우 응답률이 높아질 가능성이 크다. 조사 주관 기관이 정부나 공신력 있는 기관인 경우에도 설문에 대한 수용도가 높아지는 경향이 있다. 아울러, 면접자가 응답자의 관심사나 상황에 맞게 대화를 조정하는 능력 역시 긍정적인 영향을 미친다.\n최종 결정 단계는 초기 판단 이후에도 응답을 유도하기 위한 추가 조치들이 이루어지는 시점이다. 예를 들어, 응답자의 선호에 따라 조사 방식을 전화에서 대면으로 전환하는 모드 전환 전략이 있으며, 응답을 얻기 어려운 경우 면접자를 교체하는 방법도 있다. 또한, 설문 참여를 거절한 응답자에게 설득 편지를 보내 다시 참여를 유도하거나, 무응답자를 대상으로 별도의 모집단을 구성하여 이중 단계 표본 추출을 실시하는 방식도 활용된다. 마지막으로, 조사 후 분석 단계에서 무응답으로 인한 통계적 편향을 보정하기 위해 가중치를 조정하는 보정 기법이 적용될 수 있다.\n이와 같이 응답 과정은 단일한 선택의 결과가 아니라, 여러 단계와 다양한 요인이 상호작용한 결과이며, 각 단계에서의 전략적 개입은 전체 조사 품질을 높이는 데 중요한 역할을 한다.\n\n\n(2) 항목 무응답 출이기 단계\n설문 대상자와의 접촉 시도 횟수와 시기는 응답률에 중요한 영향을 미친다. 자기기입식 설문과 조사원이 보조하는 설문 모두에서, 설문 요청을 반복적으로 전달할수록 응답자와 성공적으로 접촉할 가능성이 높아진다.\n전화나 대면 조사의 경우, 응답자와의 접촉 가능성이 높은 시간대는 일반적으로 일요일부터 목요일까지의 저녁 시간대와 주말 낮 시간대이다. 반면, 평일 낮 시간에는 대부분의 가구가 부재 중이므로 연락이 어려운 경우가 많다.\n데이터 수집 기간 역시 응답률에 영향을 준다. 수집 기간이 길수록 응답자가 조사 요청을 인지할 가능성이 높아진다. 예를 들어, 미국 인구 센서스는 약 10일간 진행되며 거의 모든 가구와의 접촉에 성공한다. 이는 적절한 조사원 배치만으로도 비교적 짧은 시간 내에 대부분의 초기 접촉이 가능함을 시사한다.\n조사원의 업무량 또한 중요한 요소이다. 조사원에게 할당된 표본 사례당 충분한 시간이 주어져야 응답자와의 접촉과 설득이 가능하다. 예를 들어, 첫 번째 전화 연락 시도에서 접촉이 성공할 확률은 약 50%에 불과하며, 충분한 시간이 확보되지 않거나 과도한 업무량이 주어진 경우 비접촉이나 설득 부족으로 인한 무응답이 증가할 수 있다.\n조사 후원 기관도 응답 협력률에 영향을 미친다. 대부분의 국가에서 정부 기관이 주관하는 조사에 대한 응답률이 대학이나 민간기관보다 높은 경향을 보인다. 특히 조사 후원 기관이 응답자의 소속 집단이나 가치와 관련이 있을 경우 응답률은 더욱 높아진다. 예를 들어, 회원제로 운영되는 단체가 후원하는 조사에서는 소속 응답자들의 참여 의향이 더 높게 나타난다.\n대면 조사는 조사원이 직접 표본 가구를 관찰할 수 있다는 점에서 강점을 가진다. 예를 들어, 마당에 놓인 장난감을 통해 어린이의 존재를 유추하거나, 이웃을 통해 가구 구성에 대한 정보를 얻을 수 있다. 이러한 관찰 정보는 조사 진행과 관리에 유용하게 활용될 수 있으며, 응답자가 설문에 대한 질문을 하는 경우에는 오히려 응답 의향이 있다는 신호로 해석될 수 있다.\n사전 통지도 응답률에 긍정적인 영향을 준다. 응답자에게 우편이나 이메일로 조사 계획을 미리 안내하면 설문 요청의 신뢰도가 높아지고, 실제로 많은 조사에서 응답률이 향상되는 것으로 나타났다. 특히 대학이나 공공기관이 주관하는 경우 그 효과가 더 크게 나타나며, 반대로 시장 조사기관의 경우 사전 통지가 오히려 응답률을 낮추는 결과를 보이기도 한다.\n인센티브는 응답 동기를 높이는 또 다른 요인이다. 현금 보상이 물품 보상보다 더 효과적인 것으로 나타났으며, 설문 완료 이후보다 요청 이전에 인센티브를 제공할 경우 응답률이 더 높게 나타나는 경향이 있다.\n응답자가 느끼는 부담도 응답률에 영향을 미친다. 설문이 너무 길거나 내용이 복잡하면 참여를 꺼리는 경향이 있으며, 실제로 자기기입식 설문지의 페이지 수가 한 장 늘어날 때마다 응답률이 평균 0.4%포인트 감소한다는 연구 결과도 있다.\n가구 내에서 응답자를 선택하는 방식 또한 응답률에 영향을 미친다. 가능한 모든 성인이 응답할 수 있도록 허용하는 방식은 무작위로 성인을 선정하는 방식보다 응답 협력률이 높다. 또한 대리 응답을 허용하는 경우, 직접 응답만 허용하는 방식보다 높은 응답률을 기록하는 경우가 많다.\n특히 전화 조사에서는 인터뷰어의 초기 소개 방식이 중요하다. 억양이나 말하는 속도 등 미묘한 언어적 특징이 응답자의 협조 의사에 영향을 줄 수 있으며, 조사원이 지나치게 정형화된 소개 문구를 읽는 경우 응답 거부율이 높아진다는 연구 결과도 존재한다.\n응답자와 조사자 간의 신뢰 형성을 위한 적절한 매칭도 응답률을 높이는 전략으로 활용될 수 있다. 예를 들어, 혼자 사는 고령 여성 응답자에게는 보다 연령이 높은 여성 조사자를 배정하는 것이 응답 가능성을 높이는 데 도움이 될 수 있다.\n조사 방식의 변경도 응답률 향상에 기여할 수 있다. 예를 들어, 초기에는 비용 효율성이 높은 우편 설문을 사용하고, 이후 무응답자에게는 대면 조사를 적용하는 혼합 설계가 자주 활용된다. 일반적으로 대면 조사는 전화나 우편 방식보다 응답률이 높은 경향이 있다.\n설문 참여를 처음에 거절한 대상자에게 설문 목적과 중요성을 설명하는 설득 편지를 보내는 방법도 있다. 이 편지는 조사원이 다시 방문하여 질문이나 우려 사항에 답변하겠다는 내용을 포함하며, 응답자의 태도 변화와 협조 가능성을 높이기 위한 전략으로 활용된다.\n\n\n(3) 통계적 기법 활용\n무응답 문제를 해결하기 위해 통계적 분석 기법을 활용한 다양한 방법이 개발되어 왔으며, 특히 무응답자에 대해 새로운 접근 방식을 적용하는 시도들이 주목받고 있다.\n먼저, 이중 단계 표본 추출은 무응답자 중 일부를 확률적으로 다시 추출하여 새로운 방식으로 접촉을 시도하고 응답을 유도하는 방법이다. 이 과정에서 얻은 응답 데이터를 활용하면 전체 무응답자의 특성을 추정할 수 있으며, 이는 무응답 편향을 줄이는 데 효과적으로 활용될 수 있다.\n또한, 조사 후 보정은 기존 응답자의 데이터를 바탕으로 무응답자의 특성을 보정하는 방식이다. 예를 들어, 도시 지역에서 응답률이 낮을 경우, 응답한 도시 지역 표본에 더 높은 가중치를 부여하여 전체 결과의 대표성을 확보하고 편향을 줄이는 방식이 여기에 해당한다.\n이와 같은 통계적 기법들은 무응답에 의한 왜곡을 줄이는 데 중요한 역할을 하지만, 여전히 해결되지 않은 여러 연구 과제가 존재한다.\n예를 들어, 응답을 꺼리는 대상자와의 인터뷰가 성공했을 경우, 이들이 제공하는 응답은 다른 응답자보다 측정 오류가 더 클 가능성이 있는지에 대한 의문이 제기된다. 단순히 응답을 확보하는 것이 아니라, 그 응답의 품질 또한 함께 고려해야 한다는 문제의식이다.\n또한, 응답률을 높이기 위한 노력이 항상 무응답 편향 감소로 이어지는지, 또는 특정 조건에서만 효과적인지에 대한 검토도 필요하다. 응답률 자체가 개선되더라도, 응답자 구성의 대표성이 여전히 확보되지 않는다면 무응답 편향은 여전히 존재할 수 있다.\n비접촉 무응답과 거절 무응답을 줄이기 위한 전략 간의 균형도 중요한 과제이다. 예를 들어, 접촉 가능성을 높이기 위해 여러 차례 시도하는 것은 비접촉 무응답을 줄일 수 있지만, 지나치게 빈번한 연락은 오히려 거절 무응답을 증가시킬 위험이 있다. 두 가지 유형의 무응답 간에 어떻게 자원을 배분할지에 대한 전략적 판단이 필요하다.\n마지막으로, 표본 오차와 무응답 오차를 동시에 고려할 때, 제한된 예산 내에서 응답률을 무조건 극대화하지 않아도 되는 조건은 무엇인지에 대한 논의도 중요하다. 예를 들어, 응답률을 약간 희생하더라도 더 넓은 표본을 확보하거나 다른 품질 보정 기법을 적용하는 것이 전체적으로 더 나은 결과를 낳을 수 있다. 이러한 판단은 조사 설계의 목적, 예산, 대상 모집단의 특성 등을 종합적으로 고려하여 이루어져야 한다.\n\n\n\nchapter 5. 항목 무응답 대체\n항목 무응답은 조사 대상자가 전체 설문에는 응답했지만, 일부 질문에만 응답하지 않아 특정 항목의 데이터가 결측되는 경우를 의미한다. 이러한 무응답은 소득이나 건강 상태와 같은 민감한 질문에 대한 기피, 질문 내용을 정확히 이해하지 못한 경우, 응답 과정에서의 실수, 또는 조사자의 착오 등 다양한 이유로 발생할 수 있다.\n항목 무응답은 전체 응답률에는 영향을 미치지 않지만, 특정 변수에 대한 응답이 충분하지 않을 경우 해당 변수에 대한 분석이 제한된다. 특히, 항목 무응답이 많아지면 분석 가능한 표본 수가 줄어들고, 결측된 응답이 특정 집단에 집중될 경우 해당 변수와 관련된 분석 결과에 편향이 발생할 수 있다. 이는 결과의 신뢰성을 저하시킬 수 있으며, 모집단을 대표하는 정확한 추정을 어렵게 만든다. 따라서 항목 무응답의 발생 원인을 이해하고, 적절한 보정이나 결측 처리 방법을 적용하는 것이 중요하다.\n\n1. 가중치 조정\n가중치 조정은 단위 무응답으로 인해 발생하는 대표성 문제를 완화하기 위한 방법 중 하나이다. 이 방법은 응답하지 않은 표본의 특성을 고려하여, 응답자에게 부여된 가중치를 조정함으로써 전체 모집단의 분포를 보다 정확하게 반영하고자 한다.\n조정의 핵심 목적은 응답자 표본이 실제 모집단을 대표할 수 있도록 하는 것이다. 예를 들어, 특정 연령대나 지역의 응답률이 낮은 경우, 해당 집단에 속한 응답자에게 더 높은 가중치를 부여함으로써 전체 분석에서 그 집단의 영향력을 보정할 수 있다. 이를 통해 무응답으로 인한 편향을 줄이고, 통계 결과의 신뢰성과 대표성을 높이는 데 기여할 수 있다.\n\n\n(1) 후보정 가중치(Post-Stratification Weighting)\n후보정 가중치는 모집단의 이미 알려진 특성을 바탕으로 응답자의 가중치를 조정하는 방법이다. 이 방식은 표본과 모집단 간의 불균형을 수정하여, 분석 결과에 포함될 수 있는 편향을 줄이는 데 목적이 있다.\n후보정에서는 성별, 연령, 지역, 교육 수준 등과 같이 모집단의 분포가 사전에 알려진 보조 변수를 활용한다. 응답자 집단이 특정 보조 변수에서 모집단과 다르게 구성되어 있을 경우, 해당 변수의 분포를 기준으로 가중치를 재조정함으로써 전체 표본이 모집단을 보다 잘 대표하도록 보완할 수 있다. 이 과정은 조사 결과의 신뢰성과 정확성을 높이는 데 중요한 역할을 한다.\n\\(w_{i} = \\frac{N_{g}}{n_{g}}\\) 여기서, \\(w_{i}\\)은 응답자 i 의 새로운 가중치, \\(N_{g}\\)은 모집단 내 해당 그룹 \\(g\\)의 크기, \\(n_{g}\\)은 표본 내 해당 그룹 \\(g\\)의 응답자 수\n즉, 후보정 가중치는 각 그룹의 모집단 비율을 반영하여 응답자의 가중치를 조정하는 방식이다. 이를 통해 표본이 모집단의 구조를 보다 정확하게 반영하도록 한다.\n예를 들어, 모집단에서 성별 비율이 남성 60%, 여성 40%인 상황에서 실제 조사에서는 남성과 여성이 각각 50명씩 조사되었다고 가정하자. 이 경우 표본에서는 남성이 과소표집된 상태이며, 모집단의 실제 분포와 불일치가 발생한다. 이를 보정하기 위해 남성 응답자의 가중치를 증가시키고, 여성 응답자의 가중치를 상대적으로 낮춤으로써 분석 결과가 모집단의 구조에 맞도록 조정할 수 있다. 이와 같은 방식은 무응답이나 표본 추출상의 불균형으로 인한 편향을 줄이는 데 유효한 방법이다.\n\\(w_{\\text{남성}} = \\frac{N_{\\text{남성}}}{n_{\\text{남성}}} = \\frac{60}{50} = 1.2\\), \\(w_{\\text{여성}} = \\frac{N_{\\text{여성}}}{n_{\\text{여성}}} = \\frac{40}{50} = 0.8\\)\n즉, 남성 응답의 영향을 증가시키고 여성 응답의 영향을 감소시켜 모집단의 성별 비율을 반영합니다.\n\n\n(2) 무응답 가중치 조정(Nonresponse Weighting Adjustment)\n무응답 가중치 조정은 응답자의 특성을 기준으로 유사한 무응답자 그룹을 식별한 후, 해당 응답자의 가중치를 조정하여 무응답으로 인한 편향을 보정하는 방법이다. 이 기법은 응답자와 무응답자가 유사한 특성(예: 성별, 연령, 지역 등)을 가진 집단 내에 속해 있다고 가정하고, 그 집단(Strata) 내 응답자의 비율을 활용하여 가중치를 조정한다.\n특히 무응답이 특정 집단에 집중되는 경향이 있을 때 이 방법은 효과적으로 작동한다. 예를 들어, 특정 연령대나 지역에서 응답률이 낮은 경우, 그 집단의 응답자에게 더 높은 가중치를 부여함으로써 전체 표본의 대표성을 회복할 수 있다.\n통계적으로는, 응답자가 설문에 응할 확률인 응답 확률 \\(p_i\\) 를 고려하여 각 응답자의 가중치를 \\(1 / p_i\\) 의 형태로 조정할 수 있다. 이러한 방식은 무응답으로 인한 왜곡을 줄이고, 조사 결과의 정확성과 신뢰성을 높이는 데 기여한다.\n\\(w_{i} = \\frac{1}{p_{i}}\\) 여기서, \\(w_{i}\\)은 응답자 \\(i\\)의 가중치, \\(p_{i}\\) 은 응답 확률 (응답자가 해당 조사에 응답할 확률) 또는, 그룹 \\(g\\) 별 응답률을 고려하여 다음과 같이 가중치를 조정할 수 있다.\n\\(w_{i} = w_{i}^{\\text{기존}} \\times \\frac{1}{{\\widehat{p}}_{g}}\\), 여기서, \\({\\widehat{p}}_{g} = \\frac{n_{g}}{m_{g}}\\) (해당 그룹의 응답률), \\(n_{g}\\) 은 해당 그룹 내 응답자 수, \\(m_{g}\\) 은 해당 그룹 내 전체 표본 수이다.\n예를 들어, 특정 연령대(20대)의 응답률이 낮다고 가정해 보겠습니다. 모집단에서 20대는 1,000명이고, 표본에서는 100명을 선정했지만, 그중 50명만 응답했다면 20대의 응답률은 \\({\\widehat{p}}_{20\\text{대}} = \\frac{50}{100} = 0.5\\) 따라서, 응답자의 가중치는 \\(w_{\\text{20대}} = \\frac{1}{0.5} = 2.0\\)이다. 즉, 20대 응답자의 가중치를 2배 증가시켜 모집단의 특성을 반영하도록 보정한다.\n\n\n2. 평균, 중앙값, 최빈값 대체(Mean/Median/Mode Imputation)\n\n\n(1) 평균 또는 중앙값 대체(Mean/Median Imputation)\n평균 대체는 결측값을 해당 변수의 평균 값으로 대체하는 방법이며, 중앙값 대체는 결측값을 해당 변수의 중앙값으로 대체하는 방식이다. 두 방법 모두 결측값을 단일 값으로 채우는 단순 대체 방식에 속하며, 주로 소득, 나이, 키, 체중과 같은 연속형 변수에 적용된다.\n평균 대체는 전체 응답자의 평균을 활용하므로 데이터의 중심 경향을 반영할 수 있지만, 이상값의 영향을 크게 받을 수 있다는 단점이 있다. 반면, 중앙값 대체는 극단값에 덜 민감하므로 데이터의 분포가 비대칭이거나 이상값이 존재하는 경우 보다 안정적인 대체 방법으로 간주된다.\n이러한 대체 방법은 분석에 사용할 수 있는 표본 수를 늘리는 데는 도움이 되지만, 데이터의 변동성을 과소추정하거나 분산을 왜곡할 수 있으므로 해석에 주의가 필요하다.\n\\(X_{\\text{missing}} = \\frac{1}{n}\\overset{n}{\\sum_{i = 1}}X_{i}\\), \\(X_{\\text{missing}} = \\text{Median}(X_{1},X_{2},\\ldots,X_{n})\\)\n\n\n(2) 최빈값 대체(Mode Imputation)\n최빈값 대체는 결측값을 해당 변수에서 가장 자주 나타나는 값, 즉 최빈값으로 대체하는 방법이다. 이 방법은 성별, 직업, 지역과 같은 범주형 변수에서 주로 사용되며, 다음과 같은 방식으로 표현할 수 있다: \\(X_{\\text{missing}} = \\text{Mode}(X_{1},X_{2},\\ldots,X_{n})\\)\n최빈값 대체는 계산이 간단하고 해석이 명확하다는 장점이 있으나, 모든 결측값을 동일한 값으로 대체하므로 데이터의 분포를 왜곡하거나 변이를 과소추정할 수 있다는 단점도 있다.\n보다 신뢰성 있는 대체를 위해, 전체 데이터를 기반으로 대체하는 대신, 층화변수와 내재적 층화변수(즉, 표본 추출에 사용된 층화 기준)를 결합한 세분화된 층 내에서 최빈값을 계산하여 대체하는 방식이 활용될 수 있다. 이렇게 하면 각 응답자 집단의 특성을 보다 잘 반영할 수 있어, 결측값 대체의 정확성과 타당성이 높아진다.\n\n\n3. 핫덱(Hot Deck) 또는 콜드덱(Cold Deck) 대체\n핫덱(Hot Deck)과 콜드덱(Cold Deck) 대체 방법은 결측 데이터를 보완하기 위해 사용되는 대표적인 대체 기법이다. 이들은 무응답자의 값을 유사한 응답자나 외부 데이터로부터 가져와 채워 넣는 방식으로, 특히 설문조사나 표본조사에서 자주 활용된다.\n핫덱 대체는 동일한 조사 내에서 결측값이 있는 응답자와 유사한 특성을 가진 응답자의 값을 이용하여 결측값을 채우는 방법이다. 예를 들어, 연령, 성별, 지역 등이 유사한 응답자 중에서 해당 항목의 값을 가져오는 방식이다. 이 방법은 동일한 데이터셋 내에서 정보를 활용하므로 일관성과 응답 환경의 유사성을 유지할 수 있다는 장점이 있다.\n반면, 콜드덱 대체는 외부의 독립적인 데이터나 과거 조사 데이터를 활용하여 결측값을 보완하는 방식이다. 예를 들어, 이전 조사에서 축적된 데이터를 참조하여 현재 결측된 항목을 채우는 방식이다. 이 방법은 현재 조사에서 해당 값이 확보되지 않은 경우에도 활용이 가능하지만, 자료 간 차이로 인해 편차가 생길 수 있다는 점에 유의해야 한다.\n두 방법 모두 무응답 문제를 해결하고 분석의 완성도를 높이는 데 도움이 되며, 선택 시에는 조사 목적, 데이터 특성, 대체 가능한 정보의 적절성 등을 고려해야 한다.\n\n\n(1) 핫덱 대체 (Hot Deck Imputation)\n핫덱(Hot Deck) 대체는 현재 조사에서 수집된 응답 데이터를 활용하여 결측값을 보완하는 방법이다. 이 방식은 동일한 조사 내에서 무응답자와 유사한 특성을 가진 응답자를 찾아, 해당 응답자의 값을 결측값에 할당함으로써 데이터를 보완한다.\n핫덱 대체는 주로 성별, 연령, 지역 등과 같은 보조 변수를 기준으로 유사한 응답자를 찾는 방식으로 이루어지며, 두 가지 방식으로 수행될 수 있다. 첫째, 무작위 핫덱(random hot deck) 방식은 유사한 집단 내에서 무작위로 한 응답자를 선택하여 그 값을 결측값에 할당한다. 둘째, 층화 핫덱(stratified hot deck) 방식은 사전에 정의된 층화 기준에 따라 동일한 층 내에서 가장 유사한 응답자를 선택하여 대체한다.\n핫덱 대체는 실제 응답 데이터 기반으로 이루어지므로 현실적인 값이 할당될 가능성이 높고, 응답자의 특성을 고려한 대체가 가능하다는 점에서 비교적 신뢰성이 높은 방법으로 간주된다. 다만, 유사한 응답자를 선정하는 기준과 방식에 따라 대체 결과가 달라질 수 있으므로, 적절한 기준 설정이 중요하다.\n핫덱 대체는 결측값을 유사한 응답자의 값으로 대체한다.\n\\[Y_{\\text{결측값},i} = Y_{\\text{유사},j}\\]\n핫덱 대체에서 유사한 응답자를 선택하는 기준은 결측값을 얼마나 정확하게 보완할 수 있는지를 결정짓는 핵심 요소이다. 일반적으로 다음과 같은 세 가지 방법이 활용된다.\n첫째, 계층적 방법(stratified hot deck)은 성별, 연령, 지역 등과 같은 주요 변수를 기준으로 응답자를 그룹화한 뒤, 동일한 그룹 내에서 유사한 응답자의 값을 결측값에 할당하는 방식이다. 이 방법은 미리 정의된 계층 구조를 활용하여 응답자의 특성을 최대한 반영하려는 목적에 적합하다.\n둘째, 무작위 방법(random hot deck)은 응답자의 특성과 상관없이 동일한 모집단 내에서 임의로 응답자의 값을 선택하여 결측값을 대체하는 방식이다. 이 방법은 간단하고 계산이 빠르지만, 유사성 기준이 적용되지 않아 오차가 발생할 가능성이 있다.\n셋째, 최근접 이웃 방법(nearest neighbor hot deck)은 응답자 간 유사도를 수치적으로 계산한 후, 가장 유사한 응답자를 선택하여 해당 값을 대체하는 방식이다. 이 방법은 응답자 특성을 세밀하게 고려할 수 있다는 장점이 있다.\n예를 들어, 설문조사에서 소득 정보가 결측된 응답자 A가 20대 남성이며 대학을 졸업한 경우, 같은 조사 내에서 동일한 특성을 가진 응답자 B가 소득 정보를 제공했다면, A의 결측값을 B의 소득 값으로 대체할 수 있다. 이처럼 핫덱 대체는 현재 조사 내에서 유사한 응답자의 데이터를 활용하여 결측값을 보완한다는 점에서 실용적이며, 현실적인 응답을 반영할 수 있는 유용한 방법이다.\n\n\n(2) 콜드덱 대체 (Cold Deck Imputation)\n콜드덱(Cold Deck) 대체는 현재 조사 내의 데이터를 활용하는 핫덱 대체와 달리, 외부의 독립적인 데이터원을 활용하여 결측값을 보완하는 방법이다. 이때 활용되는 외부 데이터는 이전에 실시된 조사, 행정자료, 공공 데이터, 또는 기존 연구에서 축적된 정보 등이 될 수 있다.\n콜드덱 대체는 과거 조사에서 수집된 자료 중에서 현재 조사 대상자와 유사한 특성을 가진 응답자의 값을 활용하여 결측된 항목을 대체한다. 이 방식은 데이터의 일관성과 안정성이 유지된다면 핫덱 대체보다 더 신뢰도 높은 결과를 제공할 수 있다. 특히 조사 환경이나 문항 구성이 유사할 경우 효과적이다.\n그러나 콜드덱 방식은 외부 데이터가 오래되었거나 현재의 모집단 특성과 차이가 클 경우, 대체의 정확도가 떨어질 수 있다. 시간의 경과로 인한 사회적 변화나 조사 방식의 차이로 인해 과거 데이터가 현재 상황을 적절히 반영하지 못할 위험이 있기 때문이다.\n결론적으로, 콜드덱 대체는 외부 자료의 품질과 최신성, 그리고 현재 조사와의 정합성 여부에 따라 성과가 달라질 수 있으며, 외부 데이터의 적절성을 충분히 평가한 후 활용하는 것이 중요하다.\n\\[Y_{\\text{결측값},i} = Y_{\\text{이전조사},k}\\]\n예를 들어, 2025년에 실시된 소득 조사에서 일부 응답자의 소득 정보가 누락된 경우, 콜드덱 대체 방법을 활용하여 이전 자료에서 해당 결측값을 보완할 수 있다. 이때 2020년 인구조사와 같은 과거 데이터를 참고하여, 동일한 연령, 성별, 지역에 해당하는 집단의 평균 소득 값을 활용하는 방식이다.\n2025년 조사에서 소득 정보가 누락된 응답자 A가 30대 남성이고 특정 지역에 거주하고 있다면, 2020년 인구조사에서 동일한 특성을 가진 집단의 평균 소득이 4,000만 원으로 나타났을 경우, A의 결측된 소득 값은 4,000만 원으로 대체할 수 있다. 이와 같은 방식은 적절한 외부 자료가 존재하고, 그 자료가 현재 조사와 충분히 유사한 구조를 갖고 있을 때 신뢰성 있는 대체 수단이 될 수 있다.\n\n\n4. 모델 기반 대체(Model-Based Imputation)\n모델 기반 대체(Model-Based Imputation)는 통계적 또는 기계 학습 모델을 활용하여 결측값을 예측하는 방법이다. 이 방식은 기존 응답 데이터를 바탕으로 변수 간의 패턴을 학습한 뒤, 무응답자의 결측값을 예측하여 채우는 절차로 이루어진다. 단순한 평균이나 최빈값 대체와 달리, 여러 변수 간의 관계를 고려한다는 점에서 보다 정교하고 유연한 접근이 가능하다.\n대표적인 방법으로는 회귀 대체와 다중 대체가 있다. 회귀 대체는 결측값이 있는 변수를 종속 변수로 설정하고, 다른 관측 가능한 변수들을 독립 변수로 사용하여 회귀모형을 적합시킨 후, 예측값으로 결측값을 대체하는 방식이다. 다중 대체(Multiple Imputation)는 단일 예측값이 아닌, 확률적 방법을 통해 여러 개의 대체값을 생성하고, 각각의 대체된 데이터를 분석한 후 그 결과를 종합하여 최종 추정치를 도출하는 방식이다.\n모델 기반 대체는 복잡한 데이터 구조와 변수 간 상호작용을 반영할 수 있다는 장점이 있으나, 모델의 적합성과 가정에 따라 대체 결과가 달라질 수 있으므로 주의 깊은 검토와 모형 진단이 필요하다.\n\n\n(1) 회귀 대체(Regression Imputation)\n회귀 대체는 응답자의 데이터를 활용하여 회귀 모형을 구성한 뒤, 이를 바탕으로 무응답자의 결측값을 예측하는 방법이다. 이 기법은 변수 간의 통계적 관계를 이용해 결측값을 보완하며, 예측하려는 변수의 성격에 따라 다른 회귀 모형이 사용된다. 예를 들어, 연속형 변수의 경우에는 선형 회귀를, 범주형 변수의 경우에는 로지스틱 회귀를 적용할 수 있다.\n회귀 대체는 단순한 평균이나 최빈값 대체보다 더 많은 정보를 활용하므로 예측력이 높고, 데이터의 구조를 잘 반영할 수 있는 강력한 대체 방법이다. 하지만 회귀 모형의 성능에 따라 대체 결과가 달라질 수 있으며, 특히 모형이 과적합되는 경우에는 실제보다 과도하게 정확한 예측을 제공하는 듯 보일 수 있어 주의가 필요하다. 따라서 회귀 대체를 사용할 때는 적절한 변수 선택, 교차 검증, 잔차 분석 등을 통해 모형의 타당성을 충분히 점검해야 한다.\n\n선형 회귀 모델(측정형 무응답)\n연속형 변수가 결측된 경우, 회귀식을 통해 예측한다.\n\\(Y = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\ldots + \\beta_{k}X_{k} + \\epsilon\\), 여기서 \\(Y\\)은 응답자의 값을 사용해 예측할 종속 변수(결측값을 포함하는 변수), \\(X_{1},X_{2},\\ldots,X_{k}\\)은 예측에 사용되는 독립 변수(결측값이 없는 변수들) 회귀 분석을 통해 계수를 추정한 후, 무응답자의 값을 예측값으 로 대체한다.\n\\[Y_{\\text{miss}} = \\widehat{Y} = {\\widehat{\\beta}}_{0} + {\\widehat{\\beta}}_{1}X_{1} + {\\widehat{\\beta}}_{2}X_{2} + \\ldots + {\\widehat{\\beta}}_{k}X_{k}\\]\n예를들어, 설문조사에서 연령, 교육 수준, 직업을 기반으로 소득이 결측된 응답자의 소득을 예측한다고 가정하자. 데이터셋에는 연령, 교육 수준, 직업, 소득 변수가 포함되어 있고 일부 응답자가 소득을 응답하지 않았다면 다음 추정값으로 대체한다. \\(\\widehat{\\text{Income}} = {\\widehat{\\beta}}_{0} + {\\widehat{\\beta}}_{1}\\text{Age} + {\\widehat{\\beta}}_{2}\\text{Education} + {\\widehat{\\beta}}_{3}\\text{Occupation}\\)\n\n\n\n(2) 다항 로짓회귀모형(범주형 무응답)\n\\[P(Y = j|X) = \\frac{\\exp(X\\beta_{j})}{\\sum_{k = 1}^{J}\\exp(X\\beta_{k})},j = 1,2,\\ldots,J\\]\n\\(P(Y = j|X)\\): 독립 변수 \\(X\\)가 주어졌을 때, 종속 변수가 범주 \\(j\\)를 선택할 확률\n\\(X\\): 예측에 사용되는 독립 변수(결측값이 없는 변수들\n\\(J\\): 가능한 범주의 개수\n\n\n(3) 다중 대체(Multiple Imputation, MI)\n다중 대체(Multiple Imputation)는 결측값을 하나의 예측값으로 대체하는 단일 대체 방법과 달리, 여러 개의 가능한 대체값을 생성하여 결측에 따른 불확실성을 반영하는 방식이다. 단일 대체 방법, 예를 들어 회귀 대체는 하나의 고정된 값을 결측값에 할당하기 때문에 대체값 간의 변동성을 반영하지 못하는 한계가 있다. 반면, 다중 대체는 확률 기반 접근을 통해 서로 다른 대체값을 여러 개 생성하고, 각 대체된 데이터셋에 대해 분석을 수행한 뒤, 그 결과를 통합하여 최종 추정치를 도출한다. 이 과정은 결측으로 인한 통계적 불확실성을 분석 결과에 포함시키는 효과가 있다.\n예를 들어, 개인의 소득(Income), 연령(Age), 교육 수준(Education), 직업(Occupation)을 포함한 설문조사를 수행했을 때 일부 응답자의 소득 정보가 누락되어 결측값이 발생했다고 가정하자. 이 경우, 다중 대체를 적용하면 연령, 교육 수준, 직업 등의 정보를 이용해 소득에 대해 여러 개의 가능한 예측값을 생성할 수 있다. 이후 각 대체값을 포함한 데이터셋으로 동일한 분석을 반복 수행하고, 그 결과를 통합함으로써 보다 신뢰할 수 있고 불확실성이 반영된 추정치를 얻을 수 있다.\n다중 대체는 결측값 처리에서 가장 권장되는 방법 중 하나로, 결측이 분석 결과에 미치는 영향을 최소화하면서도 통계적 일관성을 유지하는 데 효과적인 기법이다. 다중 대체 단계는 다음과 같다.\n\n1. 대체(Imputation):\n다중 대체는 결측값이 존재하는 데이터를 대상으로 여러 개의 대체값을 생성하는 절차를 포함한다. 이 과정에서는 회귀 분석이나 예측 모델 등 통계적 기법을 활용하여 결측값을 예측하고, 여기에 확률적 오차를 반영함으로써 반복적으로 다양한 대체값을 생성한다.\n예를 들어, 소득 변수에 결측값이 존재하는 경우, 연령, 교육 수준, 직업 등의 변수를 설명 변수로 활용하여 소득을 예측하는 회귀 모형을 구축한다. 이 회귀 모형을 기반으로 확률적 요소를 포함한 예측값을 생성하고, 이를 반복하여 서로 다른 다섯 개의 대체 데이터셋을 만든다. 각 데이터셋은 동일한 결측값에 대해 서로 다른 값을 가지며, 이후 각 데이터셋에 대해 독립적인 분석을 수행한다. 마지막으로 그 결과를 통합함으로써 결측으로 인한 불확실성이 반영된 최종 추정치를 도출할 수 있다.\n이와 같은 방식은 단일 대체에서 발생할 수 있는 과소추정 문제를 보완하고, 보다 신뢰도 높은 분석 결과를 제공하는 데 효과적이다.\n\n\n\n\n\n결측값이 있는 ID 3, 5번의 소득을 5가지 방법으로 대체하여 총 5개의 데이터셋을 생성하여 대체값 추정하였다.\n데이터셋 1: ID 3 → 3,500 / ID 5 → 4,000\n데이터셋 2: ID 3 → 3,800 / ID 5 → 4,200\n데이터셋 3: ID 3 → 3,600 / ID 5 → 4,100\n데이터셋 4: ID 3 → 3,700 / ID 5 → 4,300\n데이터셋 5: ID 3 → 3,900 / ID 5 → 4,500\n\n\n2. 분석(Analysis):\n생성된 각 대체 데이터셋을 이용하여 동일한 분석을 수행한다. 각 데이터셋에서 회귀 분석, 평균 추정 등의 통계 분석을 진행한다. 각각의 대체 데이터셋에서 동일한 분석을 수행한다. 예를 들어, 소득과 연령 간의 회귀 분석을 수행하면,\n\n데이터셋 1에서 회귀 계수(β) = 0.25\n데이터셋 2에서 회귀 계수(β) = 0.27\n데이터셋 3에서 회귀 계수(β) = 0.26\n데이터셋 4에서 회귀 계수(β) = 0.28\n데이터셋 5에서 회귀 계수(β) = 0.29\n\n\n\n\n3. 결합(Pooling):\n여러 개의 분석 결과를 결합하여 최종 추정치를 계산한다. 보통 Rubin’s Rules을 사용하여 평균과 표준 오차를 결합한다.\n회귀 계수(β)의 평균 및 표준 오차를 계산: \\(\\overline{\\beta} = \\frac{1}{m}\\overset{m}{\\sum_{j = 1}}\\beta_{j}\\), \\(T = W + \\left( 1 + \\frac{1}{m} \\right)B\\) 여기서, \\(m = 5\\) (대체 데이터셋 개수), \\(W\\) 는 대체 데이터셋 내부의 분산(Within-Imputation Variance), \\(B\\) 는 대체 데이터셋 간의 분산(Between-Imputation Variance)\n최종적으로 회귀 계수(β) = 0.27 ± 0.02로 사용한다.\n\n\n5. 최근접 이웃 대체(Nearest Neighbor Imputation)\n응답자 간의 유사성을 바탕으로 결측값을 대체하는 방법은, 결측값을 예측하는 것이 아니라 기존 응답자 중에서 가장 유사한 대상을 찾아 해당 값을 그대로 할당하는 방식이다. 이 방법은 모델 기반 예측이 아닌 실제 데이터 값을 활용하므로, 기존 데이터의 분포를 잘 보존할 수 있다는 장점이 있다.\n무응답자의 특성과 가장 유사한 응답자를 선택하기 위해 거리 기반 알고리즘이 활용되며, 대표적으로 유클리드 거리, 맨해튼 거리, 코사인 유사도 등이 사용된다. 이들 거리 지표는 응답자 간의 특성 차이를 수치적으로 측정하여 가장 가까운 이웃을 찾는 데 사용된다.\n이러한 방식에서 가장 널리 쓰이는 알고리즘은 K-최근접 이웃(K-Nearest Neighbors, KNN) 알고리즘이다. 이 알고리즘은 결측값이 있는 무응답자에 대해, K개의 가장 유사한 응답자를 찾아 그들의 값을 참조하여 대체한다. K가 1인 경우에는 가장 가까운 단일 응답자의 값을 그대로 사용하는 방식이 된다. 이 기법은 연속형 변수와 범주형 변수 모두에 적용이 가능하며, 특히 복수의 예측 변수를 바탕으로 유사도를 정량화할 수 있다는 점에서 유연성이 크다.\n\n거리계산\n예를 들어, 응답자 i와 j 사이의 유클리드 거리는 다음과 같은 방식으로 계산할 수 있다: \\[d(i,j) = \\sqrt{(X_{i1} - X_{j1})^{2} + (X_{i2} - X_{j2})^{2} + \\ldots + (X_{ik} - X_{jk})^{2}}\\]\n가장 가까운 이웃인 응답자 \\(j^{*}\\) 를 찾고 해당 응답자의 값을 무응답자 \\(i\\) 에게 대체한다. \\(Y_{\\text{결축값},i} = Y_{\\text{유사},j^{*}}\\)\n\n\nK-최근접 이웃(K-Nearest Neighbors, KNN) 대체\n최근접 이웃 기반 대체 방법에서는 하나의 이웃만을 사용하는 방식보다, 여러 개의 최근접 이웃(K개의 이웃)을 선택하여 대체값을 산출하는 방식이 보다 안정적인 결과를 제공할 수 있다. 이 접근은 개별 응답자 간의 변동성을 완화하고, 대체값에 대한 신뢰도를 높이는 데 유리하다.\n연속형 변수의 경우, 선택된 K개의 최근접 이웃의 값을 평균하여 결측값을 대체한다. 이 방법은 극단값의 영향을 줄이고, 보다 일반적인 값을 반영할 수 있다는 점에서 효과적이다.\n범주형 변수의 경우에는 K개의 이웃 중 가장 빈번하게 나타나는 값을 선택하여 대체하는데, 이는 최빈값(mode)을 기준으로 결측값을 채우는 방식이다. 이와 같이 최근접 이웃을 복수로 활용하는 K-최근접 이웃(KNN) 대체 방법은 데이터의 유형에 따라 유연하게 적용 가능하며, 단일 이웃 방식보다 일반적으로 더 안정적인 대체 결과를 제공한다.\n\\(Y_{\\text{miss},i} = \\frac{1}{K}\\sum_{j \\in KNN(i)}Y_{j}\\), 여기서 \\(KNN(i)\\)은 무응답자 \\(i\\)와 가장 가까운 \\(K\\)개의 응답자 집합, \\(Y_{j}\\)은 선택된 이웃 응답자의 값이다.\n예를 들어, 설문조사에서 소득(Income) 값이 누락된 응답자 A가 있다고 가정하자.\nA의 특성: 연령: 35세, 교육 수준: 대졸, 직업: 엔지니어\n기존 응답자 중 A와 가장 유사한 가장 가까운 응답자 B, C를 선택 (K=2, KNN방식)\n\n\n\n\n\n\\[{\\widehat{Y}}_{A} = \\frac{4,500 + 4,700}{2} = 4,600\\text{만}\\]\n\n\n\n6. 기계 학습 기반 대체(Machine Learning Imputation)\n기계 학습 기반 대체는 평균 대체나 핫덱 대체와 같은 전통적인 방식보다 더 정교한 예측 기법을 활용하여 결측값을 보완하는 방법이다. 이 접근은 결측값 예측을 회귀 또는 분류 문제로 간주하고, 머신 러닝 알고리즘을 사용하여 데이터 내의 패턴을 학습한 후 결측값을 예측한다는 점이 특징이다.\n연속형 변수(예: 소득, 키, 체중 등)에 대해서는 회귀(regression) 모델을, 범주형 변수(예: 성별, 직업, 지역 등)에 대해서는 분류(classification) 모델을 사용한다. 대체 과정은 다음과 같이 구성된다:\n\n\n예측 모델 학습: 결측값이 없는 데이터를 이용하여 예측 모델을 학습시킨다.\n결측값 예측: 학습된 모델에 결측이 존재하는 데이터를 입력하여 결측값을 예측한다.\n결측값 보완: 예측된 값을 실제 결측값에 대체함으로써 데이터셋을 보완한다.\n\n\n이러한 방식에 활용되는 대표적인 알고리즘으로는 랜덤 포레스트(Random Forest), K-최근접 이웃(K-Nearest Neighbors, KNN), 그리고 신경망(Neural Networks) 등이 있으며, 각각의 알고리즘은 변수의 특성 및 데이터 구조에 따라 다양한 방식으로 결측값 보완에 활용될 수 있다.\n기계 학습 기반 대체는 데이터의 구조를 충분히 반영하여 보다 정밀한 대체값을 제공할 수 있으며, 특히 다변량 데이터 환경에서 효과적인 결측값 처리 방법으로 평가받는다.\n\n\n(1) 랜덤 포레스트 기반 대체 (Random Forest Imputation)\n랜덤 포레스트는 여러 개의 결정 트리(Decision Tree)를 앙상블하여 예측하는 모델로, 결측값을 예측할 때 기존 응답자의 데이터를 활용하여 랜덤 포레스트 회귀 또는 분류 모델을 학습한 후, 이를 바탕으로 결측값을 예측한다.\n결측값이 연속형 변수일 경우 → 회귀(Random Forest Regression) 모델을 이용해 예측된 평균값으로 대체 결측값이 범주형 변수일 경우 → 분류(Random Forest Classification) 모델을 이용해 가장 자주 등장한 값(다수결)으로 대체\n이 방식은 다음과 같은 절차로 진행된다:\n\n\n결측값이 없는 데이터를 사용해 랜덤 포레스트 모델을 학습한다.\n결측값이 존재하는 관측치에 대해 예측 수행한다.\n예측된 값을 해당 결측 셀에 대체한다.\n\n\n이 방법은 변수 간 상호작용이나 비선형 관계를 잘 포착할 수 있으며, 기존 데이터의 분포를 유지하면서도 예측 정확도를 높이는 데 효과적이다.\n\\(\\widehat{Y} = \\frac{1}{T}\\overset{T}{\\sum_{t = 1}}f_{t}(X)\\), 여기서, \\(T\\) 랜덤 포레스트에서 사용된 결정 트리의 개수, \\(f_{t}(X)\\)은 각 트리에서의 예측값, \\(\\widehat{Y}\\)은 최종 대체값 (회귀: 평균, 분류: 다수)\n예를 들어 소득 변수에 결측값이 존재하는 경우, 랜덤 포레스트 회귀(Random Forest Regression)를 활용하여 이를 대체할 수 있다. 이 방법은 먼저 소득 값이 결측되지 않은 응답자들의 데이터를 이용해 예측 모델을 학습하는 것으로 시작된다. 이때 소득을 예측하기 위한 독립 변수로는 응답자의 연령, 교육 수준, 직업 등이 사용된다. 학습된 랜덤 포레스트 모델은 다수의 결정 트리(decision tree)로 구성되어 있어, 변수들 간의 복잡한 관계를 효과적으로 포착할 수 있다.\n이후, 소득 값이 결측된 응답자에 대해 해당 응답자의 연령, 교육 수준, 직업 정보를 모델에 입력하면, 랜덤 포레스트는 이를 바탕으로 해당 응답자의 소득을 예측하게 된다. 마지막으로, 이렇게 예측된 값을 원래 결측되어 있던 소득 항목에 대체함으로써 데이터를 보완한다.\n이와 같은 방식은 단순히 평균이나 중앙값으로 대체하는 방법보다 예측 정확도가 높고, 데이터의 구조적 특성을 반영할 수 있다는 장점이 있다. 또한 랜덤 포레스트는 이상값에 강하고 과적합 위험이 낮아, 결측값 보완을 위한 실무적 대안으로 널리 사용된다.\n\n\n(2) K-최근접 이웃(KNN) 기반 대체 (K-Nearest Neighbors Imputation)\nKNN 기반 대체(K-Nearest Neighbors Imputation)는 결측값이 있는 관측치에 대해, 해당 관측치와 유사한 특성을 가진 다른 관측치들을 찾아 그 정보를 이용해 결측값을 보완하는 기계 학습 기반 방법이다. 기본 개념은 전통적인 최근접 이웃 대체 방식과 유사하지만, KNN 알고리즘의 특성을 활용하여 보다 정교하고 자동화된 방식으로 수행된다는 점에서 차별화된다.\n이 방법에서는 먼저 결측값이 없는 관측치를 기준으로, 결측값이 포함된 관측치와의 거리를 계산한다. 거리 측정에는 유클리드 거리, 맨해튼 거리, 마할라노비스 거리 등 다양한 지표가 사용될 수 있으며, 변수 간 스케일 차이를 보정하기 위해 정규화(normalization)를 적용하기도 한다.\n그 후, 계산된 거리값을 기준으로 가장 가까운 K개의 관측치를 선택한다. 이때 K 값은 교차검증(cross-validation) 등을 통해 최적의 값을 자동으로 결정할 수 있으며, 고정된 값이 아닌 데이터 구조에 맞게 유연하게 설정된다.\n결측값이 연속형 변수인 경우에는 K개의 이웃값의 평균이나 중앙값을 사용하여 대체하며, 범주형 변수인 경우에는 가장 자주 등장하는 값(최빈값, mode)을 사용한다.\n예를 들어, 어떤 응답자의 소득 정보가 결측된 상황에서 그 사람의 연령, 직업, 교육 수준 등이 다른 응답자와 유사하다면, 이와 유사한 응답자 K명을 찾아 이들의 소득 평균으로 결측값을 대체한다. 이렇게 하면 개별 응답자의 맥락을 반영한 대체가 가능해져, 보다 정확하고 현실적인 결측값 보완이 가능해진다.\nKNN 기반 대체는 연속형 변수와 범주형 변수 모두에 적용 가능하고, 데이터 분포를 유지하면서도 단순 대체 방식보다 유연하고 정밀한 보완이 가능하다는 점에서 강력한 결측 대체 기법으로 평가된다.\n\\(Y_{\\text{miss},i} = \\frac{1}{K}\\sum_{j \\in KNN(i)}Y_{j}\\), 여기서 \\(KNN(i)\\)은 무응답자 \\(i\\) 와 가장 가까운 \\(k\\) 개의 응답자 집합,\\(Y_{j}\\)은 선택된 이웃 응답자의 값이다.\n예를 들어, 어떤 응답자의 키(height)가 결측된 상황을 가정해 보자. 이때 KNN 기반 대체 방법을 적용하면 다음과 같은 절차로 결측값을 보완할 수 있다.\n먼저, 기존 응답자들의 연령(Age), 체중(Weight), 성별(Gender) 등의 정보를 활용하여 결측된 응답자와의 거리를 계산한다. 이때 거리 계산은 유클리드 거리와 같은 수학적 기준을 사용하며, 변수들의 척도 차이를 보정하기 위해 표준화가 선행될 수 있다.\n그다음, 계산된 거리값을 바탕으로 가장 가까운 K명의 응답자를 선택한다. 이웃 수 K는 사전에 지정하거나 교차검증을 통해 결정할 수 있으며, 일반적으로 3명 또는 5명 등의 값이 많이 사용된다.\n선정된 K명의 응답자 중 키(height) 정보가 결측되지 않은 사람들의 키 값을 평균 내어, 해당 평균값을 결측된 응답자의 키 대신 입력한다. 이를 통해 결측값은 유사한 특성을 가진 집단의 평균을 반영한 값으로 대체되며, 데이터의 구조적 일관성을 유지할 수 있다.\n이러한 방식은 단순 평균 대체보다 개별 응답자의 맥락을 반영할 수 있다는 점에서 통계적 타당성과 해석 가능성을 동시에 확보할 수 있다.\n\n\n(3) 신경망(Neural Network) 기반 대체\n신경망을 활용한 결측값 대체는, 특히 변수 간 관계가 복잡하고 비선형적인 경우에 효과적인 방법이다. 이때 주로 사용되는 구조는 다층 퍼셉트론(MLP, Multi-Layer Perceptron)으로, 입력층(input layer), 하나 이상의 은닉층(hidden layer), 그리고 출력층(output layer)으로 구성된다.\n결측값 대체를 위한 일반적인 절차는 다음과 같다.\n\n1. 데이터 전처리\n먼저, 결측값이 없는 관측값을 기반으로 입력 변수(예: 연령, 성별, 직업 등)와 타겟 변수(예: 소득, 키, 체중 등)를 분리하여 모델 학습용 데이터를 구성한다. 변수 간 범위 차이가 클 경우에는 정규화(normalization) 또는 표준화(standardization)를 통해 모델 학습을 안정화시킨다.\n\n\n2. 신경망 모델 학습\n전처리된 데이터를 이용해 신경망 모델을 학습시킨다. 이 과정에서 모델은 입력 변수와 타겟 변수 간의 비선형 관계를 반복적으로 학습하면서, 결측된 값을 예측할 수 있는 패턴을 습득한다. 역전파(backpropagation) 알고리즘과 옵티마이저(예: Adam, SGD)를 활용해 가중치를 조정하며 학습을 진행한다.\n\n\n3. 결측값 예측 및 대체\n학습된 모델을 사용하여 결측이 발생한 관측값의 입력 변수들을 모델에 넣고, 해당 타겟 변수(결측된 값)를 예측한다. 이렇게 생성된 예측값을 원래 데이터의 결측값에 대체하여 보완한다.\n예를 들어, 어떤 응답자의 체중 데이터가 누락된 경우, 신경망은 동일한 조사에서 얻은 연령, 키, 성별 등의 정보를 활용하여 체중을 예측하고, 그 값을 해당 응답자의 결측값에 입력한다.\n이 방식은 단순 대체 방법에 비해 학습 기반의 정교한 예측을 제공하며, 특히 변수 간 관계가 복잡한 대규모 데이터셋에서 우수한 성능을 발휘할 수 있다.\n신경망은 다층 퍼셉트론(MLP)을 기반으로 가중치 \\(w\\)를 최적화하여 결측값을 예측한다.\n\\(Y_{\\text{miss}} = f(WX + b)\\) 여기서, \\(f\\)은 활성화 함수(예: ReLU, Sigmoid), \\(W\\)은 가중치, \\(X\\)은 입력 변수, \\(b\\)는 편향이다.\n예를 들어, 건강 관련 조사에서 일부 응답자의 BMI(체질량지수) 정보가 누락된 경우, 신경망을 이용해 이 결측값을 보완할 수 있다. 이때 먼저 BMI와 밀접하게 관련된 변수들, 예컨대 연령, 체중, 성별, 운동 습관 등의 데이터를 활용하여 신경망 모델을 학습시킨다.\n모델 학습이 완료되면, BMI가 결측된 응답자에 대해 해당 변수들을 입력하여 BMI를 예측한다. 이렇게 예측된 BMI 값은 결측된 위치에 삽입되어 데이터셋을 보완하게 된다. 이 과정은 단순히 평균이나 중앙값을 넣는 방식보다 더 정밀하게 데이터의 패턴을 반영할 수 있다는 장점이 있다.\n\n\n\n7. 재조사 및 보완 조사(Follow-up Survey & Call-back)\n재조사 및 보완 조사(Follow-up Survey & Call-back)는 최초 조사에서 응답하지 않은 대상자에게 다시 연락하여 실제 응답을 확보하는 전략이다. 이 방법은 단순히 통계적 기법으로 결측값을 대체하는 방식과 달리, 응답자에게 직접 접근하여 응답을 얻는다는 점에서 데이터의 정확성과 신뢰도를 크게 향상시킨다.\n이러한 접근은 특히 정부 통계, 보건의료 연구, 선거 여론 조사처럼 정책 결정이나 사회적 영향력이 큰 조사에서 중요하게 활용된다. 보완 조사는 전화, 이메일, 방문 등의 다양한 방식으로 수행되며, 무응답 편향을 줄이고 대표성을 높이는 데 기여한다. 또한, 재조사를 통해 무응답자의 특성과 응답행태를 파악할 수 있어 향후 조사 설계의 개선에도 유용하다.\n\n후속 조사(Follow-up Survey)\n후속 조사는 초기 조사에서 응답하지 않은 대상자에게 다시 연락하여 응답을 유도하는 방식으로, 무응답률을 낮추고 조사 결과의 신뢰도를 높이는 데 중요한 역할을 한다. 이러한 후속 조사는 다양한 형태로 이루어질 수 있다.\n가장 일반적인 방법 중 하나는 전화 재조사(call-back survey)이다. 이는 초기 연락에서 응답을 얻지 못한 대상자에게 다시 전화를 걸어 설문 참여를 요청하는 방식이다. 전화 재조사는 비교적 빠르게 응답을 확보할 수 있는 장점이 있으며, 응답자의 부담이 적을 경우 응답률이 높아질 가능성이 크다.\n또 다른 방법으로는 이메일이나 문자 메시지를 활용한 독려(contact reminder)가 있다. 설문 링크나 마감일, 간단한 조사 목적을 포함한 메시지를 전송함으로써 대상자에게 설문 참여를 다시 상기시키는 방식이다. 이 방법은 시간과 비용이 적게 들고, 자기기입식 조사와 같이 비접촉 방식의 설문에서 특히 효과적이다.\n보다 적극적인 방식으로는 대면 방문(face-to-face interview)이 있다. 이는 조사원이 직접 대상자의 집을 방문하여 설문에 응하도록 요청하는 방식으로, 인구총조사나 국가 단위의 중요 조사에서 주로 활용된다. 응답자가 조사원과 직접 대화하면서 설문에 참여할 수 있어 응답률을 크게 향상시킬 수 있는 반면, 시간과 비용 부담이 크다는 단점이 있다.\n예를 들어, 선거 여론조사에서 초기 응답률이 낮은 경우, 조사 기관은 응답하지 않은 대상자에게 다시 전화를 걸거나 문자 메시지를 보내 설문 참여를 유도할 수 있다. 이러한 후속 조치를 통해 조사에 대한 응답을 확보하고, 조사 결과의 대표성과 신뢰성을 제고할 수 있다.\n\n\n보완 조사(Supplementary Survey)\n기존 조사 방식과는 다른 대체 수단을 활용하여 무응답자에게서 응답을 확보하는 방식은, 조사 대상자의 편의성과 접근성을 고려하여 설계된 전략이다. 이는 조사 모드 변경(mode switch) 또는 혼합 모드 설계(mixed-mode design)로도 불리며, 특정 조사 방식에 대한 응답자의 선호나 제약을 고려해 유연하게 대응할 수 있다는 장점이 있다.\n예를 들어, 전화 설문을 중심으로 한 의료 연구에서 응답률이 낮은 경우, 조사자는 대상자에게 우편 설문지를 보내거나, 온라인 응답 링크를 제공하여 다른 방식으로 응답할 수 있는 기회를 부여할 수 있다. 이는 시간대나 장소, 개인적 선호 등 다양한 이유로 기존 조사 방식에 응답하지 못한 사람들에게 효과적인 대안이 될 수 있다.\n이러한 보완 조사를 통해 확보된 응답 데이터는 원래 조사 데이터와 결합되어 분석되며, 이는 전체 데이터의 완전성을 높이고 무응답 편향을 줄이는 데 기여한다. 단, 조사 방식이 다를 경우 질문 해석이나 응답 방식의 차이로 인해 모드 효과(mode effect)가 발생할 수 있으므로, 결합 시에는 적절한 통계적 조정이 필요할 수 있다.\n\n\n\n8. 데이터 결합(Data Fusion)\n기존 조사 방식과는 다른 대체 수단을 활용하여 무응답자에게서 응답을 확보하는 방식은, 조사 대상자의 편의성과 접근성을 고려하여 설계된 전략이다. 이는 조사 모드 변경(mode switch) 또는 혼합 모드 설계(mixed-mode design)로도 불리며, 특정 조사 방식에 대한 응답자의 선호나 제약을 고려해 유연하게 대응할 수 있다는 장점이 있다.\n예를 들어, 전화 설문을 중심으로 한 의료 연구에서 응답률이 낮은 경우, 조사자는 대상자에게 우편 설문지를 보내거나, 온라인 응답 링크를 제공하여 다른 방식으로 응답할 수 있는 기회를 부여할 수 있다. 이는 시간대나 장소, 개인적 선호 등 다양한 이유로 기존 조사 방식에 응답하지 못한 사람들에게 효과적인 대안이 될 수 있다.\n이러한 보완 조사를 통해 확보된 응답 데이터는 원래 조사 데이터와 결합되어 분석되며, 이는 전체 데이터의 완전성을 높이고 무응답 편향을 줄이는 데 기여한다. 단, 조사 방식이 다를 경우 질문 해석이나 응답 방식의 차이로 인해 모드 효과(mode effect)가 발생할 수 있으므로, 결합 시에는 적절한 통계적 조정이 필요할 수 있다.\n\n정확한 키 매칭(Exact Matching)\n유일한 식별자(Unique Identifier)를 활용한 데이터 결합 방식은 가장 정밀하고 신뢰도 높은 방법으로, 주민등록번호, 사업자등록번호, 학생번호 등 각 개인 또는 단위를 고유하게 식별할 수 있는 정보를 기반으로 서로 다른 데이터셋을 연결한다.\n이 방식의 핵심 장점은 데이터 간 연결 정확도가 매우 높다는 점이다. 예를 들어, 인구조사 데이터와 국세청의 소득 신고 자료를 주민등록번호를 기준으로 결합하면, 설문에서 소득 정보를 응답하지 않은 무응답자의 소득 데이터를 행정 기록을 통해 보완할 수 있다. 마찬가지로, 환자의 건강 관련 설문조사 데이터를 건강보험청구자료와 연결하면 병원 방문 이력이나 치료 내역을 확인할 수 있어, 설문 응답 외에 객관적 행태 정보를 확보할 수 있다.\n하지만 이러한 방식은 개인정보 보호 측면에서 큰 주의가 필요하다. 유일 식별자를 직접 사용하는 경우, 개인 식별 가능성이 매우 높아지므로, 법적·윤리적 제한이 뒤따르며, 데이터 마스킹이나 가명 처리 등의 조치가 필요하다. 따라서, 이 방식은 통상적으로 통계청, 건강보험공단 등 공공기관이 보안 체계 하에 한정적으로 운영하거나, 연구 목적에 따라 엄격한 심사를 거친 후에만 사용된다."
  },
  {
    "objectID": "notes/survey/sample_design.html",
    "href": "notes/survey/sample_design.html",
    "title": "조사방법론. 2. 표본설계",
    "section": "",
    "text": "chapter 1. 표본설계 개요\n표본 설계는 설문조사가 모집단의 특성을 신뢰성 있고 효율적으로 반영하며 조사 목적을 충실히 달성하기 위해 필요한 핵심 과정이다.\n설문조사의 주요 목적은 모집단 전체의 특성을 이해하거나 추론하는 것이다. 그러나 모집단의 모든 구성원을 조사하는 것은 현실적으로 어렵기 때문에, 이를 대체할 수 있는 대표 표본을 구성하는 과정이 필수적이다. 표본 설계를 통해 모집단의 다양한 특성을 균형 있게 반영할 수 있으며, 이는 신뢰할 수 있는 통계 추정의 기반이 된다.\n표본이 특정 집단에 치우치거나 무작위성이 확보되지 않는다면 조사 결과는 왜곡될 수 있다. 표본 설계는 모집단의 모든 하위 그룹이 적절히 포함되도록 구성하여 편향을 방지하고, 통계적 균형을 유지하는 데 기여한다.\n또한, 표본 설계는 조사 자원을 효율적으로 사용하는 데 중요한 역할을 한다. 제한된 시간과 예산 안에서 필요한 정확도를 확보하기 위해, 층화 표본이나 군집 표본 등 다양한 표본 추출 방법이 활용된다. 이는 조사 비용을 절감하면서도 충분한 정보를 얻을 수 있도록 돕는다.\n표본이 체계적으로 설계되면 통계적 편향과 오차가 줄어들고, 결과적으로 조사 결과의 신뢰성이 향상된다. 이는 조사 데이터를 기반으로 한 정책 수립이나 연구 분석의 질을 높이는 데 직접적인 영향을 미친다.\n마지막으로, 설문조사는 특정 하위 집단에 대한 통찰을 요구하는 경우가 많다. 표본 설계를 통해 특정 집단을 적절히 포함하거나 과대표함으로써, 해당 집단에 대한 정밀한 분석이 가능해진다. 이를 통해 보다 세분화된 해석과 의사결정이 이루어질 수 있다.\n\n1. 용어\n\n모집단 population\n조사를 할 때 정보를 얻고자 하는 관심 집단, 즉 관심 대상이 되는 모든 사람들의 모임을 모집단이라고 한다.\n\n목표 모집단은 조사 대상 전체를 의미하며, 조사 시점 기준의 유권자가 이에 해당한다.\n조사 모집단은 실제로 조사가 가능한 모집단으로, 예를 들어 전화번호부 CD에 등재된 유권자가 이에 해당한다.\n모수는 모집단의 관심 특성을 의미하며, 예를 들어 A 후보에 대한 지지율이 이에 해당한다.\n\n\n\n표본 sample\n모집단 중 조사를 위하여 추출한 일부를 표본이라고 한다.\n추정량은 모수를 추정하기 위하여 표본으로부터 계산된 통계량이며, 이를 통계량(statistic)이라고도 한다. 예를 들어, 표본 1,000명 중 A 후보를 지지하는 사람이 560명이라면, A 후보의 지지율에 대한 추정량은 56%이다.\n\n\n표본 프레임\n표본을 추출하기 위해 모집단 대상을 식별하고, 컨택(contact)에 필요한 정보를 포함한 목록을 말한다. 일반적으로 식별 아이디, 이름, 주소, 연락처 등으로 구성된다. 예를 들어 전화번호 CD를 활용한 조사에서는 해당 가구의 가구원 정보를 알 수 없기 때문에, 조사원이 “최근 생일이 지난 유권자”를 선정하거나, 현장에서 할당 인원을 조정하며 가구원 중 한 명을 조사 대상으로 선정한다. 표본프레임의 3가지 요건은 다음과 같다.\n\n\n포괄성: 표본프레임은 조사 가능한 대상을 모두 포함하고 있어야 한다.\n추출 확률의 동일성: 모집단의 각 구성원이 표본으로 추출될 확률이 동일해야 한다.\n효율성: 사전에 조사되기를 바라는 사람들로만 표본프레임을 구성하는 것은 불가능하지만, 가능한 한 조사 목적에 부합하는 대상이 추출되도록 효율성을 고려한다.\n\n\n표본추출\n\n표본추출은 조사 대상인 표본을 모집단으로부터 확률적으로 선택하는 과정이며, 조사 목적을 최대한 달성할 수 있도록 설계되어야 한다.\n\n표본 크기\n\n표본 크기는 조사의 신뢰수준, 표본추출 방법, 허용오차(예: 변동계수) 등을 고려하여 결정한다.\n\n조사단위\n\n표본추출단위: 표본을 추출하는 기본 단위. 예를 들어 전화여론조사의 경우 ’가구’가 해당된다.\n\n\n조사단위: 실제로 응답하는 사람. 대부분의 경우 표본추출단위와 조사단위는 일치하지만, 다른 경우도 존재한다. (상이한 경우) 전화여론조사에서 가구를 추출한 뒤, 그 안의 가구원 중 한 명이 응답하는 경우 (동일한 경우) 인터넷 쇼핑몰 이용 고객 실태조사에서 고객 자체가 추출단위이자 조사단위인 경우\n\n\n\n\n2. 표본과 추정\n모든 설문조사 표본이 확률적 방법으로 선택되는 것은 아니다. 많은 설문조사는 즉흥적으로 표본을 구성하거나, 조사 목적에 부합하도록 표본을 선택한다.\n예를 들어, 쇼핑몰에 방문하는 사람들에게 설문 응답을 요청하고, 일정 수의 인터뷰가 완료될 때까지 조사를 계속 진행하는 경우가 있다. 이러한 즉흥적 또는 편의 표본추출 방법에는 공통된 약점이 존재하는데, 바로 모집단의 특성을 설명하기 위한 이론적 기반이 부족하다는 점이다.\n이에 반해, 확률 표본추출은 단일 표본으로부터 모집단에 대해 통계적으로 유의미한 진술을 할 수 있는 기반을 제공하며, 일정한 신뢰 수준에서 추론이 가능하다는 장점이 있다.\n외식비용 가구 설문조사의 프레임 모집단은 전화 서비스를 이용하는 모든 가구의 성인을 포함한다. 외식비의 전체 분포를 관찰하거나 완벽히 알 수는 없다. 설문조사는 이러한 분포를 알아내기 위해 수행된다. 모집단 개별 개체는 \\(Y\\)로 표시하고 모집단 평균은 \\(\\overline{Y}\\), 모집단 분산 \\(S^{2}\\)으로 표현하고 설문조사의 주목적은 \\(\\overline{Y}\\)를 추정하는 것이다.\n각 설문조사는 여러 가지 발생 가능한 확률 표본 설계 중 하나의 실현으로 간주될 수 있다. 표본 조사 결과는 소문자를 사용하여 표현한다. 표본 관측값 \\(y\\) 값은 모집단 분포에 대한 평균과 분산을 가지고 있다. 표본평균은 \\(\\overline{y}\\)로 불리며 이를 이용하여 \\(\\overline{Y}\\)를 추정한다. \\(y_{i}\\) 관측값의 표본분산은 \\(s^{2}\\)으로 표시된다.\n표본평균의 표집 분포 분산을 추정하기 위해 하나의 표본 실현에서 계산을 사용하여 \\(V(\\overline{y})\\)를 추정한다. 표본평균의 표집 분포 분산의 또 다른 용어는 ”표본평균의 표본분산”이며 그 제곱근은 ”평균의 표준오차”라고 한다.\n주어진 표본 조사(하나의 실현)에서 프레임 모집단 평균을 추정하고자 할 때, 표준오차를 사용하여 주어진 추정치에 대한 신뢰 구간을 설정한다. ”신뢰구간”은 모든 표본 실현에서 계산된 평균이 전체 프레임 모집단 평균으로부터 일정한 거리 내에 있을 신뢰 수준을 설명한다(포괄성, 비응답 및 기타 설문 조사 오류를 무시한 경우).\n예를 들어, 소비자 조사에서 표본 외식비 평균을 \\(\\overline{y} = 42\\)(천원)로 추정했다고 가정하자. 이 추정치의 표준오차를 2(천원)으로 추정 했다면, 95% 신뢰구간은 (42 - 2*2, 42 + 2*2) = (38, 46)가 된다.\n표본통계의 표준오차는 동일한 설계에서 가능한 표본 실현들 간의 통계적 분포 또는 변동성을 측정하는 지표이다. 표준오차는 \\(se(\\overline{y}) = \\sqrt{v(\\overline{y})}\\) 이며, 표본분산의 제곱근으로 계산된다.\n\n\n\n\n\n\n\n\n\n구분\n모집단 분포\n표본 분포\n표본평균 분포\n\n\n\n\n현황\n실현된 분포\n모름\n모름\n\n\n크기\n\\[i = 1,2,...,n\\]\n\\[i = 1,2,...,N\\]\n\\[s = 1,2,...,S\\]\n\n\n개별 원소\n\\[y_{i}\\]\n\\[Y_{i}\\]\n\\[{\\overline{y}}_{s}\\]\n\n\n평균\n\\[\\overline{y}\\]\n\\[\\overline{Y}\\]\n\\[E({\\overline{y}}_{s})\\]\n\n\n분포 분산\n\\[s^{2}\\]\n\\[S^{2}\\]\n\\[V(\\overline{y})\\]\n\n\n표준오차\n\\[s\\]\n\\[S\\]\n\\[se(\\overline{y})\\]\n\n\n\n샘플링으로 인한 오류의 정도는 설계의 네 가지 기본 원칙에 의해 결정된다.\n\n선택된 표본의 크기.\n다른 모집단 요소가 표본에 선택될 가능성.\n개별 요소가 독립적으로 또는 그룹(요소 또는 클러스터 샘플로 불리는) 내에서 선택되었는지 여부\n표본이 샘플 내 주요 하위 모집단(층화)의 대표성을 제어하도록 설계되었는지 여부\n\n\n\n3. 표본설계 절차\n\n(1) 조사 목표 모집단 정의\n조사의 출발점은 명확한 조사 목표를 설정하는 것이다. 이는 어떤 주제에 대해 누구를 대상으로 정보를 수집할 것인지를 규정하는 단계이다. 예를 들어, 고객 만족도를 평가하거나 특정 지역의 유권자 여론을 파악하고자 할 때, 각각의 조사 목적에 따라 관심 대상이 되는 모집단이 달라진다. 따라서 조사 목표에 부합하는 모집단을 명확히 정의하는 것이 설계 과정의 핵심이다.\n\n\n(2). 모집단 정의 및 분석\n조사 목표가 설정되면, 그에 따라 모집단의 범위를 명확히 정의해야 한다. 모집단이란 조사 대상이 되는 전체 집단으로, 예를 들어 특정 연령대의 고객이나 특정 지역의 거주자 등이 이에 해당한다. 모집단을 정의한 후에는 그 특성을 구체적으로 파악하는 작업이 필요하다. 모집단의 크기, 인구 구성, 지리적 분포와 같은 정보는 표본 설계의 기초가 되며, 이러한 분석을 통해 조사 대상의 대표성을 확보할 수 있다. 모집단에 대한 충분한 분석은 조사 과정 전반의 신뢰성을 높이며, 궁극적으로 정확하고 의미 있는 조사 결과를 도출하는 데 필수적인 단계이다.\n\n\n(3). 표본 프레임 정의\n표본을 추출하기 위해서는 먼저 모집단을 대표할 수 있는 표본 프레임을 정의해야 한다. 표본 프레임은 모집단의 구성원을 식별하고 접근할 수 있도록 구성된 명단이나 데이터베이스로, 예를 들어 고객 리스트, 유권자 명부, 전화번호 디렉터리 등이 이에 해당한다.\n표본 프레임이 조사 목적에 부합하려면 그 정확성과 적절성을 면밀히 평가해야 한다. 프레임이 모집단 전체를 충분히 포괄하고 있는지, 동일한 대상이 중복 포함되어 있지는 않은지, 정보가 최신 상태로 유지되고 있는지 등을 점검하는 과정이 필요하다. 이러한 검토를 통해 불포함 오류나 중복 오류와 같은 표본 추출상의 문제를 최소화할 수 있다.\n\n\n(4). 표본 설계 유형 선택\n표본 설계는 조사 목표와 모집단의 특성에 따라 가장 적합한 추출 방법을 선택하는 과정이다. 이는 조사 결과의 신뢰성과 대표성을 확보하기 위한 핵심 단계로, 단순 무작위추출, 층화추출, 집락추출, 다단계추출 등 다양한 방법 중에서 조사 상황에 맞는 방식을 선택하게 된다. 적절한 표본 설계 유형을 선택하기 위해서는 모집단의 이질성 여부, 표본 프레임의 구조, 예산 및 시간 제약 등 여러 요소를 종합적으로 고려해야 한다.\n\n\n(5). 표본 크기 결정\n표본의 크기는 조사 결과의 정밀도와 신뢰도를 확보하는 데 직접적인 영향을 미치므로 신중하게 결정되어야 한다. 표본크기는 조사 목적, 허용 오차, 신뢰 수준, 모집단의 변동성, 그리고 예산 및 시간 제약 등을 종합적으로 고려하여 산정한다.\n\n\n(6). 표본 추출\n표본 추출은 사전에 설계된 표본 설계 유형에 따라 모집단에서 실제 표본을 선택하는 과정이다. 이 과정에서는 주관적 판단이 개입되지 않도록 무작위성을 철저히 확보해야 하며, 이는 추후 통계적 추론의 타당성을 담보하는 핵심 요건이다.\n\n\n(7). 조사 및 데이터 수집\n표본으로 선정된 대상에게 설문조사, 전화 인터뷰 등 다양한 방법을 통해 자료를 수집한다. 높은 응답률을 확보하기 위해 조사 전 사전 안내를 실시하고, 비응답자에 대해서는 추후 연락을 계획하는 등 응답 유도를 위한 전략이 병행된다.\n\n\n(8). 자료 분석 및 결과 검토\n수수집된 데이터를 분석하여 모집단의 특성을 추정한다. 분석 과정에서는 표본 설계에 따른 가중치를 적용하여 편향을 보정하고, 설계 효과(design effect)를 산출함으로써 표본 설계가 추정 결과에 미친 영향을 평가한다.\n\n\n(9). 결과 보고\n분석 결과는 조사 목적에 맞게 해석하여 보고되며, 조사 결과와 함께 사용된 표본 설계 방법, 표본 추출 방식, 표본 크기, 조사 한계점 등을 함께 제시해야 한다. 이를 통해 결과의 신뢰성, 정밀도, 해석 가능성을 독자가 판단할 수 있도록 한다.\n\n\n\n\nchapter 2. 표본설계 방법\n\n1. 단순임의추출방법 SRS Simple Random Sampling\n\n\n(1) 정의 및 절차\n\n\n\n\n\n단순임의 표본추출은 모집단에 포함된 모든 요소가 동일한 확률로 선택될 수 있도록 하는 표본 추출 방법이다. 즉, 크기 n의 모든 가능한 표본이 동일한 확률로 선택될 수 있도록 설계된다. 이 방법은 대표성과 무작위성을 보장하는 가장 기본적인 확률 표본 추출 방식으로, 표본 추출의 이론적 기준점이 된다.\n단순임의 표본추출의 절차는 다음과 같다.\n\n\n표본 프레임에 포함된 N개의 모든 원소에 일련번호를 부여한다.\n난수 생성기를 활용하여 중복되지 않는 n개의 난수를 생성한다.\n해당 난수에 해당하는 원소를 표본으로 선택한다.\n\n\n이 과정은 모집단의 각 구성원이 표본에 포함될 동등한 기회를 가지도록 하며, 편향 없는 표본 구성을 가능하게 한다.\n\n\n(2) 추정\n\n단순 무작위 표본에서 평균 및 표본분산 계산\n\\(\\overline{y} = \\frac{1}{n}\\overset{n}{\\sum_{j = 1}}y_{i}\\), \\(v(\\overline{y}) = \\frac{(1 - f)}{n}s^{2}\\), 여기서 \\(f = n/N\\) 표본 비율, \\(s^{2}\\)은 표본분산이다. \\((1 - f)\\)은 유한모집단보정계수(Finite Population Correction, FPC)이라 하고 \\(N\\)이 충분히 크면 1에 근사하여 \\(v(\\overline{y}) \\approx \\frac{s^{2}}{n}\\) 이다.\n\\(v(\\overline{y})\\)는 표본평균의 샘플링 분산에 대한 표본 기반 추정치에 불과하다는 점을 주목할 필요가 있다. 여기에는 실제 모집단 값 \\(V(\\overline{y})\\)이 존재하며 \\(v(\\overline{y})\\)는 \\(V(\\overline{y})\\)의 불편 추정치로 간주된다. 여론조사와 같이 응답자의 선호 비율을 묻는 경우 표본평균(표본비율)의 표본분산은 다음과 같다. \\(v(p) = \\frac{(1 - f)}{n - 1}p(1 - p)\\). 표본분산 \\(v(p)\\)는 \\(fpc\\)(유한모집단보정계수), 표본크기 \\(n\\), 모집단 비율 \\(p\\) 값 자체에만 의존하므로 \\(y_{i}\\) 값을 알 필요 없이 계산 가능하다.\n표본크기 결정 시 모평균 추정의 경우 모집단 분산 \\(S^{2}\\)에 대한 정보가 있어야 하지만 모비율 추정 시에는 보수적으로 \\(p = 0.5\\)을 사용하여 결정한다.\n\n\n모집단 평균 95% 신뢰구간\n\\(\\overline{y} + z_{0.975}se(\\overline{y})\\), 여기서 \\(se(\\overline{y}) = \\frac{s}{\\sqrt{n}}\\)\n\n\n모비율 평균 95% 신뢰구간\n\\(\\widehat{p} + z_{0.975}se(\\overline{y})\\), 여기서 \\(se(\\widehat{p}) = \\frac{p(1 - p)}{\\sqrt{n}}\\)\n\n\n표본크기 허용오차 margin of error 표본오차: \\(e\\)\n【표본크기 : 유한 모집단】\n모평균 추정: \\(n = \\frac{N \\cdot z^{2} \\cdot S^{2}}{(N - 1) \\cdot e^{2} + z^{2} \\cdot S^{2}}\\)\n모비율 추정: \\(n = \\frac{N \\cdot z^{2} \\cdot p \\cdot (1 - p)}{(N - 1) \\cdot e^{2} + z^{2} \\cdot p \\cdot (1 - p)}\\)\n【표본크기 : 무한 모집단】\n모평균 추정: \\(n = \\frac{z^{2} \\cdot S^{2}}{e^{2}}\\)\n모비율 추정: \\(n_{0} = \\frac{z^{2} \\cdot p \\cdot (1 - p)}{e^{2}}\\) (유한 \\(n = \\frac{n_{0}}{1 + \\frac{n_{0} - 1}{N}}\\))\n\n\n\n2. 군집추출방법 cluster sampling\n\n\n\n\n\n\n단순임의표본추출과 군집표본추출의 비교\n단순임의표본추출은 모집단의 모든 구성 요소 중에서 각각이 동일한 확률로 선택될 수 있도록 표본을 추출하는 방법이다. 이 방식은 통계적으로 가장 이상적인 방법 중 하나지만, 실제 조사에서는 표본 프레임의 구성과 개별 요소에 접근하는 데 드는 시간과 비용이 상당히 크다는 한계가 있다.\n이러한 실용적 제약을 해결하기 위해 사용되는 방법이 군집표본추출이다. 군집표본추출은 모집단을 사전에 정의된 군집(집단) 단위로 나누고, 이 군집들 중 일부를 무작위로 선택한 뒤, 선택된 군집 내의 모든 요소를 조사하는 방식이다. 이는 전체 프레임을 구성하지 않고도 비교적 적은 비용으로 표본을 수집할 수 있다는 장점이 있다.\n\n\n군집표본추출의 절차와 사례\n예를 들어, 표본 프레임이 총 60가구로 구성되어 있고, 그 중 30가구는 O로, 나머지 30가구는 +로 표시되어 있다고 하자. 전체 가구 중 20가구를 조사 대상으로 선택해야 하는 경우, 단순임의추출을 사용할 경우 60가구 중 무작위로 20가구를 선택하게 된다.\n반면 군집표본추출을 적용하면, 예컨대 10가구씩 구성된 6개의 단지를 군집으로 보고, 이 중 2개의 단지를 무작위로 선택한 후, 선택된 단지의 모든 가구(총 20가구)를 조사하게 된다.\n\n\n군집표본추출의 장점과 주의점\n군집표본추출은 조사 단위를 군집화함으로써 조사에 소요되는 시간과 비용을 크게 줄일 수 있다. 예를 들어 단지 단위로 이동하거나 접촉하는 것이 개별 가구를 조사하는 것보다 훨씬 효율적일 수 있다.\n그러나 이 방법에는 중요한 단점도 존재한다. 만약 무작위로 선택된 두 개의 단지(예: 5번과 6번 단지)에 O로 표시된 가구가 거의 없는 경우, 전체 표본에서 O 가구의 비율이 실제 모집단에서의 비율과 현저히 달라질 수 있다. 이로 인해 표본의 대표성이 훼손되고, 왜곡된 추정 결과를 초래할 수 있다.\n\n\n\n(1) 군집표본 추출 절차\n군집표본추출은 모집단을 일정 기준에 따라 여러 개의 소집단, 즉 군집으로 나눈 뒤, 일부 군집만을 무작위로 선택하고 그 안의 구성원들을 표본으로 조사하는 방법이다. 모집단을 그룹으로 나눈다는 점에서는 층화추출과 유사하지만, 군집 간에는 응답의 차이가 없다고 가정한다는 점에서 차이가 있다. 따라서 한 군집이 무작위로 선택되면, 그 안에 포함된 구성원만을 대상으로 표본을 추출하게 된다.\n군집표본추출의 절차는 다음과 같다.\n\n\n모집단을 인구학적 특성이나 지리적 위치 등을 기준으로 군집으로 나눈다.\n난수를 이용하여 군집을 무작위로 선택한다.\n선택된 군집에 속한 모든 응답자를 표본으로 포함시킨다. 단, 군집의 크기가 표본 크기보다 클 경우에는 군집 내부에서 다시 단순임의추출 방법으로 일부 응답자만 선택한다.\n\n\n군집추출은 조사 비용과 시간을 줄이는 데 효과적이지만, 군집 간의 동질성이 확보되지 않을 경우 표본의 대표성이 떨어질 수 있으며, 그에 따라 추정의 정확도도 낮아질 수 있다. 따라서 군집을 설정할 때에는 군집 간 차이를 최소화하고, 군집 내의 다양성을 충분히 확보하는 것이 중요하다.\n\n가구조사 표본추출 사례\n가구조사에서는 규모 비례 확률 방법을 사용하여 전국을 200개 지역으로 층화하고, 이후 일련의 계통추출 과정을 통해 가구 내 응답자를 선택한다. 표본추출은 다음과 같은 네 단계로 이루어진다.\n첫째, 전국을 12개 층으로 구분한다. 6개 광역도시는 서울, 부산, 대구, 인천, 대전, 광주이며, 8개 도는 경기, 강원, 충청남북도, 경상남북도, 전라남북도로 구분된다. 도 지역은 다시 시, 읍, 면으로 세분화한다.\n둘째, 6개 도시와 각 도의 시·읍·면을 모집단으로 배열한 후, 각 지역 내 동(또는 면의 경우 리)을 계통추출 방식으로 선택한다. 이 단계에서 선택된 동 또는 리는 1차 표본 지역(primary sampling location)으로 정의된다. 표본의 전체 크기가 1,500일 경우, 약 200개의 1차 표본 지역이 확보된다.\n셋째, 실질적인 최종 표본 지역(actual final sampling location)인 반 또는 부락이 선택될 때까지 계통추출을 반복한다. 반은 대체로 약 20가구, 부락은 20~80가구로 구성된다.\n넷째, 조사원은 선정된 표본 지역을 직접 방문하여 주민 명부를 바탕으로 8가구를 임의로 선정한다. 각 가구에서 응답자는 18세 이상인 사람 중 생일이 가장 빠른 사람으로 지정하며, 최초 방문 시 해당 응답자를 만나지 못한 경우에는 재방문하여 조사를 진행한다.\n이 사례는 다단계 층화 계통추출의 전형적인 구조를 보여주며, 실제 조사의 대표성과 실현 가능성을 동시에 고려한 표본설계의 예라 할 수 있다. 필요하시면 이 내용을 도식화하거나 표본설계 흐름도로도 제공해드릴 수 있습니다.\n\n\n\n(2) 표본평균 추정\n평균은 SRS와 동일하게 계산되지만, 각 단지 내의 모든 소득을 합한 후, 각 단지의 합계를 더하고 최종적으로 표본크기로 나누는 방식으로 이루진다.\n\\(\\overline{y} = \\frac{\\sum_{\\alpha = 1}^{a}\\sum_{\\beta = 1}^{B}y_{\\alpha\\beta}}{aB}\\), 여기서 \\(a\\)는 단지 수, \\(\\beta\\)는 가구 수이다.\n\n평균의 표본분산\n무작위화는 단지에만 적용되며, 단지가 표본 단위이다. 어떤 단지가 선택되는지에 따라 \\(\\overline{y}\\)의 값이 달라진다. 어떤 면에서는 모든 것이 SRS와 동일하게 유지되지만, 군집을 표본 내 요소로 간주한다는 점이 다르다.\n\\(v(\\overline{y}) = \\left( \\frac{1 - f}{a} \\right)s_{a}^{2}\\), 여기서 \\(s_{a}^{2}\\)는 \\(a\\)개의 단지에 걸친 평균 소득의 변동성을 나타낸다. 즉, \\(s_{a}^{2} = \\left( \\frac{1}{a - 1} \\right)\\overset{a}{\\sum_{\\alpha = 1}}\\left( \\overline{y}\\alpha - \\overline{y} \\right)^{2}\\), 여기서 \\(\\overline{y}\\alpha\\)는 \\(\\alpha\\)번째 단지의 평균 소득이다. 군집표본의 경우, 요소 분산 \\(s^{2}\\)대신 ”군집 간 분산”을 사용한다.\n\n\n\n(3) 설계효과 design effect\n단순임의추출과 비교했을 때 실제 사용된 표본설계로 인해 표본분산이 얼마나 증가했는지를 나타내는 지표를 설계효과(design effect)라고 한다. 설계효과는 설문조사에서 군집화 효과, 층화 효과, 또는 복합 표본설계가 추정 결과에 미치는 영향을 정량적으로 표현하는 데 사용된다.\n설계효과: \\(d^{2} = \\frac{v(\\overline{y})}{v_{\\text{SRS}}(\\overline{y})}\\)\n\\(v(\\overline{y})\\): 군집표본에서의 표본 분산\n\\(v_{\\text{SRS}}(\\overline{y})\\): 동일한 표본 크기에서 SRS 표본분산\n\n설계효과와 군집 내 동질성\n설계효과는 군집 표본 추출이 단순임의추출에 비해 표본분산에 미치는 영향을 측정하는 지표로, 군집 내 요소들의 동질성과 밀접한 관련이 있다. 일반적으로 군집 표본은 요소 단위의 표본에 비해 표본분산이 더 크게 나타나는 경향이 있다. 이는 군집 간 평균값의 차이가 존재한다는 것을 의미하며, 동시에 각 군집 내에서는 요소들이 서로 유사한 특성을 가질 가능성이 높다는 것을 나타낸다.\n예를 들어, 단지 간 평균 소득에 차이가 있다는 것은 각 단지 내 가구들의 소득이 서로 유사하다는, 즉 군집 내 동질성이 높다는 의미로 해석될 수 있다. 이러한 경우, 한 군집에서 여러 요소를 표본으로 포함시켜도 얻어지는 정보는 중복될 가능성이 높다.\n이러한 맥락에서 다음과 같은 질문이 제기된다. “같은 군집에서 한 요소를 추가로 표본에 포함시킬 때, 모집단에 대한 어떤 새로운 정보를 얻을 수 있는가?” 극단적인 예로, 교실의 모든 학생이 동일한 시험 점수를 가지고 있다고 가정하면, 한 학생의 점수를 알게 된 순간 나머지 학생들의 점수는 별다른 추가 정보를 제공하지 못하게 된다. 이 경우, 각 교실에서 단 한 명만 조사해도 전체 분포를 파악할 수 있으므로, 조사 비용을 크게 절감할 수 있게 된다.\n군집 내 동질성이 높을수록 설계효과는 커지며, 이는 추정의 정확도를 낮출 수 있다. 따라서 군집 표본을 설계할 때는 군집 간 이질성을 확보하고 군집 내 동질성을 최소화하려는 노력이 필요하다.\n\n\n설계효과 측정\n군집 내 요소 값의 상관성 intraclass correlation을 사용하는 것이다. 이는 군집 간을 평균으로 한 상관계수로, 군집 내 변수 값들이 군집 외부의 값들과 비교하여 서로 얼마나 상관되어 있는지를 측정한다. 군집 내 동질성 rate of homogeneity은 \\(roh\\)로 나타내며, 이는 거의 항상 0보다 큰 양수이다.또한, 이 \\(\\rho\\)를 설계효과와 연결할 수 있다. 이는 크기 n인 SRS에서 크기 n인 군집 표본으로 전환할 때 표본 분산 변화의 요약값을 제공한다.\n설계효과는 \\(d^{2} = 1 + (b - 1)roh\\), 여기서 \\(b\\)는 각 군집(예: 단지)에서 표본으로 추출된 요소의 크기를 나타낸다. 즉, 표본분산의 증가는 단지 소득에서 관찰된 가구 간 동질성의 정도와 각 단지에서 추출된 표본크기 \\(b\\)에 실제로 의존한다. \\(roh\\)는 변수의 유형에 따라 달라지며, 군집 내 동질성의 비율이 높은 변수는 평균에 대해 더 큰 설계효과를 가진다. 일반적으로 이 표는 사회경제적 변수에서 높은 roh 값을 보이며, 태도나 여성의 출산 경험과 같은 변수에서는 낮은 roh 값을 보인다. 군집에서 추출된 표본 크기가 클수록 설계효과도 커진다. 각 군집에서 1개만 선택하거나, \\(roh = 0\\)이면 설계효과는 1로 SRS 분산과 동일하다.\n\n\n\\(roh\\) 추정 및 활용\n추정: \\(roh = \\frac{(d^{2} - 1)}{(b - 1)}\\)\n동일하거나 유사한 주제에 대해, 거의 동일한 모집단에서 사전 조사 결과로부터 \\(roh_{old}\\)값을 계산했다고 가정한다. 새로운 설계에서 표본 분산을 추정하려면, 먼저 새로운 설계 효과를 계산해야 한다.\n\\(d_{\\text{new}}^{2} = 1 + (b_{\\text{new}} - 1)roh_{\\text{old}}\\), 여기서 \\(b_{\\text{new}}\\)는 새로운 설계에서 군집당 표본 요소 수이다. 그런 다음, 이 새로운 설계 효과를 사용하여 새 표본의 평균에 대한 SRS 분산 추정치에 곱한다.\n\\(v(\\overline{y}) = \\left( \\frac{1 - f}{n} \\right)s^{2},\\) 여기서 \\(s^{2}\\)는 사전 조사에서 추정되며, \\(n\\)은 새로운 설계에 의해 결정된다.\n\n\n설계효과 \\(d^{2}\\)의 또 다른 해석\n\\(d^{2}\\)는 군집 표본을 추출함으로써 정밀도가 손실된 정도를 나타낸다. 표본 크기는 200명이고 설계효과 \\(d^{2} = 3.13\\)라 하자. 실제로 동일한 분산을 가지는 SRS 표본 크기는 \\(n_{\\text{eff}} = \\frac{200}{3.13} \\approx 64\\)로 200명이 아니다. ”효과적 표본 크기”는 실제 설계로 달성된 것과 동일한 표본 분산을 산출하는 SRS 표본 크기이다.\n\n\n선택된 군집 내 하위 표본 추출\n선택된 군집 내 표본 크기(예: 단지당 선택된 가구 수)를 줄이면 평균 소득의 표본 분산에 대한 군집 효과를 감소시킬 수 있다. 이는 군집화가 결과의 정밀도에 미치는 해로운 영향을 완화하려는 타협점이다. 군집 표본을 더 많은 군집에 분산시키는 것은 전체 표본 요소 수를 유지하면서도 일반적으로 총 비용을 증가시킨다.\n\n\n\n3. 층화추출방법 stratified sampling\n\n\n\n\n\n확률 표본 설계는 모집단의 하위 그룹들이 표본 내에 적절히 대표되도록 보장하는 방식으로 개선될 수 있다. 이러한 기능 중 하나가 층화(stratification)이다.\n층화는 표본 프레임에 포함된 모집단 요소들이 사전에 정의된 기준에 따라 상호 배타적인 그룹, 즉 층(strata)으로 구분될 수 있는 정보를 가지고 있다는 전제에 기반한다. 각 요소는 오직 하나의 층에만 속할 수 있으며, 이처럼 나뉜 층은 서로 겹치지 않는 범주로 구성된다.\n층화표본추출에서는 각 층에서 표본을 독립적으로 선택한다. 이때 모든 층에서 동일한 표본추출 절차(예: 단순임의추출)를 사용할 수도 있고, 층의 특성에 따라 서로 다른 추출 방법(예: 어떤 층에서는 단순임의추출, 다른 층에서는 군집추출)을 적용할 수도 있다.\n층화는 특히 모집단 내에 중요한 이질적 특성이 존재할 경우 유용하며, 각 하위 집단의 특성을 보다 정확하게 추정할 수 있도록 도와준다. 또한 전체 표본의 분산을 줄이는 데에도 기여할 수 있다.\n\n\n(1) 층화표본 추출 절차\n층화추출과 군집추출은 모두 모집단을 그룹으로 나누는 방식이지만, 그 목적과 활용 방식에서 중요한 차이가 있다.\n층화추출은 모집단을 사전에 정의된 기준에 따라 여러 개의 층으로 구분하고, 각 층에서 독립적으로 표본을 추출하는 방법이다. 이때 각 층은 내부적으로는 비교적 동질적이고, 층 간에는 이질적인 특성을 가지도록 구성된다. 이러한 방식은 모집단 내 다양한 하위 집단이 표본에 반드시 포함되도록 보장하므로, 조사 결과의 대표성과 정밀도를 높이는 데 효과적이다. 특히 성별, 연령대, 지역 등과 같이 사전에 알려진 중요한 구분 기준이 있는 경우 유용하다.\n반면, 군집추출은 모집단을 물리적 또는 행정적 단위에 따라 군집으로 나눈 후, 이들 군집 중 일부만을 무작위로 선택하여 조사하는 방식이다. 선택된 군집 내에서는 모든 구성원을 조사하거나, 추가적인 표본추출 절차를 통해 일부만을 조사할 수 있다. 군집 간에는 큰 차이가 없다고 가정하며, 각 군집은 내부적으로 다양한 특성을 가진 이질적인 집단으로 구성되는 것이 일반적이다. 군집추출은 시간과 비용을 절감하는 데 유리하지만, 군집 간 이질성이 크고 군집 내 동질성이 높을 경우 표본 오차가 증가할 수 있다는 단점이 있다.\n요약하자면, 층화추출은 하위 집단의 대표성을 보장하고 정밀도를 높이기 위해 사용되며, 군집추출은 접근성과 비용 효율성을 고려할 때 활용되는 방법이다. 두 방법은 모두 확률 표본 설계의 일종이지만, 조사 목적과 상황에 따라 적절히 선택되어야 한다.\n\n\n(2) 층화표본 추출 절차\n층화표본추출은 모집단을 인구학적 특성에 따라 서로 다른 집단으로 구분한 뒤, 각 집단에서 일정 수의 표본을 선택하여 전체 표본을 구성하는 방식이다. 여기서 각 집단은 ’층’이라고 하며, 층화의 목적은 모집단 내 서로 다른 응답 성향을 가진 하위 집단이 표본에 적절히 대표되도록 보장하는 데 있다.\n일반적으로 집단 간에는 응답의 차이가 존재하며, 각 집단 내의 개체는 모집단의 특성을 반영하는 정보를 고르게 가지고 있다고 본다. 따라서 각 층에서 고르게 표본을 추출함으로써, 전체 표본의 대표성과 추정의 정확도를 높일 수 있다.\n층화표본추출은 다음과 같은 절차에 따라 진행된다.\n첫째, 모집단을 인구학적 특성에 따라 분류한다. 성별, 연령, 학년, 직업, 거주 지역 등과 같이 응답 성향에 영향을 미칠 수 있는 변수들을 기준으로 그룹화하며, 이를 통해 모집단을 이질적인 하위 집단으로 나눈다.\n둘째, 각 층에서 몇 개의 표본을 추출할 것인지를 결정한다. 이는 각 층의 크기를 기준으로 하여 비례적으로 할당하거나, 조사 목적에 따라 비례하지 않게 배정할 수도 있다. 표본 수를 층의 크기에 비례하여 결정하는 방식을 확률비례추출이라 한다.\n셋째, 각 층에서 배정된 표본을 실제로 추출한다. 이때 표본추출 방법은 단순임의추출(SRS)이나 계통추출(Systematic Sampling)과 같은 무작위 방법을 사용할 수 있다.\n이와 같이 층화표본추출은 표본의 구조적 대표성을 높이는 데 효과적인 방법이며, 특히 모집단 내 이질성이 예상될 때 유용하게 활용된다.\n\n\n(3) 표본평균 추정\n비례 할당은 각 층에서 동일한 선택 확률을 사용하여 표본을 선택하는 것과 동일하며, 이는 동등한 확률 선택 방법이다. 즉, \\(f_{h} = n_{h}/N_{h}\\)로 층 \\(h\\) 의 표본 추출 비율이다. 층 \\(h\\)의 \\(n_{h}\\)크기의 표본을 선택할 수 있으며, 이때 표본에서 해당 층의 요소 비율은 모집단에서 해당 층의 요소 비율 \\(\\frac{N_{h}}{N}\\)과 동일하다. 여기서 \\(N_{h}\\)는 층 \\(h\\)에 있는 모집단 요소의 수를 의미하며, \\(\\frac{N_{h}}{N}\\)은 각 층의 모집단 비율이다.\n전체 모집단에 대한 추정치를 얻으려면 각 층의 결과에 모집단 비율 \\(W_{h}\\)를 가중치로 사용하는 것이다. 예를 들어, 모집단 평균을 추정하고자 하고, 각 층에 대한 평균 \\({\\overline{y}}_{h}\\)를 계산했다고 하자. 모집단 평균에 대한 층화된 추정치는 \\({\\overline{y}}_{st}\\)로 불리며, 여기서 st는 ”층화”를 나타낸다.\n\\({\\overline{y}}_{st} = \\overset{H}{\\sum_{h = 1}}W_{h}{\\overline{y}}_{h}\\), 여기서 \\({\\overline{y}}_{st}\\)는 층 평균의 가중 합이다.\n\n\n(4) \\({\\overline{y}}_{st}\\)의 표본 분산\n\\(v({\\overline{y}}_{h}) = \\left( \\frac{1 - f_{h}}{n_{h}} \\right)s_{h}^{2}\\), 여기서 \\(f_{h} = n_{h}/N_{h}\\)는 층 h의 표본 추출률이다. \\(s_{h}^{2}\\)는 층 \\(h\\)의 요소 분산으로, 층 내 요소 평균 \\({\\overline{y}}_{h}\\)를 기준으로 다음과 같이 계산된다. \\(s_{h}^{2} = \\left( \\frac{1}{n_{h} - 1} \\right)\\overset{n_{h}}{\\sum_{i = 1}}(y_{hi} - {\\overline{y}}_{h})^{2}\\).\n따라서, 층화된 임의 표본 추출에서는 SRS에서처럼 하나의 요소 분산만 계산하는 것이 아니라, 각 층에 대해 별도의 분산을 계산해야 한다.\n\\(v(\\overline{y}st) = \\overset{H}{\\sum_{h = 1}}W_{h}^{2}\\left( \\frac{1 - f_{h}}{n_{h}} \\right)s_{h}^{2}\\), 여기서 \\(W_{h}\\)는 각 층의 모집단 비율로, 각 층의 SRS 분산에 대해 모집단 비율의 제곱을 가중치로 사용한다.\n\n\n(5) 설계효과\n\\[d^{2} = \\frac{v(\\overline{y}st)}{v\\text{SRS}(\\overline{y})} = \\frac{\\sum_{h = 1}^{H}W_{h}^{2}\\left( \\frac{1 - f_{h}}{n_{h}} \\right)s_{h}^{2}}{\\left( \\frac{1 - f}{n} \\right)s^{2}}\\]\n이 설계효과는 1보다 작거나, 1과 같거나, 심지어 1보다 클 수도 있다. 설계효과의 크기는 각 층에서 선택된 표본 크기, 즉 층화 내 표본 할당 방식에 크게 의존한다.\n비율의 추정 절차는 평균에 대한 추정 절차와 유사하며, 실제로 동일한 공식을 사용할 수 있다. 그러나 비율의 추정은 종종 다음과 같은 비율의 형태로 표현된다.\n\\(p_{st} = \\overset{H}{\\sum_{h = 1}}W_{h}p_{h}\\), \\(v(p_{st}) = \\overset{H}{\\sum_{h = 1}}W_{h}^{2}\\left( \\frac{1 - f_{h}}{n_{h} - 1} \\right)p_{h}(1 - p_{h})\\)\n모평균 추정치 \\({\\overline{y}}_{st} = \\overset{H}{\\sum_{h = 1}}W_{h}{\\overline{y}}_{h} = \\overset{H}{\\sum_{h = 1}}\\left( \\frac{N_{h}}{N} \\right){\\overline{y}}_{h}\\)을 대수적 방법으로 재표현 하면 \\(\\overline{y}st = \\frac{\\sum_{h = 1}^{H}\\sum_{i = 1}^{n_{h}}w_{hi}y_{hi}}{\\sum_{h = 1}^{H}\\sum_{i = 1}^{n_{h}}w_{hi}}\\), 여기서 \\(w_{hi}\\)는 데이터 세트의 가중치 변수로, 층 \\(h\\)에 있는 요소 \\(i\\)의 \\(w_{hi} = \\frac{N_{h}}{n_{h}}\\)이다. 즉, 가중 평균은 가중 총합을 가중치의 합으로 나눈 값이다.\n\\({\\overline{y}}_{st}\\)의 표본 분산은 가장 간단하게 층 전체의 분산에 대한 가중 합으로 표현될 수 있다. 각 층에서 단순 임의 표본 추출(SRS)을 사용했다면, 다음과 같이 계산된다.\n\\[v({\\overline{y}}_{st}) = \\overset{H}{\\sum_{h = 1}}W_{h}^{2}(\\text{variance of}h\\text{-th stratum mean})\\]\n\\(v({\\overline{y}}_{st}) = W_{1}^{2}\\left( \\frac{1 - f_{1}}{n_{1}} \\right)s_{1}^{2} + W_{2}^{2}\\left( \\frac{1 - f_{2}}{n_{2}} \\right)s_{2}^{2} + W_{3}^{2}\\left( \\frac{1 - f_{3}}{n_{3}} \\right)s_{3}^{2} + \\cdots\\), 여기서 \\(W_{h}\\)는 층 \\(h\\)의 모집단 비율, \\(f_{h} = n_{h}/N_{h}\\)는 층 \\(h\\)의 표본 추출률, \\(s_{h}^{2}\\)는 층 \\(h\\)의 분산이다. 즉, 분산의 추정은 층별로 계산된 후, 층별 결과를 결합하여 이루어진다.\n\n\n(6) 층화 추출의 설계효과가 \\(d^{2} &lt; 1\\) (1보다 작은 경우)\n설계효과 \\(d^{2} = \\frac{v(\\overline{y}st)}{v\\text{SRS}(\\overline{y})} = \\frac{\\sum_{h = 1}^{H}W_{h}^{2}\\left( \\frac{1 - f_{h}}{n_{h}} \\right)s_{h}^{2}}{\\left( \\frac{1 - f}{n} \\right)s^{2}}\\)이므로 만약 \\(\\overset{H}{\\sum_{h = 1}}W_{h}^{2}s_{h}^{2}\\)가 \\(s^{2}\\)보다 작아지면 설계효과는 1보다 작아진다.\n\n1. 층 간 변동이 큰 경우\n층화 추출의 가장 큰 이점은 **층 간의 이질성(층 간 변동)**을 활용하여 전체 모집단의 변동을 줄이는 데 있다.\n층화 추출은 동일한 크기의 단순 임의 추출(SRS)보다 표본이 더 모집단을 잘 대표하도록 설계된다. 각 층 내부는 상대적으로 동질적이지만, 층 간 차이가 클 경우, 층화는 표본 평균의 변동성을 줄여 설계효과가 1보다 작아지게 된다.\n예를 들어, 수입 수준, 교육 수준, 지역별 생활비 등에서 층 간 큰 차이가 있는 경우 설계효과가 1보다 작아질 가능성이 높다.\n\n\n2. 적절한 층화 및 비례 할당\n층화는 모집단을 적절히 나누고, 각 층에서 비례적으로 표본을 추출할 때 설계효과가 줄어들 가능성이 크다.\n\\(f_{h} = \\frac{n_{h}}{N_{h}},W_{h} = \\frac{N_{h}}{N}\\) 비례 할당을 통해 각 층이 모집단을 더 잘 대표하도록 표본을 추출하면, 분산 감소 효과가 더 크게 나타난다.\n\n\n3. 층 내 내부 변동이 작은 경우\n각 층 내부의 요소들이 상대적으로 동질적일수록(층 내 변동이 작을수록), 해당 층의 분산 s_h^2가 감소하여 전체 표본 분산이 줄어든다.\n층 내 요소들이 비슷한 특성을 가지고 있다면, 적은 표본으로도 각 층을 충분히 대표할 수 있다.\n\n\n4. 효율적인 표본 배분 (Neyman Allocation)\nNeyman Allocation과 같은 최적 배분 방식을 사용하면 각 층의 변동성에 비례하여 표본을 배분할 수 있다. \\(n_{h} \\propto N_{h} \\cdot s_{h}\\)\n각 층의 크기와 분산을 고려하여 표본을 배분하면, 층화 추출의 효율성이 높아지고 설계효과가 줄어든다.\n\n\n\n(7) 층에 대한 비례하지 않은 할당\n층화표본추출에서 가장 일반적인 표본 할당 방식은 각 층의 크기에 비례하여 표본을 배분하는 비례할당이다. 그러나 비례할당 외에도 단순임의표본추출에 비해 더 작은 표본 분산을 유도할 수 있는 다양한 할당 방법이 존재한다.\n표본설계에서 어떤 할당 방식이 사용되느냐에 따라 추정값의 정확도가 달라질 수 있으며, 특정 할당 방법은 가능한 모든 할당 방식 중에서 표본 평균의 분산을 최소화하는 특징을 가진다. 이러한 최적의 할당 방식은 폴란드의 통계학자 예지 네이만(Jerzy Neyman)에 의해 제안되었으며, 그의 이름을 따서 네이만 할당(Neyman allocation)이라 불린다.\n네이만 할당은 각 층의 표준편차와 크기를 함께 고려하여 표본을 배분하는 방식으로, 층 간 변동성이 클수록 더 많은 표본을 배정하게 된다. 이를 통해 표본의 효율성을 극대화하고, 동일한 표본 크기 하에서 보다 정밀한 추정을 가능하게 한다.\n층화 표본을 위한 네이만 할당은 여러 비례하지 않은 할당 방법 중 하나이다. 하지만 이 방법은 동일한 크기의 표본을 사용할 때 가장 작은 표본 분산을 가지는 특징을 가진다. 네이만 할당을 사용하려면 각 층의 모집단 비율 \\(W_{h}\\)뿐만 아니라, 표준편차 \\(S_{h} = \\sqrt{S_{h}^{2}},\\)도 알고 있어야 한다.\n\n표본크기\n각 층에 대해 \\(W_{h}S_{h}\\)의 곱을 계산하고, 이를 모든 층에서 합산한다. 그러면 네이만 할당 방식에서 각 층의 표본 크기는 다음과 같이 주어진다. \\(n_{h} = n\\frac{W_{h}S_{h}}{\\sum_{h = 1}^{H}W_{h}S_{h}}\\). 즉, 표본 크기는 \\(W_{h}\\)에 비례하는 것이 아니라 \\(W_{h}S_{h}\\)에 비례하도록 할당된다. 따라서 층의 크기가 크면, 비례 할당과 마찬가지로 더 많은 표본을 할당한다. 하지만, 층 내 요소들의 변동성이 클 경우에도 더 많은 표본을 할당하게 된다. 즉, 층 내 변동성이 높을수록 표본 크기를 증가시키게 된다.\n\\(S_{h} = \\sqrt{S_{h}^{2}}\\) 값이 클수록 해당 층에 더 많은 표본을 할당해야 한다. 다시 말해, 층 내 요소들의 분산이 높은 경우, 해당 층에서 더 큰 표본을 추출하여 다른 층보다 상대적으로 더 안정적인 표본 통계를 얻을 수 있도록 한다.\n\n\n네이만 할당 관련 코멘트\n네이만 할당은 단순 임의 표본 추출(SRS)보다, 심지어 비례 할당보다도 정밀도를 크게 향상시킬 수 있다. 그러나 이 방법에는 몇 가지 단점이 있다.\n첫째, 네이만 할당은 반드시 비율 추정에 적합하지 않다. 비율 데이터를 다룰 때 층 간 비율 차이가 크게 나야 하지만, 그러한 차이를 가지는 변수를 찾기가 어려울 수도 있다.\n둘째, 네이만 할당은 한 번에 하나의 변수에 대해서만 최적화된다. 만약 조사에서 여러 개의 변수를 수집하고 있다면, 한 변수에 대한 네이만 할당이 다른 변수에 대한 할당과 다를 수 있다. 그리고 주된 관심 변수에 대해 최적화된 네이만 할당이 다른 변수들에는 적절하지 않을 가능성이 있다. 이로 인해 일부 변수에서는 오히려 설계효과가 1보다 커지는 경우가 발생할 수 있다.\n층 내 분산에 대한 충분한 정보 없이 비례하지 않은 할당을 적용하는 것은 위험하다. 이는 전체 표본의 표준 오차 증가로 이어질 수 있다. 예를 들어, 단순한 할당 방식으로 모든 층에 동일한 표본 크기를 배정하는 경우를 생각해 보자. 층 크기가 다름에도 불구하고 동일한 표본 크기를 배정하면 표본 오차가 증가할 수 있다.\n\n\n\n4. 계통 표본 추출 systematic selection\n\n\n\n\n\n\n\n(1) 계통 추출 절차\n표본을 추출하기 위해 먼저 모집단의 크기와 원하는 표본의 크기를 정한다. 그런 다음, 모집단 크기를 표본 크기로 나눈 값을 추출 간격 k로 계산한다. 이때 \\(k = \\frac{\\text{모집단 크기}}{\\text{표본 크기}}\\) 이며, k는 정수일 수도 있고 아닐 수도 있다. k가 정수가 아닌 경우에는 소수점을 포함한 값을 사용한 뒤, 최종적으로 추출 시 정수 부분만을 활용한다.\n초기 시작점은 1부터 k 사이의 숫자 중 무작위로 하나를 선택하여 결정하며, 이 값을 시작으로 이후 매 k번째 위치에 있는 요소를 순차적으로 표본에 포함시킨다. 이러한 방식은 간단하지만, 모집단이 일정한 방식으로 배열되어 있거나 정렬된 상태일 경우, 특정 패턴에 따라 다양한 모집단 특성을 균등하게 반영할 수 있다.\n이러한 체계적 표본추출은 표면적으로는 단순한 방식이지만, 적절한 조건 하에서는 층화표본추출처럼 모집단의 하위 구조를 고르게 대표할 수 있는 장점을 지닌다. 특히, 모집단 요소들이 조사 변수와 관련 있는 기준에 따라 정렬되어 있는 경우에는 단순임의추출보다 더 높은 정밀도를 확보할 수 있다.\n\n\n(2) 계통추출 관련 코멘트\n체계적 표본추출은 단순임의추출(SRS)이나 층화임의추출에 비해 절차가 간단하고 적용이 용이한 방법이다. 일정한 간격을 기준으로 모집단에서 표본을 선택하는 방식으로, 모집단 전체에 대한 리스트가 준비되어 있다면 빠르고 효율적으로 표본을 구성할 수 있다.\n첫째, 체계적 표본추출에서 사용되는 추출 간격 k는 모집단 크기 N을 원하는 표본 크기 n으로 나누어 계산된다. 이때 k가 항상 정수가 되지 않을 수 있는데, 이러한 경우에는 소수점을 포함한 값을 계산한 뒤 소수점 이하는 버리고 정수 부분만을 사용하여 추출 간격을 설정한다.\n둘째, 체계적 표본추출은 정렬된 리스트를 기반으로 수행될 경우 묵시적 층화 효과를 제공할 수 있다. 이를 ’묵시적 층화 표본추출(implicit stratified sampling)’이라고 하며, 실제 층화를 하지 않았더라도 비례할당이 적용된 층화표본추출과 유사한 결과를 낳을 수 있다. 특히, 정렬 기준이 조사 변수와 상관관계를 가질 경우 표본의 정밀도는 단순임의추출보다 현저히 향상될 수 있다.\n셋째, 이러한 정렬 방식의 대표적인 예로는 지리적 정렬을 들 수 있다. 예를 들어, 특정 지역 내 기업들을 대상으로 평균 종업원 수를 추정하고자 할 때, 기업을 남동쪽에서 북서쪽으로 이동하는 순서로 정렬하면, 대도시 지역과 농촌 지역의 기업들이 자연스럽게 구분되어 배치된다. 일반적으로 대도시 기업은 종업원 수가 많고, 농촌 기업은 적은 경향이 있으며, 유사한 규모의 기업들이 지리적으로 모여 있는 경우도 많다. 이러한 리스트에서 체계적 표본을 추출하면 자동으로 규모별 층화와 유사한 효과를 얻게 되어, 단순임의추출보다 높은 정밀도의 추정을 가능하게 한다.\n이처럼 체계적 표본추출은 간단한 절차에도 불구하고, 적절한 정렬이 이루어진 경우 상당한 효율성을 확보할 수 있는 표본설계 방법이다.\n\n\n\nchapter 3. 표본설계 방법 가중치, 추정분산\n\n(1) 단순임의추출\n단순임의추출은 모집단 내 모든 요소가 동일한 확률로 선택되는 가장 기본적인 확률 표본추출 방법이다. 이 방식에서는 각 요소가 표본에 포함될 기회가 동등하게 주어지며, 통계학에서 널리 사용되는 이론적 기준이 된다.\n단순임의추출은 절차가 명확하고 이해하기 쉬우며, 통계적 추론의 기초를 이루는 중요한 방법이다. 그러나 모집단의 이질성이 크거나 하위 집단 간에 중요한 차이가 존재하는 경우에는 층화추출이나 군집추출과 같은 다른 표본설계 방식보다 효율성이 떨어질 수 있다. 특히 동일한 표본 크기 하에서 추정의 정확도나 분산 측면에서 상대적으로 불리할 수 있다.\n이 방식에서는 모든 표본 요소의 가중치가 동일하게 적용된다. 각 표본 요소의 가중치는 \\(w_{i} = \\frac{N}{n}\\) 으로 계산되며, 여기서 N은 모집단의 크기, n은 표본의 크기를 의미한다. 이는 각 표본이 모집단에서 차지하는 비율이 같다는 것을 의미하며, 단순임의추출의 대표성과 균형성을 수학적으로 뒷받침한다.\n\n표본분산 (추정 오차)\n\\(v(\\overline{y}) = \\left( \\frac{1 - f}{n} \\right)s^{2}\\), \\(s^{2}\\) 은 모집단의 분산, \\(f = \\frac{n}{N}\\)은 표본비율 (유한 모집단 보정) \\(n\\) 증가 시 표본분산 감소한다.\n\n\n\n(2) 계통추출\n계통추출은 모집단을 일정한 순서로 정렬한 후, 고정된 간격마다 표본을 선택하는 확률 표본추출 방법이다. 추출 간격 k는 모집단 크기 N을 표본 크기 n으로 나누어 계산하며, \\(k = \\frac{N}{n}\\) 으로 정의된다. 먼저 1부터 k까지의 숫자 중 무작위로 하나를 선택하여 시작점을 정한 뒤, 그 이후로 매 k번째 요소를 표본으로 포함시킨다.\n계통추출의 장점은 단순임의추출보다 적용이 간편하고 조사 준비 시간이 짧다는 점이다. 특히 모집단이 정렬되어 있을 때, 그 정렬 기준이 조사 변수와 상관관계를 가질 경우 표본의 대표성과 추정의 정밀도가 높아질 수 있다. 예를 들어, 지리적 순서, 알파벳 순서, 시간 순서 등으로 정렬된 목록에서 계통추출을 수행하면 묵시적 층화 효과를 얻을 수 있다.\n계통추출에서도 각 표본 요소는 동일한 확률로 선택되므로, 가중치는 단순임의추출과 동일하게 적용된다. 각 요소의 가중치는 \\(w_i = \\frac{N}{n}\\) 이며, 이는 전체 모집단을 표본으로 환산할 때의 비율을 나타낸다.\n\n\n표본분산 (추정 오차)\n\\(v({\\overline{y}}_{sys}) \\approx v({\\overline{y}}_{SRS})\\)\n\n모집단이 주기성을 가지면 편향 발생 가능이 있다.\n모집단이 정렬된 상태라면 층화표본추출과 유사한 효과를 가진다.\n\n\n\n(3) 군집추출\n군집표본추출은 모집단을 여러 개의 군집으로 나눈 뒤, 이들 중 일부 군집을 무작위로 선택하여 표본으로 삼는 방법이다. 선택된 군집에 포함된 모든 개체를 조사 대상으로 포함시킨다는 점에서, 개별 요소가 아닌 집단 단위로 표본을 구성하는 특징이 있다.\n이 방식은 조사 대상이 지리적으로 넓게 분포해 있거나, 개별 단위에 직접 접근하는 데 시간이 많이 소요되는 경우에 유리하다. 군집 단위로 접근하고 조사함으로써 조사 비용과 시간이 크게 절감될 수 있다. 그러나 군집 내 개체들이 서로 유사한 특성을 가질 가능성이 높기 때문에, 군집 간의 이질성이 충분히 확보되지 않으면 표본 오차가 커질 수 있다는 단점이 있다.\n가중치는 단순임의추출과 유사하게 계산되며, 선택된 군집 내의 각 표본 요소는 동일한 가중치를 갖는다. 이때 가중치는 \\(w_{c} = \\frac{N}{n}\\) 으로 표현되며, 여기서 N은 모집단 전체의 개체 수, n은 조사에 포함된 전체 표본 개체 수를 의미한다.\n\n표본분산 (추정 오차)\n\\(v({\\overline{y}}_{cl}) = \\left( \\frac{1 - f}{a} \\right)s_{a}^{2}\\), 여기서 \\(a\\)는 선택된 군집 수, \\(s_{a}^{2}\\)은 군집 평균 간 분산,\n\n군집 내 동질성이 클수록(높은 \\(\\rho\\)) 표본 오차가 증가한다.\n군집 내 이질성이 크고, 군집 간 동질성이 높을수록 효과적이다.\n\n\n\n\n(4) 층화추출\n층화표본추출은 모집단을 서로 겹치지 않는 여러 개의 층(stratum)으로 구분한 뒤, 각 층에서 단순임의추출(SRS)을 독립적으로 수행하는 방식이다. 각 층은 내부적으로는 동질적이고, 층 간에는 이질적인 특성을 갖도록 구성된다. 이 방법은 모집단 내 특정 특성이 층마다 다르게 나타나는 경우, 보다 정밀하고 대표성 있는 추정을 가능하게 한다.\n층화표본추출의 가장 큰 장점은 표본 분산을 줄이고 추정의 정확도를 높일 수 있다는 점이다. 특히 조사 대상의 응답 성향이나 특성이 층별로 뚜렷하게 구분될 경우, 단순임의추출보다 훨씬 효율적인 결과를 기대할 수 있다.\n이 방법에서 가중치는 층별로 계산되며, 각 층 h에 속한 표본 요소의 가중치는 다음과 같다. \\(w_h = \\frac{N_h}{n_h}\\) , 여기서 \\(N_h\\) 는 층 h의 모집단 크기, n_h는 해당 층에서 추출된 표본의 크기를 의미한다. 이는 층별 대표성 보정을 위해 각 표본의 기여도를 조정하는 역할을 한다.\n\n표본분산 (추정 오차):\n\\(v(\\overline{y}st) = \\overset{H}{\\sum_{h = 1}}W_{h}^{2}\\left( \\frac{1 - f_{h}}{n_{h}} \\right)s_{h}^{2}\\), 여기서 \\(s_{h}^{2}\\)은 층 \\(h\\)의 분산, \\(W_{h} = \\frac{N_{h}}{N}\\)은 층의 모집단 비율, \\(f_{h} = \\frac{n_{h}}{N_{h}}\\)은 층의 표본비율\n\n층 간 변동이 크고, 층 내 변동이 작을수록 효율적이다."
  },
  {
    "objectID": "notes/math/derivate_integral.html",
    "href": "notes/math/derivate_integral.html",
    "title": "수학의 기초 2. 미분과 적분",
    "section": "",
    "text": "chapter 1. 미분\n세상에는 정지해 있는 것이 없다. 우리가 함께 움직이고 있기 때문에 느끼지 못할 뿐, 지구는 자전 속도로 약 시속 1,660킬로미터, 공전 속도로는 약 시속 10만 7천5백 킬로미터로 끊임없이 움직이고 있다. 이러한 사실은 코페르니쿠스가 제안한 지동설에 바탕을 두고 있다. 갈릴레오는 망원경을 통해 목성의 위성을 관찰하고 금성의 위상 변화를 확인함으로써 지동설을 뒷받침했다. 케플러는 행성의 궤도가 완전한 원이 아니라 타원임을 밝혔으며, 이는 지동설의 정밀함을 더하는 데 기여했다. 같은 시대를 살았던 뉴턴은 왜 달은 하늘에 떠 있는 반면, 사과는 땅으로 떨어지는지를 고민하며 만유인력의 법칙을 세우고 중력 개념을 정립했다.\n이러한 천체의 움직임과 자연 현상의 본질은 결국 변화에서 출발한다. 미분은 변화의 순간을 정량적으로 포착하는 방법이다. 상태가 변할 때, 우리는 그 변화의 양상에 주목하게 된다. 거리의 변화는 속도로, 속도의 변화는 가속도로 표현되며, 경제학에서는 비용과 효용의 변화가 한계비용과 한계효용으로 나타난다.\n미분은 함수의 특정 지점에서 접선의 기울기를 계산하는 도구다. 이 접선의 기울기는 함수가 그 점에서 얼마나 빠르게 증가하거나 감소하는지를 나타낸다. 다항함수, 지수함수, 로그함수, 삼각함수 등 대부분의 함수는 미분 가능하며, 특히 통계학에서 자주 사용되는 함수들은 거의 예외 없이 미분이 가능한 형태를 가지고 있다.\n통계학에서 미분은 여러 분야에 활용된다. 회귀분석에서는 오차의 제곱합을 최소화하기 위해 미분을 통해 회귀계수를 추정하고, 확률 밀도 함수의 극댓값을 찾거나 함수의 모양을 분석할 때도 미분이 필수적이다. 또한 최대우도법이나 베이지안 추정 등에서도 목적함수의 최적값을 구하기 위한 과정에 미분이 사용된다.\n이처럼 미분은 단순히 수학적인 연산을 넘어서, 변화와 움직임을 이해하는 데 필요한 핵심 개념으로 작용한다. 자연의 움직임을 설명하고자 했던 과학자들의 질문이 결국 수학적 사고와 연결되듯, 통계학에서도 미분은 현상을 분석하고 설명하는 데 중요한 역할을 수행한다.\n\n 1. 평균변화율 average rate of change\n구간 \\(a \\leq x \\leq b\\)에서 함수 \\(f\\)의 평균 변화량으로 \\(\\frac{rise}{run} = \\frac{\\Delta y}{\\Delta x} = \\frac{f(b) - f(b)}{b - a}\\)이다.\n\n\n\n\n\n\\(a \\leq x \\leq b\\) 구간에서 단위당 평균적으로 함수의 변화량을 측정한 것이다. 평균변화량은 고속도로 구간단속에 이용된다. 미분은 지점 과속 단속에 이용된다.\n\n\n\n\n\n측정 1: 구간단속 시작, 종료 지점에서 과속여부 측정 (미분 응용)\n측정 2: 예를 들어 구간 거리가 6km라 하자. 2분만에 구간을 통과했다면 평균속도는 \\(\\frac{6 - 0}{2 - 0} = 3km/min.\\)분당 3km를 달렸으므로 시간당 180km를 달렸으니 과속이 되는 것입니다. (평균변화량)\n\n\n 2. 미분 정의\n함수 \\(f(x)\\)의 임의의 점 \\(x = a\\)에서의 미분값 \\(f'(a)\\)는 다음과 같이 정의된다. \\(f'(a) = \\lim_{h \\rightarrow 0}\\frac{f(a + h) - f(a)}{h}\\)\n\\(\\frac{f(a + h) - f(a)}{h}\\)는 Fermat’s Difference Quotient로 불리며, 점 \\(a\\)에서의 평균 변화율을 나타낸다.\n극한이 존재하면 \\(f'(a)\\)는 \\(x = a\\)에서의 접선의 기울기로 해석할 수 있다.\n미분 가능성: \\(f'(a)\\)가 존재하면, 점 \\(x = a\\)에서 함수 \\(f(x)\\)는 미분 가능하다고 한다. 함수 \\(f(x)\\)가 정의역 전체에서 미분 가능하, 함수 f(x)는 미분 가능 함수이다.\n미분의 기하학적 해석: 미분값 \\(f'(a)\\)는 곡선 \\(y = f(x)\\)의 점 \\(x = a\\)에서의 접선의 기울기를 의미한다. \\(h\\)가 0으로 가까워질수록 평균 변화율은 접선의 기울기에 점점 가까워진다.\n미분 가능성과 연속성: 함수 \\(f(x)\\)가 점 \\(x = a\\)에서 미분 가능하면 \\(f(x)\\)는 반드시 그 점에서 연속이다. 하지만, 연속이라고 해서 항상 미분 가능한 것은 아니다. 예를 들어, 절대값 함수 가능하지 않다.\n\n\n\n\n\n\n\n3. 미분 규칙\n상수 함수의 미분 \\[\\frac{d}{dx}\\lbrack c\\rbrack = 0\\]\n거듭제곱 함수의 미분 \\[\\frac{d}{dx}\\lbrack x^{n}\\rbrack = nx^{n - 1}, f(x) = x^{n}(n \\in \\mathbb{R})\\]\n【예제】 \\(f(x) = 2\\sqrt{x}\\) 을 미분하시오.\n\\[f'(x) = 2(\\frac{1}{2})x^{1/2 - 1} = x^{- 1/2} = \\frac{1}{\\sqrt{x}}\\]\n상수배의 미분: \\[\\frac{d}{dx}\\lbrack c \\cdot f(x)\\rbrack = c \\cdot \\frac{d}{dx}\\lbrack f(x)\\rbrack\\]\n합/차의 미분\n\\[\\frac{d}{dx}\\lbrack f(x) \\pm g(x)\\rbrack = \\frac{d}{dx}\\lbrack f(x)\\rbrack \\pm \\frac{d}{dx}\\lbrack g(x)\\rbrack\\]\n곱의 미분\n\\[\\frac{d}{dx}\\lbrack f(x) \\cdot g(x)\\rbrack = f'(x) \\cdot g(x) + f(x) \\cdot g'(x)\\]\n나눗셈의 미분\n\\(\\frac{d}{dx}\\left\\lbrack \\frac{f(x)}{g(x)} \\right\\rbrack = \\frac{f'(x) \\cdot g(x) - f(x) \\cdot g'(x)}{\\lbrack g(x)\\rbrack^{2}}\\), \\(g(x) \\neq 0\\)\n체인룰 chain rule 연쇄규칙\n\\[\\frac{d}{dx}\\lbrack f(g(x))\\rbrack = f'(g(x)) \\cdot g'(x)\\]\n【예제】 \\(f(x) = 2\\sqrt{3x^{2} - 1}\\)을 미분하시오.\n\n\n\n\n\n  바깥부분 미분하고 안쪽 부분 그대로 적는다.\n  \\(2*(1/2){\\sqrt{(3x^{2} - 1)}}^{- 1/2}\\) 그리고 안쪽부분을 미분한다.\n\\[f'(x) = {\\sqrt{(3x^{2} - 1)}}^{- 1/2}6x = \\frac{6x}{\\sqrt{3x^{2} - 1}}\\]\n로그함수 미분 \\[\\frac{d}{dx}\\lbrack\\log_{a}(x)\\rbrack = \\frac{1}{x\\ln(a)},x &gt; 0\\]\n\\[\\frac{d}{dx}\\lbrack\\ln(x)\\rbrack = \\frac{1}{x},x &gt; 0\\]\n【예제】 \\(f(x) = ln(x^{2} - 1)\\)을 미분하시오.\n  연쇄법칙 적용 : \\(f'(x) = \\frac{1}{x^{2} - 1}2x\\)\n지수함수 미분\n\\[\\frac{d}{dx}\\lbrack a^{x}\\rbrack = a^{x}\\ln(a)\\]\n\\[\\frac{d}{dx}\\lbrack e^{x}\\rbrack = e^{x}\\]\nimport sympy as sp\n\n# 변수와 함수를 정의\nx = sp.Symbol('x')\nf = 5*(x**2 - 2*x)**2\n\n# 함수 입력을 파싱하여 미분\nfunc = sp.sympify(f)\nderivative = sp.diff(func, x)\n\n\n4. 미분 응용\n\n(1) 최대, 최소\n1차 미분정리\n함수 f(x) 가 일정 구간 (a, b) 안의 모든 점에서 미분 가능하고, 구간 내 임의의 점 c 에서 1차 미분이 0이면, f(x) 함수는 c 점에서 지역 최대값이나 최소값을 갖는다. 이는 페르마의 정리에 Fermat’s 해당하며, 극대값 또는 극소값이 존재하는 필수 조건을 설명한다.\n함수 f(x) 가 c 에서 미분 가능하고, 극값이 c 에서 존재하면, 반드시 \\(f'(c) = 0\\)이어야 한다.\n다만, \\(f'(c) = 0\\)이라고 해서 반드시 극값이 존재하는 것은 아니며, 이는 필요조건일 뿐 충분조건은 아니다. 극값의 존재를 확실히 판단하려면 2차 도함수 테스트나 첫 도함수의 부호 변화를 추가로 고려해야 한다.\n증가 함수와 감소 함수\n함수 f(x)가 구간 \\(I\\)에서 정의되어 있을 때, \\(x_{1} &lt; x_{2} \\Longrightarrow f(x_{1}) \\leq f(x_{2})\\) 이면 구간 \\(I\\)에서 증가 함수이다.\n\\(x_{1} &lt; x_{2} \\Longrightarrow f(x_{1}) \\geq f(x_{2})\\) 이면 구간 \\(I\\)에서 감소 함수이다.\n1차 미분과 증가·감소 함수의 관계\n함수 f(x) 가 구간 \\(I\\)에서 미분 가능하다면,\n\n\\(f'(x) &gt; 0\\) 이면, f(x) 는 구간 \\(I\\)에서 엄격히 증가한다\n\\(f'(x) &lt; 0\\) 이면, f(x) 는 구간 \\(I\\)에서 엄격히 감소한다.\n\n오목성 concavity 정의\n함수 f(x) 의 기울기가 감소하는 경우 \\(f''(x) &lt; 0\\),\n\n함수 f(x) 는 concave down (오목 아래)이다.\n그래프가 아래로 휘어진 모양을 갖는다.\n\n함수 f(x) 의 기울기가 증가하는 경우 \\(f''(x) &gt; 0\\),\n\n함수 f(x) 는 concave up (오목 위)이다.\n그래프가 위로 휘어진 모양을 갖는다.\n\n\n\n\n\n\n변곡점 inflexion point 정의\n함수 \\(f(x)\\)의 오목성이 변하는 점이 있을 때, 이 점을 변곡점이라고 한다. 즉, \\(f(x)\\)가 \\(f’’(x) &gt; 0\\)에서 \\(f’’(x) &lt; 0\\)로 바뀌거나 \\(f’’(x) &lt; 0\\)에서 \\(f’’(x) &gt; 0\\)로 바뀌는 점이 변곡점이다.”\n1차 미분과 2차 미분을 이용한 최대, 최소 판단\n주어진 \\(f'(c) = 0\\)에서, \\(f''(c)\\)를 확인한다.\n\n\\(f''(c) &gt; 0\\) 이면 \\(x = c\\)에서 (지역) 최소값\n\\(f''(c) &lt; 0\\) 이면 \\(x = c\\)에서 (지역) 최대값\n\\(f''(c) = 0\\) 이고 \\(f''(x)\\) 부호가 바뀌면 \\(x = c\\)에서 변곡점\n\n\n\n(2) 통계학 응용\n단순 회귀모형 \\[y_{i} = \\beta_{0} + \\beta_{1}x_{i} + \\epsilon_{i},i = 1,2,\\ldots,n\\]\nOLS 추정치 \\[\\text{Minimize:}S(\\beta_{0},\\beta_{1}) = \\overset{n}{\\sum_{i = 1}}(y_{i} - \\beta_{0} - \\beta_{1}x_{i})^{2}\\]\n오차 제곱합    \\(S(\\beta_{0},\\beta_{1})\\)을 \\(\\beta_{0}\\)와 \\(\\beta_{1}\\)에 대해 편미분한 뒤 0으로 설정하여 최소값(OLS)을 찾는다.\n정규방정식\n\\[\\frac{\\partial S}{\\partial\\beta_{0}} = - 2\\overset{n}{\\sum_{i = 1}}(y_{i} - \\beta_{0} - \\beta_{1}x_{i}) = 0\\]\n\\[\\overset{n}{\\sum_{i = 1}}y_{i} = n\\beta_{0} + \\beta_{1}\\overset{n}{\\sum_{i = 1}}x_{i}\\]\n\\[\\frac{\\partial S}{\\partial\\beta_{1}} = - 2\\overset{n}{\\sum_{i = 1}}x_{i}(y_{i} - \\beta_{0} - \\beta_{1}x_{i}) = 0\\]\n\\[\\overset{n}{\\sum_{i = 1}}x_{i}y_{i} = \\beta_{0}\\overset{n}{\\sum_{i = 1}}x_{i} + \\beta_{1}\\overset{n}{\\sum_{i = 1}}x_{i}^{2}\\]\n두 식을 함께 사용하여 \\(\\beta_{0}\\)와 \\(\\beta_{1}\\)를 계산한다.\n\\[\\beta_{1} = \\frac{\\sum_{i = 1}^{n}(x_{i} - \\overline{x})(y_{i} - \\overline{y})}{\\sum_{i = 1}^{n}(x_{i} - \\overline{x})^{2}} = \\frac{\\text{Cov}(x,y)}{\\text{Var}(x)}\\]\n\\[\\beta_{0} = \\overline{y} - \\beta_{1}\\overline{x}\\]\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import curve_fit\n\n# 가상의 데이터 생성 n=20\nnp.random.seed(0)\nx_data = np.linspace(-5, 5, 20)\ny_data = 2 * x_data**3 - 3 * x_data**2 + 4 * x_data + 10 + np.random.normal(0, 10, 20)\n\n# 직선 적합 함수\ndef linear(x, a, b):\n    return a * x + b\n# 2차 함수 적합 함수\ndef quadratic(x, a, b, c):\n    return a * x**2 + b * x + c\n# 3차 함수 적합 함수\ndef cubic(x, a, b, c, d):\n    return a * x**3 + b * x**2 + c * x + d\n# 최소자승법을 이용한 직선, 2차, 3차 적합\nparams_linear, _ = curve_fit(linear, x_data, y_data)\nparams_quadratic, _ = curve_fit(quadratic, x_data, y_data)\nparams_cubic, _ = curve_fit(cubic, x_data, y_data)\n\n# 적합된 함수의 값을 계산\ny_fit_linear = linear(x_data, *params_linear)\ny_fit_quadratic = quadratic(x_data, *params_quadratic)\ny_fit_cubic = cubic(x_data, *params_cubic)\n\n# Residual Sum of Squares 계산\nrss_linear = np.sum((y_data - y_fit_linear) ** 2)\nrss_quadratic = np.sum((y_data - y_fit_quadratic) ** 2)\nrss_cubic = np.sum((y_data - y_fit_cubic) ** 2)\n\n# 최소자승법을 이용한 직선, 2차, 3차 적합\nparams_linear, _ = curve_fit(linear, x_data, y_data)\nparams_quadratic, _ = curve_fit(quadratic, x_data, y_data)\nparams_cubic, _ = curve_fit(cubic, x_data, y_data)\n\n# 적합된 함수의 값을 계산\ny_fit_linear = linear(x_data, *params_linear)\ny_fit_quadratic = quadratic(x_data, *params_quadratic)\ny_fit_cubic = cubic(x_data, *params_cubic)\n\n# Residual Sum of Squares 계산\nrss_linear = np.sum((y_data - y_fit_linear) ** 2)\nrss_quadratic = np.sum((y_data - y_fit_quadratic) ** 2)\nrss_cubic = np.sum((y_data - y_fit_cubic) ** 2)\n\n# 그래프 그리기\nplt.figure(figsize=(10, 6))\nplt.scatter(x_data, y_data, label='data', color='black')\nplt.plot(x_data, y_fit_linear, label='Linear fit (y = {:.2f}x + {:.2f}) : RSS={:.2f}'.format(params_linear[0], params_linear[1],rss_linear), color='blue')\nplt.plot(x_data, y_fit_quadratic, label='Quardratic fit (y = {:.2f}x^2 + {:.2f}x + {:.2f}) : RSS={:.2f}'.format(params_quadratic[0], params_quadratic[1], params_quadratic[2],rss_quadratic), color='green')\nplt.plot(x_data, y_fit_cubic, label='Cubic fit (y = {:.2f}x^3 + {:.2f}x^2 + {:.2f}x + {:.2f}) : RSS={:.2f}'.format(params_cubic[0], params_cubic[1], params_cubic[2], params_cubic[3],rss_cubic), color='red')\nplt.axhline(0, color='grey', lw=0.5, ls='--')\nplt.axvline(0, color='grey', lw=0.5, ls='--')\nplt.title('fit by OLS')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.legend()\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n(3) 한계효용체감의 법칙\n한계효용 marginal utility은 재화가 증가 혹은 감소함에 따라 주관적으로 매겨지는 경제적 효용(혹은 가치)의 관계에 대한 개념으로 합리적인 경제에서 인간 행동은 자신에게 가장 시급한 욕구를 충족하는 일을 가장 먼저 하거나 가치를 두는 특성이 있다. 따라서 어떤 사람이 재화나 용역을 이용하여 효용을 얻고자 할 때 주관적으로 판단되는 욕망 충족의 정도인 효용의 가치가 높은 것부터 낮은 것 쪽으로 추구한다. 재화나 용역의 한계효용은 그 재화나 용역을 사용하는 것을 증가하거나 감소함에 따라 변화한 가치의 양을 상정한 것인데 이런 변화에서 추가의 1단위 즉 경계인 단위에서의 재화나 용역의 효용을 한계효용이라고 한다.[위키피디아]\n\n\n\n\n\n총효용 total utility 은 주어진 기간 동안 소비된 특정 상품의 모든 단위에서 얻은 총만족입니다. 한계효용 marginal utility 마지막 소비량에서 상품 소비의 1단위 변화로 인해 발생하는 총 효용의 변화이다. 더 많은 단위의 상품을 구매하면 한계 효용은 감소하기 시작하지만 총 효용은 계속해서 감소 비율이 줄어든다. 한계효용이 0가 되는 포화점 satiety에 이르렀을 때 이 지점에서의 총효용은 최대가 된다. 이 지점에서 소비가 더 증가하면 한계 효용은 음수가 되고 총 효용은 감소하기 시작한다.\n\n\n(4) Cobb-Douglas 생산함수\n\\(Q = f(K,L) = AL^{\\alpha}K^{\\beta}\\), \\(Q\\)= 생산, \\(K\\)=자본, \\(L\\)=노동, \\(A,\\alpha,\\beta\\)는 모수이다. \\(K,L\\)에 대하여 각각 편미분 하면 다음과 같다.\n  - 양변에 로그를 취한다. \\(ln(Q) = lnA + \\alpha lnL + \\beta lnK\\)\n  - \\(\\frac{\\partial(lnQ)}{\\partial L} = \\alpha\\) : 한계 노동 생산량\n  - \\(\\frac{\\partial(lnQ)}{\\partial K} = \\beta\\) : 한계 자본 생산량\n\n\n\n\n\nchapter 2. 적분\n고대 수학자들은 직선으로 이루어진 도형의 면적을 비교적 쉽게 계산할 수 있었습니다. 사각형, 삼각형, 평행사변형, 사다리꼴과 같은 도형은 밑변과 높이를 활용한 간단한 공식을 통해 면적을 구할 수 있었기 때문입니다. 그러나 곡선이 포함된 도형의 면적을 계산하는 문제는 훨씬 더 복잡한 도전 과제였습니다.\n곡선이 포함된 도형의 면적을 구하기 위해 현대 수학에서는 적분이라는 개념이 도입되었습니다. 이는 고대 그리스의 수학자 아르키메데스가 처음으로 탐구한 주제 중 하나였습니다. 아르키메데스는 곡선 아래의 면적을 구하기 위해 곡선을 아주 작은 직사각형들로 나누고, 그 면적을 합산하여 근사값을 구하는 방식을 사용했습니다. 이 과정은 시간이 지나며 점점 더 체계적으로 발전하였고, 마침내 미적분학으로 이어졌습니다.\n아이작 뉴턴과 고트프리트 라이프니츠는 아르키메데스의 아이디어를 발전시켜 적분과 미분이라는 두 가지 핵심 개념을 정립하였고, 이를 통해 곡선 아래의 면적을 정확히 계산할 수 있는 도구를 완성했습니다. 오늘날 우리가 사용하는 적분법은 이들의 연구에 기반을 두고 있으며, 곡선의 면적뿐만 아니라 물리학, 공학, 경제학 등 다양한 분야에서 중요한 역할을 하고 있습니다.\n적분은 통계학에서 확률 계산, 기대값, 분산, 베이지안 추론 등 다양한 개념과 도구에 중요한 역할을 합니다. 확률을 곡선 아래 면적으로 해석하는데서부터 시작해, 통계적 추론의 기초를 형성하는 데 적분이 필수적입니다. 이러한 적분 개념은 통계학 이론뿐만 아니라 데이터 분석, 머신러닝, 신뢰구간 계산 등 실무적인 응용에서도 널리 사용됩니다.\n\n1. 부정 적분\n함수 F(x) 가 주어진 함수 f(x) 에 대해 정의역의 모든 점에서 \\(F'(x) = f(x)\\)를 만족한다면, F(x) 를 f(x) 의 역-미분 anti-derivative 또는 원시함수 primitive function 합니다. 이는 적분이 미분의 역연산임을 의미합니다.\n적분이 미분의 역연산이라는 사실을 처음 체계적으로 증명하고 이를 수학적으로 정립한 사람들은 아이작 뉴턴(Isaac Newton)과 고트프리트 라이프니츠(Gottfried Wilhelm Leibniz)입니다. 이들은 독립적으로 미적분학의 기본 개념을 발전시켰으며, 이 과정에서 적분과 미분의 관계를 설명한 미적분학의 기본정리를 도출했습니다.\n정적분과 미분의 관계\n특정 구간에서의 정적분은 미분을 통해 함수의 값을 복원할 수 있습니다. 예를 들어, 함수 f(x) 에 대해 다음과 같은 정적분이 있을 때,\n\\(F(x) = \\int_{a}^{x}f(t)dt\\). 이를 x 에 대해 미분하면 \\(\\frac{d}{dx}F(x) = f(x)\\)\n즉, 적분을 통해 구한 누적 변화량을 다시 미분하면, 원래의 함수로 돌아갑니다.\n적분과 미분은 서로 반대되는 과정처럼 보이지만, 실제로는 상호보완적입니다. 적분은 함수의 누적적인 변화(예: 곡선 아래의 면적)를 측정하며, 미분은 순간적인 변화(예: 기울기)를 측정합니다.\n\n\n2. 정적분\n\n(1) 정적분 개념\n정적분(면적)은 부정적분(역-미분 함수)과는 다른 접근 방식에서 출발합니다. 그러나 이 두 개념은 17세기에 뉴턴(Newton)과 라이프니츠(Leibniz)에 의해 서로 밀접하게 연결되었고, 이를 통합하여 적분(integral)이라고 명명하였습니다.\n우선, 정적분의 개념을 살펴보겠습니다. 구간 [a, b]에서 함수 f(x) 아래의 면적을 어떻게 구할 수 있을까요? 이를 위해 구간 [a, b]를 여러 작은 구간으로 나눈 다음, 각 구간에서 직사각형의 면적을 계산하여 합산하는 방법을 생각할 수 있습니다. 이러한 직사각형의 면적 합은 점점 더 작은 구간으로 나눌수록 실제 면적에 근사하게 됩니다.\n\n\n\n\n\n함수와 x-축 사이에 형성된 이 면적은 정적분이라 하며, 이는 구간 [a, b]에서 함수 f(x)와 x-축 사이의 공간에 해당합니다. 직사각형을 이용해 근사한 면적은 실제 면적보다 클 수도 있고 작을 수도 있습니다. 하지만 구간을 점점 더 세분화하면, 이 근사값은 실제 정적분 값에 수렴하게 됩니다.\n정적분은 함수의 곡선 아래의 면적을 계산하는 방법으로 출발했지만, 부정적분(역-미분 함수)과의 연결을 통해 더욱 강력한 수학적 도구로 발전하였습니다.\n\n\n(2) 정적분과 부정적분의 관계\n함수 f(x) 가 구간 [a, b]에서 연속일 때:\n\n부정적분(역-미분 함수): 함수 F(x) 가 f(x) 의 부정적분이라면 \\(F'(x) = f(x)\\)\n정적분(구간의 면적): 함수 f(x) 의 정적분은 구간 [a, b]에서 f(x) 와 x -축 사이의 면적을 나타냅니다. \\(\\int_{a}^{b}f(x)dx\\)\n뉴턴-라이프니츠 정리: 부정적분과 정적분은 다음과 같이 연결됩니다. \\(\\int_{a}^{b}f(x)dx = F(b) - F(a)\\)\n여기서 F(x) 는 f(x) 의 부정적분입니다.\n\n이 정리는 정적분(구간에서의 면적 계산)이 부정적분(역-미분 함수)을 사용하여 계산될 수 있음을 보여줍니다.\n\n\n(3) 정적분 규칙\n특정 점에서의 확률\n\\[\\int_{a}^{a}f(x)dx = 0\\]\n이는 구간의 길이가 0 일 때, 정적분의 결과가 항상 0 임을 나타냅니다(통계적으로: 연속 확률변수에서 특정 점에서의 확률은 0 이다).\n구간 순서 반대\n\\[\\int_{a}^{b}f(x)dx = - \\int_{b}^{a}f(x)dx\\]\n구간의 순서를 바꾸면 정적분의 부호가 반대가 됩니다.\n상수 배율\n\\[\\int_{a}^{b}c \\cdot f(x)dx = c\\int_{a}^{b}f(x)dx(\\text{c is constant})\\]\n적분 내부에 상수가 곱해져 있을 경우, 상수를 적분 기호 밖으로 꺼낼 수 있습니다.\n합과 차\n\\[\\int_{a}^{b}\\left( f(x) \\pm g(x) \\right)dx = \\int_{a}^{b}f(x)dx \\pm \\int_{a}^{b}g(x)dx\\]\n적분은 덧셈과 뺄셈 연산에 대해 분배법칙을 따릅니다.\nDomination Rule\n만약 \\(f(x) \\geq 0\\)가 구간 [a, b]에서 항상 성립하면\n\\(\\int_{a}^{b}f(x)dx \\geq 0\\) 이다. 통계적으로 확률변수의 분포 함수는 항상 0 이상 이므로, 확률값은 항상 0 이상이다.\n부등식 관계\n만약 \\(f(x) \\leq g(x)\\)가 구간 [a, b]에서 항상 성립하면\n\\(\\int_{a}^{b}f(x)dx \\leq \\int_{a}^{b}g(x)dx\\) 이다.\n구간 쪼개기\n\\[\\int_{a}^{c}f(x)dx + \\int_{c}^{b}f(x)dx = \\int_{a}^{b}f(x)dx\\]\n적분 구간을 나누어 계산할 수 있습니다.\n확률밀도함수 전체 구간\n\\(\\int_{- \\infty}^{\\infty}f(x)dx = 1\\). 확률밀도함수(PDF)는 전체 구간에서의 적분, 확률의 총합이 1 임을 나타냅니다.\n지수함수 적분\n\\[\\int a^{x}dx = \\frac{a^{x}}{\\ln a} + C(a &gt; 0,a \\neq 1)\\]\n\\[\\int e^{x}dx = e^{x} + C\\]\n로그함수 적분\n\\[\\int\\log_{a}(x)dx = \\frac{1}{\\ln(a)}\\left( x\\ln(x) - x \\right) + C\\]\n\\[\\int\\ln(x)dx = x\\ln(x) - x + C\\]\n특수한 적분\n\\[\\int\\frac{1}{x} = ln|x| + C\\]\n치환적분\n함수 g(x) 가 x 에 대한 미분가능한 함수이고, f(u) 가 u = g(x) 에 대한 함수라고 가정하겠습니다.\n\\[\\int f(g(x)) \\cdot g'(x)dx = \\int f(u)du\\]\n\\[u = g(x) , du = g'(x)dx\\]\n【사례】 \\(\\int x \\cdot e^{x^{2}}dx = \\frac{1}{2}e^{x^{2}} + C\\)\n\\(u = x^{2}\\)로 치환하면, \\(du = 2xdx\\). 따라서 \\(xdx = \\frac{1}{2}du\\)\n\\(\\int x \\cdot e^{x^{2}}dx = \\int e^{u} \\cdot \\frac{1}{2}du = \\frac{1}{2}\\int e^{u}du\\)=\\(\\frac{1}{2}\\int e^{u}du = \\frac{1}{2}e^{u} + C\\)\n\\(u = x^{2}\\) 이므로 \\(\\int x \\cdot e^{x^{2}}dx = \\frac{1}{2}e^{x^{2}} + C\\) 이다.\n부분적분\n함수 u(x) 와 v(x) 가 미분 가능할 때, 다음 공식이 성립합니다:\n\\[\\int udv = uv - \\int vdu\\]\n\n\\(u\\): 미분할 함수 (\\(u \\rightarrow du\\))\n\\(dv\\): 적분할 함수 (\\(dv \\rightarrow v\\))\n\n【사례】 \\(\\int xe^{x}dx\\)\n1) 함수 선택: \\(u = x,dv = e^{x}dx\\)\n2) 미분 및 적분: \\(u \\rightarrow du = dx\\),\\(dv \\rightarrow v = e^{x}\\)\n3) 부분적분 공식 적용: \\(\\int xe^{x}dx = uv - \\int vdu\\)\n\\(= xe^{x} - \\int e^{x}dx\\)\\(= xe^{x} - e^{x} + C\\).\n【사례】 \\(\\int_{0}^{1}x^{2} + \\sqrt{x}dx\\) 구하시오.\n\\(f(x) = x^{2} + \\sqrt{x}\\)이므로 \\(F(x) = \\frac{1}{3}x^{3} + \\frac{2}{3}x^{\\frac{3}{2}}\\)\n\\(F(1) = 1\\), \\(F(0) = 0\\)이므로 1이다.\n\\[\\int_{0}^{1}x^{2} + \\sqrt{x}dx = \\frac{1}{3}x^{3} + \\frac{2}{3}x^{\\frac{3}{2}}\\rbrack_{0}^{1} = 1 - 0 = 1\\]\n#부정적분\nfrom sympy import *\nx=Symbol('x')\nintegrate(x**2+x**(0.5), x)\n\\[ x^3/3 + 0.66667x^{1.5}\n\\]\n#정적분\nfrom scipy.integrate import quad\ndef integrand(x):\n   return x**2+x**(0.5)\nquad(integrand,0, 1)\n【결과】 첫번째 값은 적분값이고 두 번째는 적분 값을 얼마나 근사하게 계산하였는지 값이다. 완벽한 값이면 0이어야 하나 출력된 값은 0.0(14개)11…이다. root는 실제 근이다. (1.0, 1.1102230246251565e-15)\n【사례】 표준 정규확률분포함수\\(\\int_{0}^{\\infty}\\frac{1}{\\sqrt{2\\pi}}e^{- \\frac{x^{2}}{2}}dx\\) 구하시오.\n#부정적분\nfrom sympy import *\nimport numpy as np\nx=Symbol('x')\nintegrate(1/(2*np.pi)**0.5*exp(-x**2/2), x)\n\\[\n0.199471140200716 \\sqrt{2} \\sqrt{\\pi} \\, \\mathrm{erf}\\left( \\frac{\\sqrt{2}x}{2} \\right)\n\\]\nimport numpy as np\n#정적분\nfrom scipy.integrate import quad\ndef integrand(x):\n   return 1/(2*np.pi)**0.5*exp(-x**2/2)\nquad(integrand,0,np.inf)\n【결과】 (0.49999999999999983, 5.08909572547112e-09)\n\n\n(4) 표적분 tabular integral\n표 적분은 부분적분을 용이하게 한다. 미분 부분 \\(f(x)\\)는 미분하면서 차수가 용이해야 하고, 적분함수 \\(g(x)\\)는 용이하게 적분할 수 있어야 한다.\n(방법1) 미분 부분이 0이 될 때까지 미분과 적분을 반복 시행한다.\n\\[\\int_{a}^{b}udv = (1)*(a) - (2)*(b) + (3)(c)...\\rbrack_{a}^{b}\\]\n(방법2)한 번만 미분하고 \\(\\int_{a}^{b}udv = (1)*(a) - \\int_{a}^{b}(2)*(b)dx\\)\n\n\n\n\n\n【예제】 \\(\\int_{0}^{\\infty}xe^{- x}dx\\) 표 적분하시오.\n\n\n\n\n\n(방법1) \\(x( - e^{- x}) - e^{- x}\\rbrack_{0}^{\\infty} = 1\\)\n(방법2) \\(x( - e^{- x})\\rbrack_{0}^{\\infty} - \\int_{0}^{\\infty} - e^{- x} = 1\\)으로 계산한다.\n【예제】 \\(\\int_{1}^{2}ln(x)dx\\) 표 적분하시오.\n\n\n\n\n\n\\[\\int_{1}^{2}ln(x)dx = ln(x)x\\rbrack_{1}^{2} - \\int_{0}^{1}1dx = 2ln(2) - ln(1) - x\\rbrack_{0}^{1} = 0.386\\]\n\n\n\n3. 적분 응용\n연속형 확률분포의 확률밀도함수\n\n\n\n\n\n연속형 확률변수 X 의 확률밀도함수 f(x) 는 특정 구간에서 확률을 계산하는 데 사용됩니다. 이때 확률은 적분을 통해 구합니다:\n\\[P(a \\leq X \\leq b) = \\int_{a}^{b}f(x)dx\\]\nf(x) 는 음수가 아니며, 전체 구간에서의 적분값은 항상 1이 됩니다:\n\\[\\int_{- \\infty}^{\\infty}f(x)dx = 1\\]\n【예제】 정규분포 N(0, 1) 에서 \\(P( - 1 \\leq Z \\leq 1) = \\int_{- 1}^{1}\\phi(z)dz\\) 이다. 여기서 \\(\\phi(z) = \\frac{1}{\\sqrt{2\\pi}}e^{- z^{2}/2}\\)는 표준정규분포의 확률밀도함수입니다.\n누적확률분포함수 cumulative probability density fuction\n\n\n\n\n\n기대값\n  연속형 확률변수 X 의 확률밀도함수 f(x)라 하면 기대값은 \\(E(X) = \\int xf(x)dx\\) 이다.\n적분과 백분위값\n  백분위값 percentile은 확률분포에서 특정 비율의 누적 확률을 기준으로 하는 값입니다. P번째 백분위값은 확률변수 X의 값 \\(X_{P}\\)로, 확률변수가 \\(X_{P}\\)이하일 확률이 \\(\\frac{P}{100}\\)이 되는 값입니다.\n\\[F(x_{P}) = \\int_{- \\infty}^{x_{P}}f(x)dx = \\frac{P}{100}\\]\n  - \\(f(x)\\): 확률밀도함수(PDF)\n  - \\(F(x)\\): 누적분포함수(CDF)\n  - \\(x_{P}\\): \\(P\\)번째 백분위값"
  },
  {
    "objectID": "notes/math/function.html",
    "href": "notes/math/function.html",
    "title": "수학의 기초 1. 함수",
    "section": "",
    "text": "chapter 1. 기초\n\n 1. 함수와 통계학\n함수는 통계학에서 데이터를 설명하고 모델링하는 수단이며, 이론적 개념을 수학적으로 표현하는 핵심 도구이다. 데이터 간의 관계를 나타내고, 확률분포, 추정, 검정 등 다양한 통계 기법에서 필수적인 역할을 수행한다.\n통계함수: 통계함수는 독립변수(\\(x\\))와 종속변수(\\(y\\)) 데이터 간 관계를 설명한다. \\(y = f(x) + e\\)로 표현되며 \\(e\\)는 오차항이다.\n확률밀도함수: 확률밀도함수 \\(p(x)\\)는 확률변수의 확률이 함수값이다.\n기대값: 확률변수의 평균적인 값이다. \\(E(X) = \\sum xp(x)\\)\n\n\n 2. 함수와 시리즈\n시리즈는 복잡한 함수를 단순한 다항식으로 근사하거나, 함수의 특성을 분석하는 데 사용된다. 시리즈는 유한하거나 무한한 항들로 이루어진 수열의 합으로 정의된다.\n유한 시리즈: \\(S_{n} = {\\sum_{i = 1}^{n}}a_{k}\\)\n무한 시리즈: \\(S_{\\infty} = {\\sum_{i = 1}^{\\infty}}a_{k}\\)\n이항시리즈 binomial series\n\\[(a + b)^{n} = a^{n} + \\binom{n}{1}a^{n - 1}b + ... + \\binom{n}{n - 1}ab^{n - 1} + b^{n}\\]\n\n특수한 경우\n\n\\[\\frac{1}{(1 + x)^{2}} = - 1 + 2x - 3x^{2} + 4x^{3} - ...\\]\n\\[\\frac{1}{1 + x} = 1 - x + x^{2} - x^{3} + x^{4} - ...\\]\n지수시리즈 exponential series\n\\[e^{x} = 1 + x + \\frac{x^{2}}{2!} + \\frac{x^{3}}{3!} + ...\\]\n\\[e^{x} = lim_{n \\rightarrow}^{\\infty}(1 + \\frac{x}{n})^{n}\\]\n\\[ln(1 + x) = x - \\frac{{}^{2}}{2} + \\frac{x^{3}}{3} - \\frac{x^{4}}{4} + ..., - 1 &lt; x &lt; 1\\]\n산술시리즈 arithmetic series\n\\[S_{n} = a + (a + d) + (a + 2d) + \\cdots + \\lbrack a + (n - 1)d\\rbrack\\]\n      - \\(a\\): 첫 번째 항, \\(d\\): 공차(항 사이의 일정한 차이), \\(n\\): 항의 개수\n\\[S_{n} = \\frac{n}{2}\\lbrack 2a + (n - 1)d\\rbrack\\]\n기하시리즈 geometric series\n\\[S_{n} = a + ar + ar^{2} + \\cdots + ar^{n - 1}\\]\n     - \\(a\\): 첫 번째 항, \\(r\\): 공비(항 사이의 일정한 차이)\n\\[S_{n} = \\frac{a(1 - r^{n})}{1 - r},r \\neq 1\\]\n무한 기하시리즈: \\(S_{n} = \\frac{a}{1 - r}, - 1 &lt; r &lt; 1\\)\n\n\n 3. 통계학 주요상수\n지수 exponent \\(e\\)\n  자연로그 함수의 밑으로 정의되며, 무한 급수로 표현된다.\n  \\(e \\approx 2.71828182845904\\ldots\\)(무리수)\n  통계학의 주요 확률분포함수(정규분포, 포아송분포)의 항이다.\n자연상수 \\(ln2\\)\n\\[\\ln 2 \\approx 0.69314718056\\ldots \\text{(무리수)}\\]\n  정보 이론: 1비트의 정보. 이진수 체계와 로그 연산.\n황금비 \\(\\phi \\approx 1.61803398874989\\ldots\\)\n  \\(a/b = (a + b)/a\\)를 만족하는 비율 \\(\\phi = \\frac{1 + \\sqrt{5}}{2}\\)\n오일러상수: 조화급수와 자연로그의 차이로 정의된다.\n\\[\\gamma = \\lim_{n \\rightarrow \\infty}\\left( \\overset{n}{\\sum_{k = 1}}\\frac{1}{k} - \\ln n \\right) \\approx 0.577215664901532\\ldots\\]\n\n기호\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n소문자\nα\nβ\nγ\nδ\nε\nζ\nη\nθ\n\n\n대문자\nΑ\nΒ\nΓ\nΔ\nΕ\nΖ\nΗ\nΘ\n\n\n발음\nalpha\nbeta\ngamma\ndelta\nepsilon\nzeta\neta\ntheta\n\n\n소문자\nι\nκ\nχ\nλ\nμ\nν\nξ\nο\n\n\n대문자\nΙ\nΚ\nΧ\nΛ\nΜ\nΝ\nΞ\nΟ\n\n\n발음\niota\nkappa\nchi\nlambda\nmu\nnu\nxi(ksi)\nomicron\n\n\n소문자\nπ\nρ\nσ\nτ\nυ\nϕ\nψ\nω\n\n\n대문자\nΠ\nΡ\nΣ\nΤ\nΥ\nΦ\nΨ\nΩ\n\n\n발음\npi\nrho\nsigma\ntau\nupsilon\nphi\npsi\nomega\n\n\n\n\n\n\n\n\nchapter 2. 좌표와 직선방정식\n\n 1. 이차원평면과 데카르트 좌표\n\n\n\n\n\n이차원 평면에서 모든 점은 숫자 좌표로 coordinate 표현할 수 있으며, 점들의 집합으로 이루어진 선이나 곡선은 좌표방정식으로 나타낼 수 있다. 이를 위해 이차원 평면에는 두 개의 직선이 설정된다.. 수평선인 \\(x\\)-축 axis과 수직선인 \\(y\\)-축이다. 이 두 직선은 원점에서 직각으로 교차하며, 원점은 두 축의 기준점이 된다.\n원점을 기준으로 \\(x\\)-축에서 \\(a\\)만큼, \\(y\\)-축에서 \\(b\\)만큼 떨어진 점의 좌표는 \\((a,b)\\)로 표기된다. 이러한 표기 방식은 데카르트 좌표라고 한다. 여기서 \\(a\\)와 \\(b\\)는 각각 \\(x\\)-좌표와 \\(y\\)-좌표를 나타내며, 이 값들은 모두 실수 값으로 구성된다.\n데카르트 Cartesian 좌표계는 이차원 평면에서 점의 위치를 명확하고 직관적으로 나타내는 데 사용되며, 수학적 분석 및 응용의 기초가 된다. 이를 활용하면 점, 선, 곡선, 그리고 다양한 기하학적 형태를 방정식으로 표현하고, 이를 통해 여러 문제를 해결할 수 있다.\n\n\n 2. 직선과 증가\n\n직선\n두 점을 가장 짧은 거리로 연결하는 선을 직선이라고 한다. 직선은 두 점 사이의 최단 경로로 정의되며, 그 위에는 무수히 많은 점이 존재한다. 좌표평면에서 직선은 중요한 기하학적 구조로, 점과 점 사이의 관계를 나타내는 기본 도구이다.\n\n\n증가량 (Increment)\n\n\n\n\n\n좌표평면에서 두 점 \\((x_{1},y_{1})\\)과 \\((x_{2},y_{2})\\)의 이동을 고려할 때, x-좌표와 y-좌표의 변화량을 각각 증가량이라고 한다.\nx-좌표의 증가량: \\(\\Delta x = x_{2} - x_{1}\\)\ny-좌표의 증가량: \\(\\Delta y = y_{2} - y_{1}\\)\n증가량의 부호와 크기는 두 점의 좌표 차이에 의해 결정되며, x-좌표나 y-좌표의 변화 방향을 나타낸다.\n\n\n기울기 slope\n증가량은 두 점을 지나는 직선의 기울기를 계산하는 데 활용된다. 기울기 m은 두 점 사이의 x-좌표의 증가량에 대한 y-좌표의 증가량의 비율로 정의되며, 다음과 같은 식으로 표현된다:\n\\[m = \\frac{\\Delta y}{\\Delta x} = \\frac{y_{2} - y_{1}}{x_{2} - x_{1}},\\Delta x \\neq 0\\]\n    - \\(m &gt; 0\\): 직선이 오른쪽으로 올라간다.\n    - \\(m &lt; 0\\): 직선이 오른쪽으로 내려간다.\n    - \\(m = 0\\): 직선이 수평이다.\n    - \\(m\\)이 정의되지 않음 (\\(\\Delta x = 0\\)): 직선이 수직이다.\n\n\n수평 parallel과 수직 perpendicular\n두 직선 \\(L_{1}\\)과 \\(L_{2}\\)의 기울기가 동일하면, 즉 \\(m_{1} = m_{2}\\)이면 두 직선은 서로 평행 하다고 한다. 이 경우, 두 직선은 교차하지 않으며, 동일한 방향으로 뻗어 있다.\n두 직선 \\(L_{1}\\)과 \\(L_{3}\\)의 기울기의 곱이 -1이면, 즉 \\(m_{1} \\cdot m_{2} = - 1\\)이면 두 직선은 서로 수직하다고 한다. 이는 두 직선이 교차할 때 \\(90^{\\circ}\\)의 각을 이루는 경우이다.\n\n\n3. 직선 방정식 linear equation\n직선 방정식은 직선 위의 모든 점의 좌표를 만족하며, 직선 이외의 점의 좌표에서는 만족하지 않는 방정식이다. 좌표평면에서 직선은 절편 intercept과 기울기 slope를 이용해 다음과 같은 일반적인 형태로 표현된다. \\(y = bx + a\\)\n\n\\(b\\): 직선의 기울기, \\(a\\): y-축과 교차하는 절편\n\n\n\n직선 구성요소\n기울기 \\(b\\)는 직선이 얼마나 가파르게 증가하거나 감소하는지를 나타내며, x-좌표의 변화량에 대한 y-좌표의 변화량의 비율로 정의된다:\n\\[b = \\frac{\\Delta y}{\\Delta x}\\]\n    - b &gt; 0: 직선이 오른쪽으로 올라간다.\n    - b &lt; 0: 직선이 오른쪽으로 내려간다.\n    - b = 0: 직선이 수평이다.\n절편 a는 직선이 y-축과 만나는 점의 y-좌표를 나타낸다. x = 0일 때, 직선 방정식에서 y = a가 된다.\n\n\n수평선 horizontal line\n기울기 b = 0인 경우, 직선은 수평선이 된다. 이러한 직선의 방정식은 \\(y = a\\)이다. 이 직선은 x-축과 평행하며, y-축 상에서 y = a를 지난다.\n\n\n수직선 vertical line\ny-축과 평행한 직선의 방정식으로 \\(x = c\\)이다. 이 직선은 x-축과 x = c에서 교차한다. 기울기가 정의되지 않으며, 수직선은 y-축과 항상 평행하다.\n\n\n\n\n\nchapter 3. 함수란?\n\n 1. 함수 정의\n함수는 두 집합 사이의 특정 규칙에 따라 값을 대응시키는 관계를 나타낸다. 함수는 정의역과 치역으로 구성되며, 정의역의 각 원소에 대해 치역의 단 하나의 원소만 대응된다. 이를 통해 y가 x에 의해 결정된다고 표현하며, 수학적으로 다음과 같이 나타낸다. \\(y = f(x)\\)\n이는 ”y는 x의 함수이다”라고 읽는다.\n\n정의역 domain: 정의역은 함수에서 x가 가질 수 있는 값들의 집합을 말한다. 즉, 함수 f(x)가 유효하게 정의될 수 있는 모든 입력값의 집합이다.\n치역 range: 치역은 함수가 출력할 수 있는 값들의 집합이다. 정의역의 원소 x가 함수 f를 통해 출력되는 값 y = f(x)의 모임이 치역이다.\n대응 규칙: 함수는 정의역의 각 원소를 치역의 한 원소에 대응시키는 규칙을 가지고 있다. 각 정의역의 값 x는 치역에서 정확히 하나의 값 y에 대응해야 한다. (2)번은 동일 x-값에 대하여 2개 y-값이 대응되므로 함수가 아니고 다른 모든 것은 함수이다.\n\n\n\n\n\n\n\n 2. 우함수와 기함수 \n우함수 even function: 함수 \\(f(x)\\)가 다음 조건을 만족하면 우함수라 한다.\n\\[f( - x) = f(x)\\text{모든}x \\in \\text{정의역(domain)}\\]\n우함수는 y-축을 기준으로 대칭적이다. 즉, 그래프의 왼쪽 부분을 y-축을 따라 접으면 오른쪽 부분과 정확히 일치한다.\n기함수 odd function: 함수 \\(f(x)\\)가 다음 조건을 만족하면 기함수라 정의한다.\n\\[f( - x) = - f(x)\\text{모든}x \\in \\text{정의역(domain)}\\]\n기함수는 원점을 기준으로 대칭적이다. 즉, 그래프를 원점을 중심으로 180° 회전시키면 동일한 모양이 된다.\n\n\n 3. 함수 종류\n\n(1) 함성함수 Composite Function\n합성함수는 두 함수 f(x)와 g(x)가 주어졌을 때, 함수 g(x)의 출력값이 함수 f(x)의 입력값으로 사용되는 새로운 함수이다. 이를 다음과 같이 나타낸다. \\((f \\circ g)(x) = f(g(x))\\)\n    - g(x): 먼저 적용되는 함수.\n    - f(x): g(x)의 출력값을 입력값으로 사용하는 함수.\n    - \\((f \\circ g)(x)\\): f(x)와 g(x)의 합성함수.\n합성함수 \\((f \\circ g)(x)\\)의 정의역은 g(x)와 f(x)가 동시에 유효하게 정의되는 입력값으로 구성된다. 즉, x는 g(x)의 정의역에 속하고, g(x)의 출력값은 f(x)의 정의역에 속해야 한다.\n\\((f \\circ g)(x)\\)는 다음 두 단계를 거친다:\n    - 먼저 x에 대해 g(x)를 계산하고 그런 다음, f(x)에 g(x)를 대입하여 f(g(x))를 계산한다.\n\\[f(x) = 2x + 1,g(x) = x^{2}\\]\n\\[f(g(x)) = f(x^{2}) = 2x^{2} + 1\\]\n\\[g(f(x)) = g(2x + 1) = (2x + 1)^{2}\\]\n\n\n(2) 절대값 함수\n숫자 x의 절대값(absolute value)은 x의 크기(거리를 나타냄)를 의미하며, 항상 0 이상의 값을 가진다. 절대값은 다음과 같이 정의된다.\n\\[|x| = \\{\\begin{matrix}\nx, & \\text{if}x \\geq 0 \\\\\n- x, & \\text{if}x &lt; 0\n\\end{matrix}\\]\n절대값은 숫자 x와 0 사이의 거리로 해석된다. 절대값의 결과는 항상 양수이거나 0이다.\n\n\n(3) 정수함수 integer function\n정수 함수는 숫자 x를 넘지 않는 최대 정수를 반환하는 함수이다. 이를 바닥함수 floor function라고도 하며, 다음과 같이 정의된다.\n\\[\\lfloor x\\rfloor = \\text{최대 정수}n\\text{such that}n \\leq x\\]\n    - \\(\\lfloor x\\rfloor\\): x를 넘지 않는 가장 큰 정수.\n    - \\(\\lfloor x\\rfloor\\)는 항상 \\(n \\leq x &lt; n + 1\\)을 만족한다.\n\n\n\n 4. 함수의 사칙연산\n두 함수 f(x)와 g(x)가 주어졌을 때, 이들 함수에 대해 덧셈, 뺄셈, 곱셈, 나눗셈과 같은 사칙연산을 정의할 수 있다. 각 연산은 정의역에서 두 함수의 값에 기반하여 계산된다.\n함수의 덧셈/뺄셈: \\[(f \\pm g)(x) = f(x) \\pm g(x)\\]\n\n정의역: f(x)와 g(x)가 동시에 정의된 구간.\n결과: f(x)의 값과 g(x)의 값을 더한(뺀) 결과.\n\n함수의 곱셈: \\[(f \\cdot g)(x) = f(x) \\cdot g(x)\\]\n\n정의역: f(x)와 g(x)가 동시에 정의된 구간.\n결과: f(x)와 g(x)의 값을 곱한 결과.\n\n함수의 나눗셈: \\[\\left( \\frac{f}{g} \\right)(x) = \\frac{f(x)}{g(x)},g(x) \\neq 0\\]\n\n정의역: f(x)와 g(x)가 동시에 정의되고, \\(g(x) \\neq 0\\)인 구간.\n결과: f(x)의 값을 g(x)의 값으로 나눈 결과.\n\n\n\n\nchapter 4. 함수의 응용 및 극한\n\n 1. 함수의 통계 응용\n\n(1) 확률밀도함수 \\(f(x)\\)\n연속형확률변수의 분포를 나타내는 함수로, 특정 구간 내에서 값이 나타날 확률의 상대적인 가능성을 표현한다.\n    - 확률밀도함수 정의: \\(f(x) \\geq 0,\\int_{- \\infty}^{\\infty}f(x)dx = 1\\)\n    - 정규분포의 확률밀도함수: \\(f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}e^{- \\frac{(x - \\mu)^{2}}{2\\sigma^{2}}}\\)\n    - 데이터의 분포, 확률 계산 \\(P(a \\leq X \\leq b) = \\int_{a}^{b}f(x)dx\\)\n\n\n(2) 누적확률밀도함수\n확률변수가 특정 값 이하일 확률을 나타내는 함수이다.\n\n누적확률밀도함수 정의: \\(F(x) = P(X \\leq x) = \\int_{- \\infty}^{x}f(t)dt\\)\n정규분포 CDF: \\(F(x) = \\frac{1}{2}\\left\\lbrack 1 + \\text{erf}\\left( \\frac{x - \\mu}{\\sqrt{2}\\sigma} \\right) \\right\\rbrack\\)\n분위수 결정: \\(P(X \\leq x_{p}) = p\\) 만족하는 \\(X_{p}\\)를 찾음.\n\n\n\n(3) 회귀모형\n함수는 독립변수와 종속변수 간의 관계를 모델링하는 데 사용된다. 회귀모형은 함수 형태로 데이터의 추세를 설명한다.\n    - 선형회귀: \\(y = \\beta_{0} + \\beta_{1}x + \\epsilon\\)\n    - 비선형 회귀: \\(y = ae^{bx} + \\epsilon\\)\n    - 변수 간 관계 분석, 예측 모델 구축\n\n\n(4) 생존분석\n생존분석에서는 생존시간 분포를 분석하는 데 함수가 사용된다.\n\n생존survival 함수: \\(S(t) = P(T &gt; t) = 1 - F(t)\\)\n위험hazard 함수: \\(h(t) = \\frac{f(t)}{S(t)}\\)\n제품 수명 분석, 의료 데이터에서 생존 확률 평가\n\n\n\n(5) 시계열분석\n함수는 시간에 따른 데이터의 변화를 모델링하고 분석하는 데 사용된다.\n\n자기회귀 모델: \\(X_{t} = \\phi_{1}X_{t - 1} + \\phi_{2}X_{t - 2} + \\cdots + \\epsilon_{t}\\)\n주식 시장 예측, 온도 변화 모델링.\n\n\n\n(6) 함수와 몬테카를로 시뮬레이션\n함수는 확률 분포로부터 난수를 생성하여 복잡한 통계 문제를 해결하는 데 사용된다.\n\n\\(\\pi\\) 값 추정: \\(f(x) = \\sqrt{1 - x^{2}},\\text{for}x \\in \\lbrack 0,1\\rbrack\\)\n\n\n\n\n 2. 함수의 극한\n\n(1) 극한 정의\n임의의 \\(\\varepsilon &gt; 0\\)가 주어졌을 때, 모든 \\(x\\)가 특정 값 \\(a\\)에 충분히 가까워질 때 \\((0 &lt; |x - a| &lt; \\delta),f(x)\\)가 특정 값 \\(L\\)에 가까워진다면, 함수 \\(f(x)\\)의 극한은 존재하며 그 극한값은 \\(L\\)이라고 정의한다. 이를 수학적으로 표현하면 \\(\\lim_{x \\rightarrow a}f(x) = L\\) 이다.\n\n\\(\\varepsilon\\): \\(f(x)\\)와 \\(L\\)사이의 허용 오차.\n\\(\\delta\\): \\(x\\)와 \\(a\\) 사이의 거리 제한.\n\n엄밀한 정의 (\\(\\varepsilon - \\delta\\)정의)\\(\\forall\\varepsilon &gt; 0,\\exists\\delta &gt; 0\\text{such that}0 &lt; |x - a| &lt; \\delta \\Longrightarrow |f(x) - L| &lt; \\varepsilon\\)이 의미는 \\(x\\)와 \\(a\\)에 충분히 가까워지면 \\((|x - a| &lt; \\delta)\\) 함수 \\(f(x)\\)의 값이 \\(L\\)에 충분히 가까워짐 \\((|f(x) - L| &lt; \\varepsilon)\\)을 보장한다.\n\n\n(2) 함수값과 극한값\n함수값 \\(f(a)\\)는 함수가 특정 점 \\(x = a\\)에서 실제로 가지는 값이다. 반면, 극한값 \\(\\lim_{x \\rightarrow a}f(x)\\)는 \\(x\\)가 \\(a\\)에 가까워질 때 \\(f(x)\\)가 수렴하는 값을 나타낸다. 함수값과 극한값은 다를 수 있으며, 함수가 \\(x = a\\)에서 정의되지 않아도 극한값은 존재할 수 있다.\n함수값 \\(f(a) = k\\): 함수가 \\(x = a\\)에서 정의되어 있다면 \\(f(a)\\)는 \\(k\\), 특정 값을 가진다.\n극한값: 극한값은 좌극한(left-hand limit)과 우극한(right-hand limit)에 따라 달라질 수 있다:\n    - 좌극한 \\(L_{2}\\): \\(\\lim_{x \\rightarrow a^{-}}f(x) = L_{2}\\)\n    - 우극한 \\(L_{1}\\): \\(\\lim_{x \\rightarrow a^{+}}f(x) = L_{1}\\)\n    - 전체 극한은 좌극한과 우극한이 동일할 때 존재한다,\n\n\n(3) 연속함수 정의\n함수 \\(f(x)\\)가 \\(x = a\\)에서 연속하려면 다음 세 가지 조건을 모두 만족해야 한다:\n  1. \\(f(a)\\)가 정의되어 있어야 한다.\n  2. \\(\\lim_{x \\rightarrow a}f(x)\\)가 존재해야 한다.\n  3. 함수값과 극한값이 일치해야 한다. \\(\\lim_{x \\rightarrow a}f(x) = f(a)\\)\n\n\n(4) 극한 계산 규칙\n상수함수의 극한: \\(\\lim_{x \\rightarrow a}c = c\\), 상수 함수의 극한은 상수 자신이다.\n항등함수의 극한: \\[\\lim_{x \\rightarrow a}x = a\\]\n선형성: 극한 연산은 선형성을 가진다:\n\\[\\lim_{x \\rightarrow a}\\lbrack f(x) \\pm g(x)\\rbrack = \\lim_{x \\rightarrow a}f(x) \\pm \\lim_{x \\rightarrow a}g(x)\\]\n곱셈: 두 함수의 곱의 극한은 각 함수의 극한의 곱과 같다.\n\\[\\lim_{x \\rightarrow a}\\lbrack f(x) \\cdot g(x)\\rbrack = \\left( \\lim_{x \\rightarrow a}f(x) \\right) \\cdot \\left( \\lim_{x \\rightarrow a}g(x) \\right)\\]\n나눗셈: 두 함수의 나눗셈의 극한은 각 함수의 극한의 나눗셈과 같다 (분모가 0이 아닌 경우)\n\\[\\lim_{x \\rightarrow a}\\frac{f(x)}{g(x)} = \\frac{\\lim_{x \\rightarrow a}f(x)}{\\lim_{x \\rightarrow a}g(x)},\\lim_{x \\rightarrow a}g(x) \\neq 0\\]\n거듭제곱\n  \\(\\lim_{x \\rightarrow a}\\lbrack f(x)\\rbrack^{n} = \\left( \\lim_{x \\rightarrow a}f(x) \\right)^{n}\\), 여기서 \\(n\\)은 정수이다.\n루트\n  \\[\\lim_{x \\rightarrow a}\\sqrt[n]{f(x)} = \\sqrt[n]{\\lim_{x \\rightarrow a}f(x)},\\text{if}\\lim_{x \\rightarrow a}f(x) \\geq 0\\]\n합성함수의 극한 (연쇄법칙): 만약 \\(g(x)\\) 의 극한이 \\(a\\)로 접근할 때 \\(b\\)이고, \\(f(x)\\)가 \\(b\\)에서 연속이면\n\\(\\lim_{x \\rightarrow a}f(g(x)) = f\\left( \\lim_{x \\rightarrow a}g(x) \\right)\\) 이다.\nL’Hôpital’s Rule의 정의: 함수 f(x)와 g(x)가 x \\to a에서 각각 0/0 형태 또는 \\infty/\\infty 형태를 가지는 경우, 두 함수의 극한은 다음과 같이 계산할 수 있다:\n\\[\\lim_{x \\rightarrow a}\\frac{f(x)}{g(x)} = \\lim_{x \\rightarrow a}\\frac{f'(x)}{g'(x)},\\text{if}\\lim_{x \\rightarrow a}\\frac{f'(x)}{g'(x)}\\text{exists.}\\]\n\n형태: \\(\\frac{0}{0}\\) 또는 \\(\\frac{\\infty}{\\infty}\\)와 같은 불정형 형태를 가져야 한다.\n미분 가능성: \\(f(x)\\)와 \\(g(x)\\)는 \\(x \\rightarrow a\\)에서 미분 가능해야 한다.\n분모의 도함수가 0이 아님: \\(g'(x) \\neq 0\\)인 구간에서 적용 가능\n\\(\\frac{0}{0}\\) 형태: \\(\\lim_{x \\rightarrow 0}\\frac{\\sin(x)}{x} = \\lim_{x \\rightarrow 0}\\frac{\\cos(x)}{1} = \\cos(0) = 1\\)\n\\(\\frac{\\infty}{\\infty}\\) 형태: \\(\\lim_{x \\rightarrow \\infty}\\frac{x}{e^{x}} = \\lim_{x \\rightarrow \\infty}\\frac{1}{e^{x}} = 0\\)\n\n무한대 있는 극한: \\(x\\)가 무한대 \\(\\infty\\)혹은 \\(- \\infty\\)로 접근할 때 함수 \\(f(x)\\)의 극한을 구하는 규칙이다.\n\\[lim_{x \\rightarrow \\pm \\infty}\\frac{1}{x} = 0\\]\n\\(lim_{x \\rightarrow \\pm \\infty}c = c\\), \\(c\\)는 상수\n함수가 분수의 형태를 가지면 분모의 가장 큰 \\(x\\)차수로 나누고 위의 규칙을 이용하면 된다.\n특정 함수의 극한\n\n지수 함수: \\(\\lim_{x \\rightarrow \\infty}e^{- x} = 0\\)\n삼각 함수: \\(\\lim_{x \\rightarrow 0}\\frac{\\sin(x)}{x} = 1\\), \\(\\lim_{x \\rightarrow 0}\\frac{1 - \\cos(x)}{x^{2}} = \\frac{1}{2}\\)\n로그 함수: \\(\\lim_{x \\rightarrow \\infty}\\ln(x) = \\infty\\)\n\n\n\n\n 3. 수렴 convergence\n수렴의 정의: 함수 \\(f(x)\\) 또는 수열 \\(\\{ a_{n}\\}\\)가 특정 값에 수렴한다는 것은 극한값이 존재하며, 일정 값에 점점 가까워진다는 것을 의미한다.\n수열의 수렴: 수열 \\(\\{ a_{n}\\}\\)이 \\(L\\)로 수렴한다면, 임의의 \\(\\varepsilon &gt; 0\\)에 대해 \\(n \\geq N\\) 일 때 다음 조건을 만족하는 \\(N\\)이 존재한다.\n\\(|a_{n} - L| &lt; \\varepsilon\\), 여기서 \\(L\\)은 수열의 극한값이다.\n함수의 수렴: 함수 \\(f(x)\\)가 \\(L\\)로 수렴하면, \\(x \\rightarrow a\\)에서 \\(\\lim_{x \\rightarrow a}f(x) = L\\)\n수렴의 성질\n\n수열이나 함수가 수렴하면 극한값은 유일하다.\n수렴하는 함수나 수열은 경계값을 가지며, 점점 극한값에 가까워진다.\n\n극한과 수렴의 차이\n\n극한은 특정 값에 접근하는 경향을 나타내며, 함수나 수열이 특정 점에서 어떻게 동작 하는지 설명한다.\n수렴은 극한값이 존재하고 일정 값에 점점 가까워지는 성질을 나타낸다.\n\n\n\n 4. 확률수렴과 분포수렴\n\n(1) 확률수렴 (Convergence in Probability)\n확률변수의 열 \\(\\{ X_{n}\\}\\)이 확률변수 \\(X\\)에 확률수렴한다는 것은, 임의의 \\(\\varepsilon &gt; 0\\)에 대해 다음 조건을 만족하는 \\(n \\rightarrow \\infty\\)가 존재함을 의미한다. \\(\\lim_{n \\rightarrow \\infty}P(|X_{n} - X| \\geq \\varepsilon) = 0\\)\n  - 표기: \\(X_{n}\\overset{P}{\\rightarrow}X\\)\n해석: 확률적으로 \\(|X_{n} - X|\\)가 작아질 가능성이 1에 가까워짐을 나타낸다. 즉, \\(X_{n}\\)과 \\(X\\)가 점점 ”가까워진다”고 해석할 수 있다.\n성질\n\n확률수렴의 유일성: 극한값 \\(X\\)는 유일하다.\n확률수렴과 함수: \\(X_{n}\\overset{P}{\\rightarrow}X\\)이고 \\(g(x)\\)가 연속 함수라면 \\(g(X_{n})\\overset{P}{\\rightarrow}g(X)\\)\n\n통계학 응용: (추정량의 일치성) 추정량 \\({\\widehat{\\theta}}_{n}\\)이 모수 \\(\\theta\\)에 확률수렴하면 \\({\\widehat{\\theta}}_{n}\\)은 일치추정량이다. 법칙의 수렴: 큰 수의 약법칙은 확률수렴으로 표현된다:\n\\[{\\overline{X}}_{n}\\overset{P}{\\rightarrow}\\mu\\]\n\n\n(2) 분포수렴 (Convergence in Distribution)\n확률변수의 수열 \\(\\{ X_{n}\\}\\)이 확률변수 \\(X\\)에 분포수렴한다는 것은, 모든 연속점 \\(x\\)에서 누적분포함수(FDF) \\(F_{X_{n}}(x)\\)가 \\(F(x)\\)로 수렴함을 의미한다. \\(\\lim_{n \\rightarrow \\infty}F_{X_{n}}(x) = F_{X}(x),\\forall x\\) \\(F_{X}(x)\\)에서 연속함수.\n  표기: \\(X_{n}\\overset{\\mathcal{D}}{\\rightarrow}X\\)\n해석: 분포수렴은 \\(X_{n}\\)의 분포가 \\(X\\)의 분포로 점점 가까워지는 것을 의미한다. 개별적인 실현값이 아니라 분포 전체의 형태를 고려한다.\n성질\n\n연속성: 분포수렴은 누적분포함수의 연속점에서 정의된다.\n함수와 분포수렴: \\(X_{n}\\overset{\\mathcal{D}}{\\rightarrow}X\\)이고 \\(g(x)\\) 가 연속 함수라면 \\(g(X_{n})\\overset{\\mathcal{D}}{\\rightarrow}g(X)\\) 이다.\n\n응용: 중심 극한 정리: 표본 평균이 정규분포로 수렴하는 현상은 분포수렴으로 나타낸다. \\(\\sqrt{n}({\\overline{X}}_{n} - \\mu)\\overset{\\mathcal{D}}{\\rightarrow}N(0,\\sigma^{2})\\)\n\n\n(3) 확률수렴과 분포수렴의 관계\n확률수렴 → 분포수렴\n\\[X_{n}\\overset{P}{\\rightarrow}X \\Longrightarrow X_{n}\\overset{\\mathcal{D}}{\\rightarrow}X\\]\n분포수렴 ≠ 확률수렴\n  분포수렴이 확률수렴을 보장하지 않는다. 예를 들어, \\(X_{n} \\sim U( - n,n)\\)은 \\(X = 0\\)에 분포수렴하나 확률수렴하지 않는다."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "세상의 모든 통계 이야기",
    "section": "",
    "text": "🎓 Welcome to Prof. Kwon’s 통계이야기\n\n\n\n\n\n1995년부터 한남대학교에서 제공해온 통계학 강의노트를 데이터 사이언스 중심으로 새롭게 구성했습니다. since 1999.03(첫 웹이지 구축) / 2023.01 (1차 수정)\n\n| put a ding in the universe |\n\n\n\n\n👤 Who am I?\n\n\n\n성균관대학교 통계학 학사\n성균관대학교 통계학 석사\n미국 North Carolina State University 통계학 박사\n~ 1995. 전자통신연구원 선임연구원\n~ 2026. 한남대학교 통계학과 교수"
  },
  {
    "objectID": "notes/math/vector.html",
    "href": "notes/math/vector.html",
    "title": "수학의 기초 1. 함수",
    "section": "",
    "text": "chapter 1. 선형대수 개념\n\n1. 선형대수 정의\n선형대수는 벡터 공간과 그 안에 존재하는 벡터 간의 관계를 다루는 수학의 한 분야로, 벡터와 행렬을 이용한 수학적 표현과 계산을 중심으로 구성된다. 이 분야의 기본 구성 요소로는 벡터, 행렬, 스칼라가 있으며, 주요 개념에는 선형 변환, 고유값과 고유벡터, 내적과 외적, 행렬의 분해 등이 포함된다.\n통계학에서 선형대수는 데이터를 벡터와 행렬의 형태로 구조화함으로써 복잡한 수치 연산을 간결하게 수행할 수 있도록 돕는다. 특히 고차원 데이터의 계산과 변환을 수학적으로 명확하게 정의할 수 있기 때문에, 데이터 구조를 이해하고 차원을 축소하는 데 핵심적인 도구로 사용된다.\n이러한 선형대수의 기법은 통계 모델링과 머신러닝의 기초가 되며, 회귀 분석이나 주성분 분석(PCA), 군집 분석 등 다양한 통계적 방법론에서 필수적인 역할을 수행한다. 결과적으로, 선형대수는 현대 통계학에서 이론적 기반뿐 아니라 실용적 계산의 핵심 수단으로 작용한다.\n\n\n2. 선형대수와 선형변환\n선형대수는 선형적인 관계를 다루는 수학의 한 분야로, 이 이론 체계 내에서 이루어지는 연산과 변환은 모두 선형성을 만족해야 한다. 이러한 특성 때문에 일반적인 함수는 선형대수의 중심 개념으로 다루어지지 않지만, 함수의 특수한 형태인 선형 변환은 예외적으로 핵심 개념으로 간주된다. 선형 변환은 벡터 공간의 구조를 보존하면서 벡터를 다른 벡터로 사상하는 과정을 의미하며, 행렬을 이용해 구체적으로 표현될 수 있다. 따라서 선형 변환은 선형대수의 이론과 응용 모두에서 중심적인 역할을 수행한다.\n함수 \\(y = f(x)\\)\n\n함수는 두 집합 사이의 관계로, 각 입력값(정의역, domain)에 대해 정확히 하나의 출력값(공역, range)을 대응시키는 규칙이다.\n함수는 일반적으로 \\(f:D \\rightarrow R\\)와 같이 표기되며, \\(D\\)는 정의역, \\(R\\)는 공역입니다.\n특정함수에 대하여 함수값이 0인 \\(f(x) = 0\\)를 방정식이라 하고 이를 만족하는 \\(x\\)를 방정식의 해(root, solution)라고 한다.\n\n\n\n\n\n\n선형함수\n선형함수는 입력 변수와 출력 변수 사이의 관계를 직선으로 나타내는 함수로, 일반적으로 다음과 같은 형태로 표현된다: \\(f(x) = a + bx\\), \\(a:\\) 절편, \\(b:\\) 기울기\n\n가법성 additivity: \\(f(x + y) = f(x) + f(y)\\)\n동차성 homogeniety: \\(f(cx) = cf(x)\\), \\(c\\)는 상수\n\n선형변환\n선형 변환(linear transformation)은 벡터 공간에서 정의된 함수 중 하나로, 한 벡터를 동일하거나 다른 벡터 공간의 또 다른 벡터로 변환하는 함수의 특수한 형태이다. 이 변환은 선형성(linearity)이라 불리는 다음의 두 가지 성질을 만족해야 한다. \\(\\underset{¯}{u},\\underset{¯}{v}\\) 동일 차원의 벡터에 대하여 함수 \\(T\\)가 다음 조건을 만족하면 선형변환이다.\n\n덧셈에 대한 선형성: \\(T(\\underset{¯}{u} + \\underset{¯}{v}) = T(\\underset{¯}{u}) + T(\\underset{¯}{v})\\)\n스칼라 곱에 대한 선형성: \\(T(c\\underset{¯}{u}) = cT(\\underset{¯}{u})\\)\n\n\n\n\n\n\n\n\n\nchapter 2. 벡터 vector 기초\n\n1. 벡터정의\n벡터는 정렬된 유한한 수들의 목록으로, 일반적으로 정사각형 괄호 또는 곡선 괄호로 둘러싸인 수직 형태의 배열로 표현된다. 이러한 형태는 수평 배열인 행벡터(row vector)와 구별하여 열벡터(column vector)라고 부른다.\n\\(\\left( \\begin{array}{r}\n1 \\\\\n- 2 \\\\\n0\n\\end{array} \\right)\\), \\(\\left\\lbrack \\begin{array}{r}\n1 \\\\\n- 2 \\\\\n0\n\\end{array} \\right\\rbrack\\)벡터를 행으로 사용할 때는 쉼표로 구분되고 괄호로 둘러싸인 숫자로 쓴다. \\(\\left( \\begin{array}{r}\n1, - 2,0\n\\end{array} \\right)\\)\n배열의 값을 벡터의 원소 element 라 하고 원소의 개수를 벡터의 크기(차원 demension)라고 한다. 위 벡터는 크기가 3 이고 세 번째 원소는 0 이다. n 크기의 벡터는 n-벡터라고 불리고 1벡터는 숫자와 같은 것으로 간주한다. 즉, 우리는 1-벡터 [ 13 ]와 숫자 13을 구별하지 않으며 숫자는 스칼라 scalar 라 한다. 벡터의 각 원소는 스칼라이고 원소가 실수인 \\(a_{i} \\in R^{n}\\) 벡터를 실수 벡터라 한다.\n\n\n2. 벡터 기호\nn-벡터를 나타내기 위해 \\({\\underset{¯}{a}}_{n}\\)(구별이 가능한 경우 알파벳 \\(a\\)를 벡터로 표현) 기호를 사용한다. \\(a_{n}\\)벡터 의 i-번째 요소는 \\(a_{i}\\)로 표시되며, 여기서 첨자 i는 벡터의 크기인 1에서 \\(n\\)까지 정의되는 정수 인덱스이다.\n두 벡터 \\(a_{n},b_{n}\\)가 동일하다는 것은 (1)크기(차수)도 \\(n\\) 동일하고 (2) 각 대응 원소가 동일 \\(a_{i} = b_{i}\\)함을 의미한다.\n\n\n3. 특수한 벡터\n\n(1) 영벡터 zero vector\n모든 원소가 0인 벡터이며 \\(0_{n}\\)으로 표현된다. 일반적으로 모든 0 벡터는 0으로 표시되며, 숫자 0을 나타내는데 사용되는 것과 동일한 기호이다. 다른 크기의 제로 벡터를 나타내기 위해 모두 같은 기호 0을 사용하므로 기호 0은 문맥에 따라 다른 것을 의미할 수 있기 때문에 컴퓨터에서는 이를 과부하라 한다.\n\n\n(2) 단위벡터 unit vector\n(표준) 단위 벡터는 1인 하나의 원소를 제외한 모든 요소가 0과 같은 벡터이다. i-번째 단위 벡터(n 크기)는 i-번째 원소만 1을 가진 단위 벡터이며, \\(e_{i}\\)로 표현한다. 이렇게 되면 크기를 나타내는 첨자와 1인 원소 위치를 나타내는 첨자가 구별이 되지 않는 모호성을 갖는다.\n\n\n(3) 일벡터 ones vector\n모든 원소가 1인 n-벡터이며 \\(1_{n}\\)로 표현한다. 우리는 또한 벡터의 크기가 문맥에서 결정될 수 있다면 1로 쓴다.\n\n\n\n4. 벡터 개념\n\n(1) 위치 location\n2차원 공간, 즉 평면의 위치를 나타내는 데 사용될 수 있다. 3-벡터는 3차원(3-D) 공간에서 어떤 지점의 위치나 위치를 나타내는 데 사용된다. 벡터의 원소는 위치의 좌표를 제공한다.\n\n\n\n\n\n벡터는 주어진 시간에 평면이나 3차원 공간에서 움직이는 지점의 속도나 가속도를 나타내는 데 사용될 수 있다.\n\n\n\n\n\n\n\n(2) 희소성\n많은 원소가 0이면 희소하다고 한다. 그것의 희소성 패턴은 0이 아닌 항목의 인덱스 집합이다. \\(n\\)-벡터 \\(a_{n}\\)의 0이 아닌 항목의 수는 \\(nnz(a_{n})\\)로 표시한다다. 단위벡터는 0이 아닌 항목이 하나만 있기 있고 0 벡터는 0이 아닌 항목이 없기 때문에 희소한 벡터이다.\n\n\n(3) 이미지\n3차원 벡터는 빨간색, 녹색 및 파란색(R-G-B) 강도 값(0에서 1 사이)을 제공하는 항목을 통해 색상을 나타낸다. 벡터(0,0,0)는 검은색을 나타내고, 벡터(0, 1, 0)는 밝은 순수한 녹색을 나타내며, 벡터(1, 0.5, 0.5)는 분홍색을 나타낸다.\n\n\n\n\nchapter 3. 벡터 연산과 크기\n\n1. 벡터 연산\n\n(1) 벡터 합\n두 벡터를 합을 구한다는 것은 (1) 차수가 동일한 두 벡터의 (2) 동일 위치의 원소를 합하여 하나의 벡터를 계산한다는 것을 의미한다. 차도 동일하다.\n\\(\\left\\lbrack \\begin{array}{r}\n1 \\\\\n- 2 \\\\\n0\n\\end{array} \\right\\rbrack + \\left\\lbrack \\begin{array}{r}\n1 \\\\\n2 \\\\\n3\n\\end{array} \\right\\rbrack = \\left\\lbrack \\begin{array}{r}\n2 \\\\\n0 \\\\\n3\n\\end{array} \\right\\rbrack\\), \\(\\left\\lbrack \\begin{array}{r}\n1 \\\\\n- 2 \\\\\n0\n\\end{array} \\right\\rbrack - \\left\\lbrack \\begin{array}{r}\n1 \\\\\n2 \\\\\n3\n\\end{array} \\right\\rbrack = \\left\\lbrack \\begin{array}{r}\n0 \\\\\n- 4 \\\\\n- 3\n\\end{array} \\right\\rbrack\\)\n성질\n차수가 동일한 벡터 \\(a,b,c\\)에 대하여 다음이 성립한다.\n\n교환법칙 : \\(a + b = b + a\\)\n교환법칙 : \\((a + b) + c = a + (b + c)\\)\n영벡터를 더하거나 빼도 영향을 받지 않는다. \\(a \\pm 0 = a\\)\n벡터에서 자체 벡터를 빼면 영벡터가 된다. \\(a - a = 0\\)\n\n\n\n(2) 스칼라-벡터 곱\n벡터에 스칼라(즉, 숫자)를 곱하는 스칼라-벡터 곱셈은 벡터의 모든 요소에 스칼라를 곱하여 수행한다. 일반적으로 스칼라를 왼쪽, 벡터를 오른쪽에 적지만 순서를 바꾸어 사용해도 되고 계산 결과는 동일하다.\n\\(a = \\left\\lbrack \\begin{array}{r}\n1 \\\\\n- 2 \\\\\n0\n\\end{array} \\right\\rbrack\\)이면 \\(3a = a3 = \\left\\lbrack \\begin{array}{r}\n3 \\\\\n- 6 \\\\\n0\n\\end{array} \\right\\rbrack\\)\n성질\n벡터 \\(a\\), 스칼라 \\(c,k\\)에 대하여 다음이 성립한다.\n\n교환법칙 : \\(ka = ak\\)\n배분법칙 : \\((c + k)a = ca + ka\\)\n\n\n\n(3) 선형 결합 linear combination\n차수 \\(n\\)-벡터 \\(a_{1},a_{2},...,a_{m}\\), 스칼라 \\(k_{1},k_{2},...,k_{m}\\)에 대하여 다음 \\(n\\)-벡터를 벡터 \\(a_{1},a_{2},...,a_{m}\\)의 선형결합이라 하고 스칼라 \\(k_{1},k_{2},...,k_{m}\\)는 선형결합의 계수라 한다.\n\\[k_{1}a_{1} + k_{2}a_{2} + ... + k_{m}a_{m}\\]\n\n\\(k_{1} = k_{2} = ... = k_{m} = 1\\)이면, 선형결합은 벡터 합이다.\n\\(k_{1} = k_{2} = ... = k_{m} = \\frac{1}{m}\\)이면, 선형결합은 벡터 평균이다.\n\\(k_{1} + k_{2} + ... + k_{m} = 1\\)이면, 선형결합은 affine 결합이라 하고 모든 계수가 양수인 경우 선형결합을 가중평균이라 한다.\n\n\n\n(4) 내적 inner product\n두 벡터 간의 관계를 정의하고 벡터의 길이와 각도 등의 개념을 도입하는 중요한 연산이다. 차수(\\(m\\))가 동일한 두 벡터 (\\(u,v\\))의 내적 곱은 다음과 같이 정의하고 결과는 스칼라이다.\n\\[u^{T}v = \\lbrack u_{1},u_{2},...,u_{m}\\rbrack\\left\\lbrack \\begin{array}{r}\nv_{1} \\\\\nv_{2} \\\\\n... \\\\\nv_{m}\n\\end{array} \\right\\rbrack = u_{1}v_{1} + u_{2}v_{2} + ... + u_{m}v_{m} = \\overset{m}{\\sum_{i = 1}}u_{i}v_{i}\\]\n단, \\(u^{T}\\)는 \\(u\\)의 전치 transpose라 하고 열벡터를 행벡터로 변환한 것이다.\n【예제】\n\\[\\lbrack 1,3,5\\rbrack^{T}\\left\\lbrack \\begin{array}{r}\n  0 \\\\\n   - 1 \\\\\n  1\n  \\end{array} \\right\\rbrack = (1)(0) + (3)( - 1) + (5)(1) = 2\\]\n내적 성질\n\nunit 벡터 : \\(e_{i}v = v_{i}\\)\n벡터 합 : \\(1_{m}^{T}v = \\overset{m}{\\sum_{i = 1}}v_{i}\\)\n벡터 평균 : \\(avg(v) = (1/n)1_{m}^{T}v = (1/n)\\overset{m}{\\sum_{i = 1}}v_{i}\\)\n벡터 제곱합 : \\(v^{T}v = v_{1}^{2} + v_{2}^{2} + ... + v_{m}^{2} = \\overset{m}{\\sum_{i = 1}}v_{i}^{2}\\)\n\nCauchy–Schwarz inequality\n차수 동일한 두 벡터의 내적 inner product에 대하여 다음이 성립한다.\n\\[\\parallel a^{T}b \\parallel \\leq \\parallel a \\parallel \\parallel b \\parallel\\]\n\\[|\\overset{n}{\\sum_{i}}a_{i}b_{i}| \\leq (\\sum a_{i}^{2})^{\\frac{1}{2}}(\\sum b_{i}^{2})^{\\frac{1}{2}}\\]\n\n\n(5) 외적 cross product\n주로 3차원 공간에서 두 벡터로부터 새로운 벡터를 생성하는 연산입니다. 이 연산의 결과는 두 벡터에 모두 수직인 벡터이며, 크기는 두 벡터가 이루는 평행사변형의 면적에 해당합니다.\n외적 정의\n벡터 \\(\\underset{¯}{a} = (a_{1},a_{2},a_{3})\\)와 벡터 \\(\\underset{¯}{b} = (b_{1},b_{2},b_{3})\\) 의 외적 \\(\\underset{¯}{a} \\times \\underset{¯}{b}\\) 는 다음과 같이 계산한다.\n\n\\(x\\) 성분: \\(a_{2}b_{3} - a_{3}b_{2}\\)\n\\(y\\) 성분: \\(a_{3}b_{1} - a_{1}b_{3}\\)\n\\(z\\) 성분: \\(a_{1}b_{2} - a_{2}b_{1}\\)\n\n\n\n\n\n\n【예제】 벡터 \\(\\underset{¯}{a} = (2,3,4)\\)와 벡터 \\(\\underset{¯}{b} = (5,6,7)\\)의 외적은 \\(\\underset{¯}{c} = \\underset{¯}{a} \\times \\underset{¯}{b} = ( - 3,6, - 3)\\) 이다.\n외적은 벡터 \\(\\underset{¯}{a},\\underset{¯}{b}\\)와 수직(\\({\\underset{¯}{c}}^{T}\\underset{¯}{a} = 0\\), \\({\\underset{¯}{c}}^{T}\\underset{¯}{b} = 0\\))이며 외적의 크기(놈 norm)는 두 벡터가 이루는 평행사면형 면적이다.\n\n\n\n2. 선형함수\n선형함수 정의\n\\(f:R^{n} \\rightarrow R\\)는 크기 n-벡터를 실수(스칼라)로 매핑하는 함수이다. 함수 \\(f(x)\\)의 \\(x_{1},x_{2},...,x_{n}\\)은 함수 \\(f\\)의 인수 argument라 하고 결과 값 스칼라는 함수 값이다. \\(f(x) = f(x_{1},x_{2},...,x_{n})\\)\n【예제】\n\\[f:R^{4} \\rightarrow R$ : $f(x) = x_{1} - x_{2} + x_{4}^{2}\\]\n차수 n-벡터 \\(a,x\\)에 대하여 내적 함수 \\(f(x) = a^{T}x = scalar\\)는 선형함수일 때 다음이 성립한다. 단, \\(\\alpha,\\beta\\)는 스칼라, \\((x,y)\\)는 n-벡터이다. \\(f(\\alpha x + \\beta y) = \\alpha f(x) + \\beta f(y)\\)\n선형함수 조건\n다음 조건을 만족하는 \\(f:R^{n} \\rightarrow R\\) 는 선형함수이다. 단, \\(\\alpha\\)는 스칼라, \\((x,y)\\)는 n-벡터이다.\n\nHomogeniety : \\(f(\\alpha x) = \\alpha f(x)\\)\nAdditivity : \\(f(x + y) = f(x) + f(y)\\)\n\n\n(1) 절편 Affine 함수\n선형 함수에 상수 항을 추가한 형태의 함수이다. 이는 선형 변환과 평행 이동을 결합한 함수로, 다음과 같은 수식으로 표현된다.\nn-벡터, \\(x\\)에 대하여 다음 \\(f\\)는 절편 함수이다. 단, \\(a\\)는 n-벡터, \\(k\\)는 스칼라이다. \\(f(a^{T}x + k) = a^{T}f(x) + k\\)\n【예제】 \\(f(x) = 7 - 2x_{1} + 3x_{2} - x_{3}\\), \\(k = 7,a = \\left\\lbrack \\begin{array}{r}\n   - 2 \\\\\n  3 \\\\\n   - 1\n  \\end{array} \\right\\rbrack\\)\n\n\n(2) 선형함수의 내적 표현\n\\(e_{i}\\) 단위벡터, \\(x_{n}\\) 차수 n-벡터, \\(f\\) 선형함수라 하면, \\[\\begin{matrix}\nf(x) & = f(x_{1}e_{1} + x_{2}e_{2} + ... + x_{n}e_{n}) \\\\\n& = x_{1}f(e_{1}) + x_{2}f(e_{2}) + ... + x_{n}f(e_{n}) \\\\\n& = a^{T}x,wherea^{T} = \\lbrack f(e_{1}),f(e_{2}),...,f(e_{n})\\rbrack\n\\end{matrix}\\]\n\n\n(3) 사례 : sag 처짐 (단위: mm)\n하중벡터 \\(w = \\left( \\begin{array}{r}\nw_{1} \\\\\nw_{2} \\\\\nw_{3}\n\\end{array} \\right)\\)(단위:톤), 변형 compliance 민감도 벡터 \\(c = \\left( \\begin{array}{r}\nc_{1} \\\\\nc_{2} \\\\\nc_{3}\n\\end{array} \\right)\\)(단위:mm/톤)이라면 교량 처짐 sag은 \\(s = c^{T}w\\) (하중 가중합)이다.\n\n\n\n\n\n\n\n(4) 테일러 근사 Taylor proximation\n함수 \\(f:R^{n} \\rightarrow R\\)이 1차 미분이 가능하다고 하면 \\(n\\)-벡터 함수 \\(f(x)\\)의 근사값은 다음과 같이 구한다. 이를 1차 테일러 근사라 한다. 단, n-벡터 \\(z\\)는 n-벡터 \\(x\\)와 가까운 값이다.\n\\[\\widehat{f}(x) = f(z) + \\frac{\\partial f}{\\partial x_{1}}(z)(x_{1} - z_{1}) + ... + \\frac{\\partial f}{\\partial x_{n}}(z)(x_{n} - z_{n})\\]\n【예제】\n함수 \\(f:R^{2} \\rightarrow R\\)을 \\(f(x) = x_{1} + \\exp(x_{2} - x_{1})\\)라 하자. 이 함수는 선형함수는 아니다. 이를 선형함수로 근사하는 것을 테일러 근사라 한다. \\(z = (1,2)\\)라 하면,\n\\[\\triangledown f(z) = \\left\\lbrack \\begin{array}{r}\n1 - \\exp(z_{2} - z_{1}) \\\\  \n\\exp(z_{2} - z_{1})  \n\\end{array} \\right\\rbrack|_{z_{1} = 1,z_{2} = 2} = ( - 1.72,2.72)\\]\n그러므로 \\(z = (1,2)\\)에서 \\(f(x)\\)의 테일러 근사값은 다음과 같다:\n\\[\\widehat{f}(x) = 3.718 + \\left\\lbrack \\begin{array}{r}  - 1.72 \\\\  2.72 \\end{array} \\right\\rbrack^{T}(\\left\\lbrack \\begin{array}{r} x_{1} \\\\  x_{2} \\end{array} \\right\\rbrack - \\left\\lbrack \\begin{array}{r}  1 \\\\ 2  \\end{array} \\right\\rbrack)\\]\n\n\n(5) 회귀모형\n차원 2-예측(설명, 독립) 벡터 \\(x = \\left\\lbrack \\begin{array}{r}\nx_{1} \\\\\nx_{2}\n\\end{array} \\right\\rbrack\\), 회귀계수 벡터 \\(b = \\left\\lbrack \\begin{array}{r}\nb_{1} \\\\\nb_{2}\n\\end{array} \\right\\rbrack\\), 그리고 \\(a\\)을 절편 스칼라라 하면 회귀모형은 다음과 같다.\n\\(\\widehat{y} = \\left\\lbrack \\begin{array}{r}\n1 \\\\\nx\n\\end{array} \\right\\rbrack^{T}\\left\\lbrack \\begin{array}{r}\na \\\\\nb\n\\end{array} \\right\\rbrack = {\\overset{˜}{x}}^{T}\\overset{˜}{b}\\) OLS 추정치 : \\(\\widehat{\\overset{˜}{b}} = ({\\overset{˜}{x}}^{T}\\overset{˜}{x})^{- 1}{\\overset{˜}{x}}^{T}y\\)\n\n\n\n3. 벡터놈 norm\n\n(1) 정의\n벡터의 유클리디안 놈, \\(\\parallel x \\parallel\\)은 벡터의 크기에 대한 척도로 다음과 같이 구한다. 놈은 벡터의 원점에서의 거리이다.\n\\[\\parallel x \\parallel = \\sqrt{x_{1}^{2} + x_{2}^{2} + ... + x_{n}^{2}} = \\sqrt{x^{T}x}\\]\n【예제】\n\\[\\parallel \\left\\lbrack \\begin{array}{r}\n  0 \\\\\n   - 1 \\\\\n  1\n  \\end{array} \\right\\rbrack \\parallel = \\sqrt{2}$,\n  $\\parallel \\left\\lbrack \\begin{array}{r}\n   - 1 \\\\\n  2\n  \\end{array} \\right\\rbrack \\parallel = \\sqrt{5}\\]\n성질\n\n비음수 동차성: \\(\\parallel \\beta x \\parallel = |\\beta| \\parallel x \\parallel\\), where \\(\\beta\\)는 스칼라\n삼각 부등식: \\(\\parallel x + y \\parallel \\leq \\parallel x \\parallel + \\parallel y \\parallel\\)\n비음수: \\(\\parallel x \\parallel \\geq 0\\)\n\n\n\n(2) 놈의 종류\n\nL1 norm : \\(L_{1} = \\overset{n}{\\sum_{i}}|x_{i}|\\) 절대값의 합으로 맨하튼 Manhattan 놈이라고도 한다. 지도의 거리 측정에 사용된다.\nL2 norm : \\(L_{2} = (\\overset{n}{\\sum_{i}}x_{i}^{2})^{\\frac{1}{2}}\\) 제곱합의 제곱근으로 유클리디안 놈이라 한다. 통계학에서 가장 많이 사용된다. 회귀계수 추정치를 구하는 최소제곱추정치 구할 때 사용된다.\n\n\n\n\n\n\n#행렬 정의\nimport numpy as np\nA=np.array([[1,2,3], [4,5,7],[8,9,10]])\n#L1 norm Mahattan\nla.norm(A,axis=1,ord=1)\n【결과】 array([ 6., 16., 27.])\n#L2 norm Euclidean\nla.norm(A,axis=1,ord=2)\n【결과】 array([ 3.74165739, 9.48683298, 15.65247584])\n\n\n(3) 평균 제곱근 RMS root mean square value\n데이터 크기를 정량화하는데 사용되며 데이터의 평균적인 크기를 나타낸다. \\(rms(x) = \\frac{\\parallel x \\parallel}{\\sqrt{n}} = \\sqrt{\\frac{1}{n}\\sum x_{i}^{2}}\\)\n\n\n(4) 두 벡터의 합의 놈\n\\[\\parallel x + y \\parallel = \\sqrt{\\parallel x \\parallel^{2} + 2x^{T}y + \\parallel y \\parallel^{2}}\\]\n\n\n(5) Chebyshev inequality\n차수 n-벡터 \\(x\\), \\(x_{i}^{2} \\geq a^{2}\\)을 만족하는 원소 개수를 \\(k\\)라 하면, \\(\\parallel x \\parallel^{2} = x_{1}^{2} + ... + x_{2}^{2} \\geq ka^{2}\\)이다. \\(k \\leq n\\)이므로 \\(n \\leq \\frac{\\parallel x \\parallel}{a^{2}}\\)이다. 즉, 벡터의 어떠한 원소도 그 벡터의 놈보다 크지 않다.\n\\(\\frac{k}{n} \\leq (\\frac{rms(x)}{a})^{2}\\). 왼쪽 항은 벡터의 성분 중 절대값이 최소한 \\(a\\)이상인 성분의 비율을 나타낸다. 오른쪽 항은 \\(a\\)와 \\(rms(x)\\)의 비율의 제곱에 대한 역수이다. 예를 들어, 벡터의 성분 중 1/25 = 4% 이상은 RMS 값의 5배를 초과할 수 없다는 것을 의미한다.\n\n\n\n\nchapter 4. 벡터간 거리\n\n1. 유클리디안 거리\n\n(1) 정의\n차수가 동일한 두 벡터(\\(a,b\\))의 놈을 유클리디안 거리로 정의한다.\n\\[dist(a,b) = \\parallel a - b \\parallel = \\parallel b - a \\parallel\\]\n\\[||a - b|| = \\sqrt{(a_{1} - b_{1})^{2} + (a_{2} - b_{2})^{2} + ... + (a_{n} - b_{n})^{2}}\\]\n두 벡터의 Root Mean Square 편차 = \\(\\frac{\\parallel x - y \\parallel}{\\sqrt{n}}\\)\n【예제】\n\\[a = \\left\\lbrack \\begin{array}{r} 0 \\\\ - 1 \\\\ 1 \\end{array} \\right\\rbrack,b = \\left\\lbrack \\begin{array}{r} 1 \\\\ - 2 \\\\ 1  \\end{array} \\right\\rbrack,c = \\left\\lbrack \\begin{array}{r} 1 \\\\ 0 \\\\3 \\end{array} \\right\\rbrack\\] \\[dist(a,b) = \\sqrt{2},dist(b,c) = 2.8284\\]\n#행렬 정의\nimport numpy as np\na=np.array([[0],[-1],[1]])\nb=np.array([[1],[-2],[1]])\nc=np.array([[1],[0],[3]])\n#거리 계산\nnp.linalg.norm(a-b),np.linalg.norm(b-c)\n【결과】 (np.float64(1.4142135623730951), np.float64(2.8284271247461903))\n\n\n(2) 활용\n\nfeature distance: \\(\\parallel x - y \\parallel\\) 차수가 동일한 두 벡터의 거리를 개체의 유사성 척도로 사용한다.\nNearest neighbor: \\(\\parallel x - z_{i} \\parallel\\) 두 개체 간의 거리를 이용하여 유사한 개체를 군집으로 묶는다. k-means 알고리즘\nRMS prediction error: \\(rms(y - \\widehat{y})\\) 관측치와 예측치의 거리를 예측의 정확도 척도로 사용한다.\n\n#감성 분석\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n# 데이터 준비\ntexts = [\"I love this product\", \"This is terrible\", \"Absolutely fantastic\", \"Not good at all\"]\nlabels = [1, 0, 1, 0]  # 1: 긍정, 0: 부정\n# TF-IDF 벡터화\nvectorizer = TfidfVectorizer()\nX = vectorizer.fit_transform(texts)\n# KNN 모델\nknn = KNeighborsClassifier(n_neighbors=1, metric='euclidean')\nknn.fit(X, labels)\n# 새로운 리뷰 분류\nnew_text = [\"I hate this product\"]\nnew_vector = vectorizer.transform(new_text)\nprediction = knn.predict(new_vector)\nprint(f\"Prediction: {'Positive' if prediction[0] == 1 else 'Negative'}\")\n【결과】 Prediction: Positive\n\n\n(3) 삼각 부등식\n차수가 동일한 n벡터 \\(a,b,c\\)에 대하여 다음이 발생한다.\n\\[\\parallel a - c \\parallel \\leq \\parallel a - b \\parallel + \\parallel b - c \\parallel\\]\n\n\n(4) triangle 부등식\n\\[\\parallel a + b \\parallel^{2} \\leq ( \\parallel a \\parallel + \\parallel b \\parallel )^{2}\\]\n\n\n(5) 맨해튼 거리\n\\[d(\\mathbf{a},\\mathbf{b}) = \\overset{n}{\\sum_{i = 1}}|a_{i} - b_{i}|\\]\n맨해튼 거리는 벡터 간의 축을 따라 이동한 거리의 합으로 이는 그리드 기반 공간에서 이동하는 경우에 적합하다. 맨해튼 거리라는 이름은 도로망이 격자 형태로 이루어진 맨해튼 도시 구조에서 유래되었다. 자동차나 사람이 이동할 때 대각선으로 이동하지 못하고 도로를 따라 움직이는 경우에 적합하다. 예: 두 위치 간 최단 이동 거리 계산.\n\n\n\n\n\n\n\n\n2. 유클리디안 거리와 통계\n\n(1) de-meanded 벡터\n【reall】 치수 n-벡터 \\(x_{n}\\), 평균은 \\(avg(x) = (1_{n}^{T}x)/n = (instat) = \\overline{x}\\)\n【정의】 \\(\\overset{˜}{x} = x - avg(x)1_{n}\\) : 벡터의 각 원소를 평균을 뺀 벡터\n【성질】 \\(avg(\\overset{˜}{x}) = 0\\)\n\n통계 분석: 데이터의 평균을 제거함으로써 분산이나 공분산과 같은 통계적 특성을 더 명확하게 분석할 수 있다.\n주성분 분석(PCA): 데이터의 분산을 분석하기 전에 데이터를 중심에 맞추기 위해 사용된다.\n회귀 분석: 회귀 분석에서 독립 변수와 종속 변수의 평균을 제거하여 상수항 없이 회귀 모델을 구축할 수 있다.\n\n\n\n(2) 표준편차 standard deviation\n\\[std(x) = \\sqrt{\\frac{(x_{1} - avg(x))^{2} + (x_{2} - avg(x))^{2} + ... + (x_{n} - avg(x))^{2})}{n}}\\]\n\\[std(x) = \\frac{\\parallel x - (1^{T}x/n)1 \\parallel}{\\sqrt{n}}\\]\n【응용】 투자에서 평균은 일정기간 평균 수익율, 표준편차는 위험 척도이다.\n표준편차 성질\n상수를 더해도 표준편차는 동일하다. \\(std(x + a1) = std(x)\\)\n스칼라(상수) 곱 : \\(std(kx) = |k|std(x)\\)\n평균, RMS, STD 관계\n\\(std(x)^{2} = rms(x)^{2} - avg(x)^{2}\\)\n(in stat) \\(std(x)^{2} = var(x)\\) 분산\n표준편차와 Chebychev 부등식\n만약 차원 \\(n\\)-벡터에서 \\(|x_{i} - avg(x)| \\geq a\\)을 만족하는 원소 개수를 \\(k\\)라 하면 \\(\\frac{k}{n} \\leq (\\frac{std(x)}{a})^{2}\\)이다. 벡터 \\(x\\) 평균으로부터 \\(k\\) 표준편차 이내에 있는 성분 비율은 최소 \\(1 - 1/k^{2}\\)이다.\n\\[P(|X - \\mu| &gt; k\\sigma) \\leq 1 - \\frac{1}{k^{2}}\\]\n예를 들어, 일정 기간 투자 평균 수익률은 8%이고, 리스크(표준편차)는 3%입니다. 체비셰프의 부등식에 따르면, 손실을 기록한 기간의 비율(즉, 0% 이하인 기간, 16% 이상인 기간)은 최대 (3/8)^2 = 14.1%이다.\n\n\n(3) 실증적 규칙\n\\[P(|X - \\mu| \\leq k\\sigma)\\]\n\n\\(k = 1\\), 데이터의 68.3%가 \\((\\mu - \\sigma,\\mu + \\sigma)\\) 내에 있음\n\\(k = 2\\), 데이터의 95.4%, \\(k = 3\\), 데이터의 99.9%\n\n\n\n\n\n\n\n\n특징\n실증적 규칙\n체비세프 규칙\n\n\n\n\n분포가정\n정규분포에만 적용 가능\n모든 분포에 적용 가능\n\n\n그래프 모양\n종형 곡선(정규분포)\n다양한 분포(정규분포, 비대칭, 멀티모달 등)\n\n\n데이터 범위\n평균과 표준편차로 대칭적인 확률 분포\n최소한의 비율을 보장하며 보수적(더 큰 범위를 포함)\n\n\n데이터 비율\n±1σ: 68%, ±2σ: 95%, ±3σ: 99.7%\n±2σ: ≥75%, ±3σ: ≥88.9%\n\n\n\n\n\n\n\n3. 거리와 개체 군집화\n\n(1) 개념\n\\(N\\)개의 차수 \\(n\\)-벡터 \\((x_{1},x_{2},...,x_{N})\\)에 대하여 각 벡터(개체) 쌍 사이의 거리로 측정하여 서로 가까운 클러스터 또는 클러스터로 묶는 작업을 다룬다. 클러스터링의 목표는 가능한 경우 벡터들을 \\(k\\)개의 클러스터 또는 클러스터로 묶거나 나누어, 각 클러스터 내의 벡터들이 서로 가깝도록 하는 것이다. 클러스터링은 벡터들이 객체의 특징을 나타낼 때 널리 사용된다. 다음은 \\(n = 2\\)(군집변수 2개), \\(k = 3\\)으로 클러스터링 한 사례이다.\n\n\n\n\n\n\n\n(2) 클러스터 할당\n\\(N\\)개 개체, \\(x_{i}\\)를 개체(\\(i = 1,2,...,N\\)), \\(c_{i}\\)는 \\(i\\)-개체가 할당된 클러스터이고 (\\(j = 1,2,...k\\)), \\(G_{j}\\)을 \\(j\\)-클러스터에 속한 개체의 집합이라 하자.\n\\[G_{j} = \\{ i|c_{i} = j\\}\\]\n클러스터을 대표하는 차원 \\(n\\)-벡터를 \\(z_{1},z_{2},...,z_{k}\\)라 하자. \\(i\\)-개체가 \\(j = c_{i}\\)에 있다면 \\(\\parallel x_{i} - z_{c_{i}} \\parallel\\)은 모든 클러스터 중 가장 가까워야 한다.\n\n\n(3) 클러스터 목적\n\\(J^{clust} = ( \\parallel x_{1} - z_{c_{1}} \\parallel + \\parallel x_{2} - z_{c_{2}} \\parallel + ... + \\parallel x_{N} - z_{c_{N}} \\parallel )/N\\) 함수를 최소화 하는 \\(z_{c_{1}},z_{c_{2}},...,z_{c_{N}}\\)을 구한다.\n\n\n(4) 최적 클러스링\n목적함수 \\(J^{clust}\\)을 최소화 하는 \\(z_{c_{1}},z_{c_{2}},...,z_{c_{N}}\\)을 찾는 것은 개체 수가 많고 차원 개수가 커지면 계산 회수가 기하 급수적으로 늘어나 불가능하다. 그러므로 최적 대신 차선 sub-optimal 방법으로 대표 벡터를 고정화 하는 k-평균 방법을 사용한다.\n\n\n\n\n\n\n\n\n4. k-means 알고리즘\n\n(1) 개념\n클러스터 할당과 클러스터 대표자를 선택하여 \\(J^{clust}\\)를 최소화하는 문제를 해결할 수 있을 것처럼 보이나 두 가지 선택은 순환적입니다. 즉, 각각의 선택이 다른 하나에 의존한다. 클러스터 대표자를 선택하고 클러스터 할당을 선택하는 것을 반복하는 것이 벡터 집합을 클러스터링하는 데 있어서 유명한 k-means 알고리즘이다. k-means 알고리즘은 1957년에 Stuart Lloyd와 독립적으로 Hugo Steinhaus에 의해 처음 제안되어 때때로 Lloyd 알고리즘이라고도 불린다. k-means라는 이름은 1960년대부터 사용되었다.\n\n\n(2) k-평균 알고리즘\n\\(N\\)개 개체를 \\(k\\)개 클러스터으로 분류한다고 가정하자. \\(z_{1},z_{2},...,z_{k}\\)을 각 클러스터의 대표 벡터라 하자. k-평균 알고리즘은 다음 작업을 반복 실행한다.\n\n대표 벡터를 결정하고 각 개체를 가장 가까운 대표 벡터의 클러스터으로 분류한다.\n클러스터에 할당된 개체의 중심점(평균 벡터)을 대표 벡터로 설정한다.\n수렴 조건 만족 때까지 위의 작업을 반복한다.\n\n\n\n(3) 이슈사항\n타이 브레이커: 두 개 이상의 클러스터과 최소 거리인 개체는 클러스터 할당을 하지 않는다. 그러므로 이 개체는 다음 단계에서 대표 벡터 결정에는 활용되지 않는다.\n수렴 조건: 개체의 클러스터 이동이 더 이상 발생하지 않으면 대표 벡터는 움직이지 않음을 의미하므로 클러스터링 결과는 동일해진다.\nk-평균 알고리즘은 직관적이다.: 목표함수 \\(J^{clust}\\)을 최적화 하지 못하지만 반복을 통하여 줄여 나가게 된다.\n대표벡터 해석: 각 \\(N\\) 개의 회사마다 총 자본화, 분기별 수익 및 위험, 거래량, 손익, 배당금 등과 같은 금융 및 사업 속성을 구성 요소로 하는 n-벡터을 이용하여 k-평균 클러스터링 결과 얻은 대표벡터를 이용하여 클러스터(군집)에 이름을 부여한다. 기업연수, 기업종류, 매출액 등 군집변수로 사용하지 않은 특성 벡터를 이용하여 개체 군의 이름을 부여하고 해석한다.\n클러스터 \\(k\\) 결정: \\(k\\) 의 결정은 다소 주관적이고 시행착오 방법을 사용한다. \\((k,J^{clust})\\)을 이용하여 Elbow Method 팔꿈치 기법을 사용한다. 군집 개수가 증가할수록 \\(J^{clust}\\)는 감소하게 되지만, 이 감소율이 꺾이는 지점을 찾아내는 방법이다.\n고정 대표 벡터 분할하기: 만약 \\(j\\) 클러스터을 대표하는 벡터 \\(z_{1},z_{2},...,z_{j}\\)르 고정하면 모든 개체 \\(x_{1},x_{2},...,x_{N}\\)을 최적 클러스터으로 분류 문제는 다음과 같다.\n\\[\\parallel x_{i} - z_{c_{i}} \\parallel = min_{j = 1,2,...,k} \\parallel x_{i} - z_{j} \\parallel\\]\n고정 대표 벡터를 활용하면 최적 클러스터링 문제는 다음과 같이 sub 최적 문제로 변환된다. 각 \\(N\\)개 개체에 최적 \\(j\\)-클러스터(거리가 가장 가까운 클러스터)을 결정하는 개별적 문제와 동일하다.\n\\[J^{clust} = min_{j = 1,2,...,k} \\parallel x_{1} - z_{j} \\parallel + ... + min_{j = 1,2,...,k} \\parallel x_{N} - z_{j} \\parallel )/N\\]\n고정 벡터를 group(or cluster) centroid라 한다.\n\n\n(4) 사례\n# 60000(train 훈련)/10000(test 테스트), 28x28\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.datasets import mnist\n# MNIST 데이터셋 로드 및 훈련데이터, 테스트데이터 분할 \n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n# 데이터 형태 출력\nprint(f\"x_train shape: {x_train.shape}\")\nprint(f\"y_train shape: {y_train.shape}\")\nprint(f\"x_test shape: {x_test.shape}\")\nprint(f\"y_test shape: {y_test.shape}\")\n# 첫 10개 샘플 이미지와 레이블 시각화\nnum_samples = 10\nplt.figure(figsize=(10, 1))\nfor i in range(num_samples):\n    plt.subplot(1, num_samples, i+1)\n    plt.imshow(x_train[i], cmap='gray')\n    plt.title(y_train[i])\n    plt.axis('off')\nplt.show()\n\n\n\n\n\n# 훈련 데이터 클러스트링, 첫 20개 군집결과\n# 이미지 데이터를 2차원 배열로 변환\nx_train2 = x_train.reshape((x_train.shape[0], -1))\nx_test2 = x_test.reshape((x_test.shape[0], -1))\n# 데이터 정규화\nx_train2 = x_train2 / 255.0\nx_test2 = x_test2 / 255.0\n# k-means 모델 생성 및 학습\nkmeans = KMeans(n_clusters=10, random_state=42)\nkmeans.fit(x_train2)\n# 클러스터 할당 결과\ny_kmeans = kmeans.predict(x_train2)\n# 첫 20개 분류결과 이미지와 레이블 시각화\nnum_samples = 20\nplt.figure(figsize=(10, 1))\nfor i in range(num_samples):\n    plt.subplot(1, num_samples, i+1)\n    plt.imshow(x_train[i], cmap='gray')\n    plt.title(y_kmeans[i])\n    plt.axis('off')\nplt.show()\n 10개 클러스터명은 임의로 정해져 숫자와 매칭이 되지 않는다. 클러스터에 속한 이미지를 이용하여 결정한다. 클러스터9, 클러스터1에는 이미지 6/2이 두개이므로 숫자6,숫자2 클러스터으로 하면 된다. 클러스터3에는 2개 이지지 중 숫자5, 3, 8이 각각 1개이므로 나머지 클러스터3으로 분류된 이미지 번호 확인하여 숫자번호를 결정한다. 클러스터5에는 이미지9 2개, 이미지7, 이미지4 각각 1개이므로 클러스터5는 이미지9 군집으로 한다.\n# 클러스터 대표 이미지\n# 클러스터 3 평균벡터 출력\nplt.figure(figsize=(10, 1))\nplt.imshow((x_train[0]+x_train[7]+x_train[17])/3, cmap='gray')\nplt.title('cluster 3')\nplt.axis('off')\nplt.show()\n\n\n\n\n\n\n\n\n5. 벡터의 각도\n\n(1) 코사인 유사도\n벡터의 코사인 유사도(Cosine Similarity)는 두 벡터 간의 방향적 유사성을 측정하는 지표로, 벡터 간의 각도 \\(\\theta\\)의 코사인 값을 이용하여 계산된다.\n\\[\\text{Cosine Similarity} = cos(\\theta) = \\frac{\\mathbf{A} \\cdot \\mathbf{B}}{\\parallel \\mathbf{A} \\parallel \\parallel \\mathbf{B} \\parallel}\\]\n코사인 유사도와 유클리드 거리의 차이는 다음과 같다.\n\n코사인 유사도는 두 벡터의 방향에 집중하며, 벡터 크기의 차이를 무시한다.\n유클리드 거리는 두 벡터 사이의 실제 거리(크기 차이 포함)를 측정한다.\n예를 들어, 텍스트 데이터에서 코사인 유사도는 문서 간의 내용적 유사성을 비교하는 데 유리하며, 추천 시스템, 정보 검색, 클러스터링 등에서 널리 사용된다.\n\n【예제】\n\n\n\n\n\n\n\n(2) 코사인 유사도의 특징\n코사인 유사도 값의 범위는 [-1, 1]이고 다음의 특징을 갖는다.\n\\(cos(\\theta) = 1\\): 두 벡터가 완전히 같은 방향\n\\(cos(\\theta) = 0\\): 두 벡터가 직교(Orthogonal, 90도)\n\\(cos(\\theta) = - 1\\): 두 벡터가 완전히 반대 방향.\n코사인 유사도는 벡터의 크기가 아닌 방향만 고려되므로 벡터를 정규화하지 않고도 비교할 수 있다. 고차원 벡터에도 적용 가능하여 텍스트 데이터, 사용자 선호도 등 고차원 데이터에서 벡터 간 유사성 측정에 많이 사용된다.\n각도 종류\n\n각도가 \\(\\theta = 90^{o} = \\pi/2\\)이면 두 벡터는 직교 orthogonal 한다.\n각도가 \\(\\theta = 0^{o}\\)이면 두 벡터는 정렬 aligned 되어 있다.\n각도가 \\(\\theta = 180^{o} = \\pi\\)이면 두 벡터는 역정렬 anti-aligned 되어 있다.\n각도가 \\(\\theta &gt; 90^{o} = \\pi/2\\)이면 두 벡터의 각은 둔각 obtuse, \\(\\theta &lt; 90^{o} = \\pi/2\\)이면 두 벡터의 각은 예각 acute 이다.\n\n\n\n\n\n\n두 벡터 합의 놈과 각도\n\\[\\parallel x + y \\parallel^{2} = \\parallel x \\parallel^{2} + 2 \\parallel x \\parallel \\parallel y \\parallel \\cos(\\theta) + \\parallel y \\parallel^{2}\\]\n만약 \\(\\theta = 90^{o} = \\pi/2\\)이면 \\(\\parallel x + y \\parallel^{2} = \\parallel x \\parallel^{2} + \\parallel y \\parallel^{2}\\) (피타고라스 정리)\n\n\n\n6. 상관계수\n\n(1) 상관계수 정의\n만약 \\(\\overset{˜}{a} = a - avg(a)1,\\overset{˜}{b} = b - avg(b)1\\)이면, 상관계수(correlation coefficient) \\(\\rho\\)는 다음과 같이 정의된다.\n\\(\\rho = \\frac{{\\overset{˜}{a}}^{T}\\overset{˜}{b}}{\\parallel \\overset{˜}{a} \\parallel \\parallel \\overset{˜}{b} \\parallel}\\) ⇔ \\(\\rho = (\\frac{\\overset{˜}{a}}{std(a)})^{T}(\\frac{\\overset{˜}{b}}{std(b)})/n\\)\n\n\\(cov(a,b) = {\\overset{˜}{a}}^{T}\\overset{˜}{b}/n\\): 두 벡터의 공분산\n\\(var(a) = std(a)^{2}\\): 벡터의 분산\n상관계수와 공분산 관계: \\(cov(a,b) = \\rho std(a)std(b)\\)\n\\(\\rho = \\pm 1\\) (완전 상관) : 두 벡터가 (역)정렬되어 있음\n\\(\\rho = 0\\) (독립) : 두 벡터가 직교되어 있음. \\(cov(a,b) = 0\\)\n\n\n\n(2) 두 벡터 합의 분산\n\\[var(a + b) = var(a) + 2cov(a,b) + var(b)\\]\n\\[var(a + b) = var(a) + 2\\rho std(a)std(b) + var(b)\\]\n\n만약 \\(\\rho = 0\\)이면, \\(var(a + b) = var(a) + var(b)\\)\n만약 \\(\\rho = 1\\)이면, \\(var(a + b) = (std(a) + std(b))^{2}\\)\n만약 \\(\\rho = - 1\\)이면, \\(var(a + b) = (std(a) - std(b))^{2}\\)\n\n\n\n(3) 헤징 hedging 투자\n두 개 회사 주가 벡터 \\((a,b)\\)의 평균은\\(\\mu\\), 표준편차(위험) \\(\\sigma\\)이고 상관계수는 \\(\\rho\\)이다. 각각 50% 투자, \\(c = \\frac{(a + b)}{2}\\)의 평균 수익율과 표준편차은 다음과 같다.\n\n평균 : \\(avg(\\frac{a + b}{2}) = \\mu\\)\n표준편차 : \\(std(c) = \\sigma\\sqrt{(1 + \\rho)/2}\\)\n상관계수 \\(\\rho = 0\\)이면 (독립) 표준편차는 \\(\\frac{1}{\\sqrt{2}}\\)만큼 줄어든다.\n완벽한 상관관계가 있는 경우에만 표준편차는 동일하다.\n\n\n\n\n\nchapter 5. 선형독립\n\n1. 선형독립 정의\n\n(1) 선형 종속 linear dependence\n\\(k \\geq 2\\)개의 크기 n-벡터 \\(x_{1},x_{2},...,x_{k}\\)가 다음을 만족하면 선형종속이라 한다. 만약 \\(a_{1}x_{1} + a_{2}x_{2} + ... + a_{k}x_{k} = 0\\)을 만족하는 \\(a_{i}\\)가 적어도 하나는 0이 아니다.\n선형독립이면 적어도 하나의 \\(a_{i}\\)는 0이 아니므로 벡터 \\(x_{i}\\) 다음과 같이 다른 벡터의 선형함수로 표현될 수 있다.\n\\[x_{k} = \\frac{- a_{1}}{a_{i}}x_{1} + ... + \\frac{- a_{i - 1}}{a_{i}}x_{i - 1} + \\frac{- a_{i + 1}}{a_{i}}x_{i + 1} + ... + \\frac{- a_{k}}{a_{i}}x_{k}\\]\n【예제】\n\n\\(x_{1} = \\left\\lbrack \\begin{array}{r} &gt; 0 \\\\ &gt;  - 1 \\\\  &gt; 1 &gt; \\end{array} \\right\\rbrack,x_{2} = \\left\\lbrack \\begin{array}{r} &gt; 1 \\\\ &gt;  - 2 \\\\ &gt; 1  &gt; \\end{array} \\right\\rbrack,x_{3} = \\left\\lbrack \\begin{array}{r} &gt; 1 \\\\ &gt; 0 \\\\ &gt;  - 1  &gt; \\end{array} \\right\\rbrack\\) ⬄\\(- 2x_{1} + x_{2} - x_{3} = 0\\)\n\n\n\n(2) 선형 독립 linear independence\n만약 \\(a_{1}x_{1} + a_{2}x_{2} + ... + a_{k}x_{k} = 0\\)이 모든 \\(a_{k} = 0\\)일 때만 만족한다면, n-벡터 \\(x_{1},x_{2},...,x_{k}\\)을 선형독립이라 한다.\n【예제】\n\n\n\n\n\n\n\n\\[x_{1} = \\left\\lbrack \\begin{array}{r}\n1 \\\\\n0 \\\\\n0\n\\end{array} \\right\\rbrack,x_{2} = \\left\\lbrack \\begin{array}{r}\n0 \\\\\n- 1 \\\\\n1\n\\end{array} \\right\\rbrack,x_{3} = \\left\\lbrack \\begin{array}{r}\n- 1 \\\\\n1 \\\\\n1\n\\end{array} \\right\\rbrack\\]\n\n\n\n\n\n\n\n\n(3) 선형독립 벡터의 선형결합\n선형독립인 \\(x_{1},x_{2},...,x_{k}\\)의 선형결합의 모든 계수(\\(a_{k}\\))는 유일하다. 선형결합 \\(x = a_{1}x_{1} + a_{2}x_{2} + ... + a_{k}x_{k}\\)\n【증명】 다른 계수를 \\(b_{k}\\)라 하자. \\(x = b_{1}x_{1} + b_{2}x_{2} + ... + b_{k}x_{k}\\) \\(0 = (a_{1} - b_{1})x_{1} + (a_{2} - b_{2})x_{2} + ... + (a_{k} - b_{k})x_{k}\\)이다. \\(x_{1},x_{2},...,x_{k}\\)가 선형독립이므로 모든 \\((a_{i} - b_{i}) = 0\\) 만족한다.\n\n\n\n2. 기저\n\n(1) 기저 개념\n벡터 공간은 다양한 차원의 벡터로 이루어진 공간이며, 그 공간 안의 벡터들을 다른 벡터들의 선형 조합으로 표현할 수 있다. 이때, 특정 벡터 공간의 기저 basis 는 그 공간 안의 모든 벡터들을 생성할 수 있는 최소한의 독립적인 벡터들의 집합이다.\n예를 들어, 2차원 공간에서의 기저는 일반적으로 (1,0)과 (0,1)이다. 이 두 벡터는 선형 독립이며, 이들의 모든 선형 조합으로 2차원 평면 상의 어떤 점이든 표현할 수 있다. 따라서 (1,0)과 (0,1)은 2차원 공간의 기저입니다. 단, 벡터 공간의 기저는 유일하지 않다.\n\n\n\n\n\n크기 2인 벡터의 기저 벡터는 \\(k = 2\\)개이다. 위의 그림에서 \\(a_{3}\\)벡터는 \\((a_{1},a_{2})\\)(기저 벡터)의 선형결합으로 만들 수 있다.\n\n\n(2) 기저 정의\nn개의 선형독립인 크기 n-벡터를 기저 basis 라 한다. 즉, n-벡터 \\((x_{1},x_{2},...,x_{n})\\)가 기저이면, 모든 크기 n-벡터는 \\((x_{1},x_{2},...,x_{n})\\)의 선형 결합으로 표현할 수 있다.\n【증명】 (n+1)개 차원 n-벡터 \\((x_{1},x_{2},...,x_{n},y)\\)개가 있다고 가정하자. 단,\\((x_{1},x_{2},...,x_{n})\\) 선형독립이며 기저이다. 이들 벡터는 선형독립(차원개수 n보다 벡터 개수가 (n+1)로 크다)이므로 다음을 만족하는 모든 \\(a_{i}\\)가 0은 아니다. \\(a_{1}x_{1} + a_{2}x_{2} + ... + a_{n}x_{n} + a_{n + 1}y = 0\\)\n만약 \\(a_{n + 1} = 0\\)이면, \\(a_{1}x_{1} + a_{2}x_{2} + ... + a_{n}x_{n} = 0\\)을 만족하는 모든 \\(a_{i} = 0\\)이다. 왜냐하면 \\((x_{1},x_{2},...,x_{n})\\) 선형독립이기 때문이다.(모순)\n\n\n\n3. 직교정규\n\n(1) 정의\n만약 \\(\\parallel x_{i} \\parallel = 1\\)이고 \\(x_{i}^{T}x_{j} = 0fori \\neq j\\) (두 벡터 \\((x_{i},x_{j})\\)는 직교)이면, \\((x_{1},x_{2},...,x_{k})\\) 벡터 집합은 직교 정규 orthonormal 벡터라고 한다.\n직교정규성은 선형종속, 선형독립처럼 집합의 속성이지 개별 벡터의 속성은 아니다.\n\n\n(2) 예제\n\nn개의 단위벡터는 직교정규 벡터이다.\n직교정규벡터 \\(\\left\\lbrack \\begin{array}{r}\n   - 1 \\\\0 \\\\ 0\n  \\end{array} \\right\\rbrack,\\frac{1}{\\sqrt{2}}\\left\\lbrack \\begin{array}{r}\n  0 \\\\ 1 \\\\ 1\n  \\end{array} \\right\\rbrack,\\frac{1}{\\sqrt{2}}\\left\\lbrack \\begin{array}{r}\n  0 \\\\ - 1 \\\\ 1\n  \\end{array} \\right\\rbrack\\)\n직교정규 벡터는 선형독립이다.\n\n\n\n(3) 직교정규 성질\n\n벡터 \\(x\\)가 직교정규벡터 선형결합이면 \\(x = a_{1}x_{1} + a_{2}x_{2} + ... + a_{k}x_{k}\\) 내적을 이용하여 다음을 얻으므로 내적을 이용하여 계수를 얻을 수 있다.\n\\[x_{i}^{T}x = x_{i}^{T}(a_{1}x_{1} + a_{2}x_{2} + ... + a_{k}x_{k}) = a_{i}\\]\n벡터 \\((x_{1},x_{2},...,x_{k})\\)가 직교정규 (선형독립이고 기저임) 벡터이면 \\(x = (x_{1}^{T}x)x_{1} + (x_{2}^{T}x)x_{2} + ... + (x_{k}^{T}x)x_{k}\\)이 성립한다.\n\n벡터 (1, 2, 3)을 직교정규 벡터의 선형결합으로 표현하자.\n\\[\\left\\lbrack \\begin{array}{r}\n1 \\\\\n2 \\\\\n3\n\\end{array} \\right\\rbrack = 1\\left\\lbrack \\begin{array}{r}\n1 \\\\\n0 \\\\\n0\n\\end{array} \\right\\rbrack + 2\\left\\lbrack \\begin{array}{r}\n0 \\\\\n1 \\\\\n0\n\\end{array} \\right\\rbrack + 3\\left\\lbrack \\begin{array}{r}\n0 \\\\\n0 \\\\\n1\n\\end{array} \\right\\rbrack\\]\n\\(\\lbrack - 1 0 0\\rbrack\\left\\lbrack \\begin{array}{r}\n  1 \\\\\n  2 \\\\\n  3\n  \\end{array} \\right\\rbrack = - 1\\), \\(\\frac{1}{\\sqrt{2}}\\lbrack 011\\rbrack\\left\\lbrack \\begin{array}{r}\n  1 \\\\\n  2 \\\\\n  3\n  \\end{array} \\right\\rbrack = \\frac{5}{\\sqrt{2}}\\), \\(\\frac{1}{\\sqrt{2}}\\lbrack 0 - 11\\rbrack\\left\\lbrack \\begin{array}{r}\n  1 \\\\\n  2 \\\\\n  3\n  \\end{array} \\right\\rbrack = \\frac{1}{\\sqrt{2}}\\)\n\\[\\left\\lbrack \\begin{array}{r}\n1 \\\\\n2 \\\\\n3\n\\end{array} \\right\\rbrack = - 1\\left\\lbrack \\begin{array}{r}\n- 1 \\\\\n0 \\\\\n0\n\\end{array} \\right\\rbrack + \\frac{5}{2}\\left\\lbrack \\begin{array}{r}\n0 \\\\\n1 \\\\\n1\n\\end{array} \\right\\rbrack + \\frac{1}{2}\\left\\lbrack \\begin{array}{r}\n0 \\\\\n- 1 \\\\\n1\n\\end{array} \\right\\rbrack\\]\n\n\n\n4. Gram-Schmidt 알고리즘\n\n(1) 개념\nn-벡터 \\(x_{1},x_{2},...,x_{k}\\)가 선형 독립인지 여부를 결정할 수 있는 알고리즘으로 수학자 Jørgen Pedersen Gram과 Erhard Schmidt의 이름을 따서 명명되었다.\n만약 벡터들이 선형 독립이라면, Gram–Schmidt 알고리즘은 다음과 같은 속성을 가진 직교정규 벡터 \\(q_{1},q_{2},...,q_{k}\\) 을 생성한다.\n\n각 \\(i = 1,2,...,k\\)에서 \\(x_{i}\\)는 \\(q_{1},q_{2},...,q_{i}\\)의 선형결합이다.\n각 \\(i = 1,2,...,k\\)에서 \\(q_{i}\\)는 \\(x_{1},x_{2},...,x_{i}\\)의 선형결합이다.\n만약 \\(x_{1},x_{2},...,x_{i - 1}\\) 선형독립이나 \\(x_{1},x_{2},...,x_{i}\\)는 선형종속이면 멈춘다.\n\n\n\n(2) 알고리즘\n주어진 n-벡터 \\(x_{1},x_{2},...,x_{k}\\), \\(i = 1,2,...,k\\)일 때\n\n직교화 : \\({\\overset{˜}{q}}_{i} = x_{i} - (q_{1}^{T}x_{i})q_{1} - ... - (q_{i - 1}^{T}x_{i})q_{i - 1}\\)\n선형종속 검증 : 만약 \\({\\overset{˜}{q}}_{i} = 0\\)이면, 멈춘다.\n정규화 : \\(q_{i} = \\frac{{\\overset{˜}{q}}_{i}}{\\parallel q_{i} \\parallel}\\).\n\n이렇게 얻은 \\(q_{1},q_{2},...,q_{i}\\)는 직교정규 벡터이다. 알고리즘 적용 중 중간에 중단되면 기저젝터가 아니다.\n\n\n(3) Gram-Schmidt 알고리즘 예제\n\\(x_{1} = ( - 1,1, - 1,1),x_{2} = ( - 1,3, - 1,3),x_{3} = (1,3,5,7)\\) 에 대하여 Gram–Schmidt 알고리즘을 적용하자.\ni=1\n\\(\\parallel {\\overset{˜}{q}}_{1} \\parallel = 2\\)이므로 \\(q_{1} = \\frac{{\\overset{˜}{q}}_{1}}{\\parallel {\\overset{˜}{q}}_{1} \\parallel} = \\left\\lbrack \\begin{array}{r}\n- 1/2 \\\\\n1/2 \\\\\n- 1/2 \\\\\n1/2\n\\end{array} \\right\\rbrack\\)이다.\ni=2\n\\(q_{1}^{T}x_{2} = 4\\)이므로 \\({\\overset{˜}{q}}_{2} = x_{2} - (q_{1}^{T}x_{2})q_{1} = \\left\\lbrack \\begin{array}{r}\n1 \\\\\n1 \\\\\n1 \\\\\n1\n\\end{array} \\right\\rbrack\\)이고 \\(\\parallel {\\overset{˜}{q}}_{2} \\parallel = 2\\)이다. 그러므로 \\(q_{2} = \\frac{{\\overset{˜}{q}}_{2}}{\\parallel {\\overset{˜}{q}}_{2} \\parallel} = \\left\\lbrack \\begin{array}{r}\n1/2 \\\\\n1/2 \\\\\n1/2 \\\\\n1/2\n\\end{array} \\right\\rbrack\\).\ni=3\n\\(q_{1}^{T}x_{3} = 2,q_{2}^{T}x_{3} = 8\\)이므로 \\({\\overset{˜}{q}}_{3} = x_{3} - (q_{1}^{T}x_{3})q_{1} - (q_{2}^{T}x_{3})q_{2} = \\left\\lbrack \\begin{array}{r}\n- 2 \\\\\n- 2 \\\\\n2 \\\\\n2\n\\end{array} \\right\\rbrack\\)이고 \\(\\parallel {\\overset{˜}{q}}_{3} \\parallel = 4\\)이다. 그러므로 \\(q_{3} = \\frac{{\\overset{˜}{q}}_{3}}{\\parallel {\\overset{˜}{q}}_{3} \\parallel} = \\left\\lbrack \\begin{array}{r}\n- 1/2 \\\\\n- 1/2 \\\\\n1/2 \\\\\n1/2\n\\end{array} \\right\\rbrack\\).\n# Gram-Schmidt 알고리즘\nimport numpy as np\n\ndef gram_schmidt(A):\n    # Get the number of rows (n) and columns (k) in A\n    n, k = A.shape\n    # Initialize matrix Q with zeros, same shape as A\n    Q = np.zeros((n, k))\n    \n    for j in range(k):\n        # Start with the current column vector of A\n        v = A[:, j]\n        for i in range(j):\n            # Subtract the projection of v onto the ith orthonormal vector\n            v -= np.dot(Q[:, i], A[:, j]) * Q[:, i]\n        \n        # Normalize the vector\n        Q[:, j] = v / np.linalg.norm(v)\n    return Q\n# Example usage\nA = np.array([[-1,-1,1],\n              [1,3,3],\n              [-1,-1,5],\n              [1,3,7]], dtype=float)\n\ngram_schmidt(A)\n【결과】 array([[-0.5, 0.5, -0.5], [ 0.5, 0.5, -0.5], [-0.5, 0.5, 0.5], [ 0.5, 0.5, 0.5]])"
  },
  {
    "objectID": "notes/math/matrix.html",
    "href": "notes/math/matrix.html",
    "title": "수학의 기초 4. 행렬",
    "section": "",
    "text": "chapter 1. 행렬 기초\n\n1. 개념\n\n(1) 통계학과 행렬\n행렬은 통계학에서 데이터를 표현하고 분석하는 데 핵심적인 도구로 사용된다. 행렬은 대규모 데이터의 구조를 간단히 표현하고, 계산을 효율적으로 수행하여 통계학에서 중요한 역할을 한다.\n데이터 표현: 데이터를 행렬로 저장하여 표 형식으로 표현한다. 다음은 관측값(행)과 변수(열)로 구성된 데이터 행렬이다.\n\\[X = \\begin{bmatrix}\nx_{11} & x_{12} & \\cdots & x_{1p} \\\\\nx_{21} & x_{22} & \\cdots & x_{2p} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nx_{n1} & x_{n2} & \\cdots & x_{np}\n\\end{bmatrix}\\]\n연산의 간결화: 여러 변수와 관측값 간의 관계를 분석할 때 행렬식으로 간단히 표현하고 행렬 연산을 이용하여 추정값을 계산한다.\n\\(Y = X\\beta + \\epsilon\\), OLS 추정=\\(\\widehat{\\beta} = (X'X)^{- 1}X'Y\\)\n\n\n(2) 정의\n행과 열로 배열된 숫자, 기호 또는 표현식의 직사각형 배열을 행렬이라 한다. 행의 차수는 \\(m\\), 열의 차수는 \\(n\\)이다.\n\\(A_{m \\times n} = \\begin{bmatrix}\na_{11} & a_{12} & \\cdots & a_{1n} \\\\\na_{21} & a_{22} & \\cdots & a_{2n} \\\\\n\\cdots & \\cdots & \\cdots & \\cdots \\\\\na_{m1} & a_{m2} & \\cdots & a_{mn}\n\\end{bmatrix}\\) (간편식) \\(A = \\{ a_{ij}\\}\\)\n\n행렬의 각 셀을 원소 element라 한다.\n행의 차수 \\(m = 1\\)인 행렬을 열 column 벡터이다.\n열의 차수 \\(n = 1\\)인 행렬을 행 row 벡터이다.\n행의 차수, 열의 차수 모두 1인 행렬을 스칼라 scalar이다.\n행렬을 \\(n\\)-열벡터로 표현 : \\(A_{m \\times n} = \\begin{bmatrix}\n  a_{1} & a_{2} & \\cdots a_{n}\n  \\end{bmatrix}\\)\n행렬을 \\(m\\)-헹벡터로 표현 : \\(A_{m \\times n} = \\left\\lbrack \\begin{array}{r}\n  a_{1} \\\\\n  a_{2} \\\\\n  \\cdots \\\\\n  a_{m}\n  \\end{array} \\right\\rbrack\\)\n\n\n\n(3) 동일 행렬이란\n\n행의 차수와 열의 차수가 같다. \\(A_{m \\times n} = B_{m \\times n}\\)\n대응하는 모든 원소 값은 동일하다. \\(\\{ a_{ij} = b_{ij}\\} foralli,j\\)\n\n\n\n\n2. 특수한 행렬\n영행렬 zero matrix: 행렬의 모든 원소가 0인 행렬입니다. 기호 : \\(0_{m \\times n}or0\\) 숫자 0에 해당된다.\n정방행렬 square matrix: 행렬의 행차수와 열차수가 동일한 행렬이다. 기호 : \\(A_{m \\times m} = A_{m}\\)\n대각행렬 diagonal matrix: 대각원소를 제외한 모든 원소가 0인 정방행렬이다. 기호 : \\(A_{ij} = 0fori \\neq j\\), \\(diag(a_{11},a_{22},...,a_{mm})\\)\n\\[D = \\begin{pmatrix}\n- 1 & 0 \\\\\n0 & 7\n\\end{pmatrix}\\]\n대각합 trace: 대각행렬의 대각원소의 합을 대각합이라 한다. \\(tr(D) = 6\\)\n단위행렬 identity matrix: 정방행렬의 대각 원소가 모두 1이고 그외 원소는 0인 행렬로 숫자 1과 같은 역할을 한다. 기호 : \\(I_{ij} = \\{\\begin{array}{r}\n1i = j \\\\\n0i \\neq j\n\\end{array}\\) , \\(I_{m \\times m}orI_{m}\\)\n\\(A = \\begin{bmatrix}\n1 & 2 & 3 \\\\\n3 & 4 & 5\n\\end{bmatrix}\\)⇨ \\(A = \\begin{bmatrix}\n1 & 0 & 1 & 2 & 3 \\\\\n0 & 1 & 3 & 4 & 5 \\\\\n0 & 0 & 1 & 0 & 0 \\\\\n0 & 0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 0 & 1\n\\end{bmatrix} = \\begin{bmatrix}\nI & A \\\\\n0 & I\n\\end{bmatrix}\\)\n삼각행렬 triangular matrix\n\n【상삼각행렬】 대각원소 아래 원소가 모두 0인 정방행렬이다. 기호 : \\(A_{ij} = 0fori &gt; j\\)\n【하삼각행렬】 대각원소 윗 원소가 모두 0인 정방행렬이다. 기호 : \\(A_{ij} = 0fori &lt; j\\)\n\n희소행렬 Sparse matrices: 행렬 원소의 대부분이 0인 행렬을 의미하며 \\(nnz(A)\\)은 행렬 \\(A_{m \\times n}\\)에서 0인 아닌 원소의 개수를 나타내며 \\(nnz(A)/(m \\times n)\\) 을 행렬의 밀도라 정의한다.\n수학자 제임스 H. 윌킨슨(James H. Wilkinson)이 정의 : ”행렬이 충분히 많은 0 원소를 포함하고 있어 이를 활용하는 것이 유리한 경우, 그 행렬을 희소 행렬이라 한다.” 희소행렬은 컴퓨터에서 효율적으로 저장하고 조작할 수 있다.\n영행렬 &gt; 단위행렬 &gt; 대각행렬 &gt; 삼각행렬 : 대표적인 희소행렬\n\n\n3. 행렬 놈\n모든 원소의 제곱합의 양의 제곱근: \\(\\parallel A \\parallel = \\sqrt{\\overset{m}{\\sum_{i}}\\overset{n}{\\sum_{j}}a_{ij}}\\)\n행렬의 놈은 스칼라이며 행렬의 크기나 거리를 측정하며 행렬의 평균제곱근(Root Means Square)는 \\(RMS(A) = \\frac{\\parallel A \\parallel}{\\sqrt{mn}}\\)이다.\n\n\\(\\parallel A \\parallel \\geq 0\\) 행렬 놈은 0보다 크거나 같다.\n\\(\\parallel cA \\parallel = |c| \\parallel A \\parallel\\)\n\\(\\parallel A + B \\parallel \\leq \\parallel A \\parallel + \\parallel B \\parallel\\)\n\\(\\parallel A - B \\parallel\\) : 두 행렬의 유사성(거리)을 나타낸다.\n\\(\\parallel A \\parallel = \\parallel A^{T} \\parallel\\) : 원행렬 놈과 전치행렬 놈은 동일하다.\n\n\n\n4. 전치\n전치 transpose는 행과 열을 서로 바꾸는 연산: \\((A^{T})_{ij} = A_{ji}\\)\n\n\\((A^{T})^{T} = A\\) : 전치 행렬을 다시 전치하면 원래 행렬이 된다.\n\\((A + B)^{T} = A^{T} + B^{T}\\) : 행렬 합의 전치는 각 행렬의 전치 합과 같다.\n\\((cA)^{T} = cA^{T}\\) : 스칼라 곱의 전치는 스칼라 곱과 같다.\n\\((AB)^{T} = B^{T}A^{T}\\) : 행렬 곱의 전치는 각 행렬의 전치의 순서를 바꾼 곱과 같다.\n\n원행렬과 전치행렬과 동일한 행렬은 대칭행렬이다. \\(A = A^{T}\\)\n\n\n\nchapter 2. 행렬 연산\n\n1. 행렬 합 연산\n행렬의 합을 구하는 경우 두 행렬의 차수는 동일해야 하며(conformable for addition/substraction: 합 연산 적합) 각 행렬에서 대응하는 원소들의 합을 그 위치에 적으면 된다.\n\\[(A + B)_{m \\times n} = \\{ a_{ij} + b_{ij}\\}\\]\n\\[(A + B)_{m \\times n} = \\begin{bmatrix}\na_{11} + b_{11} & a_{12} + b_{12} & \\cdots & a_{1n} + b_{1n} \\\\\na_{21} + b_{21} & a_{22} + b_{22} & \\cdots & a_{2n} + b_{2n} \\\\\n\\cdots & \\cdots & \\cdots & \\cdots \\\\\na_{m1} + b_{m1} & a_{m2} + b_{m2} & \\cdots & a_{mn} + b_{mn}\n\\end{bmatrix}\\]\n\\[A = \\begin{bmatrix}\n1 & 3 & 5 \\\\\n7 & 3 & 1\n\\end{bmatrix}$, $B = \\begin{bmatrix}\n1 & 0 & 1 \\\\\n- 1 & 1 & 0\n\\end{bmatrix}$ ⇢ $A + B = \\begin{bmatrix}\n2 & 3 & 6 \\\\\n6 & 4 & 1\n\\end{bmatrix}\\]\n성질\n\n교환법칙 Commutativity : \\(A + B = B + A\\)\n결합법칙 Associativity : \\(A + (B + C) = (A + B) + C = A + B + C\\)\n영행렬과 합 : \\(A + 0 = 0 + A = A\\)\n합의 전치 : \\((A + B)^{T} = A^{T} + B^{T}\\)\n\n\n\n2. 스칼라-행렬 곱하기\n행렬 모든 원소에 스칼라 곱을 하여 결과는 원행렬과 동일한 차수의 행렬이다. (기호) \\(cA = \\{ ca_{ij}\\} = Ac\\) 다음의 성질을 갖는다.\n\n\\((cA)^{T} = cA^{T}\\)\n\\((c + d)A = cA + dA\\)\n\n\n\n3. 행렬x벡터 곱하기\n행렬 \\(A_{m \\times n}\\)와 행벡터 \\(x_{n}\\) 곱 연산은 다음과 같이 정의되며 결과는 행벡터 \\(y_{m \\times 1} = A_{m \\times n}x_{n \\times 1}\\)이며 차수는 \\(m\\)이다.\n\n\n\n\n\n연산 가능: 앞의 행렬(\\(A_{m \\times n}\\))의 열차수와 뒤의 행벡터(\\(x_{n}\\)) 행차수가 동일해야 한다.\n행 측면: 행렬 \\(A\\)의 \\(i\\)-번째 행벡터을 \\(a_{i}^{T}\\)라 하면 \\(y_{i} = a_{i}^{T}x\\)(내적)이다.\n열 측면: \\(A\\)의 \\(k\\)-번째 열벡터을 \\(a_{k}\\)라 하면 \\(y = x_{1}a_{1} + x_{2}a_{2} + + ... + x_{n}a_{n}\\).\n\n\n\n\n\n행렬 \\(A\\)의 열벡터 선형독립이다\n만약 \\(x = 0\\)인 경우에만 \\(Ax = 0\\)이 성립하면, 열벡터는 선형독립이다.\n활용\n\n행렬 \\(A\\)가 영행렬이면 \\(Ax = 0\\)는 영벡터이다.\n행렬 \\(A\\)가 단위행렬이면 \\(Ax = x\\)이다.\n행렬 \\(A\\)의 \\(j\\)-번째 열벡터는 \\(Ae_{j} = a_{j}\\)이다.\n행렬 \\(A\\)의 \\(i\\)-번째 행벡터는 \\((A^{T}e_{i})^{T}\\)이다.\n\n예제\n(예측데이터 행렬) Feature matrix \\(X_{N \\times n}\\)는 \\(N\\)개의 객체에 대한 특성 \\(n\\)-벡터, 객체들에 대한 가중치 \\(w\\)-벡터(차수 \\(N\\))라 하자. \\(X^{T}w\\)는 객체들에 대한 가중 점수 벡터이다.\n(포트폴리오 자산 수익율) 포트폴리오 자산 수익율 행렬 \\(R_{T \\times n}\\)(\\(T\\) 기간 동안 \\(n\\)개의 자산의 수익률)이라 하고 \\(w\\)을 포트폴리오 \\(n\\)-벡터라 하면 \\(Rw\\)는 \\(T\\)기간 포트폴리오 수익률이다.\n(오디오 믹싱) \\(A\\)의 \\(k\\)개 열이 길이 \\(T\\)의 오디오 신호나 트랙을 나타내는 벡터들이고, \\(w\\)가 \\(k\\)-벡터인 경우를 가정하면 \\(Aw\\)는 오디오 신호들을 믹싱한 결과를 나타내는 \\(T\\)-벡터이다.\n(문서 점수화) 검색 엔진은 검색 쿼리를 기반으로 w를 선택하여 문서의 점수를 예측한다. \\(A\\)는 \\(N \\times n\\)크기의 문서-단어 행렬로, \\(N\\)개의 문서가 \\(n\\)개의 단어 사전을 사용하여 단어의 출현 빈도, \\(w\\)는 \\(n\\)-벡터로, 단어 사전 내 단어들에 대한 가중치로 \\(Aw\\)는 \\(N\\)-벡터로, 각 문서의 점수를 나타낸다.\n\n\n4. 행렬x행렬 곱하기\n\n(1) 정의\n행렬을 곱하기 위해서는 앞 행렬의 열 차수와 뒤 행렬의 행의 차수와 일치해야 곱이 가능하다. conformable for product 결과의 차수는 앞 행렬의 행 차수, 뒤 행렬의 열 차수를 갖는다.\n\\(A_{m \\times n}B_{n \\times p} = (AB)_{m \\times p}\\)\n\\(A = \\{ a_{ij}\\}\\), \\(B = \\{ b_{ij}\\}\\) ⇢ \\(AB = \\{\\overset{n}{\\sum_{k = 1}}a_{ik}b_{kj}\\}\\)\n\n\n\n\n\n\n\n(2) 곱의 성질\n\n결합 associate 법칙: \\((AB)C = A(BC)\\)\n배분 distribution 법칙: \\(A(B + C) = AB + AC\\)\n전치 : \\((AB)^{T} = B^{T}A^{T}\\)\n\\((A + B)(C + D) = AC + AD + BC + BD\\)\n\\(y^{T}(Ax) = (y^{T}A)x = (A^{T}y)^{T}x\\)\n\n\n\n(3) 행렬의 거듭제곱\n\\[A^{2} = AA$, $A^{3} = AAA$, $A^{4} = AAAA \\cdots \\]\ndirected graph: 인접 adjacency 행렬을 다음과 같이 정의하자.\n\\[A_{ij} = \\{\\begin{array}{r}\n\\text{1 there is a edge from vertex j to vertex i} \\\\\n\\text{0 otherwise}\n\\end{array}\\]\n\n\n\n\n\n\n\n멱등행렬 idempotent\n자신의 행렬 곱이 자신이 되는 행렬을 멱등행렬이라 한다. \\(M^{2} = M^{3} = ... = M\\) 자신의 곱이 연산 가능해야 하므로 멱등행렬이려면 정방행렬이어야 한다.\n\n\n\n5. QR 분해, Q는 직교행렬, R은 상삼각행렬\n\n(1) 직교행렬 orthonormal matrix\n열벡터 \\(A_{m \\times n}\\)의 n-벡터 \\(a_{1},a_{2},...,a_{m}\\)들이 orthonomal 하면, 즉 \\(A^{T}A = I\\)을 만족하는 행렬을 직교정규행렬이라 한다.만약 \\(A_{m \\times n}\\)는 직교정규행렬, \\(x,y\\)는 n-벡터라 하고 \\(f:R^{n} \\rightarrow R^{m}\\) 함수가 \\(z\\)를 \\(Az\\)로 매핑한다고 가정하자.\n\n\\(\\parallel Ax \\parallel = \\parallel x \\parallel\\) : 함수 \\(f\\)는 놈을 보존한다.\n\\((Ax)^{T}(Ay) = x^{T}y\\) : 함수 \\(f\\)는 두 벡터의 내적을 보존한다.\n\\(\\angle(Ax,Ay) = \\angle(x,y)\\) : 함수 \\(f\\)는 두 벡터의 각도을 보존한다.\n\n【recall】 Gram-Schmidt 알고리즘\n만약 벡터들이 선형 독립이라면, Gram–Schmidt 알고리즘은 다음과 같은 속성을 가진 직교정규 벡터 \\(q_{1},q_{2},...,q_{k}\\) 을 생성한다.\n\n\n(2) QR분해 \\(A = QR\\)\n행렬 \\(A_{n \\times k}\\)의 n-벡터 \\(a_{1},a_{2},...,a_{k}\\)가 선형 독립인 행렬이다. 여기에 Gram-Schmidt 알고리즘을 적용하여 얻은 직교정규 벡터 \\(q_{1},q_{2},...,q_{k}\\)으로 직교정규 행렬 \\(Q\\)을 생성하자. \\(Q^{T}Q = I\\)이다.\n\\(a_{i}\\)와 \\(q_{i}\\)의 관계식 : \\(a_{i} = (q_{1}^{T}a_{i})q_{1} + \\cdots + (q_{i - 1}^{T}a_{i})q_{i - 1} + \\parallel {\\overset{˜}{q}}_{i} \\parallel q_{i}\\)\n이를 다시 쓰면 \\(a_{i} = R_{1i} + \\cdots + R_{ii}q_{1}\\)이다. \\(R_{ij} = q_{i}^{T}a_{j}fori &lt; j\\), \\(R_{ij} = 0fori &gt; j\\), 그리고\\(R_{ii} = \\parallel {\\overset{˜}{q}}_{i} \\parallel\\)\n그러므로 \\(A_{n \\times k}\\) (열이 독립인 행렬)은 직교정규 행렬 \\(Q_{n \\times k}\\)과 \\(R_{k \\times k}\\) 상삼각행렬로 분해된다.\n\n\n(3) QR 분해 활용\n선형 시스템의 해 구하기, 최소자승 문제, 정규방정식 문제\n선형 방정식 \\(Ax = b\\)를 푸는 데 사용될 수 있다. \\(A = QR\\)로 분해하면 \\(QRx = b\\)가 되고 \\(R_{x} = Q^{T}b\\)이므로 \\(R\\)이 상삼각 행렬이므로 후진 대입을 사용하여 해, \\(x\\)를 효율적으로 구할 수 있다.\n고유값 계산\n\\(QR\\) 알고리즘을 이용하여 특정 행렬의 고유값을 계산할 수 있다. \\(QR\\) 분해를 사용한 고유값 계산 알고리즘은 변환 행렬을 상삼각 행렬로 변환하고, 이로부터 고유값을 추출한다.\n행렬의 특성 분석\n\\(QR\\) 분해는 행렬의 특성을 분석하는 데 도움을 준다. 예를 들어, 행렬의 계수(rank)를 결정하거나, 행렬이 정칙인지 (역행렬이 존재하는지) 파악하는데 사용될 수 있다.\nimport numpy as np\n# 행렬 A 정의\nA = np.array([[1, 1], [1, -1], [1, 1]])\n# QR 분해\nQ, R = np.linalg.qr(A)\n# 결과 출력\nprint(\"Q:\")\nprint(Q)\nprint(\"\\nR:\")\nprint(R)\n【결과】 Q: [[-0.57735027 0.40824829] [-0.57735027 -0.81649658] [-0.57735027 0.40824829]]\nR: [[-1.73205081 -0.57735027] [ 0. 1.63299316]]\n\n\n\n6. 역행렬\n\n(1) 왼쪽 오른쪽 역행렬\n만약 \\(XA = I\\) 만족하는 \\(X\\)가 존재하면 A는 left-invertible 이라 한다. 동일하게 \\(AX = I\\) 만족하는 \\(X\\)가 존재하면 A는 right-invertible 이라 한다.\nleft-invertible과 열 벡터는 선형독립: 만약 행렬 \\(A\\)가 left-inverse 행렬 \\(C\\) 갖는다면 행렬 \\(A\\)의 열벡터는 선형 독립이다.\n【증명】 \\(Ax = 0\\)을 만족하는 \\(x = 0\\)이므로 \\(A\\)의 열벡터는 선형 독립이다. \\(0 = CAx = Ix = x\\)\nleft-invertible 행렬(\\(C\\)) 갖는 \\(A\\) 선형방정식 \\(Ax = b\\) 해 구하기\n\\[C_{m \\times m}A_{m \\times n}x_{n} = C_{n \\times n}b_{n} \\rightarrow x_{n} = C_{n \\times n}b_{n}\\]\nright-invertible과 행 벡터는 선형독립: 만약 행렬 \\(A\\)가 right-inverse 행렬 \\(B\\) 갖는다면 행렬 \\(A\\)의 행벡터는 선형 독립이다.\nleft, right invertible 관계: 행렬 \\(A\\)의 right inverse \\(B\\)을 가지면 \\(B^{T}\\)는 \\(A^{T}\\)의 left inverse 행렬이다.\n【증명】 \\(AB = I \\rightarrow (AB)^{T} = I^{T} \\rightarrow B^{T}A^{T} = I\\)\n\n\nright-invertible 행렬(\\(B\\)) 갖는 \\(A\\) 선형방정식 \\(Ax = b\\) 해 구하기\n해는 \\(x = Bb\\)이다. 【증명】 \\(Ax = A(Bb) = (AB)b = b\\)\n\n\n(2) 역행렬 구하기\n행렬의 역수 개념이다. 3에 어떤 수를 곱하면 1이 될까? 답은 \\(\\frac{1}{3}\\)(역수)이다. 마찬가지로 행렬 \\(A\\)에 무엇을 곱하면 항등행렬 \\(I\\)가 될까? 이를 역행렬이라 한다. \\(AA^{- 1} = A^{- 1}A = I\\)\n행렬식 determinant: 행렬식은 정방행렬에서만 계산되며 결과는 스칼라이다. 기호는 \\(det(A)\\)혹은 \\(|A|\\)으로 표현한다. 다음은 행렬식 계산 방법이다.\n\\(A_{2 \\times 2} = \\begin{bmatrix}\na & b \\\\\nc & d\n\\end{bmatrix}\\) ⇢ \\(det(A) = ad - bc\\) \\(A = \\begin{bmatrix}\n1 & 3 \\\\\n2 & 4\n\\end{bmatrix}\\), \\(|A| = - 2\\)\n\n\n\n\n\n행렬식 성질\n\n\\(|A^{T}| = |A|\\)\n\\(|AB| = |BA|\\)\n\\(|AB| = |A||B|\\)\n한 열에 \\(k\\)배 한 후 다른 열에 더하여도 행렬식은 변하지 않는다.\n한 열이 다른 열의 선형결합으로 표현된다면 행렬식은 0이다.\n\n소행렬 minor: \\(i\\)행, \\(j\\)열은 제외한 행렬을 소행렬(\\(M_{ij}\\))이라 하고 소행렬의 행렬식을 소행렬식(\\(|M_{ij}|\\))이라 한다. 일반적으로 소행렬은 소행렬식을 의미한다.\n\n\n\n\n\n여인수 cofactor\n\n\\(C_{ij} = ( - 1)^{i + j}|M_{ij}|\\)을 여인수라 한다. 여인수를 이용하여 다음과 같이 행렬식을 구할 수 있다.\n\\(|A_{n \\times n}| = \\overset{n}{\\sum_{i = 1}}a_{ij}( - 1)^{i + j}|M_{ij}|\\),\\(|A_{n \\times n}| = \\overset{n}{\\sum_{j = 1}}a_{ij}( - 1)^{i + j}|M_{ij}|\\)\n\n여인수 행렬 / 수반행렬 adjoint\n\\(C_{ij} = \\begin{bmatrix}\nC_{11} & C_{12} & C_{13} \\\\\nC_{21} & C_{22} & C_{23} \\\\\nC_{31} & C_{32} & C_{33}\n\\end{bmatrix}\\)⇢ \\(adj(A) = \\begin{bmatrix}\nC_{11} & C_{21} & C_{31} \\\\\nC_{12} & C_{22} & C_{32} \\\\\nC_{13} & C_{23} & C_{33}\n\\end{bmatrix}\\)\n역행렬 구하기: 정방행렬 \\(A\\)에 대하여 \\(AB = BA = I\\)을 만족하는 행렬 \\(B\\)를 \\(A\\)의 역행렬이라 하며 \\(A^{- 1}\\)로 표현한다.\n\\[A^{- 1} = \\frac{1}{|A|}adj(A)\\]\n역행렬 성질\n\n역행렬은 유일하고 \\((A^{- 1})^{- 1} = A\\)이 성립한다.\n\\((AB)^{- 1} = B^{- 1}A^{- 1}\\)\n\\((A^{T})^{- 1} = (A^{- 1})^{T}\\)\n\\(|A^{- 1}| = \\frac{1}{|A|}\\)\n\n계수 rank: 차수가 \\(n\\)인 정방행렬 \\(A_{n \\times n}\\)의 열벡터에 대하여 \\(k_{1}\\underset{¯}{a_{1}} + k_{2}\\underset{¯}{a_{2}} + ... + k_{n}\\underset{¯}{a_{n}} = \\underset{¯}{0}\\) 방정식이 모든 상수 \\(k_{j}\\)가 0일 때만 만족하는 경우 열벡터(\\(\\underset{¯}{a_{j}}\\))는 선형독립 linearly independent이라 한다. 만약 적어도 0이 아닌 상수가 하나라도 존재하면 종속이라 한다.\n정방행렬 \\(A_{n \\times n}\\)에 대하여 선형 독립인 행의 개수와 열의 개수 중 작은 것을 행렬의 계수라 한다. 행렬의 차수와 계수가 동일하면 이를 full-rank라 한다.\n행렬 \\(A_{n \\times n}\\)에 대하여 각 열은 동일하다.\n\n\n\n\n\n\n\n역행렬 \\(A^{- 1}\\)은 존재한다.\n역행렬 \\(A^{- 1}\\)은 존재하지 않는다.\n\n\n\n\n행렬식은 0이 아니다. \\(det(A) \\neq 0\\)\n행렬식은 0이다. \\(det(A) = 0\\)\n\n\nfull rank이다. \\(rank(A) = n\\)\nfull rank 아니다. \\(rank(A) &lt; n\\)\n\n\n행렬 A는 non-singular이다.\n행렬 A는 singular이다.\n\n\n\\(AX = \\underset{¯}{b}\\) 해가 존재한다.\n\\(AX = \\underset{¯}{b}\\) 해가 존재하지 않는다.\n\n\n\n\n\n\n\nchapter 3. 행렬 활용\n\n1. 연립방정식 해 구하기 \\(Ax = b\\)\n\n(1) \\(QR\\) 분해 이용\n\n행렬 \\(A\\)을 \\(QR\\)분해 한다. \\(A = QR\\)\n\\(Q^{T}b\\)을 구한다.\n후진 제거 방법으로 \\(Rx = Q^{T}b\\)을 구한다.\n\n\n\n(2) 역행렬 계산 \\(A^{- 1}\\)\n행렬 \\(A\\)의 역행렬 \\(A^{- 1}\\)을 이용하여 \\(\\widehat{x} = A^{- 1}b\\) 해를 구한다.\n\n\n\n2. 최소자승법 \\(Ax = b\\)\n\n(1) 최소자승 문제\n\\(A_{m \\times n}x_{n} = b_{m}\\)(단 \\(m &gt; n\\)) 선형방정식에서는 \\(m\\)개의 방정식이 \\(n\\)개 변수보다 많으므로 \\(b\\)가 행렬 \\(A\\)의 열의 선형결합일 때만 해를 갖는다. \\(b\\)을 어떻게 구할 것인가? 잔차 \\(r = Ax - b\\)최소화 하는 \\(x\\)을 찾는 것을 최소자승법이라 한다. \\(minmize \\parallel Ax - b \\parallel\\) \\(2x_{1} = 1, - x_{1} + x_{2} = 0,2x_{2} = - 1\\) : 방정식 3개, 미지수 2개\n\\(Ax = b\\): \\(\\begin{bmatrix}\n2 & 0 \\\\\n- 1 & 1 \\\\\n0 & 2\n\\end{bmatrix}\\left\\lbrack \\begin{array}{r}\nx_{1} \\\\\nx_{2}\n\\end{array} \\right\\rbrack = \\begin{bmatrix}\n1 & 0 & 1\n\\end{bmatrix}\\)\n\n\n(2) 최소자승 해 구하기\n\\(minmizef(x) = \\parallel Ax - b \\parallel^{2}\\) 해 \\(\\widehat{x}\\)는 \\(\\frac{\\partial f}{\\partial x_{i}}(\\widehat{x}) = 0,i = 1,2,...,n\\)을 만족하므로 \\(\\nabla f(x) = 2A^{T}(Ax - b)\\) 방정식에서 \\(\\nabla f(\\widehat{x}) = 0\\)이다. 그러므로 최소자승 해는 \\(\\widehat{x} = (A^{T}A)^{- 1}A^{T}b\\)이다.\n\n\n\n\n\n\\(A = QR\\) 분해 이용\n\\(Ax = b\\)의 최소자승 해는 \\(\\widehat{x} = R^{- 1}Q^{T}b\\)이다.\n\\[RMS = \\sqrt{\\parallel b - A\\widehat{x} \\parallel^{2}}\\]\n매출 광고\n행은 사회인구학적 특성 10개이고 열은 3개 광고 채널이고 \\(R_{ij}\\)는 \\(i\\)-사회인구학적특성의 \\(j\\)-광고채널의 1달러당 노출회수(단위: 1000)이다. 만약 각 사회인구학적 특성 집단별로 노출회수를 \\(10^{3}\\)으로 할 경우 광고비는 얼마?\n\n\n\n\n\n\\(R_{10 \\times 3}x_{3} = 10^{3}1_{3}\\)에 대한 최소자승해는 \\(\\widehat{x} = (62,100,1443)\\)으로 각 채널당 광고비이다. \\(RMS = 13.2\\%\\)이다.\n\n\n(3) 최소자승 데이터 적합\n\\(n\\)-벡터 \\(x\\)(feature 벡터, 독립변수), 스칼라 \\(y\\)는 다음 근사 함수 관계가 있다고 하자. \\(f:R^{n} \\rightarrow R,y \\approx f(x)\\)\n데이터\n\\[x^{(1)},x^{(2)},...,x^{(N)},y^{(1)},y^{(2)},...,y^{(N)}\\]\n모델 관측치 개수 \\(N\\), 예측변수 개수 \\(p\\)\nfeature 벡터와 스칼라 벡터 사이 함수 관계는 \\(f\\)(예측함수)은\\(y \\approx \\widehat{f}(x),where\\widehat{f}:R^{n} \\rightarrow R\\)\n\\(\\widehat{f}(x)\\)는 파라미터 \\(p\\)-벡터 \\(\\theta\\)의 선형 함수이다.\n\\(\\widehat{f}(x) = \\theta_{1}f_{1}(x) + \\theta_{2}f_{2}(x) + \\cdots + \\theta_{p}f_{p}(x)\\), where \\(f_{i}:R^{n} \\rightarrow R\\)\n예측값과 예측오차\n\\(y^{(i)} \\approx \\widehat{f}(x^{(i)})\\)이고 예측오차(잔차)는 \\(r^{(i)} = y^{(i)} - {\\widehat{y}}^{(i)}\\)이다.\n최소자승 모델 적합\n\\(i = 1,2,\\cdots,N,j = 1,2,\\cdots,p\\)\n\\(y^{d} = (y^{(1)},y^{(2)},...,y^{(N)})\\), \\({\\widehat{y}}^{d} = ({\\widehat{y}}^{(1)},{\\widehat{y}}^{(2)},...,{\\widehat{y}}^{(N)})\\)\n예측오차합 \\(\\parallel r^{d} = y^{d} - {\\widehat{y}}^{d} \\parallel^{2}\\)을 최소화 하는 모수 \\(\\theta\\)을 찾는다.\n\\[{\\widehat{y}}^{(i)} = A_{i1}\\theta_{1} + A_{i1}\\theta_{2} + \\cdots + A_{i1}\\theta_{p},whereA_{ij} = {\\widehat{f}}_{j}(x^{(i)})\\]\n\\({\\widehat{y}}^{d} = A\\theta\\)이므로 \\(\\parallel r^{d} \\parallel^{2} = \\parallel y^{d} - A\\theta \\parallel^{2}\\)이다.\n최소자승 추정 : \\(\\widehat{\\theta} = (A^{T}A)^{- 1}A^{T}y^{d}\\)\n상수항(절편) 있는 선형함수 최소자승 추정\n모든 \\(x\\)에 대하여 \\(f_{1}(x) = 1\\)을 갖는 상수함수를 고려하자. \\(\\widehat{f}(x) = \\theta_{1}\\)이고 \\(A_{(N \\times 1)} = 1_{N}\\)이다.\n\\[\\widehat{\\theta} = (A^{T}A)^{- 1}A^{T}y^{d} = N^{- 1}1^{T}y^{d} = avg(y^{d})\\]\n\n\n(4) 다항식 적합\n모형 \\(\\widehat{f}(x) = \\theta_{1} + \\theta_{2}x + \\cdots + \\theta_{p}x^{p - 1}\\)\n\\[A = \\begin{bmatrix}\n1 & x^{(1)} & \\cdots & (x^{(1)})^{p - 1} \\\\\n1 & x^{(2)} & \\cdots & (x^{(2)})^{p - 1} \\\\\n\\cdots & & & \\\\\n1 & x^{(N)} & \\cdots & (x^{(N)})^{p - 1}\n\\end{bmatrix}\\]\nPiecewise-Linear Fit 분절선형 적합\n\n절단점 식별: 선의 기울기가 변하는 지점을 결정한다.\n선형 구간 적합: 절단점으로 분리된 각 데이터 구간에 선형 모델을 적합한다.\n구간 결합: 절단점에서 구간함수를 연결하여 연속적인 분절선형 함수를 형성한다.\n\n\n\n\n\n\n# Piecewise-Linear Fit\nimport numpy as np\n# 합성 데이터 생성\nnp.random.seed(0)\nx = np.linspace(0, 10, 100)\ny = np.piecewise(x, [x &lt; 4, (x &gt;= 4) & (x &lt; 7), x &gt;= 7],[lambda x: 2 * x + 1 + np.random.normal(size=len(x)),lambda x: -x + 5 + np.random.normal(size=len(x)),lambda x: 0.5 * x - 1 + np.random.normal(size=len(x))])\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import curve_fit\n# 분절선형 함수 정의\ndef piecewise_linear(x, x0, x1, y0, y1, y2, k1, k2, k3):\n    conds = [x &lt; x0, (x &gt;= x0) & (x &lt; x1), x &gt;= x1]\n    funcs = [lambda x: k1 * x + y0, lambda x: k2 * x + y1, lambda x: k3 * x + y2]\n    return np.piecewise(x, conds, funcs)\n# 초기 파라미터 추정값\np0 = [4, 7, 1, 5, -1, 2, -1, 0.5]\n# 데이터를 분절선형 함수에 적합시킴\nparams, _ = curve_fit(piecewise_linear, x, y, p0=p0)\n# 데이터를 적합한 결과와 함께 플로팅\nx_fit = np.linspace(0, 10, 100)\ny_fit = piecewise_linear(x_fit, *params)\n\nplt.scatter(x, y, label='Data')\nplt.plot(x_fit, y_fit, color='red', label='Piecewise Linear Fit')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.legend()\nplt.show()\n\n\n\n3. 간선행렬 \\(Ax = b\\)\n간선 행렬 Incidence matrix은 그래프 이론에서 사용되는 개념으로, 정점과 vertices 간선 edges, nodes 사이의 관계를 나타내는 행렬이다.\n간선 행렬 \\(G_{n \\times m}\\)은 정점이 \\(n\\)개, 간선이 \\(m\\)개이다.\n\n\\(A_{ij} = 1\\) : 정점 \\(i\\)와 간선 \\(j\\)와 연결되어 있고 정점 \\(i\\)는 끝 정점이 아니다.\n\\(A_{ij} = 1\\) : 정점 \\(i\\)와 간선 \\(j\\)와 연결되어 있고 정점 \\(i\\)는 끝 정점이다.\n\\(A_{ij} = 0\\) : 정점 \\(i\\)와 간선 \\(j\\)와 연결되어 않음\n\n\n\n\n\n\n\n\n4. 네트워크\n만약 \\(x\\)가 네트워크에서의 흐름을 나타내는 \\(m\\)-벡터라면, \\(x_{j}\\)는 간선 \\(j\\)를 통한 흐름으로 해석된다. 여기서 양의 값은 흐름이 간선 \\(j\\)의 방향으로 이동하고, 음의 값은 흐름이 간선 \\(j\\)의 반대 방향으로 이동함을 의미한다. 네트워크에서 간선이나 링크의 방향은 흐름의 방향을 지정하지 않고 그저 흐름 flow의 방향을 고려하는 것을 나타내는 것이다.\n네트워크에서의 흐름 보존은 흐름이 노드와 간선을 통해 어떻게 이동하는지를 설명하며, 각 노드로 들어오는 총 흐름이 노드에서 나가는 총 흐름과 같음을 보장한다.\n네트워크 구조를 나타내는 \\(G_{n \\times m}\\)를 사용하여\n\\(y = Gx\\)는 각 노드로 들어오는 순흐름을 나타내는 \\(n\\)-벡터이다.\n\\(y_{i}\\)는 \\(i\\)-노드로 들어오는 총 흐름에서 \\(i\\)-노드에서 나가는 총 흐름을 뺀 값이다 즉, \\(i\\)-노드에서의 흐름 잉여 surplus이다.\n요약하면, \\(y = Gx\\)는 네트워크 이론에서의 흐름 보존 원칙을 요약한 것으로, 각 요소 \\(y_{i}\\)는 노드 \\(i\\)에서의 순 흐름 균형을 나타내며 모든 들어오는 흐름과 나가는 흐름을 고려한다.\n만약 \\(Gx = 0\\)인 상태를 각 노드에서 총 들어오는 흐름과 총 나가는 흐름이 일치하기 때문에 흐름 보존이 일어난다고 말한다.\n\n\n\n\n\n위의 그래프에 의해 나타낸 네트워크에서 \\(x = (1, - 1,1,0,1)\\)이다. 소스는 source 노드에서 네트워크로 들어오거나 나가지만, 간선을 따라 흐르지는 않습니다. 위 그림에서 보여지는 것처럼 이러한 흐름들은 5-벡터 4소스로 나타낸다. \\(s_{i}\\)를 노드 \\(i\\)에서 외부에서 네트워크로 들어오는 흐름으로 생각할 수 있다. 즉, 어떤 간선을 통해서도 들어오지 않는 것이다. \\(s_{i} &gt; 0\\)일 때 외부흐름은 소스라고 부르며 \\(s_{i} &lt; 0\\)일 때 외부흐름은 싱크라고 부른다.\n소스 포함된 흐름 보전 : \\(Ax + s = 0\\)\n\n\n5. 선형함수 모델 \\(Ax = b\\)\n필드에서 발생하는 많은 함수나 변수 간의 관계는 선형 또는 아핀 함수로 근사될 수 있는데, 두 변수 집합 간의 선형 함수를 모형(model) 또는 근사(approximation) 값으로 정의한다.\n\n(1) 수요의 가격 탄력성(Price elasticity of demand)\n가격이 n개의 상품(서비스)에 의해 결정되는 n-벡터 p로 주어지고, 상품에 대한 수요가 n-벡터 d로 주어진다. n-벡터 \\(\\delta^{price}\\)를 가격변화 벡터라 하면 \\(\\delta^{price} = \\frac{(p_{i}^{new} - p_{i})}{p_{i}}\\)라 하자(\\(p^{new}\\)는 새로운 가격 n-벡터). n-벡터 \\(\\delta^{dem}\\)를 수요변화 벡터라 하면 \\(\\delta^{dem} = \\frac{(d_{i}^{new} - d_{i})}{d_{i}}\\)라 하자. \\(\\delta^{dem} = E^{d}\\delta^{price}\\), \\(E^{d}\\)는 (\\(n \\times n\\)) 수요 탄력성 행렬이다.\n\\(E_{11}^{d} = - 0.4\\), \\(E_{21}^{d} = 0.2\\) 가정해 보자. 이는 첫 번째 상품의 가격이 1% 증가할 때, 다른 가격은 동일한 상태에서 첫 번째 상품의 수요가 0.4% 감소하고, 두 번째 상품의 수요가 0.2% 증가할 것임을 의미한다. 두 번째 상품은 첫 번째 상품의 부분 대체품으로 작용하고 있다.\n\n\n(2) 탄성 변형 Elastic deformation\nf 를 구조물에 작용하는 특정 위치(및 방향)에 대한 힘(하중)을 나타내는 n-벡터라고 합시다. 구조물은 하중으로 인해 약간 변형될 것입니다. d는 하중으로 인해 구조물의 m개 지점에서 발생하는 변위(특정 방향으로)를 나타내는 m-벡터입니다. 변위와 하중 사이의 관계는 선형으로 잘 근사된다. d= Cf 여기서 C 는 m × n 컴플라이언스(compliance) 행렬이고 C 의 항목의 단위는 m/N입니다.\n\n\n(3) 테일러 근사\n함수 \\(f:R^{n} \\rightarrow R^{n}\\)이 1차 미분이 가능하다고 하면 테일러 근사는 \\(\\widehat{f}(x)_{i} = f_{i}(z) + \\triangledown f_{i}(z)^{T}(x - z)\\), 단 n-벡터 \\(z\\)는 n-벡터 \\(x\\)와 가까운 값이다.\n\\(\\widehat{f}(x) = f(z) + Df(z)(x - z)\\), 단.\\(Df(z)_{ij} = \\frac{\\partial f_{i}}{\\partial x_{i}}(z),i = 1,...,m,j = 1,...,n\\)\n\n\n(4) 회귀모형\n표본 크기 \\(N\\), 예측변수 벡터 \\(x^{(1)},x^{(2)},...,x^{(N)}\\)이다. \\(i\\)-개체의 예측치는 \\({\\widehat{y}}^{(i)} = (x^{(i)})^{T}\\beta + v,i = 1,2,...,N\\)이다. 그리고 \\(X\\)는 예측변수 행렬, \\(y\\)는 목표변수 벡터이다.\n\n잔차는 \\(r^{(i)} = y^{(i)} - {\\widehat{y}}^{(i)}\\).\n절편 없는 회귀모형 : \\({\\widehat{y}}^{d} = X^{T}\\beta + v1\\)\n절편 회귀모형 : \\({\\widehat{y}}^{d} = \\left\\lbrack \\begin{array}{r}\n1^{T} \\\\\nX\n\\end{array} \\right\\rbrack^{T}\\left\\lbrack \\begin{array}{r}\nv \\\\\n\\beta\n\\end{array} \\right\\rbrack\\)\n\n\n\n\n6. 선형 동적 시스템\n시간에 따라 변하는 상태 벡터의 선형 관계를 설명하는 모델로 시스템의 현재 상태가 다음 상태를 예측할 수 있는 간단한 수학적 구조이다. \\(x_{t}\\)가 현재 상태인 \\(x_{1},x_{2},\\cdots\\) n-벡터 시계열이라 하자. 예를 들면, \\((x_{5})_{3}\\) 3번째 포트폴리오의 5일째 주가가 된다.\n\n(1) 입력이 포함된 선형 동적 시스템\n\\[x_{t + 1} = A_{t}x_{t} + B_{t}u_{t},t = 1,2,...\\]\n\\(u_{t}\\) 는 시간 t 에서의 입력벡터이고 .B 는 입력행렬로, 입력 \\(u_{t}\\)(외생 변수라고도 함)가 상태 벡터 \\(x_{t}\\)에 미치는 영향을 설명한다.\n\n\n(2) \\(K\\)-Markov 모형\n\\[x_{t + 1} = A_{1}x_{t} + \\cdots + A_{K}x_{t - K + 1},t = K,K + 1,...\\]\n\n상태 State : 시스템이 존재할 수 있는 모든 가능한 상태들의 집합. 예를 들어, 날씨 예측 모델에서 상태는 ”맑음”, ”흐림”, ”비” 등이 될 수 있다. 시스템이 가질 수 있는 모든 상태들의 집합을 상태 공간 \\(S\\)라 한다.\n상태 전이 State Transition : 한 상태에서 다른 상태로의 전이. 상태 전이는 확률적으로 이루어지며 \\(P_{i}\\)는 초기상태 확률분포이다.\n전이 확률 Transition Probability : 현재 상태에서 다음 상태로 전이될 확률을 나타낸다. 이는 \\(P(x_{t + 1} = s_{j}|x_{t} = s_{i})\\)로 표현되며, 현재 상태 \\(i\\)에서 다음 시점에 상태 \\(j\\)로 전이될 확률이다.\n\n# Markov model\nimport numpy as np\n# 전이 행렬 정의\nP = np.array([[0.8, 0.2],[0.4, 0.6]])\n# 초기 상태 분포 정의\npi_0 = np.array([0.6, 0.4])\n# 상태 이름 정의\nstates = [\"Sunny\", \"Rainy\"]\n# 시뮬레이션을 위한 시간 단계 수\nnum_steps = 10\n# 초기 상태 선택\ncurrent_state = np.random.choice(states, p=pi_0)\nprint(f\"Day 0: {current_state}\")\n# 시뮬레이션 시작\nfor t in range(1, num_steps + 1):\n    if current_state == \"Sunny\":\n        next_state = np.random.choice(states, p=P[0])\n    else:\n        next_state = np.random.choice(states, p=P[1])\n    print(f\"Day {t}: {next_state}\")\n    current_state = next_state\n\n\n\n\n\n\n\n\n7. 인구 동태\n100-벡터 \\((x_{t})_{i}\\)는 \\(t\\) 시점의 \\((i - 1)\\)세 인구이다. 100- 벡터 \\(b\\)의 \\(b_{i}\\)는 \\((i - 1)\\)의 평균 출생율이다. 가임 연령을 고려하면 벡터 b의 원소는\\(b_{I} = 0fori &lt; 13ori &gt; 50\\)이다. 만약 사망, 이민 없다고 가정하면 내년 0세 인구는 \\((x_{t + 1})_{1} = b^{T}x_{t}\\)이다.\n나이 \\(i\\)세 \\((t + 1)\\) 시점의 인구수는 다음과 같다. \\(d_{i}\\)는 \\(i\\)세 사망자수이다.\\((x_{t + 1})_{i + 1} = (1 - d_{i})(x_{t})_{i},i = 1,2,\\cdots,99\\). 최종적으로 인구 동태 모형은 \\(x_{t + 1} = Ax_{t},t = 1,2,\\cdots\\)이다.\n전이행렬 \\(A\\)\n\\[A = \\begin{bmatrix}\nb_{1} & b_{2} & b_{3} & \\cdots & b_{98} & b_{99} & b_{100} & \\\\\n1 - d_{1} & 0 & 0 & \\cdots & 0 & 0 & 0 & \\\\\n0 & 1 - d_{2} & 0 & \\cdots & 0 & 0 & 0 & \\\\\n\\cdots & \\cdots & \\cdots & \\cdots & \\cdots & \\cdots & \\cdots & \\\\\n0 & 0 & 0 & \\cdots & 1 - d_{98} & 0 & 0 & \\\\\n0 & 0 & 0 & \\cdots & & 0 & 1 - d_{99} & 0\n\\end{bmatrix}\\]\n이민을 고려한 인구 동태 모형\n\\(x_{t + 1} = Ax_{t} + u_{t},t = 1,2,\\cdots\\), 벡터 \\((u_{t})_{i}\\)는 t-시점에 나이 \\((i - 1)\\)세의 순이민자수이다.\n간단한 인구동태 방정식\n\\[P_{t + 1} = P_{t} + (B_{t} - D_{t}) + M_{t}\\]\n\\(P_{t}\\) : \\(t\\) 시점의 인구수, \\(B_{t}\\) : \\(t\\) 시점의 출생자수, \\(D_{t}\\) : \\(t\\) 시점의 사망자수, \\(M_{t}\\) : \\(t\\) 시점의 순 이민자수\n# 인구동태모형\nimport numpy as np\nimport matplotlib.pyplot as plt\n# 초기 인구와 파라미터 설정 미국 23년 기준\ninitial_population = 330_000_000\nbirth_rate = 12.4 / 1000\ndeath_rate = 8.9 / 1000\nannual_net_migration = 1_000_000\nyears = 10\n# 인구 예측을 위한 배열 초기화\npopulation = np.zeros(years + 1)\npopulation[0] = initial_population\n# 연도별 인구 예측\nfor t in range(1, years + 1):\n    births = population[t - 1] * birth_rate\n    deaths = population[t - 1] * death_rate\n    population[t] = population[t - 1] + births - deaths + annual_net_migration\n# 결과 출력\nfor t in range(years + 1):\n    print(f\"Year {2023 + t}: {population[t]:,.0f}\")\n【결과】 Year 2024: 332,155,000 Year 2025: 334,317,542 Year 2026: 336,487,654 Year 2027: 338,665,361 Year 2028: 340,850,689 Year 2029: 343,043,667 Year 2030: 345,244,320 Year 2031: 347,452,675 Year 2032: 349,668,759Year 2033: 351,892,600\n\n\n8. 전염병 동태\n전염 역할 모델른 전염병의 전파와 확산을 연구하는 분야로, 이는 질병의 전염 방식과 전파 속도를 이해하고 예측하는 데 중점을 둔다.\n\\(SIRD\\) 모델 상태\n\\(x_{t} = (S,I,R,D),whereS + R + I + D = 1\\)\n\n감염 가능성 Susceptible (S): 현재는 비감염이지만 내일에는 질병에 감염될 수 있는 사람들\n감염 Infected (I): 현재 질병에 감염된 사람들.\n회복 Recovered (R): 질병을 회복하고 면역을 획득한 사람들.\n사망 Deceased (D): 질병으로 사망한 사람들.\n\n약학 모델 동력학\n\\(\\beta\\) : 감염 가능성에서 감염으로 전환될 감염율, \\(\\gamma\\) : 감염에서 회복으로 전화되는 회복율 \\(\\mu\\) : 감염에서 사망으로 전환되는 사망율이라면\n\\[\\begin{matrix}\n& \\frac{dS}{dt} = - \\beta SI,\\frac{dI}{dt} = - \\beta SI - \\gamma I\\mu I \\\\\n& \\frac{dR}{dt} = - \\gamma I,\\frac{dD}{dt} = \\mu I\n\\end{matrix}\\]\n사례연구\n만약 t기의 SIRD 벡터가 \\(x_{t} = (0.99,0.01,0,0)\\)라 하자. 그리고 감염 가능성 있는 인구 중 30%(\\(\\beta = 0.3\\))는 전염되고 전염자의 2%(\\(\\mu = 0.02\\))는 사망하고 회복율은 10%(\\(\\gamma = 0.1)\\)이라 하자. 그러므로 전염 상태로 남아 있는 전염자는 88%이다.\n\\(x_{t + 1} = Ax_{t}\\) 모형에서 \\(A = \\begin{bmatrix}\n0.99 & 0.1 & 0 & 0 \\\\\n0.01 & 0.88 & 0 & 0 \\\\\n0 & 0.1 & 1 & 0 \\\\\n0 & 0.02 & 0 & 1\n\\end{bmatrix}\\)\n# 전염병 동태모델 사례\nimport numpy as np\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\n# 초기 조건\nS0 = 0.99   # 초기 감수성 인구 비율\nI0 = 0.01   # 초기 감염 인구 비율\nR0 = 0.0    # 초기 회복 인구 비율\nD0 = 0.0    # 초기 사망 인구 비율\ninitial_conditions = [S0, I0, R0, D0]\n# 파라미터\nbeta = 0.3   # 전염율\ngamma = 0.1  # 회복율\nmu = 0.02    # 사망율\n# SIRD 모델 미분 방정식\ndef sird_model(y, t, beta, gamma, mu):\n    S, I, R, D = y\n    dS_dt = -beta * S * I\n    dI_dt = beta * S * I - gamma * I - mu * I\n    dR_dt = gamma * I\n    dD_dt = mu * I\n    return [dS_dt, dI_dt, dR_dt, dD_dt]\n# 시간 벡터 (일 단위)\nt = np.linspace(0, 160, 160)\n# ODE 풀기\nsolution = odeint(sird_model, initial_conditions, t, args=(beta, gamma, mu))\nS, I, R, D = solution.T\n# 결과 그래프 출력\nplt.figure(figsize=(10, 6))\nplt.plot(t, S, label='Susceptible')\nplt.plot(t, I, label='Infected')\nplt.plot(t, R, label='Recovered')\nplt.plot(t, D, label='Deceased')\nplt.xlabel('Time (days)')\nplt.ylabel('Proportion of Population')\nplt.legend()\nplt.title('SIRD Model')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nchapter 4. 고유치와 고유벡터\n\n1. 기초\n\n(1) 개념\n고유치는 행렬의 선형변환에서 중요한 특성을 나타내는 값이다. 특정 벡터(고유벡터)가 행렬 \\(A\\)에 의해 변환될 때, 방향은 변하지 않고 크기만 일정 비율로 변한다면, 이 비율을 고유치라고 한다.\n\n\n\n\n\n위 그래프는 행렬 \\(A = \\begin{bmatrix}\n3 & 1 \\\\\n0 & 2\n\\end{bmatrix}\\)의 고유치(\\(\\lambda = 3,2\\))와 고유벡터의 변환을 시각적으로 보여준다.\n\n빨간색 화살표: 첫 번째 고유벡터 \\(\\mathbf{v}_{1}\\)\n투명 빨간색 화살표: 첫 번째 고유벡터가 행렬 \\(A\\)에 의해 변환된 결과로, 고유치 \\(\\lambda_{1} = 3\\)에 의해 크기만 3배로 늘어난다.\n파란색 화살표: 두 번째 고유벡터 \\(\\mathbf{v}_{2}\\).\n투명 파란색 화살표: 두 번째 고유벡터가 행렬 A 에 의해 변환된 결과로, 고유치 \\(\\lambda_{2} = 2\\)에 의해 크기만 2배로 늘어난다.\n\n고유벡터의 방향은 행렬 변환 후에도 유지되며, 크기만 고유치 값에 따라 변한다. 이를 통해 고유치와 고유벡터의 개념을 시각적으로 이해할 수 있다.\n\n\n(2) 통계학 활용\n고유치 분석을 통해 얻을 수 있는 통계적 통찰은 다음과 같다.\n\n데이터의 분산 설명: 공분산 행렬의 고유치는 각 축의 분산 크기를 나타내며, 데이터가 어떤 축에서 더 많은 정보를 가지고 있는지 보여준다.\n중요한 변수 식별: PCA나 LDA에서 고유치를 사용해 데이터를 가장 잘 설명하는 주성분이나 판별 방향을 찾는다.\n데이터의 차원 축소: 가장 큰 고유치를 가진 축만 선택함으로써 데이터의 복잡성을 줄이고, 분석의 효율성을 높는다.\n시각화: MDS, PCA를 활용해 고차원 데이터를 저차원으로 투영하여 시각화할 수 있는다.\n\n주성분 분석(PCA, Principal Component Analysis)\nPCA는 데이터의 고차원 공간을 낮은 차원으로 축소하면서 데이터의 주요 정보를 보존하는 방법이다.\n\n데이터의 공분산 행렬에서 고유치를 계산하여 주성분의 중요도를 평가한다.\n가장 큰 고유치는 데이터의 분산을 가장 많이 설명하는 방향(주성분)을 나타낸다.\n예: 변수 100개로 구성된 데이터를 분석할 때, 고유치를 계산하여 주요한 2~3개의 주성분만 선택해 데이터 차원을 축소할 수 있다.\n\n선형 판별 분석(LDA, Linear Discriminant Analysis)\nLDA는 여러 클래스 간의 분산을 극대화하면서 각 클래스 내의 분산을 최소화하는 투영 방향을 찾는 방법이다.\n클래스 간 분산 행렬과 클래스 내 분산 행렬의 비율로 구성된 행렬의 고유치를 계산하여 최적의 분리 축을 결정한다.\n다차원 척도법(MDS, Multidimensional Scaling)\nMDS는 데이터 간의 거리 행렬을 기반으로 저차원 공간에 데이터를 시각화하는 방법이다.\n\n거리 행렬을 고유치 분해하여 데이터를 저차원 공간에 배치한다.\n가장 큰 고유치를 가진 방향이 데이터 구조의 주요 변화를 설명한다.\n\n공분산 행렬 및 상관 행렬 분석\n공분산 행렬이나 상관 행렬의 고유치는 데이터의 선형 독립성과 분산 구조를 분석하는 데 사용된다.\n\n고유치가 큰 방향은 데이터의 분산이 큰 축(정보가 많이 분포된 축)을 나타낸다.\n고유치가 0에 가까운 경우 변수들 간의 선형 종속성을 암시한다.\n\n행렬 분해 및 차원 축소\n고유치와 고유벡터는 행렬 분해 방법(예: 특이값 분해(SVD), 고유분해(Eigendecomposition))의 핵심이다.\n\n차원 축소, 데이터 압축, 노이즈 제거 등에 사용된다.\n예: 특이값 분해(SVD)는 추천 시스템이나 텍스트 분석(Latent Semantic Analysis, LSA)에서 널리 사용된다.\n\n시계열 데이터 분석 Autoregressive 모델(AR)\n시계열 모델에서 안정성을 분석할 때, 고유치를 통해 시스템의 특성을 평가한다. 예: 고유치가 1보다 크면 시스템이 불안정함을 나타낸다.\n\n\n\n2. 고유치, 고유벡터 구하기\n대칭행렬 \\(A_{n \\times n}\\)에 대하여 고유치 \\(\\lambda\\), 고유벡터 \\(\\underset{¯}{v}\\)는 다음 방정식이 성립한다. \\(A\\underset{¯}{v} = \\lambda\\underset{¯}{v}\\)\n\n(1) 고유치 eigenvalue 구하기\n\\(det(A - \\lambda I) = 0\\)을 만족하는 \\(\\lambda\\)를 고유치라 한다.\n고유치는 행렬 \\(A\\)의 차수만큼 존재한다. \\(\\lambda_{1},\\lambda_{2},...,\\lambda_{n}\\)\n\n\n(2) 고유벡터 eigenvector 구하기\n\\(A\\underset{¯}{v_{i}} = \\lambda_{i}\\underset{¯}{v_{i}}\\) 을 만족하는 벡터(\\(\\underset{¯}{v}\\))를 고유벡터라 한다.\n\\(det(A - \\lambda I) = 0\\)(singlular)가 성립하므로 고유벡터는 무수히 많이 존재한다.\n고유벡터 중 Norm(\\(\\underset{¯}{v}'\\underset{¯}{v} = 1\\))이 1인 고유 벡터를 주성분분석에서 사용한다.\n\n\n\n3. 고유치 활용\n\n(1) 고유치 분해 eigenvalue decomposition\n정방행렬 \\(A_{n \\times n}A\\)의 고유치(\\(\\lambda_{i}\\))를 대각원소로 하는 대각행렬 \\(\\Lambda\\), 고유벡터(\\(\\underset{¯}{v_{i}}\\))로 이루어진 직교 orthogonal 행렬 \\(Q\\)라 하면 행렬 \\(A\\)는 다음과 같이 고유치 분해 된다. \\(A = Q\\Lambda Q^{- 1}\\)\n\n\n(2) 주성분분석\n데이터 행렬 : \\(X_{n \\times p} = \\begin{bmatrix}\nx_{11} & x_{12} & \\cdots & x_{1p} \\\\\nx_{21} & x_{22} & \\cdots & x_{2p} \\\\\n\\cdots & \\cdots & \\cdots & \\cdots \\\\\nx_{n1} & x_{n2} & \\cdots & x_{np}\n\\end{bmatrix}\\) (변수 개수 \\(p\\))\n\n\\(\\underset{¯}{y} = P\\underset{¯}{x}\\) : 원 변수의 선형결합(선형계수 행렬은 고유벡터)으로 주성분변수를 만든다.\n\\(X'X\\) 고유치분해 : \\(X'X = (Q\\Lambda Q^{- 1})'(Q\\Lambda Q^{- 1}) = Q\\Lambda Q^{- 1}\\)\n\\(X\\)의 공분산행렬(측정 단위가 다른 경우 상관계수 행렬)로부터 고유치와 고유벡터(Norm=1인 정규고유벡터)를 구하여 서로 독립인 차원으로 변환한다.\n공분산행렬에 대한 고유치, 고유벡터 : \\(COV_{p \\times p}\\underset{¯}{v} = \\lambda\\underset{¯}{v}\\)\n공분산 행렬은 양의 정부호 행렬이므로 변수의 차수만큼의 고유치, 그에 대응하는 고유벡터가 존재한다.\n고유벡터는 원변수를 직교 축을 갖는 주성분 변수로 변환한다. 그러므로 차수는 줄어들지 않으나 모든 차원에서 관측값은 직교(독립)이다.\n주요 2~3개 차원만으로 \\(p\\)차원의 원변수 변동(정보)를 축약한다. 이를 주성분분석이라 한다.\n\n\n\n\n\n\n\n\n(3) 특이값 분해 Singular Value Decomposition\n\n\n\n\n\n\n직교행렬 \\(U\\)(\\(UU' = I\\)) : \\(AA'\\)의 고유벡터\n직교행렬 \\(V'\\)(\\(V'V = I\\)) : \\(A'A\\)의 고유벡터\n대각행렬 \\(\\Sigma\\)의 대각원소 : \\(AA'\\), \\(A'A\\)의 고유치분해 대각원소의 제곱근 값을 대각원소로 한다.\n\n\n\n(4) Cholesky factorization\n대칭행렬 \\(A\\)가 양의 정부호 행렬일 경우 사용되는 분해방법이다.\n\\(A = LL^{T}\\), \\(L\\) : 대각원소가 양이 하단 삼각행렬\n【활용】 최소제곱추정과 같은 최적해를 구할 때 사용하면 빠른 연산이 가능하다. \\(A\\underset{¯}{x} = \\underset{¯}{b}\\) (연립방정식) \\(\\underset{¯}{x} = A^{- 1}\\underset{¯}{b}\\) ➠ \\(LL^{T}\\underset{¯}{x} = \\underset{¯}{b}\\) 이것을 풀면 연산이 더 간편하다. \\(\\underset{¯}{x} = (LL^{T})^{- 1}\\underset{¯}{b} = (L^{- 1})'L^{- 1}\\underset{¯}{b}\\)\n#고유치, 고유벡터\nimport numpy as np\nA=np.array([[1,2,3], [4,5,7],[8,9,10]])\nimport numpy.linalg as la\nval,vec=la.eig(A)\nval,vec\n【결과】 (array([17.71571559, -1.44163052, -0.27408507]), array([[-0.21078452, -0.49872133, 0.47929184], [-0.52147269, -0.47685414, -0.81047488], [-0.82682291, 0.7238005 , 0.33676373]]))\n#고유벡터 분해\nimport numpy as np\nA=np.array([[1,2,3], \n  [4,5,7],\n  [8,9,10]])\nimport numpy.linalg as la\nval,vec=la.eig(A)\nS=np.diag(val); P=vec\nP@S@la.inv(P)\n【결과】 array([[ 1., 2., 3.], [ 4., 5., 7.], [ 8., 9., 10.]])\n#SVD decomposition\nu, s, vh = np.linalg.svd(A, full_matrices=True)\nu,s,vh\n【결과】 (array([[-0.19462586, -0.6193003 , -0.76064966], [-0.5071685 , -0.6002356 , 0.61846369], [-0.83958376, 0.50614657, -0.19726824]]), array([18.62202941, 1.46779937, 0.25609691]), array([[-0.48007495, -0.56284671, -0.67285334], [ 0.70100172, 0.21497525, -0.67998694], [ 0.52737523, -0.79811604, 0.29135228]]))\n#Cholesky decomposition\nimport numpy as np\nA=np.array([[25,15,-5], \n  [15,18,0],\n  [-5,0,11]])\nimport numpy.linalg as la\nnp.linalg.cholesky(A)\n【결과】 array([[ 5., 0., 0.], [ 3., 3., 0.], [-1., 1., 3.]])\n#확인 LL'\nnp.linalg.cholesky(A)@np.linalg.cholesky(A).T\n【결과】 array([[25., 15., -5.], [15., 18., 0.], [-5., 0., 11.]])\n\n\n\n\nchapter 5. 행렬미분\n\n1. 미분 공식\n\n(1) 벡터미분\n상수벡터 : \\({\\underset{¯}{a}}_{n} = \\left\\lbrack \\begin{array}{r}\na_{1} \\\\\na_{2} \\\\\n... \\\\\na_{n}\n\\end{array} \\right\\rbrack\\) 확률변수 벡터 : \\({\\underset{¯}{x}}_{n} = \\left\\lbrack \\begin{array}{r}\nx_{1} \\\\\nx_{2} \\\\\n... \\\\\nx_{n}\n\\end{array} \\right\\rbrack\\)\n확률변수 \\(x_{i} \\sim (iid)f(x)\\)는 확률표본이다.\n\\(\\frac{\\partial(\\underset{¯}{a}'\\underset{¯}{x})}{\\partial\\underset{¯}{x}} = \\underset{¯}{a}\\), \\(\\frac{\\partial(\\underset{¯}{x}'\\underset{¯}{a})}{\\partial\\underset{¯}{x}} = \\underset{¯}{a}\\)\n\n\n(2) 이차형식 미분\n\\(\\frac{\\partial(\\underset{¯}{x}'A\\underset{¯}{x})}{\\partial\\underset{¯}{x}} = (A + A')\\underset{¯}{x}\\) 만약 A가 대칭행렬이면) \\(2A\\underset{¯}{x}\\)\n\n\n\n2. 이차형식\n\n(1) 이차형식 정의\n정방행렬 : \\(A_{n \\times n} = \\begin{bmatrix}\na_{11} & a_{12} & \\cdots & a_{1n} \\\\\na_{21} & a_{22} & \\cdots & a_{2n} \\\\\n\\cdots & \\cdots & \\cdots & \\cdots \\\\\na_{n1} & a_{n2} & \\cdots & a_{nn}\n\\end{bmatrix}\\)\n이차형식 : \\(Q(x_{1},x_{2},...,x_{n}) = \\underset{¯}{x}'A\\underset{¯}{x}\\)\n\n2차형식의 경우 대칭행렬인 \\(A\\)는 적어도 한 개는 존재한다.\n\n\n\n(2) 이차형식 종류\n대칭행렬 \\(A\\), 이차형식 \\(Q(x_{1},x_{2},...,x_{n}) = \\underset{¯}{x}'A\\underset{¯}{x}\\)에 대하여\n모든 \\(x \\neq 0\\)에 대하여 \\(Q &gt; 0\\)이면 양의 정부호 positive definite\n모든 \\(x \\neq 0\\)에 대하여 \\(Q \\geq 0\\)이면 양의 반부호 positive semidefinite\n\n\n(3) 주축정리 The Principal Axes Theorem\n이차형식 \\(\\underset{¯}{x}'A\\underset{¯}{x}\\)을 교차항이 없는 이차형식 \\(\\underset{¯}{y}'D\\underset{¯}{y}\\)으로 변환하는 직교변환 \\(\\underset{¯}{x} = P\\underset{¯}{y}\\) 존재한다. \\(P\\)를 주축행렬이라 하고 대칭행렬 \\(A\\)의 고유벡터로 이루어져 있다.\n\n교차항이 없는 이차형식은 주축 변량에 대칭이다.\n\n\n\n\n\n\n\n\n(4) 이차형식과 고유치 관계\n\n이차형식 \\(Q = \\underset{¯}{x}'A\\underset{¯}{x}\\)이 양의 정부호이면 모든 고유치는 0보다 크다.\n양의 정부호 행렬의 역행렬도 양의 정부호 행렬이다.\n공분산 행렬은 양의 정부호 행렬이다.\n\n\n\n\n3. 이차형식 만들기\n\\[Q(x) = x_{1}^{2} + 2x_{2}^{2} - 7x_{3}^{2} - 4x_{1}x_{2} + 8x_{1}x_{3}\\]\n\n이차형식으로 만들면 다음과 같다. 제곱항은 그대로 대각원소로 하고 교차항은 1/2로 하여 각 셀에 배분한다.\n\n\\[Q(x) = \\begin{bmatrix}\nx_{1} & x_{2} & x_{3}\n\\end{bmatrix}\\begin{bmatrix}\n1 & - 2 & 4 \\\\\n- 2 & 2 & 0 \\\\\n4 & 0 & - 7\n\\end{bmatrix}\\left\\lbrack \\begin{array}{r}\nx_{1} \\\\\nx_{2} \\\\\nx_{3}\n\\end{array} \\right\\rbrack = \\underset{¯}{x}'A\\underset{¯}{x}\\]\n\n\\(\\underset{¯}{x} = P\\underset{¯}{y}\\), 주축행렬 \\(P\\)는 대칭행렬 \\(A\\)의 고유벡터이다.\n\\(A\\)의 교유치를 대각원소로 하는 행렬 \\(D = diag(\\lambda_{1},\\lambda_{2},\\lambda_{3})\\)를 이용하여 교차항이 없는 이차형식으로 변형한다.\n이렇게 되면 주축 변환된 이차형식의 변수 간에는 교차항이 없으므로 두 변수간에는 서로 독립이 된다.\n\\(Q(x) = \\underset{¯}{x}'A\\underset{¯}{x}\\) ⇢ \\(Q(y) = \\underset{¯}{y}'D\\underset{¯}{y}\\) (\\(\\underset{¯}{x} = P\\underset{¯}{y}\\))\n\n\n\n4. 선형 회귀모형\n\n(1) 데이터 구조\n목표변수 1개, \\(p\\)개 예측변수, 표본크기 n인 데이터를 가정하면 선형 회귀모형은 다음과 같다. \\(\\underset{¯}{y} = X\\underset{¯}{\\beta} + \\underset{¯}{e}\\)\n\\(\\left\\lbrack \\begin{array}{r}\ny_{1} \\\\\ny_{2} \\\\\n\\cdots \\\\\ny_{n}\n\\end{array} \\right\\rbrack\\)=\\(\\begin{bmatrix}\n1 & x_{11} & x_{12} & \\cdots & x_{1p} \\\\\n1 & x_{21} & x_{22} & \\cdots & x_{2p} \\\\\n\\cdots & \\cdots & \\cdots & \\cdots & \\\\\n1 & x_{n1} & x_{n2} & \\cdots & x_{np}\n\\end{bmatrix}\\left\\lbrack \\begin{array}{r}\na \\\\\nb_{1} \\\\\n\\cdots \\\\\nb_{p}\n\\end{array} \\right\\rbrack\\)+\\(\\left\\lbrack \\begin{array}{r}\ne_{1} \\\\\ne_{2} \\\\\n\\cdots \\\\\ne_{n}\n\\end{array} \\right\\rbrack\\)\n\n\n(2) 예측변수 데이터 행렬/벡터\n\\(X_{n \\times p} = \\begin{bmatrix}\nx_{11} & x_{12} & \\cdots & x_{1p} \\\\\nx_{21} & x_{22} & \\cdots & x_{2p} \\\\\n\\cdots & \\cdots & \\cdots & \\cdots \\\\\nx_{n1} & x_{n2} & \\cdots & x_{np}\n\\end{bmatrix}\\), \\(X_{n \\times p} = \\begin{bmatrix}\n{\\underset{¯}{x}}_{1} & {\\underset{¯}{x}}_{2} & \\cdots & {\\underset{¯}{x}}_{p} &\n\\end{bmatrix}\\)\n(데이터 벡터) \\({\\underset{¯}{x}}_{k} = \\left\\lbrack \\begin{array}{r}\nx_{1k} \\\\\nx_{2k} \\\\\n\\cdots \\\\\nx_{nk}\n\\end{array} \\right\\rbrack\\)\n\n\n(3) 확률변수 벡터, 평균벡터, 공분산행렬\n\\(\\underset{¯}{x} = \\left\\lbrack \\begin{array}{r}\nx_{1} \\\\\nx_{2} \\\\\n\\cdots \\\\\nx_{p}\n\\end{array} \\right\\rbrack\\), \\(x_{i}\\)는 확률변수이고 \\(E(x_{i}) = \\mu_{i},V(x_{i}) = \\sigma_{ii}\\),\n(두 변수의 공분산) \\(COV(x_{i},x_{j}) = \\sigma_{ij}\\)\n(평균벡터) \\(E(\\underset{¯}{x}) = \\underset{¯}{\\mu} = \\left\\lbrack \\begin{array}{r}\n\\mu_{1} \\\\\n\\mu_{2} \\\\\n\\cdots \\\\\n\\mu_{p}\n\\end{array} \\right\\rbrack\\)\n(공분산행렬) \\(COV(\\underset{¯}{x}) = \\Sigma = \\begin{bmatrix}\n\\sigma_{11} & \\sigma_{12} & \\cdots & \\sigma_{1p} \\\\\n\\sigma_{21} & \\sigma_{22} & \\cdots & \\sigma_{2p} \\\\\n\\cdots & \\cdots & \\cdots & \\cdots \\\\\n\\sigma_{p1} & \\sigma_{p2} & \\cdots & \\sigma_{pp}\n\\end{bmatrix}\\)\n상수벡터 : \\(\\underset{¯}{a} = \\left\\lbrack \\begin{array}{r}\na_{1},a_{2},\\cdots a_{p}\n\\end{array} \\right\\rbrack\\)\n\\(\\underset{¯}{a}'\\underset{¯}{x}\\)의 평균 : \\(E(\\underset{¯}{a}'\\underset{¯}{x}) = \\underset{¯}{a}'\\underset{¯}{\\mu}\\), 분산 \\(V(\\underset{¯}{a}'\\underset{¯}{x}) = \\underset{¯}{a}'\\underset{¯}{\\Sigma}\\underset{¯}{a}\\)\n\n\n(4) 선형 회귀모형\n\\(\\underset{¯}{y} = X\\underset{¯}{b} + \\underset{¯}{e}\\), \\(\\underset{¯}{e} \\sim N(\\underset{¯}{0},\\sigma^{2}I)\\)\n최소제곱법 추정\n\\[min_{a,b_{1},b_{2},...,b_{p}}\\sum e_{i}^{2} = min_{\\underset{¯}{b}}\\underset{¯}{e}'\\underset{¯}{e}\\]\n\\[Q(\\underset{¯}{b}) = \\underset{¯}{e}'\\underset{¯}{e} = (\\underset{¯}{y} - X\\underset{¯}{b})'(\\underset{¯}{y} - X\\underset{¯}{b}) = \\underset{¯}{y}'\\underset{¯}{y} + \\underset{¯}{b}'X'X\\underset{¯}{b} - 2\\underset{¯}{y}'X\\underset{¯}{b}\\]\n\\(\\frac{\\partial Q}{\\partial\\underset{¯}{b}} = 2X'X\\underset{¯}{b} - 2X'\\underset{¯}{y} = 0\\) ⇢ \\(\\widehat{\\underset{¯}{b}} = (X'X)^{- 1}X'\\underset{¯}{y}\\)\n적합치 fitted values 와 잔차 residuals\n적합치 : \\(\\widehat{\\underset{¯}{y}} = X\\widehat{\\underset{¯}{b}} = X(X'X)^{- 1}X'\\underset{¯}{y} = H\\underset{¯}{y}\\),\n\\(H = X(X'X)^{- 1}X'\\) hat 행렬이라 하고 대칭행렬이고 멱등행렬이다. \\(HH = H,H' = H\\)\n잔차 : \\(\\widehat{\\underset{¯}{e}} = \\underset{¯}{y} - \\widehat{\\underset{¯}{y}} = (I - H)\\underset{¯}{y}\\) \\(H\\)가 멱등행렬이면 \\((I - H)\\)도 멱등행렬이다.\n잔차의 분포 \\(\\widehat{\\underset{¯}{e}} \\sim N(\\underset{¯}{0},\\sigma^{2}I)\\)\n오차의 가정 : \\(\\underset{¯}{e} \\sim N(\\underset{¯}{0},\\sigma^{2}I)\\) ⇢ \\(\\underset{¯}{y} \\sim N(X\\underset{¯}{b},\\sigma^{2}I)\\)\n그러므로 \\(E(\\widehat{\\underset{¯}{e}}) = (I - H)E(\\underset{¯}{y}) = (I - H)(X\\underset{¯}{b}) = (X\\underset{¯}{b} - HX\\underset{¯}{b}) = \\underset{¯}{0}V(\\widehat{\\underset{¯}{e}}) = V((I - H)\\underset{¯}{y}) = (I - H)\\sigma^{2}I(I - H)' = \\sigma^{2}I\\)\n목표변수 분해\n\\(\\underset{¯}{y} = H\\underset{¯}{y} + (I - H)\\underset{¯}{y}\\)=(설명하는 변동) + (설명하지 못하는 변동)\n\n\n\n\n\n높이를 최소화 하는 \\(\\underset{¯}{b}\\)를 구하는 것이 최소제곱추정법이다.\n추정치 분포\n\\(\\widehat{\\underset{¯}{b}} = (X'X)^{- 1}X'\\underset{¯}{y}\\)이고 \\(\\underset{¯}{y} \\sim N(X\\underset{¯}{b},\\sigma^{2}I)\\)이므로\n\\[E(\\widehat{\\underset{¯}{b}}) = (X'X)^{- 1}X'E(\\underset{¯}{y}) = (X'X)^{- 1}X'X\\underset{¯}{b} = \\underset{¯}{b}\\]\n\\[V(\\widehat{\\underset{¯}{b}}) = \\sigma^{2}(X'X)^{- 1}\\]\n\\(\\widehat{\\underset{¯}{b}} \\sim N(\\underset{¯}{b},\\sigma^{2}(X'X)^{- 1})\\), \\({\\widehat{\\sigma}}^{2} = SSE\\)\n변동 분해 ANOVA\n총변동 Total Sum of Squares : \\(SST = \\sum(y_{i} - \\overline{y})^{2}\\)\n\\(SST = \\sum y_{i}^{2} - \\frac{(\\sum y_{i})^{2}}{n} = \\underset{¯}{y}'\\underset{¯}{y} - (\\frac{1}{n})\\underset{¯}{y}'J_{n \\times n}\\underset{¯}{y}\\), \\(J\\)는 1행렬\n\\[SST = \\underset{¯}{y}'(I - (\\frac{1}{n})J)\\underset{¯}{y}\\]\n오차변동 Error Sum of Squares\n\\[SSE = \\sum(y_{i} - \\widehat{y_{i}})^{2}\\]\n\\[SSE = (\\underset{¯}{y} - X\\underset{¯}{b})'(\\underset{¯}{y} - X\\underset{¯}{b}) = \\underset{¯}{y}'\\underset{¯}{y} - \\underset{¯}{b}'X'\\underset{¯}{y} = \\underset{¯}{y}'(I - H)\\underset{¯}{y}\\]\n회귀변동 Regression Sum of Squares\n\\(SSR = \\sum(\\widehat{y_{i}} - \\overline{y})^{2}\\), \\(SSR = \\underset{¯}{y}'(H - (\\frac{1}{n})J)\\underset{¯}{y}\\)\n\\[SSR = SST - SSE = \\underset{¯}{b}X'\\underset{¯}{y} - (\\frac{1}{n})\\underset{¯}{y}'J\\underset{¯}{y}\\]\n결정계수\n\\(R^{2} = \\frac{SSR}{SST} = 1 - \\frac{SSE}{SST}\\) : 모형의 총변동 설명 비중\nSSE, SSR 분포 및 \\(\\sigma^{2}\\) 추정량\n\\(\\underset{¯}{x} \\sim N(\\underset{¯}{\\mu},\\Sigma)\\) 이면 이차형식 \\(\\underset{¯}{x}'A\\underset{¯}{x}\\)의 평균은\n\\(E(\\underset{¯}{x}'A\\underset{¯}{x}) = tr(A\\Sigma) + \\mu'A\\mu\\)이다.\n\\(\\underset{¯}{x} \\sim N(\\underset{¯}{\\mu},\\sigma^{2}I)\\) 이면 이차형식 \\(\\underset{¯}{x}'A\\underset{¯}{x}\\)(\\(A\\) 대칭행렬이고 멱등행렬이면)에 대하여 \\(\\frac{\\underset{¯}{x}'A\\underset{¯}{x}}{\\sigma^{2}} \\sim \\chi^{2}(df = rank(A))\\)이다.\n\\(SSE = \\underset{¯}{y}'(I - H)\\underset{¯}{y}\\), 이차형식이고 \\((I - H)\\)는 멱등행렬\n\\(rank(I - H) = n - p - 1\\)이므로 \\(\\frac{SSE}{\\sigma^{2}} \\sim \\chi^{2}(n - p - 1)\\)이다.\n오차 분산의 추정량: \\(\\widehat{\\sigma^{2}} = MSE\\).\n\\(\\frac{SSR}{\\sigma^{2}} \\sim \\chi^{2}(p)\\), \\(F = \\frac{SSR/p}{SSE/(n - p - 1)} \\sim F(p,n - p - 1)\\)\n분산분석 표\n\n\n\n\n\n\n\n\n\n\n변동\n제곱변동\n자유도\n평균제곱\nF\n\n\n\n\n회귀\n\\[SSR\\]\n\\[p\\]\n\\[MSR = \\frac{SSR}{p}\\]\n\\[\\frac{MSR}{MSE}\\]\n\n\n오차\n\\[SSE\\]\n\\[n - p - 1\\]\n\\[MSE = \\frac{SSE}{n - p - 1}\\]\n\n\n총변동\n\\[SST\\]\n\\[n - 1\\]\n\\[{E(MSE) = \\sigma^{2}\n}{E(MSR) = \\sigma^{2} + b_{1}^{2}\\sum(x_{i} - \\overline{x})^{2}}\\]"
  },
  {
    "objectID": "notes/survey/survey_intro.html",
    "href": "notes/survey/survey_intro.html",
    "title": "조사방법론. 1. 조사방법론 개요",
    "section": "",
    "text": "chapter 1. 개요\n\n1. 조사란?\n조사는 특정 집단, 즉 표본으로부터 정보를 수집하여, 그 집단이 속한 더 큰 모집단의 특성을 수치적으로 설명하고자 하는 체계적인 방법이다. 조사를 통해 얻어진 통계는 특정 요소 집합에 대한 관찰 결과를 요약한 수치적 표현이며, 이는 크게 두 가지 유형으로 구분된다. 이러한 통계는 사회의 다양한 모집단이 가진 특성이나 경험을 이해하고 설명하는 데 중요한 도구로 활용된다.\n첫째, 기술통계는 모집단 내 다양한 특성의 수준과 분포를 설명한다. 예를 들어, 사람들의 평균 교육 연수, 병원에 있는 총 환자 수, 대통령을 지지하는 사람들의 비율 등이 이에 해당한다.\n둘째, 분석통계는 두 개 이상의 변수 간 관계를 측정한다. 예를 들어, 소득 수준과 교육 연수 간의 관계를 설명하는 회귀계수, 혹은 지난 1년 동안 읽은 책의 수와 교육 수준 간의 상관관계 등이 이에 속한다.\n조사는 사회과학에서 사회의 작동 방식이나 행동 이론을 검증하는 데 가장 널리 사용되는 방법 중 하나이며, 다양한 형태로 수행된다. 본 강의에서는 그중 특정 유형의 조사를 중심으로 다룰 예정이며, 정보는 주로 사람들에게 질문을 통해 수집된다.\n정보 수집 방식은 조사자가 직접 질문하고 응답을 기록하거나, 응답자가 스스로 질문을 읽거나 들은 뒤 답을 작성하는 방식으로 이루어진다. 일반적으로 정보는 모집단 전체가 아닌, 기술된 모집단의 일부인 표본으로부터 수집된다.\n조사방법론은 조사 과정에서 발생하는 다양한 오류의 원인을 분석하고, 조사 결과로 얻어진 수치가 가능한 한 정확하게 모집단을 반영하도록 하기 위한 연구 분야이다. 여기서 ’오류’란 원하는 결과에서 벗어난 편차나 이탈을 의미하며, 통계적 오류는 단순한 실수가 아닌, 모집단의 실제 값과 조사로 얻은 추정값 사이의 차이를 설명하기 위해 사용된다.\n\n\n2. 조사목적\n조사는 특정 현상을 이해하고 분석하기 위해 체계적으로 데이터를 수집하고 해석하는 활동으로, 다양한 목적에 따라 설계된다. 조사 과정에서 가장 중요한 두 가지 질문은 “무엇을 발견할 것인가?“와 “가장 효과적인 방법은 무엇인가?“이다. 이러한 질문을 바탕으로, 대부분의 조사는 다음 세 가지 주요 목적을 중심으로 수행된다.\n첫째, 탐구는 관심 있는 집단이나 현상을 보다 깊이 이해하기 위한 예비적 조사로, 잘 알려지지 않은 영역이나 새로운 주제를 다룰 때 활용된다. 이는 조사 설계와 연구 방향 설정의 기초를 마련하며, 예를 들어 새로운 사회적 트렌드나 특정 인구 집단의 행동 패턴을 파악하기 위한 사전 연구가 이에 해당한다. 탐구적 조사는 주로 인터뷰나 포커스 그룹과 같은 정성적 방법을 사용하여 초기 데이터를 수집한다.\n둘째, 서술은 조사 대상 집단의 특성을 수치적 또는 질적 데이터로 기술하는 데 목적을 둔다. 이는 대상 집단의 상태를 명확히 규명하고, 그 결과를 일반화할 수 있는 기반을 제공한다. 예를 들어 실업률, 인구 구조, 산업 동향과 같은 국가 통계나 시장 조사 등이 이에 해당한다. 서술적 조사에서는 데이터의 품질과 일반화 가능성이 핵심이며, 이를 위해 엄격한 표본추출과 신뢰도 검증이 요구된다.\n셋째, 설명은 특정 현상의 원인과 결과를 실증적으로 밝히는 것을 목표로 한다. 이는 변수 간의 관계를 탐구하거나, 특정 행동이나 태도의 원인을 설명하기 위해 설계된다. 예를 들어 “왜 노년층은 보수적인 정치 성향을 보이는가?“와 같은 질문에 답하기 위해 설문조사와 통계 분석을 통해 인과 관계를 추론하는 방식이 이에 해당한다. 설명적 조사는 대체로 정량적 데이터를 바탕으로 가설 검정과 통계 분석을 수행한다.\n조사의 목적을 명확히 하기 위해서는 누구를 대상으로, 어떤 방법으로, 어떤 내용을 조사할 것인지가 분명히 정의되어야 한다. 이를 위해 조사 대상 집단을 규정하고 적절한 표본 프레임을 설정한 뒤, 수집하고자 하는 정보에 기반하여 설문 항목을 신중히 설계해야 한다.\n조사 목적은 연구의 가설 설정과 직결되며, 이 가설을 바탕으로 설문지가 구성된다. 단, 설문조사 결과를 분석한 후에 가설을 설정하거나, 조사의 목적을 설정할 때부터 결론을 미리 정하는 것은 바람직하지 않다. 이러한 방식은 조사 결과를 왜곡시킬 가능성이 있으므로 피해야 한다.\n조사 목적이 분명히 설정된 이후에는 이해관계자 또는 관련 전문가로 구성된 포커스 그룹이나 컨센서스 패널을 통해 설문지를 검토하고 개선할 필요가 있다. 또한, 유사한 주제를 다룬 기존 조사 문헌을 분석함으로써 설문지의 완성도를 높이는 것이 바람직하다.\n\n\n\nchapter 2. 조사에서의 추론과 오류\n조사는 설계 단계에서 출발하여 실행 과정을 거쳐, 궁극적으로 모집단의 통계적 특성을 설명하는 데 목적을 둔다. 조사의 출발점은 응답자가 제시하는 답변이며, 이 답변을 바탕으로 응답자의 개별적인 특성을 추론하게 된다. 이후 이러한 개인 수준의 정보는 통계적 계산을 통해 표본의 특성으로 통합되며, 다시 이를 기반으로 전체 모집단의 특성을 추론하는 과정으로 이어진다.\n즉, 조사는 응답자의 답변에서 시작하여 개인의 특성을 도출하고, 이를 표본 수준으로 확장한 뒤, 다시 모집단 수준으로 일반화하는 일련의 추론 과정을 포함한다. 이 과정에서 두 가지 핵심 조건이 충족되어야 한다.\n첫째, 응답자가 제공한 답변이 실제로 그 사람의 특성을 정확하게 반영해야 한다.\n둘째, 조사에 참여한 표본이 모집단 전체의 특성을 대표할 수 있어야 한다.\n이 두 조건 중 하나라도 충족되지 않으면 오류가 발생할 수 있다. 여기서 말하는 오류는 단순한 실수가 아니라, 의도한 결과와 실제 결과 사이의 편차를 의미한다. 예를 들어, 측정 오류는 질문에 대한 응답이 실제 측정하고자 하는 속성과 일치하지 않을 때 발생하며, 비관찰 오류는 표본으로부터 추정한 통계량이 모집단의 실제 값과 차이를 보일 때 나타난다.\n조사방법론은 이러한 오류를 체계적으로 분류하고 분석하며, 오류를 최소화하기 위해 조사 설계, 표본추출, 자료 수집 등 모든 단계에서 신중한 계획이 요구된다.\n\n1. 조사 주기(조사 설계 관점)\n조사를 바라보는 데에는 두 가지 주요 관점이 있다. 하나는 설계 관점이며, 다른 하나는 품질 관점이다. 설계 관점에서는 조사 설계를 추상적인 아이디어를 구체적인 실행 단계로 전환하는 과정으로 이해한다. 반면, 품질 관점에서는 조사 설계가 조사 통계에 영향을 미치는 다양한 오류의 근원으로 작용할 수 있음을 강조한다.\n조사는 설계 단계에서 출발하여 실행 단계로 이어진다. 적절한 설계 없이는 신뢰할 수 있는 조사 결과를 얻기 어렵다. 설계에서 실행으로 초점이 이동함에 따라 조사 작업은 추상적인 구상에서 실제적인 실행으로 전환된다. 이후 조사 결과를 해석하고 모집단에 대한 추론을 수행하는 과정에서는 다시 추상적인 수준의 사고가 요구된다.\n조사의 핵심은 측정 차원과 표현 차원이라는 두 가지 틀을 통해 설명할 수 있다. 측정 차원은 표본 내 관찰 단위에서 수집되는 데이터, 즉 “무엇에 관한 조사인가?“에 해당하며, 표현 차원은 조사에서 다루는 모집단, 즉 “누구에 관한 조사인가?“에 초점을 둔다.\n\n측정 과정\n조사의 측정 과정은 먼저 조사에서 측정하고자 하는 개념이나 구성 요소를 정의하는 것으로 시작된다. 이를 바탕으로 구체적인 측정 도구와 질문이 설계되고, 응답자는 이에 대한 답변을 제공한다. 수집된 응답은 검토 및 편집 과정을 통해 오류나 불일치가 수정되며, 정제된 데이터를 기반으로 통계가 산출된다.\n\n\n표현 과정\n표현 과정은 조사 대상이 되는 모집단을 명확히 정의하는 것으로 시작된다. 이후, 해당 모집단의 특정 부분을 대상으로 하는 표본 프레임이 설정되고, 이로부터 표본이 추출된다. 표본으로 선정된 응답자가 실제로 조사에 참여하게 되며, 조사 이후에는 필요에 따라 보정 작업이 이루어진다. 이렇게 수집된 자료는 전체 모집단을 대표하는 통계로 일반화된다.\n\n\n\n(1) 구성 요소 constructs\n구성 요소는 연구자가 조사에서 얻고자 하는 정보의 내용을 의미한다. 예를 들어, 고용 통계 조사는 특정 월의 근로자 수나 일자리 개수를 측정하고자 하며, 교육 성취도 평가는 학생들의 지식을 평가하는 데 목적이 있다. 전국 범죄 피해 조사는 지난 1년 동안 발생한 범죄 피해 사건의 수를 파악하려는 조사이다. 이처럼 구성 요소는 조사 목적에 따라 다양하지만, 종종 추상적이며 정확하게 측정하기 어려운 특성을 지닌다.\n예를 들어, 범죄 피해자의 정체성을 명확히 정의하는 것은 경우에 따라 모호할 수 있다. 공공장소에 낙서가 그려진 경우, 피해자를 누구로 간주할 수 있는가? 특정 수준의 범죄가 실제로 처벌의 대상이 되는 기준은 어디에 있는가? 이러한 질문들은 단순한 서술 수준의 개념을 실제 측정 가능한 항목으로 전환하는 과정에서 발생한다.\n구성 요소의 추상성은 주제에 따라 달라질 수 있다. 예를 들어, 소비자 신뢰도 조사는 개인의 재정 상태에 대한 단기적인 낙관적 태도를 측정하는데, 이는 매우 주관적이며 사람마다 인식의 차이가 크다. 반면, 전국 약물 사용 및 건강 조사는 지난달의 맥주 소비량처럼 비교적 구체적이고 관찰 가능한 행동을 측정한다. 이 경우에는 맥주로 간주되는 음료의 범위를 어떻게 정의할 것인지와 같은 실질적인 문제를 해결하는 것이 중요하다. 이처럼 소비자 신뢰도는 맥주 소비량에 비해 훨씬 더 추상적인 구성 요소라 할 수 있다.\n\n\n(2) 측정 measurement\n측정은 구성 요소보다 한층 더 구체적인 개념이다. 조사에서 ’측정’은 특정 구성 요소에 대한 정보를 수집하는 방법을 의미한다. 조사의 측정 방식은 매우 다양하며, 조사 주제에 따라 물리적 측정, 행동 관찰, 또는 질문을 통한 정보 수집 등 여러 형태로 나타난다.\n예를 들어, 유독물질 오염에 관한 조사에서는 표본 가구의 마당에서 흙 샘플을 채취할 수 있고, 건강 조사에서는 혈압을 측정할 수 있으며, 교통 조사에서는 센서를 활용해 차량 흐름을 전자적으로 기록할 수 있다. 한편, 많은 조사는 응답자에게 질문을 던져 그들의 인식이나 행동에 대한 정보를 수집하는 방식으로 이루어진다. 예를 들어, “지난 6개월 동안 본인이 범죄라고 생각한 사건과 관련해 경찰에 신고한 적이 있습니까?“와 같은 질문이 포함될 수 있다.\n측정 과정에서 가장 중요한 과제는 측정하고자 하는 구성 요소를 충실히 반영할 수 있는 질문을 설계하는 것이다. 질문이 부정확하거나 모호할 경우, 수집된 정보는 실제 구성 요소를 제대로 대변하지 못할 수 있다.\n이러한 질문은 전화 인터뷰나 대면 조사 방식으로 제시될 수 있으며, 종이 설문지나 컴퓨터를 이용한 자가 응답 방식으로도 제공될 수 있다. 경우에 따라서는 조사자가 직접 관찰을 통해 정보를 수집해야 하는 상황도 있다.\n\n\n(3) 응답 response\n조사에서 생성된 데이터는 조사 측정을 통해 수집된 정보에서 비롯되며, 응답의 성격은 사용된 측정 방법에 따라 달라진다. 질문이 측정 도구로 사용되는 경우, 응답자는 기억을 되살리거나 주관적 판단을 통해 답을 생성하거나, 기록을 참고하거나, 때로는 타인의 도움을 받아 응답할 수 있다.\n예를 들어, 소비자 신뢰도 조사에서는 “앞으로 1년 후 본인과 가족의 경제적 상황이 더 나아질 것 같은지, 더 나빠질 것 같은지, 아니면 비슷할 것 같은지”와 같은 질문이 제시된다. 반면, 고용 통계 조사에서는 고용주가 직원 기록을 확인하여 특정 주간의 비관리직 직원 수를 보고하는 방식으로 이루어진다.\n측정 방식에 따라 응답 형식도 달라진다. 어떤 경우에는 선택지가 제공되어 응답자가 해당 범주 중 하나를 선택하면 되며, 다른 경우에는 질문만 주어지고 응답자가 자신의 언어로 자유롭게 답을 작성해야 하는 경우도 있다.\n\n\n(4) 편집된 응답 edited response\n일부 데이터 수집 방식에서는 초기 측정 데이터를 다음 단계로 넘기기 전에 사전 검토 과정을 거친다. 컴퓨터를 이용한 조사에서는 정량적 응답에 대해 범위 검사를 수행하여, 허용된 한계를 벗어난 답변을 자동으로 감지하고, 후속 질문을 통해 응답의 정확성을 확인한다. 예를 들어, 출생 연도를 묻는 질문에 1890년 이전의 숫자가 입력되었거나, 한 응답자가 자신의 나이를 14세라고 답하면서 동시에 다섯 명의 자녀가 있다고 응답한 경우, 이러한 불일치를 확인하고 수정을 유도하는 후속 질문이 제시된다.\n종이 설문지의 경우에는 조사자가 설문지를 수기로 검토하여, 읽기 어려운 답변이나 누락된 항목을 찾아 보완하는 작업이 이루어진다. 이는 현장 조사자가 수행하는 1차적인 오류 점검 단계라 할 수 있다.\n모든 응답자의 답변이 수집된 이후에도 데이터에 대한 추가적인 편집 과정이 진행될 수 있다. 이 과정에서는 전체 응답 분포를 검토하고, 비정상적인 응답 패턴이나 불일치 사례를 탐지하여 이상치를 식별한다. 경우에 따라 특정 설문지나 응답자의 응답을 보다 면밀히 검토해야 할 수도 있다.\n이러한 데이터의 검토와 편집 과정은 조사 결과의 신뢰성과 정확성을 확보하기 위한 핵심적인 절차로 간주된다.\n\n\n(5) 조사 대상 모집단 target population\n조사 대상 모집단은 조사의 대상이 되는 단위들의 집합을 의미한다. 예를 들어, 가구 조사의 경우 성인을 조사 대상 모집단으로 정의할 수 있다. 그러나 이와 같은 정의는 몇 가지 세부 사항이 명확히 설정되지 않으면 해석의 여지를 남기게 된다. 조사 시점을 특정하지 않거나, 전통적인 가구 형태에 속하지 않는 사람들(예: 노숙인, 시설 거주자 등)을 포함할지 여부를 명시하지 않는다면 모집단의 범위는 모호해질 수 있다. 또한, 최근 성인이 된 사람들을 포함할 것인지, 국내 거주 상태를 어떤 기준으로 판단할 것인지 등이 명확히 정의되지 않으면, 모집단의 일관성과 재현 가능성에 문제가 발생할 수 있다.\n조사 대상 모집단은 일반적으로 유한한 규모의 개인들로 구성되며, 이들은 조사의 분석 대상이 된다. 예를 들어, 경제활동인구조사는 만 15세 이상이면서 현재 군 복무를 하지 않고, 병원·교도소·기숙사와 같은 시설이 아닌 일반 주거지에 거주하는 사람들을 모집단으로 정의한다. 모집단의 시간적 범위는 보통 특정 월이나 주로 고정되며, 이 시점에 표본으로 선정된 사람이 해당 거주지에 실제로 거주하고 있어야 한다.\n\n\n(6) 표본 프레임 모집단 frame population\n표본 프레임 모집단은 조사 표본에 선택될 가능성이 있는 대상 모집단의 구성원 집합을 의미한다. 단순한 경우에는 표본 프레임이 대상 모집단의 모든 단위(예: 개인, 고용주 등) 목록으로 구성된다. 그러나 현실에서는 표본 프레임이 대상 모집단과 완전히 일치하지 않거나, 일부 단위만을 포함하는 경우도 많다.\n예를 들어, 소비자 신뢰도 조사의 대상 모집단은 성인 가구이며, 이때 전화번호 목록이 표본 프레임으로 사용될 수 있다. 이는 각 사람을 자신이 속한 가구의 전화번호와 연결할 수 있다는 전제에 기반한다. 그러나 실제로는 전화가 없는 가구도 존재하며, 하나의 가구가 여러 개의 전화번호를 보유하고 있는 경우도 있어, 이러한 전제가 항상 성립하지 않으며 표본 프레임의 복잡성이 발생할 수 있다.\n건강 조사의 경우, 행정구역별 거주지 목록이 표본 프레임으로 활용된다. 이 목록은 각 주택 단위를 특정 시군구와 연결시키며, 일반적으로 15세 이상의 성인이 거주하는 주택을 조사 대상으로 설정한다. 그러나 고정된 거주지가 없는 사람, 혹은 복수의 거주지를 가진 사람과 같이 표본 프레임에서 다루기 어려운 사례도 존재한다.\n\n\n(7) 표본 sample\n표본은 표본프레임에서 선택된다. 이 표본은 측정을 통해 데이터를 수집할 대상 그룹이다. 표본은 표본 프레임의 매우 작은 부분만을 차지한다.\n\n\n(8) 응답자 respondents\n대부분의 조사에서는 선택된 표본 사례를 모두 성공적으로 측정하기 어렵다. 조사에 성공적으로 응답한 사례는 ‘응답자’로 분류되며, 반대로 전혀 응답하지 않은 사례는 ‘무응답자’ 또는 ’단위 무응답’으로 간주된다.\n그러나 어떤 사례를 응답자로 분류할지, 무응답자로 간주할지를 판단하는 일은 종종 명확하지 않다. 일부 응답자는 조사에서 요구되는 정보 중 일부만을 제공하는 경우가 있으며, 이 경우 응답 상태의 구분이 애매해질 수 있다. 이러한 사례에 대해 데이터를 구축할 때는, 불완전한 응답을 포함할지 아니면 해당 응답자를 분석 파일에서 제외할지를 결정해야 한다.\n한편, ‘항목 결측’ 또는 ’항목 무응답’이라는 용어는 응답자가 전체적으로는 조사에 참여했지만, 특정 질문에 대한 응답이 누락된 경우를 지칭한다. 즉, 단위 무응답이 전체 사례에 대한 응답 실패를 의미한다면, 항목 무응답은 일부 질문에 대한 응답 누락을 의미한다.\n\n\n(9) 조사 후 조정 (Postsurvey Adjustments)\n모든 응답자가 데이터를 제공하고 해당 데이터 기록이 완성된 이후에도, 조사로부터 도출된 추정치의 품질을 향상시키기 위해 추가적인 절차가 진행되는 경우가 많다. 이는 무응답 문제나, 표본 프레임과 실제 대상 모집단 간의 불일치와 같은 커버리지 문제로 인해, 응답자 기반 통계가 전체 모집단의 통계와 차이를 보일 수 있기 때문이다.\n이러한 차이를 이해하기 위해, 조사 단계에서는 서로 다른 하위 집단에 대한 단위 무응답 패턴을 분석한다. 예를 들어, 도시 지역의 응답률이 농촌 지역보다 낮은 경우, 도시 거주자가 표본에서 과소 대표되고 있을 가능성을 시사한다. 이와 유사하게, 표본 프레임 자체에 포함되지 않은 단위 유형에 대한 정보를 분석하면, 모집단 내 특정 유형이 아예 조사 대상에서 누락되었음을 확인할 수 있다.\n이후 과정에서, 과소 대표된 집단의 영향을 보정하기 위해 가중치를 조정함으로써 전체 추정치를 개선할 수 있다. 또한, 응답하지 않은 항목은 ’결측 대체(imputation)’라 불리는 절차를 통해 추정된 값으로 대체할 수 있다.\n이러한 가중 조정과 결측 대체 방법은 다양하게 존재하며, 모두 조사 후 조정(post-survey adjustment)에 해당하는 절차로 분류된다.\n\n\n2. 조사 주기(조사 품질 관점)\n조사 방법론에서 흔히 사용하는 품질 개념을 추가적으로 표시한 타원형을 볼 수 있다. 이 개념들은 조사 과정의 연속적인 단계 사이에서 발생하는 불일치를 나타내며, 대부분 \"오류\" 라는 단어를 포함하고 있다. 조사 설계자의 역할은 설계 및 추정 선택을 통해 이러한 오류를 최소화하여 조사 통계의 품질을 높이는 것이다.\n\n\n\n\n\n\n\\(\\mu_{i}\\): 모집단에서 \\(i\\) 번째 사람의 참 값\n\\(Y_{i}\\): \\(i\\) 번째 표본 사람의 측정값\n\\(y_{i}\\): \\(i\\) 번째 표본 측정 응답값(조사 질문에 대한 응답)\n\\(y_{ip}\\): 편집 및 추가 처리 과정을 거친 \\(i\\) 번째 표본 데이터값\n\n결론적으로, 측정하려는 기본 목표 속성은 \\(\\mu_{i}\\)이지만, 실제로는 측정 오류로 인해 목표에서 벗어난 불완전한 지표 \\(y_{ip}\\)를 사용한다.\n\n\n(1) 타당성 validity\n구성 요소의 타당성 validity은 측정값이 근본적인 구성 요소와 관련된 정도를 나타낸다. 반면, 타당하지 않음은 타당성이 달성되지 않은 정도를 설명하는 데 사용되는 용어다. 통계적으로, 타당성의 개념은 개별 응답자 수준에서 적용된다. 이는 구성 요소가 관찰되지 않거나 쉽게 관찰될 수 없는 경우에도, 모집단에서 \\(i\\) 번째 사람과 관련된 일부 값을 가지며, 이는 전통적으로 \\(\\mu_{i}\\)(구성 요소의 참값)로 표시된다. 특정 측정값 \\(Y_{i}\\)의 결과는 \\(\\mu_{i}\\)가 아닌 \\(Y_{i} = \\mu_{i} + \\varepsilon_{i}\\)가 된다.\n이 식에서 \\(\\varepsilon_{i}\\)는 진짜 값에서의 편차를 나타내며, 타당성 개념의 기초를 형성한다. 또한, 측정 타당성을 이해하려면 한 번의 측정이 아닌 여러 번의 반복적인 측정을 고려해야 한다. 같은 측정이 \\(i\\) 번째 사람에게 여러 번 적용될 경우 각 결과는 달라질 수 있으며, 이를 고려해 식이 \\(Y_{it} = \\mu_{i} + \\varepsilon_{it}\\)로 확장된다. 여기서 \\(t\\)는 측정 시도의 번호를 나타낸다. 결국, 타당성은 측정값과 참값 간의 상관 관계로 정의된다. 이는 측정값 \\(Y\\)와 구성 요소 \\(\\mu\\)간의 관계가 높을수록 타당성이 높은 것으로 간주된다.\n\n\n(2) 측정 오류 measurement error\n측정 오류는 측정값이 실제 값, 즉 참값에서 벗어나는 현상을 의미한다. 예를 들어, 국민건강조사에서 “코카인을 한 번이라도 사용한 적이 있습니까?“라는 질문이 있다고 가정해보자. 연구에 따르면, 응답자가 부정적으로 인식하는 행동에 대해서는 과소 보고하는 경향이 있다. 따라서 실제로는 “예”라고 응답해야 하는 사람이 자신의 약물 사용 사실이 드러나는 것을 우려해 “아니요”라고 응답할 수 있다. 이처럼 특정 질문에 대한 응답이 반복적으로 왜곡된다면, 응답값의 평균과 모집단의 실제 평균 사이에 차이가 발생하게 된다.\n통계적으로는 특정 응답자 i에 대해, 측정값과 참값 사이의 체계적 편차를 \\((y_₁ - Y_₁)\\) 로 나타낼 수 있다. 이러한 차이가 일정한 방향으로 발생하면 이를 응답 편향이라고 한다. 예를 들어, 응답자가 자신의 약물 사용이나 범죄 피해 경험을 일관되게 과소 보고하는 경우가 이에 해당한다. 이 편향은 조사 결과가 실제보다 낮거나 높게 나타나는 경향을 유발한다.\n한편, 응답 행동의 불안정성은 또 다른 유형의 오류를 야기할 수 있다. 예를 들어, “현재 사업 환경이 1년 전보다 나아졌습니까, 아니면 나빠졌습니까?“와 같은 질문에 대해 응답자는 질문의 내용뿐 아니라 앞선 질문의 맥락이나 측정 환경의 자극 등 다양한 요소에 영향을 받아 응답할 수 있다. 이러한 자극은 예측하기 어려우며, 동일한 질문을 여러 차례 반복해도 응답이 일관되지 않을 수 있다. 다시 말해, 기대값 \\(E(y_i)\\) 가 참값 \\(Y_\\) 와 일치하지 않을 수 있다.\n응답 분산은 동일한 사람에게 동일한 질문을 여러 번 했을 때 매번 다른 응답이 나타나는 현상을 의미한다. 이는 응답 편향과 구별되며, 보통 신뢰도가 낮은 측정에서 발생한다. 설문 조사에서는 이러한 응답 분산이 추정값의 불안정성을 높이는 주요 원인 중 하나로 간주된다.\n\n\n(3) 처리 오류 processing error\n데이터가 수집된 이후, 추정 단계에 들어가기 전까지 발생할 수 있는 오류에는 여러 가지가 있다. 대표적인 예로 편집 오류와 코딩 오류가 있다.\n편집 단계에서는 응답값의 신뢰성과 일관성을 검토하면서, 명백히 이상해 보이는 값을 누락 처리하거나 수정할 수 있다. 예를 들어, 한 응답자가 “매일 여러 차례 폭행을 당했다”고 보고한 경우, 이는 직관적으로 믿기 어려운 보고로 간주되어 자동 편집 규칙에 따라 결측 처리될 수 있다. 그러나 만약 해당 응답자가 술집의 보안요원이라는 추가 정보가 제공된다면, 응답 내용이 실제 상황을 반영하고 있을 가능성이 높아진다. 이처럼 측정하려는 구성 요소의 맥락에 따라 응답을 수정하거나 유지할지 여부를 판단하는 과정에서 처리 오류가 발생할 수 있다.\n또한, 코딩 단계에서도 오류가 발생할 수 있다. 텍스트 응답을 분류할 때, 동일한 응답이라 하더라도 코딩하는 사람에 따라 다르게 해석될 수 있다. 이러한 차이는 결과의 변동성을 유발하며, 코딩 시스템의 구조나 코더 간 일관성 부족에서 기인한다. 이를 흔히 코딩 분산이라 부른다. 특히 훈련이 부족한 코더는 모호한 언어나 응답자의 설명을 일관되게 해석하지 못해 잘못된 범주로 분류할 수 있으며, 이는 코딩 편향을 초래하게 된다.\n결국, 편집과 코딩 단계 모두에서 발생하는 오류는 측정 이후 데이터 품질에 영향을 미치며, 추정 단계에서의 통계적 결과에도 왜곡을 가져올 수 있다.\n통계적 표기법으로 표현하면, 예를 들어 소득과 같은 변수를 고려할 때, 처리 효과는 제공된 응답과 편집된 응답 간의 차이로 정의될 수 있다. \\(y_{i}\\)는 조사 질문에 대한 응답을, \\(y_{ip}\\)는 편집된 응답을 나타낸다. 따라서, 처리 편차는 \\((y_{ip} - y_{i})\\)로 나타낼 수 있다.\n\n\n(4) 포함오류 coverage error\n포함 오류는 모집단과 표본 프레임 간의 차이에서 발생한다. 예를 들어, 표본 프레임이 모집단의 일부를 포함하지 못한 경우를 포함 부족(undercoverage)이라고 하며, 반대로 표본 프레임에 모집단에 속하지 않는 요소가 포함된 경우는 과잉 포함(overcoverage)이라고 한다.\n통계적으로 볼 때, 표본 평균에서 발생하는 포함 편향은 두 가지 요소에 의해 결정된다. 첫째는 표본 프레임에 포함되지 않은 모집단 구성원의 비율이고, 둘째는 프레임에 포함된 구성원과 포함되지 않은 구성원 간의 특성 차이이다. 즉, 포함되지 않은 비율이 높고, 포함된 구성원과 포함되지 않은 구성원 간에 측정하고자 하는 변수의 평균 차이가 클수록 포함 편향은 커지게 된다.\n\\({\\overline{Y}}_{C} - \\overline{Y} = \\frac{U}{N}({\\overline{Y}}_{C} - {\\overline{Y}}_{U})\\), 여기서 \\(\\overline{Y}\\)는 목표 모집단 전체의 평균, \\({\\overline{Y}}_{C}\\)는 표본 프레임에 포함된 모집단의 평균, \\({\\overline{Y}}_{U}\\)는 표본 프레임 밖 모집단의 평균을 나타낸다. \\(N\\)은 목표 모집단의 총 구성원 수, \\(C\\)는 표본 프레임에 포함된 적격 구성원의 총수, 그리고 \\(U\\)는 표본 프레임에 포함되지 않은 적격 구성원의 총수이다.\n예를 들어, 전화 조사를 통해 가구의 평균 교육 연수를 측정한다고 가정하자. 전화가 없는 가구는 표본에서 제외되므로 이들의 평균 교육 연수는 낮아질 가능성이 있다. 전화가 있는 가구의 평균 교육 연수가 14.3년이고, 전화가 없는 가구의 평균 교육 연수가 11.2년이라면, 전체 모집단 평균에 대한 편향은 다음과 같이 계산될 수 있다(단, 전화 없는 가구 비율을 5%라 가정하자).\n\\({\\overline{Y}}_{C} - \\overline{Y} = 0.05(14.3 - 11.2) = 0.16\\text{년}\\).\n즉, 전화가 없는 가구를 포함하지 않은 표본 프레임은 모집단 평균보다 약 0.16년 더 높은 평균 교육 연수를 보여줄 것이다. 결론적으로, 표본 프레임의 포괄 오류는 표본 평균 추정값에 영향을 미치며, 이는 모집단 평균이 아닌 표본 프레임 평균을 반영하게 된다.\n\n\n(5) 표본 오류 sampling err0r\n표본 설문조사에서는 비용과 시간의 제약으로 인해, 표본 프레임 내 모든 구성원을 조사하는 것이 현실적으로 어렵다. 따라서 전체 중 일부만을 선택하여 조사하고, 나머지는 제외하는 방식이 일반적으로 채택된다. 이러한 선택적 측정으로 인해 발생하는 통계적 차이를 표본 오류라고 한다.\n표본 오류는 크게 두 가지 유형으로 구분된다. - 표본 편향(sampling bias)은 표본 프레임의 일부 구성원이 표본으로 선택될 기회를 갖지 못하거나, 선택될 가능성이 상대적으로 낮을 때 발생한다. 예를 들어, 특정 표본 설계가 체계적으로 일부 그룹을 항상 제외하도록 구성되어 있다면, 그 결과로 도출된 통계치는 실제 프레임 모집단의 통계와 차이를 보일 수 있다. - 표본 분산(sampling variance)은 동일한 방법으로 표본을 반복 추출할 경우, 각 표본이 서로 다른 응답을 포함하게 되어 조사 통계가 반복마다 달라질 수 있는 현상을 의미한다. 이는 표본 선택이 확률적일 때 자연스럽게 발생하는 오차로, 표본의 수나 분포에 따라 크기가 달라질 수 있다. 표본 선택의 여러 가능성을 개념적으로 반복한 결과, 표본 분산의 개념이 만들어진다. 표본 분산은 동일한 설계에서 얻어진 여러 표본 평균이 얼마나 변동하는지를 나타낸다.\n\n\\({\\overline{Y}}_{s}\\): 특정 표본 추출의 표본 평균, 표본 \\(s;s = 1,2,\\ldots,S\\)\n\\({\\overline{Y}}_{C}\\): 표본 프레임에서의 모든 요소의 총평균\n\\(\\overline{Y}_s = \\frac{\\sum_{i=1}^{n_s} y_{si}}{n_s},\\ \\overline{Y}_C = \\frac{\\sum_{i=1}^{C} Y_i}{C}\\)\n표본 분산: \\(\\frac{\\sum_{s = 1}^{S}({\\overline{Y}}_{s} - {\\overline{Y}}_{C})^{2}}{S}\\)\n\n\n\n(6) 응답률 오류 nonresponse error\n모든 표본 구성원을 설문조사에서 완전히 측정하는 것은 현실적으로 어렵다. 특히 사람을 대상으로 하는 조사에서는 이러한 상황이 자주 발생한다. 이로 인해 발생하는 오류를 응답률 오류라고 하며, 이는 실제 응답한 사람들의 통계 값이 전체 표본을 기준으로 했을 때의 통계 값과 다를 때 나타난다.\n예를 들어, 수행평가 당일 결석한 학생들이 수학적 또는 언어적 능력이 낮은 경향이 있다면, 이들이 측정에서 제외됨으로써 전체 수행평가 점수가 과대평가될 수 있다. 즉, 응답자의 평균 점수가 전체 표본의 진정한 평균보다 체계적으로 높아지는 결과가 나타난다. 이러한 오류는 응답률이 낮을수록 그 영향이 커지며, 조사 결과의 왜곡 가능성도 더욱 심각해질 수 있다.\n응답률 편향: \\({\\overline{y}}_{r} - {\\overline{y}}_{s} = \\frac{m_{s}}{n_{s}}({\\overline{y}}_{r} - {\\overline{y}}_{m})\\)\n\n\\({\\overline{y}}_{s}\\): 선택된 특정 표본의 전체 평균,\n\\({\\overline{y}}_{r}\\): 𝑠번째 표본의 응답자 평균, \\({\\overline{y}}_{m}\\): 𝑠번째 표본의 비응답자 평균\n\n𝑛𝑠: 𝑠번째 표본의 총 구성원 수, 𝑟𝑠: 𝑠번째 표본의 응답자 수, 𝑚𝑠: 𝑠번째 표본의 비응답자 수\n따라서 표본 평균에 대한 응답률 편향은 응답률(데이터가 수집되지 않은 표본 구성원의 비율)과 응답자와 비응답자 평균 간의 차이의 곱으로 나타난다. 이는 높은 응답률만으로는 반드시 품질 지표가 아님을 나타낸다. 응답률이 높은 설문조사에서도 비응답자가 조사 변수에서 매우 독특할 경우, 높은 응답률 편향이 나타날 수 있다. 이 문제를 방지하는 가장 좋은 방법은 높은 응답률을 유지하여 응답률 편향의 위험을 줄이는 것이다.\n\n\n(7) 보정 오류 adjustment error\n조사에서 발생하는 비관측 오류를 줄이기 위한 마지막 단계는 조사 후 보정이다. 이 보정은 표본 추정치를 개선하기 위해 시행되며, 포함 오류, 표본 오류, 무응답 오류와 같은 오류를 줄이는 것을 목표로 하며, 보정 과정은 개별 응답에 대한 수정 단계와 유사한 역할을 한다.\n보정은 대상 모집단 또는 표본 프레임에 대한 정보와 응답률 데이터를 활용하여 과소 대표된 표본 사례에 더 큰 가중치를 부여함으로써 데이터의 균형을 맞춘다. 예를 들어, A지역의 응답률이 85%인 경우 해당 지역 응답자에게 \\(w_{i} = 1/0.85\\)의 가중치를 부여하여 특정 응답자의 영향을 평균 계산에서 확대한다.\n조정된 평균은 이러한 가중치를 적용해 계산되며, 조정된 표본 평균(\\(\\overline{y}nw = \\frac{\\sum_{i = 1}^{r}w_{i}y_{si}}{\\sum_{i = 1}^{r}w_{i}}\\))과 모집단 평균과 간의 차이는 \\(({\\overline{y}}_{nw} - \\overline{Y})\\) 로 나타난다. 이러한 보정은 통계적 편향을 줄이는 데 기여하지만, 경우에 따라 오류를 오히려 증가시킬 수도 있으므로 설계와 실행 단계에서 세심한 주의가 필요하다.\n\n\n\nchapter 3. 목표모집단, 표본프레임, 포함오류\n표본 설문조사는 명확히 정의된 모집단을 설명하거나, 그로부터 통계적 추론을 도출하는 과정이다. 이때 모집단을 구성하는 기본 단위는 ‘요소’ 또는 ’조사단위’로 불리며, 이 요소들이 전체 모집단을 형성한다. 예를 들어, 가구 조사의 경우 요소는 개별 가구원일 수 있으며, 학교 조사의 경우에는 학생이, 비즈니스 조사의 경우에는 사업체나 시설이 요소가 된다. 하나의 설문조사 내에서도 다양한 유형의 요소가 존재할 수 있다. 가구 조사의 경우, 조사 대상은 사람일 수도 있지만, 주거 단위나 거주 커뮤니티 등과 같은 더 넓은 단위로 확장될 수도 있다.\n설문조사에서 모집단 정의는 조사 설계와 결과 해석의 출발점이자 핵심이다. 모집단을 어떻게 정의하느냐에 따라 데이터의 대표성과 신뢰성이 결정되며, 이는 추론의 정확도와 직결된다. 다음은 설문조사에서 모집단 정의가 중요한 이유를 설명하는 네 가지 측면이다.\n\n설문의 주요 목적\n설문조사의 핵심 목적은 특정 모집단의 특성을 통계적으로 설명하거나, 그 모집단에 대해 일반화된 결론을 도출하는 것이다. 모집단이 명확히 정의되지 않으면, 조사 결과의 정확성과 대표성이 저하될 수 있다. 모집단 정의는 조사 결과가 어떤 집단을 설명하고 있는지를 분명히 밝히는 역할을 한다.\n\n\n조사의 설계 및 표본 추출\n설문조사는 모집단으로부터 표본을 추출하고, 이를 통해 모집단 전체에 대한 추정치를 산출한다. 모집단 정의가 불명확하면 표본 추출 과정에 왜곡이 생기고, 결과적으로 표본이 모집단을 제대로 대표하지 못하게 된다. 따라서 모집단 정의는 표본 설계의 출발점으로서 반드시 선행되어야 한다.\n\n\n다양한 단위와 요소 처리\n하나의 조사에서도 사람, 가구, 기업 등 다양한 요소들이 존재할 수 있다. 이러한 요소들의 범위와 성격이 명확히 정의되지 않으면, 데이터 해석 과정에서 혼란이 발생할 수 있으며, 잘못된 결론으로 이어질 위험도 존재한다.\n\n\n다른 연구와의 차별성\n실험 연구와 같이 자극과 반응 간의 인과관계를 규명하는 데 초점을 맞춘 연구에서는 모집단 정의가 상대적으로 부차적인 요소일 수 있다. 반면, 설문조사는 모집단 전체의 특성을 설명하고 해석하는 것을 궁극적인 목표로 삼기 때문에, 모집단 정의는 조사 전 과정에서 가장 중요한 요소 중 하나로 간주된다.\n\n\n1. 모집단과 프레임\n목표 모집단(target population)은 조사 결과를 일반화하고자 하는, 즉 표본 통계를 통해 추론하고자 하는 요소들의 집합을 의미한다. 목표 모집단은 다음과 같은 조건을 충족해야 한다:\n\n크기가 유한해야 한다. 이론적으로라도 개별 요소들을 셀 수 있어야 한다.\n시간적으로 정의되어야 한다. 특정 시점 또는 시기 내에서 존재하는 집단이어야 한다.\n관찰 가능해야 한다. 즉, 실제로 접근하여 조사할 수 있어야 한다.\n\n목표 모집단을 정의할 때는 두 가지 요소를 명확히 해야 한다. 첫째, 어떤 단위를 모집단의 요소로 간주할 것인가(예: 사람, 가구, 시설). 둘째, 어떤 시간적 범위를 설정할 것인가. 예를 들어, 가구 조사의 경우 조사 대상은 일반적으로 경제활동인구에 해당하는 만 15세 이상의 성인으로, 주택 단위에서 거주하는 사람들을 포함한다. 이때 ’가구’는 집, 아파트, 이동식 주택, 방 그룹 또는 독립된 방처럼 거주를 목적으로 마련된 공간을 포함한다.\n모든 사람이 반드시 성인이거나 주택에 거주하는 것은 아니므로(예: 교도소 수감자, 군부대 거주자, 장기 요양시설 입소자 등), 이들이 목표 모집단에 포함될지 여부는 조사의 목적과 범위에 따라 달라질 수 있다. 어떤 조사는 특정 지역(예: 특광역시)으로 모집단을 한정하기도 하며, 어떤 조사는 시설 거주자를 포함하기도 한다.\n모집단은 고정된 것이 아니라 시간에 따라 변할 수 있기 때문에, 조사 시점 역시 모집단 정의의 중요한 요소이다. 예를 들어, 가구 조사가 며칠 혹은 몇 주에 걸쳐 이루어질 경우, 그 조사 기간 중 해당 주택에 거주하는 사람이 모집단에 포함된다. 실무에서는 첫 번째 접촉 시점에서 거주자가 누구인지를 기준으로 모집단을 “고정”하는 방식을 자주 사용한다.\n그러나 실제로 조사 데이터를 수집할 때는, 조사 방법 자체가 모집단을 더 좁은 범위로 제한하는 경우가 많다. 예를 들어, 목표 모집단이 ’대한민국에 거주하는 만 18세 이상 성인’이라 하더라도, 전화 조사는 실제로 전화번호를 가진 사람들만 조사할 수 있다. 이처럼 실질적으로 조사가 이루어진 집단을 조사 모집단(survey population)이라 하며, 이는 원래 목표 모집단과 다를 수 있다.\n조사를 설계하기 위해서는 표본 프레임(sample frame)이 필요하다. 표본 프레임은 모집단 요소를 식별할 수 있는 자료 집합으로, 요소들의 명부(예: 회원 명단, 주소록)나 요소가 존재하는 지역·시설·시점의 목록일 수 있다. 예를 들어, 특정 전문 협회 회원 명단, 특정 지역 내 사업체 목록 등이 이에 해당한다.\n그러나 실제 조사에서는 단일한 표본 프레임이 존재하지 않는 경우도 많다. 예를 들어, 서울 지역 모든 초중고등학생의 명단이나, 교정시설 수감자 전체 명단은 현실적으로 존재하지 않거나 접근이 어렵다. 이 경우 조사자는 두 가지 선택지를 고려할 수 있다.\n\n표본 프레임에 맞게 목표 모집단을 재정의한다.\n원래 모집단을 유지하되, 포함 오류(coverage error)의 가능성을 인정한다.\n\n예를 들어, 전화 조사를 설계할 때 목표 모집단이 미국의 모든 성인이라 하더라도, 실제 표본 프레임은 전화번호를 보유한 성인으로 제한될 수 있다. 모집단을 전화가 있는 성인으로 재정의하는 것은 모집단과 프레임 간의 불일치를 해결하는 방식이지만, 원래 모집단을 그대로 유지할 경우에는 전화가 없는 성인이 누락되어 포함 오류가 발생한다.\n마지막으로, 표본 프레임 없이 조사를 수행해야 하는 경우도 있다. 이때는 확률 표집이 어려우므로, 눈덩이 표집(snowball sampling)이나 특정 지역을 설정한 현장 조사와 같은 비확률 표집(nonprobability sampling) 방식이 활용되기도 한다.\n\n\n2. 표본프레임의 포함 이슈\n조사에서 연구자들에게 중요한 통계적 관심은 표본 프레임(표본을 선택하기 위해 사용 가능한 자료)이 실제로 목표 모집단을 얼마나 잘 포함하고 있는가이다. 표본 프레임과 목표 모집단 간의 일치는 포함, 미포함(목표 모집단에 포함되어야 하지만 표본 프레임에 포함되지 않거나 포함될 수 없는 요소), 비적격(목표 모집단에 속하지 않지만 표본 프레임에 포함된 단위) 단위를 포함한 세 가지 잠재적 결과를 초래할 수 있다.\n표본 프레임이 완벽하다는 것은 프레임 요소와 목표 모집단 요소 간에 일대일 매핑이 있다는 것을 의미한다. 실제로는 완벽한 프레임이 존재하지 않으며, 일대일 매핑을 방해하는 문제가 항상 발생한다.\n프레임의 적합성을 논의할 때 포함 오류와 비적격 단위 문제이외 프레임 단위가 존재하고 목표 모집단의 요소와 매핑되지만 그 매핑이 고유하지 않을 때 발생하는 문제도 논의 되어야 한다. ”중복”은 여러 프레임 단위가 목표 모집단의 단일 요소에 매핑될 때 사용된다.\n”군집화”는 여러 목표 모집단 요소가 동일한 단일 프레임 요소와 연결될 때 사용되는 용어다. 표본 크기(요소 수로 측정)는 선택된 군집에 따라 클 수도 있고 작을 수도 있다. 또한 여러 프레임 단위가 여러 목표 모집단 요소와 매핑되는 경우(다대다 매핑)도 있다.\n\n\n(1) 미포함 undercoverage\n\n미포함 정의\n미포함는 조사 통계에서 특정 모집단 부분이 포함되지 않아 발생하는 오류를 뜻한다. 예를 들어, 전화 가구 조사는 모든 가구의 사람들을 대상으로 하지만, 전화 프레임에는 전화가 없는 가구가 포함되지 않아 미포함이 발생한다. 세계 여러 국가에서 전화 사용이 지속적인 비용을 요구하기 때문에 경제적으로 어려운 계층이 비율적으로 더 많이 제외된다. 또한, 휴대전화가 고정전화 서비스를 대체하는 국가에서는 젊은 사람들이 새로운 기술을 더 빨리 수용하기 때문에 고정전화 기반 프레임에서 제외될 가능성이 높다.\n\n\n미포함 문제의 원인\n미포함 문제는 표본 프레임 생성 과정에 따라 발생한다. 이 과정은 조사 설계에 의해 통제될 수도 있고, 외부 출처에서 프레임을 얻을 때는 조사 외부 요인에 의해 결정될 수도 있다. 예를 들어, 가구 조사의 경우, 조사 표본은 초기 지역 목록(시군구 등)에서 시작하여 시군구 내의 주택 목록으로 세분화되고, 최종적으로 가구 내 거주자 목록으로 연결된다. 이러한 샘플링 과정은 지역 샘플로 불린다.\n\n\n문제의 수준\n\n지리적 경계: 도로, 강, 철도 등 물리적 경계는 상대적으로 쉽게 구별되지만, 자연 경계선(산등성이, 능선 등)은 해석에 따라 차이가 발생할 수 있다. 경계 해석 오류로 인해 특정 가구가 목록에서 누락될 가능성이 있다.\n가구 정의: 가구는 독립된 입구를 갖춘 물리적 구조로 정의되지만, 추가가구나 숨겨진 입구가 있는 경우 누락될 가능성이 있다.\n특수 사례: 공동체 생활(공동 주방 사용 등)이나 제도적 시설(교도소, 병원 등)의 경우, 거주 단위를 정의하고 포함 여부를 결정하는 규칙이 필요하다.\n\n\n\n주민 등록 규칙의 문제\n조사에서 거주자는 일반적으로 ”일반 거주” 규칙에 따라 정의된다. 이 규칙은 거주 단위에서 통상적으로 거주하는 사람을 포함하도록 한다. 하지만, 여행하는 직업(트럭 운전사, 항공 조종사 등)을 가진 사람들의 경우 거주지 정의가 모호할 수 있다. 또한, 부모와 떨어져 살거나 복잡한 가족 구조를 가진 아동도 미포함이 발생할 수 있다.\n\n\n사업체 조사에서의 Undercoverage\n사업체 조사는 사업체의 생성, 병합, 종료로 인해 미포함이 발생할 가능성이 높다. 특히 대규모 또는 소규모 사업체는 표본 프레임에 포함되지 않을 수 있다. 새로운 사업체는 행정적 기록의 지연으로 프레임에서 누락되거나, 복잡한 사업체 구조는 데이터 정리 과정에서 오류를 일으킬 수 있다.\n\n\n\n(2) 부적격 단위 ineligible units\n표본 프레임에는 때로 목표 모집단에 속하지 않는 요소들이 포함될 수 있다. 예를 들어, 전화번호 프레임에는 작업 또는 비거주 전화번호가 많이 포함될 수 있는데, 이는 가구 모집단을 대상으로 하는 프레임의 사용을 복잡하게 만든다. 지역 확률 조사에서는 종종 지도 자료에 목표 지리적 영역 외부의 단위가 포함될 수 있다. 조사원이 주택 단위를 나열하기 위해 표본 영역을 방문할 때, 때때로 점유되지 않았거나 주택 단위로 보이는 사업장 구조물을 포함시킬 수 있다.\n조사원이 주택 단위에서 가구 구성원의 목록을 작성할 때, 응답자가 생각하는 ”가구”의 개념과 조사에서 요구하는 정의가 다를 수 있다. 예를 들어, 집을 떠나 학교에 다니는 학생의 부모는 여전히 그들을 가구의 일부로 여길 수 있지만, 대부분의 조사에서는 이들을 대학생으로 분류하여 별도로 다룬다. 또한, 응답자는 같은 주택 내에서 방을 임대해 거주하는 사람이나 친족 관계가 없는 사람들을 가구 구성원으로 포함하지 않을 가능성이 높다. 이는 조사 결과에서 특정 가구 유형이나 가족 구성원의 불균형을 초래할 수 있다.\n프레임에서 선택 시작 전에 외부 단위가 식별되면 적은 비용으로 제거될 수 있다. 외부 단위의 비율이 소수라면 표본 크기를 줄이는 것과 같은 스크리닝 단계에서 이를 식별하고 표본에서 제외할 수 있다. 외부 단위의 발생률이 대략적으로라도 사전에 알려진 경우, 일부 외부 단위를 스크리닝할 것을 예상하며 추가 단위를 선택할 수 있다. 예를 들어, 전국 전화번호 명부 리스트의 약 15%가 더 이상 존재하지 않는 번호임을 알고 있는 경우, 100개의 전화 가구 표본을 얻기 위해 디렉토리에서 100/(1 - 0.15) = 118개의 항목을 선택할 수 있으며, 그 중 18개가 유효하지 않는 번호일 것이다.\n\n\n(3) 프레임 요소 내에서 목표 모집단 요소의 클러스터링\n프레임에서 모집단으로, 또는 모집단에서 프레임으로의 다중 매핑(클러스터링 또는 중복)은 표본 선택에서 문제를 일으킬 수 있다. 전화번호부를 표본 프레임으로 사용해 전화 가구에 거주하는 성인(목표 모집단)을 표본으로 삼는 경우 전화번호부에 나열된 가구에는 하나의 프레임 요소(전화번호)로 여러 성인이 포함될 수 있다.\n\n클러스터링 문제의 예\n홍길동 가족(홀길동, 홍길동 아내, 홀길동 부모)은 같은 가구에 살며 동일 전화번호를 공유한다. 이 전화번호는 표본 프레임 요소로 사용되며, 홀길동 가족 모두가 동일한 프레임 요소와 연결됩니다. 그러나 이들은 목표 모집단의 4 요소를 구성한다.\n\n\n클러스터링 문제 해결 방법\n클러스터링 문제를 해결하는 한 가지 방법은 선택된 프레임 요소(예: 전화번호)에 속한 모든 자격 요소(목표 모집단 요소)를 포함하는 것이다. 이러한 설계에서는 클러스터 내의 모든 요소에 동일한 선택 확률이 적용된다.\n\n\n클러스터링 문제의 중요성\n클러스터링은 종종 클러스터를 부분적으로 표본화 하게 되는 중요한 문제를 제기한다.\n\n첫째, 일부 경우 클러스터의 모든 요소에서 성공적으로 정보를 수집하기 어려울 수 있다. 예를 들어, 전화 가구 조사에서는 한 가구에서 여러 번 인터뷰를 시도하면 무응답 비율이 증가하는 경우가 있다.\n둘째, 인터뷰가 여러 시간대에 걸쳐 진행되어야 할 경우 초기 응답자가 나중 응답자에게 설문 내용을 논의하면서 답변에 영향을 줄 수 있다.\n셋째, 클러스터 크기가 다를 경우 표본 크기 통제가 어려워질 수 있다.\n\n\n\n클러스터 크기와 표본 왜곡\n큰 클러스터의 요소는 작은 클러스터 요소에 비해 선택될 확률이 낮다. 예를 들어, 전화번호가 표본으로 선택되었을 때 두 명의 자격 요소를 포함한 가구에서는 한 사람이 선택될 확률이 50%인 반면, 네 명의 자격 요소를 포함한 가구에서는 각각 25%의 확률을 갖게 된다. 이러한 샘플링의 결과로 소규모 가구의 구성원이 목표 모집단에 비해 과대표될 가능성이 있다. 예를 들어, 범죄 피해 조사에서 소규모 가구의 구성원이 범죄 피해를 입을 확률이 더 높은 경우, 클러스터 크기와 변수 간의 관계로 인해 표본 결과는 편향된 추정치를 제공할 수 있다.\n\n\n해결 방법\n이러한 편향을 제거하기 위해 분석 과정에서 보상 조치를 취해야 한다. 클러스터 내 자격 요소 수에 따라 가중치를 적용해 표본 추정치를 수정할 수 있다.\n\n\n\n(4) 표본 프레임에서 목표 모집단 요소의 중복\n프레임과 목표 모집단 사이의 또 다른 중복 매핑 유형은 ”중복”이다. 중복은 단일 목표 모집단 요소가 여러 프레임 요소와 연관된 경우를 의미한다. 전화 설문조사 예를 들어, 단일 전화 가구가 전화번호부에 여러 번 나열되는 경우가 있다. 홍길동 목표 모집단 구성원은 전화번호 두 개를 등록하여 두 개의 프레임 요소와 연관되어 있다고 하자. 이러한 프레임 문제는 클러스터링과 유사하다. 여러 프레임 단위를 가진 목표 모집단 요소는 선택될 확률이 높아져 모집단에 비해 과대 대표된다. 중복과 관심 변수 간의 상관관계가 있는 경우, 설문조사 추정치는 편향될 수 있다. 문제는 중복 여부와 중복과 조사 변수 간의 상관관계가 종종 알려지지 않는다는 점이다.\n중복으로 인한 편향 문제는 다양한 방식으로 해결할 수 있다. 첫 번째 방법은 표본 선택 전에 프레임에서 중복 항목을 제거하는 것이다. 예를 들어, 전자 전화번호부를 정렬하여 동일한 번호의 중복 항목을 삭제하는 방식이다. 두 번째 방법은 표본 선택 과정이나 데이터 수집 중에 중복된 프레임 단위를 식별하는 것이다. 이 경우, 간단한 규칙을 적용하여 중복 항목을 처리할 수 있다. 예를 들어, 디렉토리에 여러 항목이 있을 경우, 첫 번째 항목만 유효하다고 간주하는 규칙을 사용할 수 있다. 데이터 수집 중에는 조사원이 가구에 여러 디렉토리 항목이 있는지 확인한 뒤, 확인된 중복 항목 중 첫 번째 항목만 선택하고 나머지는 ”외부 단위”로 분류하여 제외할 수 있다. 이러한 접근 방식은 중복으로 인한 표본 편향을 줄이는 데 효과적이다.\n또 다른 해결책은 가중치를 부여하는 방법이다. 클러스터링의 경우와 유사하게, 중복된 프레임 요소의 개수를 기반으로 역수를 사용하여 가중치를 계산한다. 예를 들어, 한 전화 가구가 두 개의 전화선을 보유하고 있으며 디렉토리에 총 세 개의 항목(한 개 번호는 홍길동 처의 이름으로 중복 등록)이 등재되어 있다면, 이 가구는 표본 내에서 가중치 1/3을 받게 된다. 반면, 무작위 숫자 다이얼(RDD) 프레임에서는 해당 가구가 가중치 1/2을 받게 된다. 이러한 가중치 계산은 표본 내의 중복 문제를 보정하여 통계적 편향을 최소화하는 데 기여한다.\n\n표본 프레임과 목표 모집단 요소 간의 복잡한 매핑\n다수의 프레임 단위가 여러 모집단 요소에 매핑될 가능성도 있습니다. 예를 들어, 성인을 대상으로 한 전화 가구 조사에서는 디렉토리에 여러 항목이 포함된 여러 성인이 있는 가구를 만날 수 있습니다. 이러한 다대다 매핑 문제는 클러스터링과 중복의 조합입니다.\n예를 들어, 홍길동 가구는 두 개의 전화번호 프레임 요소를 가지고 있으며, 이는 두 개의 표본 프레임 요소에 매핑된 세 개의 목표 모집단 요소를 나타낼 수 있습니다. 이 문제에 대한 일반적인 해결책은 조사 결과에 가중치를 부여하여 두 문제를 동시에 처리하는 것입니다. 개별 수준 통계를 위한 보정 가중치는 가구의 성인(또는 적격자) 수를 해당 가구의 프레임 항목 수로 나눈 값으로 정의됩니다. 예를 들어, 홍길동 가구의 구성원에게 부여되는 가중치는 1/2이 됩니다.\n\n\n\n3. 목표모집단과 표본프레임 이슈\n\n\n(1) 가구와 개인\n가구를 대상으로 한 일반적인 표본 프레임에는 지역 프레임(인구조사 구역 또는 카운티와 같은 지역 단위 목록), 전화번호, 전화목록, 그리고 우편목록이 있다. 지역 프레임은 지리적 단위를 기반으로 하기 때문에, 사람이 해당 지역에 속한다는 것을 거주 연결 규칙을 통해 연관지어야 한다. 이러한 프레임은 개인을 표본으로 선택할 때 여러 단계를 요구한다. 먼저 지역 단위의 일부를 선택한 후, 해당 구역의 주소 목록을 작성해야 한다. 우수한 지도나 항공사진이 있는 경우, 이 프레임은 이론적으로 주거지의 완전한 범위를 제공할 수 있다. 그러나 선택된 지역 단위 내 주거지 목록에 일부 누락된 단위가 존재할 경우, 프레임은 불포함 오류를 겪게 된다. 한 사람이 두 개 이상의 거주지를 가지고 있는 경우에는 중복 문제가 발생하며, 여러 사람이 동일한 거주지에 거주하는 경우에는 개인을 표본으로 선택할 때 클러스터링 문제가 발생한다.\n또 다른 가구 모집단 프레임은 주택 내 유선전화 번호를 기반으로 한 프레임이다. 일부 가구는 여러 개의 전화번호를 보유하고 있어 과포함 문제가 발생할 수 있다. 이 프레임에는 사용되지 않는 전화번호와 비주거용 번호가 포함되어 있기 때문에, 이를 개인 수준의 표본으로 활용하려면 제거해야 한다.\n주거용 전화번호 목록 프레임은 전화번호 프레임보다 범위가 좁지만, 비작동 번호와 비주거용 번호가 대부분 제거되어 있어 가구 조사에서는 더 효율적이다. 이 목록은 상업적 기업이 전자 및 인쇄된 전화번호 디렉토리에서 얻으며, 대량 발송업자와 조사기관에 판매한다. 그러나 상당수의 주거용 번호가 디렉토리에 포함되지 않으며, 특히 도시 지역 거주자나 일시적인 거주자의 번호가 빠질 수 있다. 같은 번호가 여러 이름으로 등재되는 경우도 많아 중복 문제가 발생하기도 한다.\n웹 설문조사에 대한 관심이 높아지면서, 이메일 주소를 기반으로 한 가구 모집단 프레임 개발에 주목이 쏠리고 있다. 그러나 이메일 프레임은 전체 가구 모집단을 충분히 포함하지 못하며, 한 사람이 여러 이메일 주소를 보유하거나 여러 사람이 하나의 이메일을 공유하는 등의 이유로 중복 및 클러스터링 문제가 존재한다.\n모바일 또는 휴대전화는 많은 국가에서 유선 전화를 빠르게 대체하고 있다. 예를 들어, 핀란드에서는 1990년대 중반부터 유선 전화 가입자가 감소하고 휴대전화 가입자가 급격히 증가하였다. 이는 기존의 유선 전화 기반 프레임에서 휴대전화 번호가 누락됨에 따라, 프레임 손실이 발생했음을 의미한다. 특히 젊은 세대 중 독립적인 가구를 처음 형성하는 층에서 이러한 손실이 두드러졌다.\n더욱이 휴대전화는 유선전화와 달리 한 사람과 직접 연결되며, 전체 가구 단위와 연결되지 않는다. 따라서 전화 설문조사는 휴대전화 번호를 표본으로 사용할 수밖에 없으며, 이는 프레임과 표본 단위가 가구에서 개인으로 분리되는 것을 요구하게 된다. 현재로서는 유선전화와 휴대전화 번호의 병용에서 비롯된 클러스터링과 중복 문제 등 여러 프레임 관련 이슈가 해결되지 않은 상태이다.\n\n\n(2) 고객, 고용주 또는 조직 구성원\n표본 프레임은 전자 파일 또는 인쇄물 형식으로 구성된 개인 기록일 수 있으며, 이러한 시스템은 주기적인 업데이트 지연으로 인해 불포함 오류가 발생하거나, 조직을 이미 떠난 인물이 빠르게 제거되지 않아 부적격 요소를 포함할 수 있다. 예를 들어, 마지막 거래가 오래전에 이루어진 고객이 여전히 목록에 남아 있는 경우가 있으며, 계약직 직원처럼 조직과의 소속이 모호한 경우도 존재한다. 고객 기반 프레임에서는 거래 단위별로 동일한 고객이 여러 차례 기록되어 중복이 발생할 수 있으며, 이때 설문조사 연구자는 목표 모집단이 ’사람’인지, ’거래’인지, 혹은 둘 다인지를 신중히 판단해야 한다.\n설문조사 연구자는 대체 가능한 프레임을 평가할 때, 해당 목록이 어떤 방식으로 생성되고 수정되는지 파악해야 하며, 예컨대 급여 목록이나 보안 시스템 기록이 특정 직원 집단을 포함하거나 제외할 가능성도 함께 검토해야 한다. 특히 월급제와 주급제의 차이, 임시 결근, 장기 병가 등은 프레임의 포괄성과 대표성을 더욱 복잡하게 만들 수 있다. 따라서 각 설문조사에서는 프레임에 포함될 대상의 기준과 선택 절차를 명확히 정의하고, 그 적절성을 면밀히 검토하는 과정이 반드시 필요하다.\n\n\n(3) 기관\n기관을 대상으로 한 표본 프레임은 일반적으로 단위 목록으로 구성되며, 이 중 기업체는 아마도 설문조사에서 가장 빈번하게 설정되는 목표 모집단일 것이다. 기업 모집단은 고유한 프레임 문제를 수반한다.\n첫째, 기업 모집단의 중요한 특성 중 하나는 규모의 차이가 매우 크다는 점이다. 예를 들어, 소프트웨어 판매업체를 조사할 경우, 연매출이 매우 큰 NC소프트와 소규모 소매점을 모두 프레임에 포함해야 한다. 많은 기업 설문조사는 산업 내 전체 고용 규모나 매출과 같은 크기 관련 변수를 측정하기 때문에, 프레임의 포괄성 문제는 일반적으로 가장 작은 기업보다 가장 큰 기업을 포함하는 데 더 많은 주의를 기울이게 된다.\n둘째, 기업 모집단은 매우 역동적이다. 소규모 기업은 빠르게 설립되거나 폐업되며, 대규모 기업은 다른 회사를 인수하거나 합병하기도 하고, 반대로 분할되기도 한다. 따라서 프레임 모집단은 새로운 기업을 포함하고, 더 이상 존재하지 않는 기업을 제거함으로써 그 포괄성을 유지하기 위해 지속적인 업데이트가 필요하다.\n셋째, 기업 모집단은 법적으로 정의된 실체와 물리적 위치 간의 구분을 내포한다. 예를 들어, 다지점 또는 다국적 기업은 전 세계에 여러 개의 사업장을 운영하지만 본사는 하나뿐이다. 이에 따라 설문조사는 ‘기업’(법적 실체)을 대상으로 할 수도 있고, ‘시설’(물리적 단위)을 대상으로 할 수도 있다. 일부 기업은 물리적 위치 없이 운영되기도 하며(예: 재택 근무 기반의 컨설팅 회사), 반대로 여러 기업이 하나의 물리적 위치를 공유하기도 한다. 이러한 구조는 표본 프레임 설계 시 조사 단위의 정의를 더욱 중요하게 만든다.\n\n\n(4) 사건\n설문조사는 사건 모집단을 대상으로 하며, 여기에 포함되는 사건의 예로는 서비스나 제품 구매, 결혼, 임신, 출생, 실직, 우울증 사례, 범죄 피해 등이 있다. 이러한 사건에 대한 설문조사는 일반적으로 사람들을 대상으로 한 프레임에서 시작되며, 일부 사람들은 여러 사건을 경험하면서 사건 요소 간의 집단을 형성하게 된다.\n사건 표본추출의 또 다른 접근 방식은 시간 단위를 프레임으로 사용하는 것이다. 예를 들어, 동물원 방문 사례를 조사할 때 방문 시간을 기준으로 프레임을 구성하고, 일정한 시간 간격(예를 들어 5분 블록)을 선택하여 해당 시간에 방문한 사람들을 대상으로 질문하는 방식이 사용될 수 있다.\n일부 시간 사용 설문조사는 무작위로 선택된 시점에 전자 호출기를 통해 신호음을 발생시키는 방식을 사용한다. 신호가 울리면, 응답자는 그 시점에 자신이 무엇을 하고 있었는지를 보고하도록 되어 있다. 예를 들어, 사무실에서 일하고 있었는지, 텔레비전을 시청하고 있었는지, 혹은 쇼핑을 하고 있었는지를 기록하게 된다.\n사건을 대상으로 하는 설문조사는 경우에 따라 여러 모집단을 동시에 포함할 수 있다. 이러한 조사는 사건 자체에 대한 통계뿐만 아니라 그 사건을 경험한 사람들에 대한 통계에도 관심을 가진다. 이처럼 목적이 이중적인 경우, 표본 설계 과정에서 클러스터링과 중복과 같은 문제가 발생할 수 있다. 예를 들어, 가족에 의한 자동차 구매 사건을 조사하는 경우, 사건 요소는 구매 행위이지만, 사건을 경험한 사람으로는 법적 소유자, 모든 가족 구성원, 또는 차량을 운전할 가능성이 있는 사람 등 다양한 해석이 가능하다.\n\n\n(5) 희귀 모집단\n희귀 모집단은 연구자가 관심을 갖는 소규모 대상 집단을 지칭하는 용어로, 이들이 희귀하다고 판단되는 이유는 절대적인 규모보다는 사용 가능한 프레임 내에서의 상대적 크기 때문이다. 예를 들어, 전체 인구가 5천만 명이고 이 중 100만 명이 노인 복지 혜택을 받고 있다면, 이는 전체 인구의 약 2%에 해당하므로 희귀 모집단으로 간주될 수 있다. 이러한 모집단을 조사 대상으로 설정할 경우, 적절한 표본 프레임을 식별하는 데 여러 가지 어려움이 따른다.\n희귀 모집단을 위한 표본 프레임을 구축하는 방식에는 크게 두 가지 접근이 있다. 첫째는 희귀 모집단에 속하는 요소들의 목록을 직접 구성하는 방법이다. 예를 들어, 복지 수급자의 목록을 복지 사무소의 행정기록에서 얻을 수 있다. 다만 이러한 자료는 종종 기밀로 취급되거나, 단일 목록이 전체 모집단을 포괄하지 못하는 경우가 많아 여러 출처의 목록을 조합해야 할 수도 있다.\n둘째는 보다 일반적인 모집단 프레임을 설정하고, 그 안에서 희귀 모집단에 해당하는 요소들을 선별하는 방식이다. 예를 들어, 일반 가구 모집단을 대상으로 하여 그 안에서 복지 수급 가구를 찾아내는 방식이 여기에 해당한다. 만약 희귀 모집단의 모든 구성원이 더 큰 프레임 모집단의 하위 집합으로 포함된다면, 희귀 모집단에 대한 완전한 포괄이 가능하다.\n\n\n4. 포함 오류\n불포함은 해결하기 어려운 문제이며, 설문조사에서 중요한 포함 오류의 원인이 될 수 있다. 포함 오류는 표본 통계나 설문조사에서 도출된 추정치의 특성에 영향을 미친다. 하나의 통계는 포함 오류로 인해 크게 왜곡될 수 있는 반면, 동일한 설문조사에서 얻어진 다른 통계는 같은 오류에 거의 영향을 받지 않을 수도 있다. 설문조사 방법론에서는 불포함, 중복, 클러스터링 등을 포함 오류를 유발하는 표본 프레임의 구조적 문제로 본다. 포함 오류란 이러한 문제들이 조사 결과에 미치는 영향을 지칭하는 개념이다.\n\n포함 오류: \\({\\overline{Y}}_{C} - \\overline{Y} = \\frac{U}{N}({\\overline{Y}}_{C} - {\\overline{Y}}_{U})\\), 여기서 \\(\\overline{Y}\\)는 목표 모집단 전체의 평균, \\({\\overline{Y}}_{C}\\)는 표본 프레임에 포함된 모집단의 평균, \\({\\overline{Y}}_{U}\\)는 표본 프레임 밖 모집단의 평균을 나타낸다. \\(N\\)은 목표 모집단의 총 구성원 수, \\(C\\)는 표본 프레임에 포함된 적격 구성원의 총수, 그리고 \\(U\\)는 표본 프레임에 포함되지 않은 적격 구성원의 총수이다.\n\n따라서 프레임에 포함되지 않은 \\((N - c)\\) 개의 단위로 인해 발생하는 오류는, 전체 모집단에서 포함되지 않은 비율과 포함된 단위와 포함되지 않은 단위 간의 평균 차이에 따라 결정된다. 설문조사는 표본 크기와 무관하게 포함된 단위의 평균 \\({\\overline{Y}}_{C}\\) 만을 추정할 수 있다. 이때, 포함되지 않은 단위 U의 규모가 크거나, 포함된 단위와 포함되지 않은 단위 간의 특성 차이가 클수록 편향, 즉 포함 오류의 크기는 커지게 된다.\n포함되지 않은 비율은 모집단의 하위 계층에 따라 달라질 수 있다. 전체 모집단에서의 불포함 비율보다 특정 하위 그룹에서의 불포함 비율이 더 높을 수도 있다. 또한 포함 오류는 포함된 단위와 포함되지 않은 단위 간의 추정치 차이에 따라 결정되므로, 동일한 적격 단위 하위 계층을 기준으로 계산된 통계라 하더라도 각 통계별로 포함 오류의 정도는 다를 수 있다."
  },
  {
    "objectID": "consult.html",
    "href": "consult.html",
    "title": "통계상담",
    "section": "",
    "text": "📋 통계상담 안내\n데이터 분석, 통계 해석, 설문 설계 등 상담이 필요하신 분은 아래 폼을 제출해 주세요.\n👉 상담 신청하기\n\n온라인/비대면 상담 가능합니다."
  },
  {
    "objectID": "cardnews/news002.html",
    "href": "cardnews/news002.html",
    "title": "출산율 감소",
    "section": "",
    "text": "👶 출산율 감소, 바닥을 뚫다\n\n\n\n출산\n\n\n\n2023년 합계출산율: 0.72명\n전 세계 최저\n지방소멸 → 학교 폐교 → 일자리 축소의 악순환\n\n\n데이터가 보여주는 출산의 현실"
  },
  {
    "objectID": "cardnews/news004.html",
    "href": "cardnews/news004.html",
    "title": "전공별 취업률 격차",
    "section": "",
    "text": "title: “전공별 취업률 격차” format: html page-layout: full —"
  },
  {
    "objectID": "cardnews/news004.html#왜-이런-차이가-날까",
    "href": "cardnews/news004.html#왜-이런-차이가-날까",
    "title": "전공별 취업률 격차",
    "section": "💡 왜 이런 차이가 날까?",
    "text": "💡 왜 이런 차이가 날까?\n\n산업 수요와의 불균형\n졸업 후 진로 다양성, 인프라 차이\n지역 대학일수록 격차 더 큼"
  },
  {
    "objectID": "cardnews/news004.html#졸업생-1인의-목소리",
    "href": "cardnews/news004.html#졸업생-1인의-목소리",
    "title": "전공별 취업률 격차",
    "section": "💬 졸업생 1인의 목소리",
    "text": "💬 졸업생 1인의 목소리\n\n“취업률 통계는 높지만,\n실제로는 계약직, 인턴이 대부분이에요.”\n(사회계열 졸업생 인터뷰 중)"
  },
  {
    "objectID": "cardnews/news004.html#통계의-해석은-숫자-너머",
    "href": "cardnews/news004.html#통계의-해석은-숫자-너머",
    "title": "전공별 취업률 격차",
    "section": "📚 통계의 해석은 숫자 너머",
    "text": "📚 통계의 해석은 숫자 너머\n통계는 단순 수치보다 맥락과 경험을 함께 살필 때 의미를 갖습니다.\n\n전공 선택이 삶 전체에 어떤 영향을 주는가,\n그 통계로 함께 이야기해야 합니다."
  }
]