![myself.png](media/image1.png){width="4.076208442694663in"
height="2.9841404199475066in"}확률론은 통계학의 모든 기초가 되는 주제로,
모집단, 실험, 혹은 무작위 현상으로 간주될 수 있는 거의 모든 것을
모델링할 수 있는 수단을 제공합니다. 이러한 모델을 통해 통계학자들은
모집단에 대해 추론을 수행할 수 있으며, 이는 전체 중 일부만을 관찰한
결과를 기반으로 이루어집니다. 확률론의 역사는 매우 오래되고 풍부하며,
적어도 17세기까지 거슬러 올라갑니다. 당시, 그들의 친구들의 요청에 따라
파스칼 Pascal과 페르마 Fermat가 도박 확률의 수학적 공식을![폰트, 원,
디자인, 타이포그래피이(가) 표시된 사진 자동 생성된
설명](media/image1.jpeg){width="2.5058180227471567in"
height="1.8019805336832897in"} 개발하였습니다.

vol 2. 추론통계

section 1. 확률론

wolfpack se kwon

<https://sites.google.com/view/wolfpack61>

권세혁교수 통계노트시리즈

파스칼의 삼각형은 숫자를 삼각형 형태로 배열한 도형으로, 이항 계수를
나타냅니다. 프랑스의 수학자 블레즈 파스칼의 이름을 따왔으나, 그 이전에도
여러 문명에서 이미 알려져 있었습니다.

이항전개 계수 :
$(a + b)^{n} = \overset{n}{\sum_{k = 0}}\binom{n}{k}a^{n - k}b^{k}$

$$(a + b)^{4} = a^{4} + 4a^{3}b + 6a^{2}b^{2} + 4ab^{3} + b^{4}$$

$11^{n}$의 값: $11^{3} = 1331$

7번 하는 경기에서 4번 먼저 이기는 게임에서 실력이 동등한 두 선수 중 A는
1번, B는 2번 이긴 상태에서 게임이 끝났다. 상금을 어떻게 배분하면 되는가?
A는 3번, B는 2번 더 승리해야 하므로 5번째 행을 합 16을 A는 첫 2개 열의
합 5, B는 마지막 3개 열 11을 배분하여 A는 상금의 5/16, B는 상금의
11/16을 갖는다.

Chapter 1. 집합론

통계분석의 목표 중 하나는 실험을 통해 특정 집단에 대한 결론을 도출하는
것이다. 이를 위한 첫 번째 단계는 가능한 결과, 표본공간을 식별하는
것이다.

1표본공간과 사건

표본공간 정의

특정 실험의 가능한 모든 결과를 포함하는 집합 $S$를 표본공간 sample
space이라고 한다.

표본공간 정의

- 실험이 동전을 던지는 것으로 구성되어 있다면, 표본공간은 앞면과 뒷면의
  두 가지 결과를 포함한다. 따라서, $S = \{ H,T\}$

- 실험이 특정 대학에서 무작위로 선택된 학생들의 수능 점수를 관찰하는
  것이라면, 표본공간은 $S = \{ 100,110,...,505\}$(10점 단위)이다.

- 특정 자극에 대한 반응 시간을 관찰하는 실험에서는 $S = (0,\infty)$가
  표본공간이다.

  표본공간의 유형

표본공간은 그 안에 포함된 원소의 수에 따라 가산 countable 표본공간과
비가산 uncountable 표본공간으로 나뉜다.

- 표본공간의 원소가 정수 집합의 부분집합과 1:1 대응을 이룰 수 있으면, 그
  표본공간은 가산이다. 예를 들어, 동전 던지기나 SAT 점수의 표본공간은
  가산 표본공간이다(사실, 유한한 집합이다)

- 반응 시간 표본공간은 비가산 표본공간이다. 이는 양의 실수들이 정수와
  1:1 대응을 이룰 수 없기 때문이다. 하지만 반응 시간을 가장 가까운 초
  단위로 측정한다면, 표본공간은 다음과 같이 표현될 수 있다.
  $S = \{ 0,1,2,3,\ldots\}$

- 가산 표본공간과 비가산 표본공간의 구분의 중요성은 확률을 할당하는
  방식에 영향을 미치기 때문입니다.

1)  사건

사건 event이란 실험에서 발생 가능한 결과들의 모임, 즉 $S$의 임의의
부분집합을 말한다 $S$ 자체도 포함).

사건 정의

어떤 사건 A가 집합 $S$의 부분집합이라고 하자. 만약 실험의 결과가 A
집합에 속한다면, 사건 A가 발생했다고 말한다. 확률에 대해 이야기할 때,
일반적으로 집합 대신 사건의 확률에 대해 언급하며 이 두 용어는 상호
교환적으로 사용할 수 있다.

- 포함 관계, 부분집합:
  $A \subseteq B \Longleftrightarrow x \in A \Longrightarrow x \in B$

- 동일성:
  $A = B \Longleftrightarrow A \subseteq B\text{and}B \subseteq A$

2집합 연산

- 집합 $A$의 모든 원소를 셀 수 있다면 가산 countable 집합이다.

- 만약 집합 $A$의 모든 원소가 집합 $B$에 포함되어 있다면 $A$는 $B$의
  부분 subset 집합이다.

- $\phi$는 공집합(null or empty set)을 의미하며 원소가 하나도 없는
  집합이다.

- $A \subset B$ : 집합 A의 모든 원소가 집합 B에 있는 경우 집합 A는 집합
  B의 부분집합 subset

- $A^{C}or\overline{A}$ : 집합 A의 여집합 complement로 집합 A에 있는
  원소를 제외한 모든 표본공간 원소의 모임 ⇔ NOT

![pasted-image.png](media/image2.png){width="3.732879483814523in"
height="2.073525809273841in"}

어떤 두 사건 A와 B가 주어졌을 때, 다음과 같은 기본적인 집합 연산이
성립한다:

- $A \cup B$ 합집합 union: A 또는 B 또는 둘 다에 속하는 원소들로 구성된
  집합이다. $A \cup B = \{ x:x \in A\text{또는}x \in B\}$

- $A \cap B$ 교집합 intersection: A와 B 모두에 속하는 원소들로 구성된
  집합이다. $A \cap B = \{ x:x \in A\text{그리고}x \in B\}$

표본공간 $S$에서 정의된 임의의 세 사건 $A,B,C$에 대해 다음이 성립합니다.

정리

- 교환법칙 commutativity: $A \cup B = B \cup A$, $A \cap B = B \cap A$

- 결합법칙 associativity:
  $A \cup (B \cup C) = (A \cup B) \cup C$,$A \cap (B \cap C) = (A \cap B) \cap C$

- 분배법칙 distributive Laws:
  $A \cap (B \cup C) = (A \cap B) \cup (A \cap C)$,
  $A \cup (B \cap C) = (A \cup B) \cap (A \cup C)$

- 드모르간 법칙 DeMorgan[']{dir="rtl"}s Laws:
  $(A \cup B)^{c} = A^{c} \cap B^{c}$,
  $(A \cap B)^{c} = A^{c} \cup B^{c}$

![pasted-image.tiff](media/image1.tif){width="2.996469816272966in"
height="1.6362303149606299in"}

만약 $A_{1},A_{2},A_{3},\ldots$가 표본공간 $S$위에 정의된 집합이라면,

$\overset{\infty}{\bigcup_{i = 1}}A_{i} = \{ x \in S:x \in A_{i}\text{for some}i\}$:
무한 합집합을 나타내며 $x$는 $A_{i}$ 중 적어도 하나의 집합에 포함되면
합집합에 포함된다.

$\overset{\infty}{\bigcap_{i = 1}}A_{i} = \{ x \in S:x \in A_{i}\text{for all}i\}$:
무한 교집합을 나타내며 $x$는 모든 $A_{i}$ 포함되어야 교집합에 포함된다.

【예제】 주사위를 한번씩 두 번 던져 나타난 결과를 적는다. 모든 가능한
쌍(pair)을 표본공간이라 정의하자. 집합 A={두 번째 주사위 눈금이 짝수},
B={두 주사위 눈금의 합이 짝수}, C={두 주사위 눈금 중 적어도 하나가
홀수}라 정의할 때 다음을 구하라.

$B^{C},A \cup B,A \cap B^{C},A^{C} \cap C$

$A = \{ 3,456,7,8,9,10,11\}$, $B = \{ 2,4,6,8,10,12\}$,
$C = \{ 23,4,5,6,7,8,9,10,11\}$

【풀이】 $S = \{ 2,3,4,5,6,7,8,9,10,11,12\}$, $A^{c} = \{ 2,12\}$,
$B^{c} = \{ 3,5,7,9,11\}$,
$A \cup B = \left\{ 2,3,4,5,6,7,8,9,10,11,12 \right\} = S$,
$A \cap B^{c} = \{ 3,5,7,9,11\}$, $A^{C} \cap C = \{ 2\}$.

3상호 배타적 사건

만약 $A \cap B = \varnothing$이면, 두 사건 A와 B는 서로소 disjoint, 또는
상호 배타적 mutually exclusive 라고 한다.

상호배타 정의

만약 $A_{i} \cap A_{j} = \varnothing foralli \neq j$이면 사건
$A_{1},A_{2},\ldots$는 쌍별로 서로소 또는 상호 배타적라고 한다.

만약 $A_{1},A_{2},\ldots$가 쌍별로 서로소이고
$\overset{\infty}{\bigcup_{i = 1}}A_{i} = S$라면, 이 집합 모음
$A_{1},A_{2},\ldots$는 $S$의 분할 partition을 이룬다.

【유용한 사례】 집합 $A_{i} = \lbrack i,i + 1)$는 $\lbrack 0,\infty)$의
분할을 이룬다.

Chapter 2. 확률론 기초

확률실험이 수행되면, 그 결과는 표본 공간에 속하는 하나의 결과로
나타난다. 만약 동일한 실험이 여러 번 수행된다면, 다양한 결과가 나타날
수도 있고 일부 결과는 반복될 수도 있다. 이때 결과의 ["]{dir="rtl"}발생
빈도["]{dir="rtl"}는 확률로 이해할 수 있다. 더 높은 확률을 가지는 결과는
더 자주 나타나며, 실험의 결과를 확률적으로 설명할 수 있다면, 이를
통계적으로 분석하는 과정으로 나아가게 된다.

  -----------------------------------------------------------------------
  확률 실험 probability experiment: 특정 조건 하에서 수행되며, 결과가
  미리 확정되지 않은 실험을 말한다. 확률 실험은 동일한 조건에서 여러 번
  반복될 수 있으며, 각 실험의 결과는 표본 공간의 원소로 표현된다.
  (불확정적, 반복가능성, 확률적 설명가능)

  -----------------------------------------------------------------------

확률은 미래에 발생할 사건에 대한 믿음에 대한 측정값이다. 확률 개념은
물리, 화학, 사회 과학 등에서 발생하는 관심 현상의 측정값을 불확실성에
의해 예측할 수 없는 경우 사용된다. 예를 들면 향후 1분간 당신 맥박 수,
다리가 무너지기 전 최대 하중 등은 정확한 값을 알 수 없다. 이런 상황을
랜덤이라 한다. 랜덤상황이더라도 이 사건에 대한 상대 빈도 정보가 있다면
예측이 가능하다.

확률은 관심 사건이 일어날 가능성 (chance or likelihood)을 숫자로 표현한
것으로 확률의 0 (일어날 가능성 없음)과 1(항상 일어남) 사이의 값(0% TO
100%)이다.

1확률 측정

확률은 관심 사건이 일어날 가능성 chance or likelihood을 숫자로 표현한
것으로 확률의 0 (일어날 가능성 없음)과 1(항상 일어남) 사이의 값으로
나타낸다.

확률 정의

![텍스트, 스크린샷, 라인, 번호이(가) 표시된 사진 자동 생성된
설명](media/image3.png){width="4.4998611111111115in"
height="1.3384437882764655in"}

상대 빈도 relative frequency

동전을 던지는 경우 {앞 면이 나올 사건}에 관심이 있어 실험을 한다고 하자.
10번을 던지니 6번이 앞 면이었다면 상대빈도는 0.6이다. 계속 100번 던지니
52번이 앞 면이 나왔다면 상대 빈도는 0.52이다. 1000번을 던지니 515번이
앞면이었다면 상대 빈도는 0.515이다.

$P(A) = \lim_{n \rightarrow \infty}\frac{f}{n}$, $n$=실험 횟수, $f$=사건
A가 발생한 횟수, 무한히 많은 시행 후에는 관심 사건의 나타날 가능성을
예상-확률은 무한 실험 후에 관심사건이 발생한 횟수(상대 빈도)를 확률이라
정의한다.

- Count Buffon (1707-1788): 4040번 동전 던지기 실험 앞면 2048회,
  P(앞면)= 0.5069

- Karl Pearson (1900): 24, 000 던지기 앞면 12,012, P(앞면)=0.5005

- John Kerrich : 10,000 던지기, 앞면 5067 heads, P(앞면)=0.5067.

예 : 공정 생산 제품의 불량률(확률)에 대한 모형을 위해서는 제품
검사(확률실험)를 통하여 검사 제품 개수 중 불량품의 개수(상대 빈도)를
계산하면 된다.

Laplace 확률

표본공간의 각 원소들이 일어날 가능성이 같다고 equally likely 가정하여
확률을 정의하는 것을 Laplace 확률(고전적 정의)이라 한다. 주사위를 던지는
실험에서 짝수가 나올 확률은 3/6=1/2으로 정의한다. 표본공간의 원소 개수는
6개이고 짝수 사건의 원소는 3개이므로 짝수가 발생할 확률은 0.5이다.
고전적 정의의 가정은 각 원소(주사위 눈금)가 나타날 확률과
동일(1/6)하다는 것이다. 다음에서 설명하는 공리적 기반의 확률 정의와
동일한 접근이다.

공리적기반

표본 공간 $S$ 내의 사건 $A$에 대해 $A$에 0과 1 사이의 숫자를 연관시키고
이를 $A$의 확률 probability 이라 부르며 $P(A)$로 표기한다. $P$ 함수의
정의역을 $S$의 모든 부분 집합으로 정의하는 것이 자연스러울 것이다. 즉,
$A \subseteq S$인 각 사건에 대해 $P(A)$를 정의할 수 있다.

집합 $S$의 부분집합 모음 $\mathcal{B}$가 다음 세 가지 성질을 만족하면
시그마 대수 sigma algebra, 또는 Borel field라고 한다.

시그마 필드

1)  $\varnothing \in \mathcal{B}$ (공집합은 $\mathcal{B}$에 포함된다).

2)  $A \in \mathcal{B}$라면 $A^{c} \in \mathcal{B}$ (보수 연산에 대해
    닫혀 있다).

3)  $A_{1},A_{2},\ldots \in \mathcal{B}$라면
    $\overset{\infty}{\bigcup_{i = 1}}A_{i} \in \mathcal{B}$ (가산
    합집합에 대해 닫혀 있다).

가장 간단한 시그마 대수는 $\{\varnothing,S\}$ 이다.

표본공간 $S$와 이에 연관된 시그마 대수 $\mathcal{B}$가 주어졌을 때,
확률함수 $P$는 다음 세 가지 조건을 만족하는 $\mathcal{B}$ 상의 함수이다.

확률함수 정의

1)  비음성 조건: $P(A) \geq 0\text{for all}A \in \mathcal{B}$. (모든
    사건 A 에 대해 확률은 0 이상이다.)

<!-- -->

4)  정규화 조건: $P(S) = 1$. (전체 표본 공간 S 의 확률은 항상 1이다.)

5)  가산 가법성 조건: 만약 $A_{1},A_{2},\ldots \in \mathcal{B}$가 쌍별로
    상호배타적이라면,
    $P\left( \bigcup_{i = 1}^{\infty}A_{i} \right) = \overset{\infty}{\sum_{i = 1}}P(A_{i})$.
    (가산 합집합의 확률은 개별 사건들의 확률 합과 같습니다.)

위 정의는 Kolmogorov 공리로 잘 알려져 있습니다. 이 공리적 정의는 확률을
직관적으로 정의하려는 시도(예: 빈도적 정의)와 달리, 수학적으로 엄격하고
보편적인 방식으로 확률을 설명합니다. 이 공리를 만족하는 함수는 모두 확률
함수로 간주됩니다.

- 확률 공간 probability space: 확률함수는 $(S,\mathcal{B},P)$로 정의되는
  확률 공간의 일부입니다. 여기서 $S$는 표본 공간, $\mathcal{B}$는 사건의
  집합(시그마 대수), $P$는 확률 함수입니다.

- 확률 함수의 다양성: 동일한 표본 공간에서도 여러 가지 확률 함수가
  정의될 수 있습니다. 예를 들어, 공정한 동전과 편향된 동전은 서로 다른
  확률 함수를 가질 수 있습니다.

2확률정의 방법

확률정의 방법)

$$S = \{\text{앞면, 뒷면}\},\mathcal{B} = \{ S,\varnothing,\{\text{앞면}\},\{\text{뒷면}\}\},P(\{\text{앞면}\}) = 0.5$$

1)  표본공간: 공정한 동전을 던지는 실험 $S = \{\text{H},\text{T}\}$

<!-- -->

6)  공정한 동전의 정의: 공정한 동전은 앞면과 뒷면이 나올 확률이 동일한
    동전을 의미합니다. 따라서 $P(\{\text{H}\}) = P(\{\text{T}\})$.

이 관계는직관에 의해 설정된 것이며 Kolmogorov 공리에서 직접적으로 도출된
것은 아닙니다.

7)  Kolmogorov 공리 적용: Kolmogorov 공리에 따라, 표본 공간 S 의 확률은
    $P(S) = 1$.

- $S = \{\text{H}\} \cup \{\text{T}\}$이고, 앞면과 뒷면은
  상호배타적이므로, 가산 가법성에 의해
  $P(\{\text{H}\} \cup \{\text{T}\}) = P(\{\text{H}\}) + P(\{\text{T}\})$.

- 이를 통해 $P(\{\text{H}\}) + P(\{\text{T}\}) = 1$이 성립합니다.

8)  결론: 앞면과 뒷면의 확률이 동일하므로
    $P(\{\text{H}\}) = P(\{\text{T}\}) = 0.5$.

다음 정리는 확률함수 $P$를 정의하는 구체적인 방법을 설명합니다. 이
정리는 유한 또는 가산 표본 공간에서 Kolmogorov 공리를 만족하는
확률함수를 체계적으로 정의하는 데 사용됩니다.

주어진 조건:

정리

표본공간 $S = \{ s_{1},s_{2},\ldots,s_{n}\}$는 유한 집합입니다.

$\mathcal{B}$는 $S$의 부분집합들로 이루어진 시그마 대수입니다.

$p_{1},p_{2},\ldots,p_{n}$은 0 이상의 숫자로 이들의 합은 1입니다
$\overset{n}{\sum_{i = 1}}p_{i} = 1$.

$A \in \mathcal{B}$에 대해 확률 함수 P(A) 는 다음과 같이 정의됩니다.

$$P(A) = \sum_{\{ i:s_{i} \in A\}}p_{i}$$

공집합에 대한 합은 0으로 정의됩니다. $P(\varnothing) = 0$.

가산 집합 확장: $S = \{ s_{1},s_{2},\ldots\}$가 가산 집합인 경우에도 위
방식으로 $P$를 정의할 수 있습니다. 이 경우에도 Kolmogorov 공리를
만족합니다.

확률정의 방법

다트 게임을 통해 확률을 정의하는 방법으로 표본공간에서 영역의 크기에
비례하여 확률을 정의하는 방법을 보여줍니다.

【문제 설정】

- 다트 게임에서는 다트를 던져 특정 영역에 맞추었을 때, 그 영역에
  해당하는 점수를 얻습니다.

- 초보 플레이어를 대상으로, 다트가 특정 영역에 맞을 확률이 영역의 면적에
  비례한다고 가정합니다.

- 따라서, 더 큰 영역은 맞을 확률이 더 높습니다.

【가정】

- 다트 보드의 반지름은 $r$입니다.

- 다트 보드에는 여러 개의 원형 영역이 있으며, 각 영역의 반지름은 일정
  간격으로 나뉩니다.

- 다트가 반드시 보드에 맞는다고 가정합니다.

【특정점수 $i$를 얻을 확률】

$P(\text{scoring}i\text{points}) = \frac{\text{Area of region}i}{\text{Area of dart board}}$.

【계산 과정】

- 점수 1을 얻을 확률: 영역 1은 중심 영역으로, 면적은 보드 전체 면적에서
  두 번째 원까지의 영역을 뺀 값입니다.

$$P(\text{scoring 1 point}) = \frac{\pi r^{2} - \pi(4r/5)^{2}}{\pi r^{2}} = 1 - \left( \frac{4}{5} \right)^{2}$$

- 영역 i 의 면적은 두 원 사이의 차이로 계산됩니다.

$$P(\text{scoring}i\text{points}) = \frac{(6 - i)^{2} - (5 - i)^{2}}{5^{2}},i = 1,2,\ldots,5$$

【특징】

- $\pi$와 $r$은 최종 확률 계산에서 상쇄되므로, 확률은 반지름과
  독립적입니다.

- 각 영역의 면적 합이 전체 보드 면적과 같으므로, 확률의 총합은 1이
  됩니다.

- 이 정의는 위 정리에 의해 올바른 확률 함수로 간주됩니다.

Chapter 3. 확률 계산

1확률계산 관련 정리

확률공리를 기반으로 확률 함수의 여러 성질을 유도하고, 이를 복잡한 확률
계산에 적용하는 방법을 설명합니다. 이러한 성질들은 단일 사건뿐만 아니라
결합 사건의 확률을 계산하는 데 매우 유용합니다.

$P$가 확률 함수이고 $A$가 $\mathcal{B}$에 속하는 임의의 집합일 때,
다음이 성립합니다.

정리

1)  $P(\varnothing) = 0$: 공집합의 확률은 항상 0입니다. 이는 직관적으로
    공집합에는 발생할 수 있는 사건이 없기 때문입니다.

<!-- -->

9)  $P(A) \leq 1$: 임의 사건 $A$의 확률은 1을 초과할 수 없습니다. 이는
    확률이 0에서 1 사이에 있어야 한다는 공리에서 유도됩니다.

10) $P(A^{c}) = 1 - P(A)$: 여집합의 확률은 A 의 확률을 전체 확률1에서 뺀
    값입니다.

$P$가 확률 함수이고, A 와 B가 $\mathcal{B}$에 속하는 임의의 집합일 때,
다음이 성립합니다.

정리

1)  $P(B \cap A^{c}) = P(B) - P(A \cap B)$.

<!-- -->

11) $P(A \cup B) = P(A) + P(B) - P(A \cap B)$.

12) $A \subseteq B$라면 $P(A) \leq P(B)$.

$P(A \cup B) \leq 1$ 이므로 정리 2)를 다음과 쓸 수 있다.

Bonferroni[']{dir="rtl"}s Inequality: $P(A \cap B) \geq P(A) + P(B) - 1$

$P$가 확률 함수이고, A 와 B가 $\mathcal{B}$에 속하는 임의의 집합일 때,
다음이 성립합니다.

정리

1)  $P(A) = \overset{\infty}{\sum_{i = 1}}P(A \cap C_{i})$, 각 $C_{i}$는
    상호배타적이고 $\overset{\infty}{\bigcup_{i = 1}}C_{i} = S$.

<!-- -->

13) (Boole[']{dir="rtl"}s Inequality)
    $P\left( \bigcup_{i = 1}^{\infty}A_{i} \right) \leq \overset{\infty}{\sum_{i = 1}}P(A_{i})$,
    모든 $A_{i}$는 임의의 집합입니다.

2확률계산

sample-point 방법

이산형(표본공간의 원소의 수가 한정적일 경우, 헤아릴 수 있는 경우)
확률실험에서 사건 A에 대한 확률 계산 방법이다.

1)  실험을 정의하고 표본공간을 정의한다. 표본공간의 원소 개수($N$)를
    카운트한다.

<!-- -->

14) 표본공간의 각 원소에 확률 공리를 만족하도록 하여 적절한 확률 값을
    할당한다. 라플라스 동등성 가정에 의해 각 원소의 활당 확률은
    ![equation.pdf](media/image4.png){width="0.2508519247594051in"
    height="0.11516732283464567in"}이다.

15) 사건A에 대한 원소를 정의하고 원소의 개수($n$)를 카운트 한다.

16) 사건 A의 원소들의 확률을 더해 사건 A의 확률로 정의한다.
    ![equation.pdf](media/image5.png){width="0.7038057742782152in"
    height="0.318500656167979in"}

곱의 법칙

r번의 실험, 각 실험의 결과 수가
![equation.pdf](media/image6.png){width="0.8390638670166229in"
height="0.11516732283464567in"}이라 하면 실험 전체 결과 수는
$n_{1} \times n_{2}... \times n_{r}$ 이다.

【예제】 컴퓨터 비번을 만들려고 한다. 총 7자리 중 첫 2자리는 소문자,
3번째는 대문자, 남은 4자리는 0\~9까지 숫자로 나열하여 만들 때 총 비번
개수는? $26 \times 26 \times 26 \times 10^{4}$

반복있고 순서 고려

실험의 결과 수가
![equation.pdf](media/image7.png){width="7.666666666666666e-2in"
height="7.500109361329833e-2in"}이고 실험을
![equation.pdf](media/image8.png){width="6.116688538932633e-2in"
height="7.3500656167979e-2in"}번 반복할 때 나타날 수 있는 결과(경우)
수는 ![equation.pdf](media/image9.png){width="0.13842082239720035in"
height="0.11535214348206474in"} 이다.

4자리로 숫자로 구성된 비밀번호을 잊었다. 반복이 가능하다면, 최악의 경우
몇 번이나 시도해야 맞출 수 있나? $10^{4}$

반복없이 나열

실험의 결과 수가
![equation.pdf](media/image10.png){width="7.666666666666666e-2in"
height="7.500109361329833e-2in"}이고 이를 나열하여 만들 수 있는 총 결과
수는 $n! = n \times (n - 1) \times ... \times 1$ 이다.

【예제】 4자리로 숫자로 구성된 비밀번호을 잊었다. 첫 번호에 0을 사용할
수 없고 반복이 불가능하다면, 최악의 경우 몇 번이나 시도해야 맞출 수
있나? $9 \times 9 \times 8 \times 7$

반복없고 순서 고려

n개의 서로 다른 원소들 중 r개를 뽑아 순서대로 배열할 경우 발생하는 총
결과 수는 $nP_{r} = \frac{n!}{(n - r)!}$ 이다.

【예제】 4자리로 숫자로 구성된 비밀번호을 잊었다. 반복이 불가능하다면,
최악의 경우 몇 번이나 시도해야 맞출 수 있나?
${}_{10}P_{4} = 10 \times 9 \times 8 \times 7$

【예제】 주머니에 6개의 칩이 있거 칩에는 E, E, P, P, P, R이 각각
적혀있다. (1) 복원 추출(with replacement) (2) 비복원 추출(without
replacement)로 하나씩 차례로 6개를 뽑아 영어 단어 PEPPER를 만들 확률을
구하시오.
$(1)P(\text{“PEPPER”}) = \frac{1}{2} \times \frac{1}{3} \times \frac{1}{2} \times \frac{1}{2} \times \frac{1}{3} \times \frac{1}{6}$

$(2)\frac{6!}{3! \times 2! \times 1!} = \frac{720}{6 \times 2 \times 1} = 60$
/720=1/12

반복, 순서 모두 없는 경우

n개의 서로 다른 원소들 중 r개를 뽑아 순서없이 배열할 경우 발생하는 총
결과 수 ${}_{n}C_{r} = \frac{n!}{(n - r)!r!}$ 이다.

【예제】 5명의 대학원생과 3명의 학부생이 공무원 시험에 응시하였다.
여기서 4명을 선발할 경우 대학원 생이 3명 포함되어 있을 확률을 구하시오.
$\frac{{}_{5}C_{3} \times_{3}C_{1}}{{}_{8}C_{4}}$

Enumerating Outcomes

유한 표본공간에서 가능한 결과를 나열하고, 이를 통해 확률을 계산하는
방법이다.

1)  유한 표본공간 $S = \{ s_{1},s_{2},\ldots,s_{N}\}$을 정의한다.

<!-- -->

17) 각 결과 $s_{j}$의 발생 가능성은 동일하다. $P(s_{j}) = \frac{1}{N}$

18) 사건 A 의 확률 계산:
    $P(A) = \sum_{s_{i} \in A}P(\{ s_{i}\}) = \sum_{s_{i} \in A}\frac{1}{N}$
    이는 사건 A 에 속한 원소의 개수를 전체 표본 공간의 원소 수로 나눈
    값과 같습니다.
    $P(A) = \frac{\text{no. of elements in}A}{\text{no. of elements in}S}$.

Chapter 4. 조건부 확률과 독립

1조건부 확률

만약 사건 A 와 B는 표본공간 $S$에서 정의더되고 $P(B) > 0$이라면, B가
발생했을 때 A가 발생할 조건부 확률은 다음과 같이 정의된다.
$P(A|B) = \frac{P(A \cap B)}{P(B)}$

조건부 확률 정의

【재표현】 $P(A \cap B) = P(A|B)P(B)$

조건부 확률은 사건 B가 발생했다고 가정하므로 B가 새로운 표본 공간 역할을
합니다. 상호 배타적인 사건 A와 B는 공통된 원소를 가지지 않으므로 조건부
확률은 0입니다.

【예제】 잘 섞인 52장의 카드 중에서 4장을 뽑을 때, 뽑은 4장이 모두
에이스일 확률을 계산 하시오.

(방법1) $P(\text{4 aces}) = 1/\binom{52}{4}$

(방법2)
$P(\text{4 aces}) = \frac{4}{52} \times \frac{3}{51} \times \frac{2}{50} \times \frac{1}{49} = \frac{1}{270,725}$

【예제】 뽑힌 $i$ 장 카드 중 에이스가 $i$ 개 있다면, 뽑은 4장이 모두
에이스일 확률을 계산 하시오.

$$P(\text{4 aces in 4 cards | i aces in i cards}) = \frac{P(\text{4 aces in 4 cards})}{P(\text{i aces in i cards})}$$

$$P(\text{4 aces in 4 cards}) = 1/\binom{52}{4}$$

$$P(\text{i aces in i cards}) = \frac{\binom{4}{i}}{\binom{52}{i}}$$

$$P(\text{4 aces in 4 cards | i aces in i cards}) = \frac{\binom{52}{i} \cdot \binom{4}{4}}{\binom{52}{4} \cdot \binom{4}{i}} = \frac{1}{\binom{52 - i}{4 - i}}$$

【Monte Hall Show】 몬티 홀 딜레마는 미국 TV 게임쇼
["]{dir="rtl"}Let[']{dir="rtl"}s Make a Deal"에서 유래한 퀴즈 게임으로,
진행자 몬티 홀의 이름을 따왔습니다. 이 게임에서 참가자는 세 개의 문 중
하나를 선택해, 문 뒤에 숨겨진 선물을 받을 기회를 갖습니다. 세 문 중 하나
뒤에는 자동차가, 나머지 두 문 뒤에는 염소가 있습니다.

예를 들어, 한 참가자가 1번 문을 선택했다고 가정해봅시다. 이때 진행자는
3번 문을 열어 염소가 있음을 보여준 후, 참가자에게 처음 선택한 1번 문
대신 2번 문으로 바꿀 기회를 제안합니다. 이 상황에서, 참가자가 자동차를
받을 확률을 최대화하려면 처음 선택을 유지하는 것이 좋을까요, 아니면
선택을 바꾸는 것이 유리할까요? 몬티 홀 문제는 이러한 질문을 통해 선택의
전략과 확률을 탐구하는 흥미로운 사례로, 단순한 직관에 반하는 결과를
보여줍니다.

![붙여넣은 동영상.png](media/image11.png){width="2.4516163604549432in"
height="1.3595330271216097in"}

선택을 바꾸지 않을 경우 자동차에 당첨될 확률은 $\frac{1}{3}$이지만,
선택을 바꿀 경우 확률은 $\frac{2}{3}$로 증가합니다. 그럼에도 불구하고,
대부분의 참가자는 처음 선택을 고수하는 경향을 보입니다. 이는 인간이 항상
합리적 선택을 한다는 전통 경제학의 가정에 반하는 사례로, 몬티 홀
딜레마는 이러한 점에서 매우 유명합니다. 전통 경제학에 따르면 인간은
합리적이고 이성적인 존재로, 언제나 자신의 이익을 극대화하기 위해
행동한다고 가정합니다. 따라서 전통 경제학의 관점에서 보면, 몬티 홀
문제를 푸는 합리적인 인간은 선택을 바꾸는 것이 당연한 전략이 될
것입니다.

【죄수 3인의 딜레마】 세 명의 수감자 A, B, C는 각각 별도의 감방에
수감되어 사형을 선고받았고, 주지사는 이들 중 무작위로 한 명을 사면하기로
결정하였습니다. 소장은 누가 사면 대상인지 알고 있지만, 이를 직접적으로
밝힐 수는 없습니다.

이 상황에서, 수감자 A는 교도관에게 처형될 두 사람 중 한 사람의 이름을
알려달라고 요청합니다. A는 다음과 같은 제안을 합니다: ["]{dir="rtl"}B가
사면 대상이라면 C의 이름을, C가 사면 대상이라면 B의 이름을 알려주세요.
만약 제가 사면 대상이라면 동전을 던져 B 또는 C 중 하나의 이름을
알려주세요." 이 요청에 따라 교도관은 A에게 B가 처형될 것이라고 말합니다.

이 말을 들은 A는 자신이 사면될 확률이 원래의 $\frac{1}{3}$에서
$\frac{1}{2}$로 높아졌다고 믿고 기뻐합니다. 반면, 수감자 C는 A와 다르게
자신이 사면될 확률이 $\frac{2}{3}$로 증가했다고 생각하며 안도합니다. 이
상황에서 누가 옳은 것일까요?

$$P(A|P) = \frac{P(AP)}{P(P)} = \frac{P(A)P(P|A)}{P(A)P(P|A) + P(B)P(P|B) + P(C)P(P|C)}$$

$= \frac{1/3 \times 1/2}{1/3 \times 1/2 + 1/3 \times 0 + 1/3 \times 1} = 1/3$.

$$P(C|P) = \frac{P(CP)}{P(P)} = \frac{P(C)P(P|C)}{P(A)P(P|A) + P(B)P(P|B) + P(C)P(P|C)}$$

$= \frac{1/3 \times 1}{1/3 \times 1/2 + 1/3 \times 0 + 1/3 \times 1} = 2/3$.

2독립

두 사건 A와 B가 독립적이면 아래와 같은 조건을 만족한다.
$P(A \cap B) = P(A)P(B$

독립 정의

사건 $E_{1},E_{2},{\ldots,E}_{k}$가 다음 조건을 만족하면 서로 독립
mutually independent 이라 한다.

서로독립 정의

$$P(E_{1}E_{2}...E_{k}) = P(E_{1})P(E_{2})...P(E_{k})$$

【사례】 도박사 Chevalier de Meré가 던진 질문을 다룬다. 그는 주사위를
4번 던졌을 때, 최소한 한 번 [']{dir="rtl"}6[']{dir="rtl"}이 나올 확률에
관심을 가졌다.

$$P(\text{at leat 1 six in 4 rolls}) = 1 - P(\text{no six in 4 rolls}) = 1 - (5/6)^{4}$$

【사례】 $P(A) = 0.5,P(B) = 0.3,P(AB) = 0.1$이다. 다음을 구하라.

1)  $$P(A|B) = P(AB)/P(B) = 0.1/0.3 = 1/3$$

2)  $$P(A|A \cup B) = \frac{P(A \cap (A \cup B))}{P(A \cup B)} = \frac{0.5}{0.5 + 0.3 - 0.1} = 5/7$$

3)  $$P(A|A \cap B) = \frac{P(A \cap (A \cap B))}{P(A \cap B)} = \frac{0.1}{0.1} = 1$$

【사례】 $P(A) > 0,P(B) > 0$이고 사건 A, B는 상호 배반이다. 서로
독립인가? 증명하라.

【풀이】 상호 배반이면 $A \cap B = \phi$이므로 $P(A \cap B) = 0$이므로
독립$(P(AB) \neq P(A)P(B))$은 아니다.

【사례】 만약 $P(A) > 0,P(B) > 0$, $P(A) < P(A|B)$이면
$P(B) < P(B|A)$임을 증명하라.

【풀이】 $P(A) < \frac{P(AB)}{P(B)}$이므로 $P(A)P(B) < P(AB)$이다.
그러므로 $P(B) < P(AB)/P(A) = P(B|A)$이다.

【사례】 두 사건 A, B는 서로 독립이다. 사건 $A,B^{c}$는 서로 독립인가?

【풀이】 두 사건 A, B는 서로 독립이면 $P(AB) = P(A)P(B)$,
$P(AB^{C}) = P(A) - P(AB) = P(A) - P(A)P(B) = P(A)(1 - P(B)) = P(A)P(B^{C})$이므로
독립이다.

동일한 방법으로 $(A^{c},B^{c}),(A^{c},B)$도 독립임을 보일 수 있다.

【사례】 동전을 세 번 던지는 실험의 표본공간은 다음과
같다.$S = \{ HHH,HHT,HTH,THH,TTH,THT,HTT,TTT\}$사건 $H_{i},i = 1,2,3$를
"i번째 던짐에서 앞면이 나오는 사건"으로 정의한다면 $H_{i}$는 서로
독립이다.

Chapter 5. 베이즈 확률

베이즈 규칙은 영국의 수학자이자 장로교 목사였던 토마스 베이즈(Thomas
Bayes, 1702--1761)가 발견했습니다. 그는 사후에 발표된 논문
\*["]{dir="rtl"}An Essay Towards Solving a Problem in the Doctrine of
Chances"\*에서 베이즈 정리를 처음으로 제시했습니다.

베이즈는 확률 이론을 사용하여 어떤 사건이 발생했을 때, 그 원인에 대해
추론하는 문제를 해결하려고 했습니다. 특히 그는 다음과 같은 상황을
다루고자 했습니다.

- 역추론 문제: 특정 결과가 관측되었을 때, 그 결과를 발생시킨 원인을
  역으로 추정하는 방법을 연구했습니다. 이는 주어진 데이터를 바탕으로
  사건의 사전 확률을 업데이트하는 과정으로, 오늘날 베이즈 통계학의
  기초가 됩니다.

- 불확실한 상황에서 의사결정: 특정한 사건이 발생할 가능성을 계산하고,
  주어진 추가 정보가 있을 때 확률을 어떻게 갱신할지를 이해하려는
  노력이었습니다.이는 확률을 동적으로 갱신하고 불확실성을 줄이는 데
  사용됩니다.

1전확률 법칙

$S = \bigcup_{i = 1}^{k}B_{i},B_{i}B_{j} = \phi fori \neq j,P\left( B_{i} \right) > 0$,
즉 $B_{1},B_{2},\ldots,B_{k}$ 상호 배타적 합이 표본공간인 mutually
exclusive and collectively exhausted 사건이라 하자. 임의의 사건 $A$에
대하여 다음이 성립하는데 이를 전확률 법칙이라 한다.

$$P(A) = \sum_{i = 1}^{k}{P(AB_{i})} = \sum_{i = 1}^{k}{P(B_{i})P({A|B}_{i})}$$

**B~1~**

**B~k~**

**A**

**B~4~...**

**B~3~**

**B~2~**

2베이지 규칙 Bayes Rule

영국 철학자 Thomas Bayes의 이름에서 유래된 것으로 사건 H(가설)의 확률을
새로운 사건 D(데이터)에 의해 조건부 확률을 계산하는 개념이다.
$P\left( H \middle| D \right) = \frac{P(D|H)P(H)}{P(D)}$.

$B_{1},B_{2},\ldots,B_{k}$ 상호 배타적 합이 표본공간인 mutually
exclusive and collectively exhausted 사건인 경우 다음이 성립하는데 이를
베이지 규칙이라 한다.

$$P\left( B_{j} \middle| A \right) = \frac{P(B_{j}A)}{P(A)} = \frac{P\left( B_{j} \right)P(A|B_{j})}{\sum_{i = 1}^{k}{P\left( B_{i} \right)P(A|B_{i})}}$$

【예제】 노랑 주머니에는 3개 빨강 구슬, 7개 파랑 구슬이 있고 초록
주머니에는 8개 빨강 구슬, 2개 파랑 구슬이 있다. 주사위를 굴려 5 이상
수가 나오면 노랑 주머니에서 4이하 수가 나오면 초록 주머니에서 구슬을
뽑는다고 하자. 뽑은 구슬이 빨강이었다면 그 구슬이 노랑 주머니에서 나왔을
확률은? (답) 1/3

> 3/30
>
> 7/30
>
> 16/30
>
> 4/30

3특이도와 민감도

> 3/30
>
> 7/30
>
> 16/30
>
> 4/30
>
> ![텍스트, 스크린샷, 번호, 폰트이(가) 표시된 사진 자동 생성된
> 설명](media/image13.png){width="4.106161417322834in"
> height="2.7589709098862643in"}

- 민감도 sensitivity : 양성(감염)을 양성으로 진단할 확률, 실제 양성
  중에서 모델이 양성으로 올바르게 예측한 비율.

- 특이도 specificity : 음성(정상)을 음성으로 진단할 확률

- 양성 예측율 positive predicted Value, 정밀도 precision: 양성 진단자 중
  참 양성 확률, 실제 음성 중에서 모델이 음성으로 올바르게 예측한 비율.

- 음성 예측율 negative predicted Value : 음성 진단자 중 참 음성 확률

- 감염율 prevalence : 전체 검사자 중 양성 비율

- 정확도 accuracy : 전체 예측 중에서 올바르게 예측한 비율.

- $\text{F1 Score} = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}$:
  정밀도와 민감도의 조화 평균. 불균형 데이터셋에서 정밀도와 민감도를
  함께 고려.

저자 정보

- 1982\. 성균관대학교 통계학 학사

- 1985\. 성균관대학교 통계학 석사

- 1992\. 미국 North Carolina State University 통계학 박사

- 1993-1995. 전자통신연구원 선임연구원

- 1995-2026. 한남대학교 통계학과 교수
