---
title: "MLDL 지도학습"
format: html
---

Chapter 1. 선형회귀 ≠ ML의 시작

권세혁교수 통계 사전 【지도학습】

지도학습은 흔히 선형회귀에서 출발한다고 설명되지만, 선형회귀 자체를
머신러닝의 출발점으로 동일시하는 것은 정확하지 않다.

이 장에서는 설명모형과 예측모형의 근본적인 차이를 출발점으로 삼아,
머신러닝이 회귀분석에서 출발하지만 왜 그 틀에 머물지 않는지를 살펴본다.
나아가 선형모형을 머신러닝 관점에서 어떻게 재해석할 수 있는지를 통계적
구조와 목표의 차이를 중심으로 정리한다.

선형회귀는 전통적으로 설명모형의 대표적인 도구이다. 반면 머신러닝은
동일한 수학적 형태에서 출발하더라도, 목표와 철학이 본질적으로 다르다.

머신러닝의 관점에서 선형회귀는 가장 단순한 예측기에 해당하며, 규제와
검증을 통해 보다 복잡한 예측 방법으로 확장된다. 따라서
["]{dir="rtl"}선형회귀는 ML의 시작이다"라는 표현은 형식적으로는 옳을 수
있으나, 개념적으로는 불완전한 설명이다.

1\. 설명모형과 예측모형의 차이

설명모형: ["]{dir="rtl"}왜 그런가?"에 대한 질문

전통적인 선형회귀는 설명을 주목적으로 하는 모형이다. 이때 분석의 관심은
주로 다음과 같은 요소에 놓인다.

회귀계수 $\beta_{j}$의 부호와 크기

통계적 유의성 (t-test, p-value)

모형의 해석 가능성

고전적 선형회귀는 다음과 같은 데이터 생성과정을 전제로 한다.

$Y = X\beta + \varepsilon,\mathbb{E}(\varepsilon \mid X) = 0,Var(\varepsilon) = \sigma^{2}$

이 가정하에서 회귀계수 $\beta$는 모집단 수준에서의 구조적 관계로
해석된다. 즉, 회귀분석은 단순히 관측값을 맞추는 것이 아니라, 데이터 뒤에
존재하는 생성 메커니즘을 추론하기 위한 통계적 도구이다.

예측모형: ["]{dir="rtl"}얼마나 잘 맞추는가?"에 대한 질문

반면, 머신러닝에서의 지도학습은 예측을 핵심 목표로 한다. 이때 관심의
대상은 다음과 같이 달라진다.

새로운 데이터 $x_{\text{new}}$에 대한 예측 정확도

일반화 오차 (generalization error)

테스트 데이터에서의 성능

이 관점에서 중요한 것은 개별 회귀계수의 해석이 아니라, 입력 X로부터 출력
Y를 얼마나 잘 예측하는 함수 $f$ 자체의 성능이다.

$\widehat{Y} = f(X)$, 여기서 $f$는 함수 공간에 속하며, 반드시 선형일
필요는 없다. 머신러닝은 특정 계수의 의미보다는, 훈련 데이터에서 학습된
함수가 보지 못한 데이터에서도 얼마나 잘 작동하는가에 초점을 둔다.

  ----------------------- ----------------------- -----------------------
           구분                  설명모형                예측모형

         관심 질문               왜 그런가          얼마나 잘 맞추는가

         핵심 대상             모수 $\beta$            예측함수 $f$

         평가 기준             유의성, 해석             테스트 오차

        데이터 관점        데이터 생성과정 복원      미지 데이터 적합
  ----------------------- ----------------------- -----------------------

2\. ML은 회귀에서 출발하나 회귀는 아니다

공통 출발점: 손실함수 최소화

선형회귀와 머신러닝은 표면적으로 서로 다른 학문 영역처럼 보이지만,
수학적으로는 동일한 출발점을 공유한다. 두 방법 모두 관측된 데이터에서
예측 오차를 최소화하는 문제로 기술될 수 있다.

선형회귀는 다음과 같은 제곱손실 최소화 문제로 표현된다.

$$\widehat{\beta} = \arg\min_{\beta}\overset{n}{\sum_{i = 1}}(y_{i} - x_{i}^{\top}\beta)^{2}$$

이 식은 반응변수 $y_{i}$와 설명변수 $x_{i}$로부터 계산된 예측값
$x_{i}^{\top}\beta$사이의 차이를 제곱한 값을 최소화하는 최적화 문제이다.
이 관점에서 선형회귀는 통계적 추론 이전에 이미 하나의 최적화 문제로
해석될 수 있다.

머신러닝 역시 기본적으로는 손실함수의 최소화를 목표로 한다. 일반적인
지도학습 문제는 다음과 같이 표현된다.

$$\widehat{f} = \arg\min_{f \in \mathcal{F}}\frac{1}{n}\overset{n}{\sum_{i = 1}}L(y_{i},f(x_{i}))$$

여기서 $L( \cdot , \cdot )$는 손실함수이며, $\mathcal{F}$는 고려하는
함수 공간을 의미한다. 선형회귀는 이 일반적인 틀에서 손실함수로
제곱손실을 사용하고, 함수 공간을 선형 함수로 제한한 특수한 경우에
해당한다.

이러한 이유로 선형회귀는 머신러닝의 자연스러운 출발점이 된다. 그러나 이
공통점은 손실함수 최소화라는 형식적 측면에 국한된다. 이후의 차이는
손실함수를 최소화하는 과정에서 어떤 가정을 유지하고, 어떤 제약을
완화하는가에 따라 결정된다.

이 지점에서 선형회귀와 머신러닝은 같은 문제에서 출발하지만, 서로 다른
방향으로 분기하게 된다.

결정적 분기점: ["]{dir="rtl"}무엇을 고정하고 무엇을 유연하게 둘 것인가"

전통적인 선형회귀에서는 모형 구조가 사전에 고정된다. 설명변수와 반응변수
사이의 관계는 선형으로 가정되며, 분석의 불확실성은 오차항을 통해
확률적으로 모델링된다. 이때 관심의 중심은 회귀계수 자체이며, 추정된
계수는 모집단 수준의 구조적 관계를 반영하는 것으로 해석된다. 따라서
회귀분석의 목적은 모형의 적합 그 자체보다는, 계수에 대한 추론과 해석에
놓인다.

반면 머신러닝에서는 모형 구조를 고정된 전제로 두지 않는다. 함수의 형태는
데이터에 따라 유연하게 변화할 수 있으며, 오차항의 분포에 대한 명시적
가정은 필수가 아니다. 분석의 목표 역시 모수 추론이 아니라, 관측되지 않은
새로운 데이터에 대한 예측 성능에 있다. 이 관점에서 중요한 것은 특정
계수의 통계적 유의성이 아니라, 학습된 함수가 얼마나 안정적으로
일반화되는가이다.

이 차이로 인해 머신러닝은 모형 해석의 명확성을 일부 포기하는 대신,
복잡한 구조와 비선형 관계를 포착할 수 있는 자유도를 확보한다.

회귀가 ML의 시작일 수는 있으나, ML 자체는 아닌 이유

선형회귀는 머신러닝의 출발점으로 활용될 수는 있으나, 그 자체로
머신러닝이라고 보기는 어렵다. 그 이유는 다음과 같다.

첫째, 선형회귀는 일반화 성능을 직접적으로 최적화하지 않는다. 전통적인
회귀분석에서의 적합 기준은 주로 학습 데이터에서의 오차 최소화이며,
새로운 데이터에서의 성능은 부차적인 고려 대상이다.

둘째, 모델 복잡도에 대한 통제가 제한적이다. 설명변수의 수가 증가하거나
변수 간 상관성이 커질 경우, 추정된 계수의 분산이 급격히 증가할 수 있다.

셋째, 고차원 자료나 비선형 구조에 취약하다. 선형회귀는 구조적으로 선형
관계에 의존하므로, 복잡한 패턴을 직접적으로 학습하기 어렵다.

머신러닝은 이러한 한계를 극복하기 위해 규제, 비선형 변환, 앙상블 기법,
신경망과 같은 방법들을 도입해 왔다. 이 과정에서 핵심은 특정 알고리즘이
아니라, 모델 선택과 평가를 중심으로 한 학습의 틀이다.

선형모형의 재해석: ML 관점에서의 선형회귀

1\. 선형회귀를 가장 단순한 예측기로 보기

머신러닝의 관점에서 선형회귀는 설명을 위한 종착점이 아니라, 예측 성능
비교를 위한 기준선 모형으로 재해석된다. 선형회귀는 함수 공간을 선형
함수로 제한한 가장 단순한 예측모형에 해당한다.

복잡도 관점에서 보면, 선형회귀는 높은 편향과 낮은 분산을 갖는 모형으로
이해할 수 있으며, 이는 이후에 등장하는 보다 유연한 모델들과의 비교
기준을 제공한다.

2\. 규제를 통한 ML적 확장

선형회귀는 규제를 도입하는 순간, 통계적 추론 도구에서 머신러닝 모델로
성격이 전환된다. 규제를 포함한 목적함수는 다음과 같이 표현된다.

$$\widehat{\beta} = \arg\min_{\beta}\left\{ \overset{n}{\sum_{i = 1}}(y_{i} - x_{i}^{\top}\beta)^{2} + \lambda \parallel \beta \parallel_{q} \right\}$$

q = 2: Ridge 회귀는 계수 크기를 제어하여 분산을 감소시킨다

q = 1: Lasso 회귀는 변수 선택 효과를 통해 모형을 단순화한다

이때 규제 강도 $\lambda$는 해석의 대상이 아니라, 교차검증을 통해
선택되는 튜닝 파라미터이다. 이는 전통적 회귀분석과 머신러닝 사이의
중요한 관점 전환을 보여준다.

3\. 중요한 관점 전환

머신러닝 관점에서 선형회귀를 사용할 때 핵심은 회귀계수의 개별적 의미가
아니다. 대신 다음과 같은 질문이 중심이 된다.

이 모형은 전체 함수 공간에서 어느 수준의 복잡도를 갖는가

다른 예측모형들과 비교했을 때 성능은 어떠한가

교차검증을 통해 선택될 수 있는 합리적인 기준선인가

이 관점에서 선형회귀는 설명을 위한 최종 모델이 아니라, 더 복잡한
예측모형으로 나아가기 위한 출발점이자 기준선으로 기능한다.

  ----------------------------------- -----------------------------------
               전통 회귀                            ML 관점

             $\beta$ 해석                    $\widehat{y}$ 정확도

               모수 추론                           함수 선택

               가정 중심                           검증 중심
  ----------------------------------- -----------------------------------

Chapter 2. 손실함수와 확률모형

머신러닝에서 학습이란 궁극적으로 손실함수를 최소화하는 문제로 귀결된다.
그러나 손실함수는 단순한 계산 도구가 아니라, 데이터 생성 과정에 대한
암묵적인 확률 가정을 내포한다.

이 장에서는 손실함수가 수행하는 통계적 역할을 정리하고, 대표적인
손실함수들이 각각 어떤 확률모형을 전제하는지를 체계적으로 살펴본다. 이를
통해 손실함수 선택이 단순한 기술적 문제가 아니라, 데이터를 어떤 확률
구조로 이해할 것인가에 대한 선택임을 분명히 한다.

손실함수는 단순한 계산 도구가 아니라 통계적 가정의 집합이다.

ERM(경험적 위험 최소화)은 기대 위험을 표본 기반으로 근사하는 통계적
원리이다.

MSE, MAE, Cross-Entropy는 각각 서로 다른 확률모형을 전제한다.

손실함수 선택은 곧 ["]{dir="rtl"}데이터를 어떤 확률 구조로 이해할
것인가"에 대한 선택이다.

1\. 손실함수의 역할과 의미

손실함수란 무엇을 측정하는가

손실함수는 관측값 y와 예측값 \\hat{y} 사이의 불일치 정도를 수치화한
함수이다. 지도학습에서의 학습 문제는 일반적으로 다음과 같이 정식화된다.

$\widehat{f} = \arg\min_{f \in \mathcal{F}}\frac{1}{n}\overset{n}{\sum_{i = 1}}L(y_{i},f(x_{i}))$,
여기서 $L( \cdot , \cdot )$는 손실함수이며, $\mathcal{F}$는 고려하는
함수 공간이다.

이 식에서 중요한 점은 두 가지이다. 첫째, 손실함수는 모델 선택의 기준이
된다. 둘째, 손실함수는 무엇이 좋은 예측인가를 정의한다. 즉, 손실함수는
단순한 평가 지표가 아니라 학습의 목표 자체를 규정한다.

손실함수와 평가 지표의 차이

평가 지표(metric)는 학습이 끝난 후 모델의 성능을 비교하거나 보고하기
위한 수단이다. 반면 손실함수는 학습 과정에서 직접 최소화되는 대상이다.
두 개념은 밀접하게 연결되어 있지만, 목적과 역할은 다르다.

통계적 관점에서 손실함수는 위험을 정의하는 핵심 요소이며, 학습 문제의
성격을 결정한다.

2\. 경험적 위험 최소화(Empirical Risk Minimization)

기대 위험과 경험적 위험

이론적으로 이상적인 학습 목표는 모집단 분포 하에서의 평균 손실을
최소화하는 것이다.

$$R(f) = \mathbb{E}\lbrack L(Y,f(X))\rbrack$$

이를 기대 위험(expected risk)이라 한다. 그러나 실제로는 데이터 생성
분포를 알 수 없으므로, 다음과 같은 표본 기반 문제를 풀게 된다.

$$\widehat{R}(f) = \frac{1}{n}\overset{n}{\sum_{i = 1}}L(y_{i},f(x_{i}))$$

이를 경험적 위험(empirical risk)이라 한다.

ERM의 통계적 의미

경험적 위험 최소화는 다음과 같은 가정을 전제로 한다. 관측 데이터는
모집단에서 독립적이고 동일한 분포로 추출되며, 표본 평균은 기대값의
일관된 추정량이라는 가정이다.

즉, ERM은 대수의 법칙에 기반한 통계적 추론 절차이다. 머신러닝이 흔히
확률 가정을 하지 않는다고 설명되지만, ERM 자체는 이미 확률적 사고 위에
서 있다.

3\. 대표적 손실함수의 통계적 해석

1\. MSE (Mean Squared Error) $L(y,\widehat{y}) = (y - \widehat{y})^{2}$

MSE를 최소화하는 것은 다음 확률모형을 암묵적으로 가정한다.

$$Y \mid X = x \sim \mathcal{N}(f(x),\sigma^{2})$$

즉, 오차는 정규분포, 분산은 상수, 조건부 평균이 예측 목표이다. 따라서
MSE 최소화는 \*\*정규오차 가정 하의 최대우도추정(MLE)\*\*과 동치이다.

2\. MAE (Mean Absolute Error) $L(y,\widehat{y}) = |y - \widehat{y}|$

MAE는 다음 분포를 전제한다.

$$Y \mid X = x \sim \text{Laplace}(f(x),b)$$

이 경우 예측 목표는 조건부 평균이 아니라 조건부 중앙값이다. 따라서 MAE는
이상치에 대해 더 강건한 성질을 갖는다.

3\. Cross-Entropy (Log Loss)

이진 분류의 경우 손실함수는 다음과 같다.

$$L(y,p) = - \lbrack y\log p + (1 - y)\log(1 - p)\rbrack$$

이는 다음 확률모형과 정확히 대응된다.

$$Y \mid X = x \sim \text{Bernoulli}(p(x))$$

즉, Cross-Entropy 최소화는 베르누이 분포에 대한 로그우도 최대화이다.
로지스틱 회귀, 신경망 분류 모두 이 구조를 공유한다.

4\. 손실함수 선택이 내포하는 확률 가정

손실함수와 분포 선택

손실함수를 선택한다는 것은 단순히 계산 규칙을 정하는 것이 아니라,
데이터의 오차 구조를 어떻게 이해할 것인가를 결정하는 행위이다. 이는
오차가 어떤 분포를 따른다고 볼 것인지, 예측의 기준을 조건부 평균으로 둘
것인지, 중앙값이나 확률로 둘 것인지를 함께 선택하는 것을 의미한다.

또한 손실함수에 따라 이상치에 얼마나 민감하게 반응할 것인지도 자연스럽게
결정된다. 이러한 점에서 손실함수의 선택은 통계모형에서 확률분포를
선택하는 행위와 본질적으로 동일한 의미를 갖는다.

["]{dir="rtl"}머신러닝은 확률 가정을 하지 않는다"는 오해

머신러닝은 오차항의 분포를 명시적으로 기술하지 않으며, 모수의 신뢰구간을
제시하지 않는 경우가 많다. 그러나 손실함수를 통해 확률모형을 암묵적으로
채택한다.

따라서 손실함수는 머신러닝에서 가장 중요한 통계적 가정이 위치하는
지점이며, 학습 알고리즘의 성격을 결정하는 핵심 요소이다.

Chapter 3. 로지스틱 회귀를 분류기로 다시 보기

로지스틱 회귀는 오랫동안 분류 문제의 대표적인 방법으로 소개되어 왔다.
그러나 통계적 관점에서 로지스틱 회귀는 본질적으로 분류기라기보다는, 이진
반응변수에 대한 조건부 확률을 추정하는 확률모형이다. 즉, 로지스틱 회귀의
1차적 목적은 개별 관측치가 특정 범주에 속할 확률을 추정하는 데 있으며,
분류는 그 이후에 수행되는 의사결정의 결과이다.

이 장에서는 로지스틱 회귀의 통계적 구조를 다시 정리하고, 확률 예측과
분류 결정을 명확히 구분하여 이해한다. 이를 통해 로지스틱 회귀 학습에서
사용되는 손실함수와, 실제 분류 성능을 평가할 때 사용하는 지표 사이에 왜
불일치가 발생하는지를 설명한다. 이러한 불일치는 모형의 결함이 아니라,
확률 추정과 의사결정이 서로 다른 단계에 속하기 때문에 발생하는 구조적
현상이다.

로지스틱 회귀는 본질적으로 이진 반응변수에 대한 확률모형이며, 학습의
목적은 분류 정확도를 직접적으로 극대화하는 것이 아니라 조건부 확률을
일관되게 추정하는 데 있다. 분류는 추정된 확률값에 임계값을 적용함으로써
이루어지며, 이 임계값의 선택은 분석 목적이나 비용 구조에 따라 달라질 수
있다.

이러한 관점에서 보면, 분류 성능지표와 손실함수 사이의 불일치는
자연스럽고 정상적인 결과이다. 손실함수는 확률 추정의 정확성을 평가하는
기준인 반면, 분류 성능지표는 확률값에 기반한 의사결정의 결과를 평가하기
때문이다. 따라서 로지스틱 회귀를 분류기로 이해하기 위해서는 확률모형과
분류 규칙을 명확히 분리하여 사고할 필요가 있다.

이 구분을 통해 로지스틱 회귀는 단순한 분류 알고리즘이 아니라, 확률
예측을 중심으로 한 통계적 모델이라는 본래의 성격을 보다 분명하게 이해할
수 있다.

1\. 로지스틱 회귀의 통계적 구조

기본 모형

이진 반응변수 $Y \in \{ 0,1\}$에 대해 로지스틱 회귀는 다음을 가정한다.

$Y \mid X = x \sim \text{Bernoulli}(p(x))$,
$\log\frac{p(x)}{1 - p(x)} = x^{\top}\beta$

즉, 반응변수는 베르누이 분포를 따르며, 설명변수는 성공확률의 로그 오즈에
선형적으로 작용한다. 이때 $p(X) = \mathbb{P}(Y = 1 \mid X)$는 조건부
확률로 해석된다. 이 구조는 처음부터 끝까지 확률모형으로 구성되어 있으며,
로지스틱 회귀는 분류 규칙이 아니라 확률 생성 메커니즘을 명시적으로
모델링한다.

학습 = 최대우도추정

로지스틱 회귀의 학습은 다음과 같은 로그우도를 최대화하는 문제로
정의된다.

$$\ell(\beta) = \overset{n}{\sum_{i = 1}}\lbrack y_{i}\log p_{i} + (1 - y_{i})\log(1 - p_{i})\rbrack$$

이는 곧 Cross-Entropy 손실을 최소화하는 문제와 동치이다. 따라서 로지스틱
회귀는 분류 정확도를 직접적으로 최적화하는 모형이 아니라, 조건부 확률
$p(X)$를 일관되게 추정하도록 설계된 확률모형이다.

2\. 확률 예측과 분류 결정의 차이

확률 예측: 통계적 산출물

로지스틱 회귀의 직접적인 결과는 각 관측치에 대해 추정된 조건부 확률이다.

$$\widehat{p}(X) = \mathbb{P}(Y = 1 \mid X)$$

이 확률값은 단순한 분류 결과 이상의 정보를 담고 있다. 확률 예측은 개별
관측치에 대한 불확실성의 정도를 표현하며, 결정 경계 근처에 위치한
관측치가 얼마나 애매한지를 보여준다. 또한 손실이나 비용이 비대칭적인
상황에서는 위험 기반 의사결정을 가능하게 한다. 이처럼 확률 예측은
연속적이며 정보가 풍부한 통계적 산출물이다.

분류 결정: 추가 규칙의 도입

분류는 확률 예측 위에 결정 규칙을 추가함으로써 이루어진다. 일반적으로는
다음과 같은 임계값 기반 규칙이 사용된다.

$\widehat{y} = \{\begin{matrix}
1 & \text{if}\widehat{p}(x) \geq c \\
0 & \text{otherwise}
\end{matrix}$, 여기서 임계값 $c$는 통계적으로 자동 결정되지 않으며, 오류
비용, 위험 선호, 문제의 목적에 따라 외생적으로 정해진다. 즉, 로지스틱
회귀는 분류기를 직접 만들어내지 않으며, 분류기는 로지스틱 회귀가 제공한
확률 예측 위에서 별도의 규칙을 통해 구성된다.

이 점을 혼동할 경우, 로지스틱 회귀가 곧 분류 규칙을 학습한다고 오해하기
쉽다.

흔한 오해

  ----------------------------------- -----------------------------------
                 오해                             정확한 해석

     로지스틱 회귀는 분류모형이다                확률모형이다

            0/1을 예측한다                      확률을 예측한다

           정확도가 목적이다                  로그우도가 목적이다
  ----------------------------------- -----------------------------------

3\. 분류 성능지표와 손실함수의 불일치

손실함수와 평가 지표의 차원 차이

로지스틱 회귀의 학습 과정에서 최소화되는 대상은 Cross-Entropy, 즉
로그손실이다. 이는 확률 예측의 정합성을 평가하는 손실함수이다. 반면 실제
분류 성능 평가는 정확도, Precision과 Recall, F1-score, ROC--AUC와 같은
지표를 사용한다.

이 두 종류의 기준은 서로 다른 대상을 측정한다. 손실함수는 연속적인 확률
예측의 품질을 평가하는 반면, 분류 성능지표는 임계값 이후의 이산적인 결정
결과만을 평가한다.

불일치가 발생하는 이유

이로 인해 다음과 같은 현상이 자연스럽게 발생할 수 있다. 로그손실은
지속적으로 개선되지만 분류 정확도는 변하지 않을 수 있으며, 반대로
정확도는 높지만 확률 예측이 심하게 왜곡된 모델도 존재할 수 있다.

통계적 관점에서 보면 이는 모형의 결함이 아니라, 확률 추정과 의사결정이
서로 다른 단계에 속하기 때문에 발생하는 구조적 결과이다. 로지스틱 회귀는
확률모형으로서의 역할을 충실히 수행하고 있으며, 분류 성능은 그 위에 얹힌
결정 규칙과 평가 기준에 의해 추가적으로 결정된다.

통계적 관점에서의 해석

  ----------------------------------- -----------------------------------
                 단계                                역할

             로지스틱 회귀                     조건부 확률 추정

               손실함수                     확률모형의 적합도 평가

               분류 규칙                      의사결정 기준 반영

               성능지표                         결정 결과 평가
  ----------------------------------- -----------------------------------

4\. 임계값 선택, 비용 민감 분류, 그리고 ROC 곡선

로지스틱 회귀에서 분류는 확률 예측 이후에 수행되는 의사결정 단계이다.
따라서 분류 결과는 확률 추정의 정확성뿐만 아니라, 예측 확률에 적용되는
임계값의 선택에 의해 결정된다. 이 임계값은 통계적으로 자동 결정되는 값이
아니며, 문제의 목적과 오류 비용 구조에 따라 외생적으로 설정된다.

임계값 선택과 분류 성능의 변화

이진 분류에서 흔히 사용되는 임계값 0.5는 두 범주의 오류 비용이
동일하다는 강한 가정을 전제로 한다. 그러나 실제 문제에서는 이 가정이
성립하지 않는 경우가 대부분이다. 임계값을 낮추면 양성으로 분류되는
관측치가 증가하여 재현율은 높아지지만, 위양성 오류도 함께 증가한다.
반대로 임계값을 높이면 정밀도는 향상되지만, 양성을 놓칠 가능성이 커진다.

이처럼 임계값은 분류 성능지표 간의 균형을 조절하는 핵심적인 결정
변수이다.

비용 민감 분류와 최적 임계값

비용 민감 분류에서는 오류의 유형에 따라 서로 다른 비용을 부여한다.
양성을 놓치는 오류의 비용을 C\_{FN}, 음성을 잘못 양성으로 분류하는
오류의 비용을 C\_{FP}라고 하면, 기대 비용을 최소화하는 분류 규칙은
다음과 같이 표현될 수 있다.

$$\widehat{y} = 1\text{if}\widehat{p}(X) \geq \frac{C_{FP}}{C_{FP} + C_{FN}}$$

이 식은 최적의 임계값이 데이터로부터 자동 추정되는 값이 아니라, 오류
비용의 상대적 크기에 의해 결정된다는 점을 보여준다. 즉, 임계값 선택은
통계적 추정의 문제가 아니라 의사결정의 문제이다.

ROC 곡선의 역할

ROC 곡선은 임계값을 변화시키면서 얻어지는 참양성률과 위양성률의 관계를
시각화한 도구이다. ROC 곡선은 특정 임계값에서의 분류 성능을 제시하지
않으며, 가능한 모든 임계값에 대해 분류 성능이 어떻게 변화하는지를
전체적으로 보여준다.

이 점에서 ROC 곡선은 하나의 최적 분류기를 제안하는 도구가 아니라, 임계값
선택에 따른 성능 변화의 범위를 제시하는 탐색 도구로 이해하는 것이
타당하다.

ROC와 확률 예측의 관계

ROC 분석은 예측 확률의 절대적인 크기보다는, 양성과 음성을 얼마나 잘
구분하여 순위화할 수 있는지를 평가한다. 따라서 ROC--AUC는 확률 예측의
보정 상태나 정확성을 직접적으로 반영하지 않으며, 확률 예측의 분리 능력을
요약한 지표로 해석되어야 한다.

동일한 ROC--AUC 값을 갖는 모델이라 하더라도, 예측 확률의 해석 가능성이나
신뢰성은 크게 다를 수 있다.

통합적 해석

로지스틱 회귀에서 분류 성능은 확률 예측, 임계값 선택, 오류 비용 구조가
결합된 결과이다. ROC 곡선은 이 관계를 한눈에 보여주는 도구이며, 비용
민감 분류는 ROC 곡선 위의 특정 지점을 선택하는 문제로 해석할 수 있다.

이러한 관점에서 로지스틱 회귀는 단순한 분류 알고리즘이 아니라, 확률
예측을 중심으로 한 통계적 의사결정 프레임워크로 이해되어야 한다.

Chapter 4. 머신러닝 정규화

머신러닝에서 정규화(regularization)는 흔히 과적합을 막기 위한 기술적
장치로 소개된다. 그러나 통계적 관점에서 정규화는 단순한 테크닉이 아니라,
모형 파라미터에 대한 사전적 믿음(prior belief)을 수식으로 구현한 것이다.
즉, 정규화는 데이터를 어떻게 해석할 것인가에 대한 통계적 선택을
명시적으로 반영한다.

정규화는 단순한 과적합 방지 기법이 아니다. 이는 계수에 대한 사전적
믿음을 수식으로 표현한 것이며, L2 정규화는 정규분포 prior, L1 정규화는
Laplace 분포 prior에 대응한다. 이러한 정규화된 학습은 본질적으로
최대사후확률(MAP) 추정 문제로 이해할 수 있다. 이 관점에서 머신러닝은
확률을 배제한 통계가 아니라, 확률을 다른 언어로 표현한 통계라고 볼 수
있다.

1\. ["]{dir="rtl"}과적합을 막는다"는 말의 정확한 의미

과적합의 통계적 의미

과적합이란 학습 데이터에서는 손실이 매우 작지만, 새로운 데이터에서는
예측 오차가 급격히 증가하는 상태를 의미한다. 이는 추정량의 분산이
지나치게 커진 상황으로 해석할 수 있다. 즉, 데이터에 과도하게 적합된
모형은 작은 데이터 변동에도 민감하게 반응하며, 일반화 성능이 저하된다.

정규화는 이러한 문제를 해결하기 위해 분산을 의도적으로 줄이는 개입이다.
일부 편향을 허용하는 대신, 전체적인 예측 안정성을 확보하는 것이 정규화의
핵심 목적이다.

정규화의 본질: 모형을 덜 믿게 만드는 장치

정규화의 도입은 데이터가 말하는 것을 100% 신뢰하지 않겠다는 선언에
가깝다. 이는 회귀계수의 크기가 과도하게 커지는 것을 허용하지 않고,
불필요하게 복잡한 해를 피하며, 적당히 단순한 모형을 선호하겠다는
의미이다. 이러한 선호가 수식으로 표현된 것이 정규화 항이다.

2\. L2 정규화(Ridge)의 통계적 해석

L2 정규화를 포함한 학습 문제는 다음과 같이 표현된다.

$$\widehat{\beta} = \arg\min_{\beta}\left\{ \overset{n}{\sum_{i = 1}}(y_{i} - x_{i}^{\top}\beta)^{2} + \lambda \parallel \beta \parallel_{2}^{2} \right\}$$

이 목적함수에서 두 항은 서로 다른 역할을 수행한다. 첫 번째 항은 데이터에
대한 적합도를 나타내며, 두 번째 항은 회귀계수의 크기에 대한 제약을
의미한다.

L2 정규화(Ridge)의 확률모형 관점

$$(y_{i} - x_{i}^{\top}\beta)^{2} \leftrightarrow \varepsilon_{i} \sim \mathcal{N}(0,\sigma^{2})$$

이제 정규화 항을 확률적으로 해석하면,
$\parallel \beta \parallel_{2}^{2} \leftrightarrow \beta_{j} \sim \mathcal{N}(0,\tau^{2})$

정규화 항을 확률적으로 해석하면, 이는 회귀계수에 대해 평균이 0이고
분산이 제한된 정규분포 prior를 부여한 것과 동일하다. 즉, Ridge 회귀는
오차항이 정규분포를 따른다는 가정과 함께, 회귀계수 역시 0을 중심으로
분포한다는 사전적 믿음을 전제한다.

결론: Ridge = MAP 추정

Ridge 회귀는 다음 문제와 동치이다.

$${\widehat{\beta}}_{\text{MAP}} = \arg\max_{\beta}\{\log p(y \mid X,\beta) + \log p(\beta)\}$$

즉, 정규 prior를 둔 베이즈 회귀의 최대사후확률(MAP) 추정량이다. 이러한
설정 하에서 Ridge 회귀는 정규 prior를 둔 베이즈 회귀모형의 최대사후확률
추정량과 동치이다. 따라서 Ridge 회귀는 빈번도적 기법처럼 보이지만,
본질적으로는 MAP 추정 문제로 해석할 수 있다.

3\. L1 정규화(Lasso)의 통계적 해석

$$\widehat{\beta} = \arg\min_{\beta}\left\{ \overset{n}{\sum_{i = 1}}(y_{i} - x_{i}^{\top}\beta)^{2} + \lambda \parallel \beta \parallel_{1} \right\}$$

L1 정규화의 가장 중요한 특징은 일부 회귀계수를 정확히 0으로 만들어 변수
선택 효과를 발생시킨다는 점이다. 이는 Ridge 회귀와 구별되는 Lasso의
핵심적인 성질이다.

확률모형 관점에서의 Lasso

$$\parallel \beta \parallel_{1} \leftrightarrow \beta_{j} \sim \text{Laplace}(0,b)$$

Laplace 분포는 0 근처에 확률 질량이 매우 크고 꼬리가 뾰족한 분포이다
이는 다음과 같은 사전 믿음을 반영한다. ["]{dir="rtl"}대부분의 변수는
중요하지 않고, 소수만 중요할 것이다."

Lasso의 통계적 의미

이러한 이유로 Lasso는 단순한 변수 선택 기법이 아니라, 희소성(sparsity)에
대한 강한 prior와 구조적 단순성에 대한 신념을 수식으로 구현한 결과로
이해할 수 있다.

4\. 정규화와 사전분포(prior)의 연결

정규화된 학습 문제는 일반적으로 다음과 같은 형태로 표현할 수 있다.

$$\arg\min_{\theta}\{ - \log p(y \mid X,\theta) - \log p(\theta)\}$$

  ----------------------------------- -----------------------------------
                ML 표현                           통계적 해석

               손실함수                            로그우도

               정규화 항                         로그 사전분포

                 학습                              MAP 추정
  ----------------------------------- -----------------------------------

이 구조는 정규화가 단순히 prior처럼 보이는 것이 아니라, prior를
명시적으로 쓰지 않은 베이즈 추론의 또 다른 표현임을 보여준다.
머신러닝에서는 prior라는 용어를 사용하지 않을 뿐, 정규화를 통해 모형에
대한 믿음을 명확히 반영한다.

이 관점에서 정규화는 머신러닝과 베이즈 통계 사이의 연결 고리이며, 두
접근법이 서로 다른 언어를 사용해 동일한 통계적 아이디어를 표현하고
있음을 드러낸다.

5\. Bias--Variance 관점에서의 정규화

정규화의 효과는 단순히 과적합을 막는다는 표현만으로는 충분히 설명되지
않는다. 정규화는 추정량의 편향과 분산 사이의 균형을 의도적으로 조정하는
통계적 개입으로 이해하는 것이 보다 정확하다.

Bias--Variance 분해와 일반화 오차

예측 오차는 일반적으로 편향, 분산, 그리고 제거할 수 없는 잡음으로 분해할
수 있다. 이 중 모델 선택과 학습 방법에 의해 영향을 받는 요소는 편향과
분산이다. 분산이 큰 모델은 학습 데이터의 작은 변동에도 예측 결과가 크게
달라지며, 이는 일반화 성능 저하로 이어진다. 반대로 편향이 큰 모델은
구조적으로 단순하여 복잡한 패턴을 충분히 포착하지 못한다.

정규화는 이 중 분산을 줄이는 방향으로 작용한다. 회귀계수의 크기를
제한함으로써, 추정량이 데이터에 과도하게 적합되는 것을 방지하고 예측의
안정성을 높인다. 이 과정에서 일정 수준의 편향이 새롭게 도입되지만,
전체적인 일반화 오차는 오히려 감소할 수 있다.

정규화 강도와 Bias--Variance 절충

정규화의 강도는 편향과 분산의 균형을 조절하는 핵심 매개변수이다.
정규화가 약할수록 모델은 데이터에 더 자유롭게 적합되어 분산이 커지고,
정규화가 강할수록 모델은 제약을 받아 분산은 줄어들지만 편향은 증가한다.

이러한 절충 관계는 단일한 최적값이 존재하지 않으며, 데이터의 크기, 잡음
수준, 모형의 복잡도에 따라 달라진다. 따라서 정규화 강도의 선택은
이론적으로 결정되기보다는, 교차검증과 같은 데이터 기반 방법을 통해
경험적으로 이루어진다.

L2 정규화와 분산 감소

L2 정규화는 회귀계수 전체를 부드럽게 축소함으로써 분산을 줄이는 효과를
가진다. 이는 계수 추정의 불확실성을 완화하고, 공선성이 존재하는
상황에서도 보다 안정적인 예측을 가능하게 한다. 이러한 특성으로 인해 L2
정규화는 예측 정확성을 중시하는 상황에서 널리 사용된다.

L1 정규화와 구조적 단순화

L1 정규화는 일부 계수를 정확히 0으로 만들며, 모형 구조 자체를
단순화한다. 이는 단순한 분산 감소를 넘어, 모델의 자유도를 직접적으로
줄이는 효과를 갖는다. 이로 인해 L1 정규화는 고차원 문제나 변수 선택이
중요한 상황에서 강력한 도구로 작용한다.

정규화의 통계적 위치

Bias--Variance 관점에서 정규화는 최적의 균형점을 찾기 위한 도구이다.
이는 정규화가 만능 해결책이 아님을 의미하며, 정규화의 효과는 데이터와
문제 설정에 따라 달라진다. 그러나 분산을 제어하고 일반화 성능을
안정화한다는 점에서, 정규화는 머신러닝 학습 과정에서 핵심적인 통계적
역할을 수행한다.

이러한 관점에서 정규화는 단순한 기술적 트릭이 아니라, 불확실한 데이터
환경에서 합리적인 예측을 가능하게 하는 통계적 절충의 구현으로 이해할 수
있다.
