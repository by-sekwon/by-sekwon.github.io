---
title: "기초통계 4. 교차표 검정"
format: html
---
### chapter 1. 교차표 개념 

#### 1. 교차표란? 

##### \(1) 개념

변수 간의 관계를 분석할 때는 먼저 예측변수(X)와 목표변수(Y)가 어떤
속성을 가지는지 확인해야 한다. 변수 속성은 크게 범주형(categorical)과
측정형(numerical)으로 나눌 수 있으며, 두 변수의 조합에 따라 적절한 분석
방법이 달라진다.

**X와 Y가 모두 범주형 변수**

각 범주 조합별로 관측 빈도를 정리한 교차표를 작성한 뒤 카이제곱 검정과
같은 방법으로 두 변수 간의 관련성을 검토한다. 교차분석은 명목척도 변수
간의 관계를 파악하는 대표적인 접근이다. 다만 기대빈도가 지나치게 작은
셀이 많으면 피셔의 정확 검정과 같은 보정된 방법이 필요하다.

**X가 범주형이고 Y가 측정형인 경우**

각 범주 수준별로 Y의 평균을 비교하는 방식이 사용된다. 이는
분산분석(ANOVA)이나 t-검정을 통해 수행되며, 집단 간 평균 차이가
통계적으로 유의한지를 판단하는 데 적합하다. 예를 들어 교육 수준별 월평균
소득 차이를 분석하는 경우가 이에 해당한다. 분석 과정에서는 집단 간
분산이 동질하다는 가정을 점검해야 하며, 이를 위배할 경우 Welch ANOVA와
같은 대안 기법을 적용할 수 있다.

**반대로 X가 측정형이고 Y가 범주형**

선형회귀와 같은 전통적 연속형 분석은 적합하지 않다. 대신 범주형
반응변수를 예측할 수 있는 로지스틱 회귀분석이나 판별분석을 활용한다.
이러한 기법은 이항 또는 다항 범주 문제에서 널리 쓰이며, 예를 들어 시험
점수로 합격 여부를 예측하는 경우가 이에 해당한다.

**X와 Y가 모두 측정형 변수**

두 변수 간의 연속적인 변화 관계를 파악하는 상관분석이나 회귀분석을
사용한다. 상관분석은 두 변수의 선형 관계의 강도와 방향을 수치로
제시하고, 회귀분석은 한 변수를 다른 변수로부터 예측할 수 있는 수학적
모형을 제공한다. 다만 상관이 높더라도 반드시 인과관계를 의미하지 않으며,
회귀분석에서는 잔차의 정규성, 등분산성, 독립성 등을 반드시 검토해야
한다.

+------------------:+:------------------------:+:---------------------:+
| Y                 | 범주형                   | 측정형                |
|                   |                          |                       |
| X                 |                          |                       |
+-------------------+--------------------------+-----------------------+
| 범주형            | 교차분석                 | 분산분석              |
+-------------------+--------------------------+-----------------------+
| 측정형            | 로지스틱 회귀분석        | 상관분석/회귀분석     |
+-------------------+--------------------------+-----------------------+


##### \(2) 이차원 교차표 맛보기

하나의 범주형 자료에 정리 방법으로 사용되는 것이 빈도표(혹은 다양한
차트)를 작성하는 것이다. 예를 들어 대학생 120에 대한 정치성향에 대한
조사 결과 다음 표를 얻었다.

  ------------------ ----------------- ----------------- -----------------
       지지정당            보수              진보              중도

      빈도(비율)         40(33.3%)          30(25%)          50(41.7%)
  ------------------ ----------------- ----------------- -----------------

동일 학생 120명들에 대해 "AI 규제 법안" 지지여부를 물어 아래 결과를
얻었다.

  ------------------------ ----------------------- -----------------------
        AI 규제 법안                지지                    반대

         빈도(비율)               80(66.7%)               40(33.3%)
  ------------------------ ----------------------- -----------------------

두 범주형 변수간의 연관성을 알아보기 위해 한 범주형 변수에 대한 빈도표는
열로, 다른 범주형 변수에 대한 빈도표는 행으로 하여 교차표를 작성하게
되는데 이를 이차원 분할표이라 한다. 일반적으로 영향을 미친다고 생각되는
변수(\~따라서, 예측변수 $X$)를 행으로, 영향을 받는다고 생각되는 것을
변수(\~차이가 있다, 목표변수 $Y$)를 열로 하여 교차표를 작성하면 된다.

위의 예제에서 정치성향에 따른 AI 규제 법안 지지 여부 차이가 있는지
알아보기 위하여 분할표를 작성하여 보자. 위의 두 표만으로는 분할표를
작성할 수 없다. 조사할 때 학생들의 (정치성향, K-방역 지지여부)를
조사하여 분할표를 작성해야 한다.

+-------------------:+:-------------:+:-------------:+:--------------:+
| AI 규제 법안       | 지지          | 반대          | 합계           |
|                    |               |               |                |
| 정치성향           |               |               |                |
+--------------------+---------------+---------------+----------------+
| 보수               | 30(75%)       | 10(25%)       | 40             |
+--------------------+---------------+---------------+----------------+
| 진보               | 10(33.3%)     | 20(66.7%)     | 30             |
+--------------------+---------------+---------------+----------------+
| 중도               | 40(80%)       | 10(20%)       | 50             |
+--------------------+---------------+---------------+----------------+
| 합계               | 80            | 40            | 120            |
+--------------------+---------------+---------------+----------------+

괄호 안에 표시된 비율은 행 비율로 정치성향별 AI 규제 법안 지지여부의
차이를 알 수 있다. 보수와 진보는 AI 규제 법안지지도가 높고 진보는 반대
비율이 높음을 알 수 있다.

#### 2. 2x2 분할표 

##### \(1) 모비율 차이 검정

두 개의 범주형 변수가 각각 2개의 범주만을 가지는 경우, 이들의 관계는 2×2
교차표를 통해 요약할 수 있다. 이러한 형태의 자료에서는 전통적인 분할표
검정(카이제곱 독립성 검정)뿐만 아니라, 두 집단 간 비율 차이에 대한
검정으로도 분석을 대체할 수 있다.

특히 변수의 수준이 각각 성공과 실패로 이분되는 경우, 이를 확률적으로
모델링할 수 있다. 어떤 사건이 발생할 확률을 $p$라고 하면, 그 사건이
발생하지 않을 확률은 $1 - p$이다. 이를 바탕으로 다음과 같이 2×2 교차표를
표현할 수 있다.

- $X = \text{집단 1}$: 성공 확률 =$\pi_{1}$, 실패 확률 =$1 - \pi_{1}$

- $Y = \text{집단 2}$: 성공 확률 =$\pi_{2}$, 실패 확률 =$1 - \pi_{2}$

이러한 구조를 통해 두 집단 간 성공 확률의 차이 검정을 수행할 수 있다. 이
검정은 2×2 교차표의 독립성 검정과 본질적으로 유사한 통계적 근거를
가지며, 데이터의 해석을 보다 직관적으로 도와준다.

+----------------------:+:--------------------:+:--------------------:+
| Y                     | 범주1                | 범주2                |
|                       |                      |                      |
| X                     |                      |                      |
+-----------------------+----------------------+----------------------+
| 범주1                 | $$\pi_{1}$$          | $$1 - \pi_{1}$$      |
+-----------------------+----------------------+----------------------+
| 범주2                 | $$\pi_{2}$$          | $$1 - \pi_{2}$$      |
+-----------------------+----------------------+----------------------+

$2 \times 2$ 분할표에서는 "두 범주형 변수가 서로 독립이다" \<=\>
$\pi_{1} = \pi_{2}$와 동일하다. 방사능 물질에 노출여부에 따른 건강의
차이가 있는지 알아보기 위하여 주민 1,000명을 임의추출하여 방사능 물질에
노출된 400, 그렇지 않은 600명을 대상으로 건강 여부를 조사한 자료이다.
\[위키피디아 예제\]

+-------------------------:+:------------------:+:--------------------:+
| 질병여부                 | 질병               | 건강                 |
|                          |                    |                      |
| 노출여부                 |                    |                      |
+--------------------------+--------------------+----------------------+
| 노출                     | 20                 | 380                  |
+--------------------------+--------------------+----------------------+
| 미노출                   | 6                  | 594                  |
+--------------------------+--------------------+----------------------+

- 방사능 노출 집단 질병 발생률 추정치:
${\widehat{\pi}}_{1} = p_{1} = \frac{20}{400} = 0.05$

- 방사능 미노출 집단 질병 발생률 추정치:
${\widehat{\pi}}_{2} = p_{2} = \frac{6}{600} = 0.01$

##### \(2) 비율 차이 검정 순서

- 귀무가설: $\pi_{1} = \pi_{2}$ 방사능 노출집단과 미노출 집단 질병
발생율은 동일하다.

- 대립가설: $\pi_{1} \neq \pi_{2}$ 방사능 노출집단과 미노출 집단 질병
발생율은 다르다.

- 검정통계량 :
$TS = \frac{{\widehat{p}}_{1} - {\widehat{p}}_{2} - 0}{s({\widehat{p}}_{1} - {\widehat{p}}_{2})} \sim z$,

$$s({\widehat{p}}_{1} - {\widehat{p}}_{2}) = \sqrt{\frac{p_{0}(1 - p_{0})}{n_{1}} + \frac{p_{0}(1 - p_{0})}{n_{2}}}$$

- 통합 비율(pooled proportion) :
$p_{0} = \frac{x + y}{n_{1} + n_{2}} = 26/1000 = 0.026$

```python
#독립인 두 모집단 비율 차이 검정
from statsmodels.stats.proportion import proportions_ztest
import numpy as np
count=[20,6]
nobs=[400,600]
np.array(count)/np.array(nobs),proportions_ztest(count,nobs)
```
(array([0.05, 0.01]), (3.894, 9.85912e-05))

검정통계량은 3.89이며, 이에 대응하는 유의확률(p-value)은 0.001 미만으로
나타났다. 따라서 유의수준 0.05에서 귀무가설은 기각된다. 분석 결과,
방사능 노출 집단의 질병 발생률은 5%로, 미노출 집단의 발생률인 1%에 비해
통계적으로 유의미하게 높았다. 이는 방사능에 노출된 경우 질병에 걸릴
위험이 유의하게 증가함을 시사한다.

##### \(3) 상대위험도 relative risk와 승산비 odds ratio

역학 연구에서 질병의 발생과 특정 위험요인 간의 관련성을 평가하기 위해
사용되는 지표로는 상대위험도와 승산비가 있다. 이 중 상대위험도는 코호트
연구와 같이 연구자가 시간의 흐름에 따라 질병의 발생을 추적할 수 있는
전향적 연구에서 사용되는 지표이다. 이는 위험요인에 노출된 집단과 그렇지
않은 집단 각각에 대해 질병이 발생한 비율을 비교할 수 있을 때 정의되며,
실제로 발생률을 비교하는 구조가 요구된다.

반면, 사례-대조군 연구는 일반적으로 후향적 연구로 분류되며, 이미 질병이
발생한 사례군과 질병이 발생하지 않은 대조군을 사후적으로 모집한 후,
과거의 위험요인 노출 여부를 조사하는 방식이다. 이 연구 설계에서는
실험군과 대조군의 비율이 연구자가 임의로 설정한 표본 구성에 따라
정해지기 때문에, 각 집단의 실제 발생률을 직접 추정할 수 없다. 따라서
상대위험도는 정의될 수 없으며, 대신 승산비를 통해 위험요인과 질병 간의
연관성을 추정한다.

예를 들어, 암 발생과 흡연 간의 관련성을 사례-대조군 연구를 통해
분석하고자 할 때, 이미 암이 발생한 집단과 암이 발생하지 않은 집단을
모집하여 이들의 과거 흡연 여부를 조사하게 된다. 그러나 이러한 연구에서는
흡연자와 비흡연자의 전체 집단 규모를 명확히 알 수 없으므로, 질병
발생률의 직접 비교가 불가능하다. 이와 같은 상황에서 유일하게 적용 가능한
측도는 흡연자의 질병 발생 승산 대비 비흡연자의 질병 발생 승산, 즉
승산비이다.

**상대위험도 정의**

두 집단 간 비율의 차이가 동일하더라도, 그 해석은 비율의 절대적 크기에
따라 달라질 수 있다. 일반적으로 비율이 0.5에 가까운 경우보다는 0 또는
1에 가까운 극단적인 경우에서 작은 차이도 더 큰 의미를 갖는다. 예를 들어,
두 집단 간 비율 차이가 0.0077이라고 할 때, (0.0171, 0.0094)라는 조합은
매우 낮은 발생률 간의 차이이며, 상대적으로 의미 있는 차이일 수 있다.
반면, (0.5000, 0.5077)은 전체 발생률이 높아 두 비율 간 차이의 상대적
중요성이 크지 않다.

이처럼 비율의 절대 차이가 아닌, 비율 간의 상대적 크기를 비교하는 개념이
바로 상대위험도이다.

$\text{Relative Risk (RR)} = \frac{P_{1}}{P_{2}}$, 여기서

- $P_{1}$은 위험요인에 노출된 집단에서의 사건 발생률,

- $P_{2}$는 위험요인에 노출되지 않은 집단에서의 사건 발생률이다.

상대위험도는 다음과 같이 해석할 수 있다:

- $RR = 1$: 두 집단 간 사건 발생률이 동일함을 의미한다.

- $RR > 1$: 노출 집단에서 사건 발생 위험이 더 큼.

- $RR < 1$: 노출 집단에서 사건 발생 위험이 더 낮음(보호 효과 가능).

**방사능 노출여부와 질병 발병 여부 실험**

상대 위험도 추정치 :
$\frac{{\widehat{\pi}}_{1}}{{\widehat{\pi}}_{2}} = \frac{0.05}{0.01} = 5$,
방사능 노출집단의 질병 발생율은 미노출 집단보다 5배 높다.

**오즈**

오즈란 어떤 사건이 성공할 확률을 실패할 확률로 나눈 비율로 정의된다. 즉,
성공 확률을 $\pi$라고 할 때, 오즈는 다음과 같이 정의된다.

$$\text{Odds} = \frac{\pi}{1 - \pi}$$

이 개념은 스포츠 경기(예: 축구, 농구 등)에서의 배당률 산정 등에서 자주
활용되며, 성공과 실패 간의 상대적 가능성을 정량적으로 비교하는 지표로
사용된다. 예를 들어, 한국이 폴란드와의 축구 경기에서 이길 확률이
$\pi = 0.1$이라면, 한국의 오즈는
$\frac{0.1}{1 - 0.1} = \frac{0.1}{0.9} = \frac{1}{9}$이다. 한국이 한 번
이기기 위해서는 평균적으로 9번 질 것이라는 의미로 해석할 수 있다. 반면,
폴란드가 이길 확률은 0.9이므로, 그 오즈는
$\frac{0.1}{1 - 0.1} = \frac{0.1}{0.9} \approx \frac{1}{9}$이다. 즉,
폴란드는 한국보다 9배 더 자주 이길 것으로 기대된다.

한편, 스포츠 베팅에서 말하는 배당률은 도박사가 설정하는 금전적 보상
비율이며, 보통 오즈를 기반으로 하지만 여기에 도박사 마진이 포함된다.
만약 오즈 그대로 1:9를 배당률로 설정한다면, 한국에 1달러를 걸면 9달러를
돌려받게 된다. 그러나 실제로는 도박사의 이윤을 위해 더 낮은 배당률이
제공된다. 예를 들어, 한국 승리 시 배당을 7.5배로 책정하는 방식이다.

**오즈비의 정의와 해석**

오즈비는 두 집단 간 사건 발생의 상대적인 가능성을 비교하는 지표로, 각
집단의 오즈를 비율로 나타낸 값이다. 특정 집단의 사건 발생 확률을
$\pi_{1}$, 비교 집단의 사건 발생 확률을 $\pi_{2}$라고 할 때, 오즈비는
다음과 같이 정의된다.

- $\text{OR} = \frac{\frac{\pi_{1}}{1 - \pi_{1}}}{\frac{\pi_{2}}{1 - \pi_{2}}} = \frac{\pi_{1}(1 - \pi_{2})}{\pi_{2}(1 - \pi_{1})}$

- $\text{OR} = 1$: 두 집단의 오즈가 동일함을 의미하며, 두 변수 간 독립성을
시사한다.

- $\text{OR} > 1$: 분자 집단(비교 대상 집단)에 비해 분모 집단보다 사건
발생의 가능성이 높다. 즉, 해당 노출이 사건(또는 질병) 발생 위험을
증가시키는 경향이 있다.

- $\text{OR} < 1$: 분자 집단의 사건 발생 가능성이 더 낮으며, 해당 노출이
사건 발생을 줄이는 보호 효과(protective effect)를 가질 수 있음을
의미한다.

오즈비는 두 범주형 변수 간 연관성을 수치화하는 데 널리 사용되며, 특히
사례--대조군 연구(case-control study)나 후향적 연구(retrospective
study)에서 유용하다. 한 가지 중요한 성질은, 2×2 분할표에서 행과 열을
서로 바꾸더라도 오즈비 값은 변하지 않는다는 점이다. 이는 오즈비가 변수
간의 비대칭적 관계를 측정하는 것이 아니라, 쌍방향적인 연관성의 정도를
나타내는 지표임을 보여준다..

**건강집단과 질병집단 오즈비**

$oddsratio = \frac{(20/6)}{(380/594)} = 5.2$, 분석 결과, 방사능 노출은
질병 발생과 유의한 양의 연관성을 보였으며, 노출군의 질병 오즈는
비노출군에 비해 약 5.2배 높았다. 여기서 오즈(odds)란, 특정 집단에서
질병이 발생할 가능성을 해당 집단에서 질병이 발생하지 않을 가능성과
비교한 비율을 의미한다.

따라서 오즈비 5.2는, 방사능에 노출된 사람의 경우 질병에 걸릴 가능성이
걸리지 않을 가능성 대비 비노출군보다 약 5.2배 더 크다는 것을 뜻한다.
다시 말해, 방사능 노출은 질병 위험을 크게 증가시키는 요인임을 시사한다.

**오즈비 추론**

두 반응 변수가 서로 독립인지 (연관성 검정) 어떻게 검정할 수 있을까?
오즈비($OR$)의 값은 0과 $\infty$을 가지고 독립인 경우는 1이다. 그러므로
좌우 비대칭 형태의 분포를 가지므로 $ln(OR)$생각해보자. 두 변수가
독립이면 $ln(1) = 0$이고 (한 개념에서) 좌우 대칭의 형태를 갖는다. (예:
$ln(4) = 1.39,ln(1/4) = - 1.39$)

표본의 크기가 커지면
$\widehat{ln(OR)} \sim N(ln(OR),\frac{1}{n_{11}} + \frac{1}{n_{12}} + \frac{1}{n_{21}} + \frac{1}{n_{22}})$이므로
신뢰구간은
$\widehat{ln(OR)} \pm z_{1 - \alpha/2}\sqrt{\frac{1}{n_{11}} + \frac{1}{n_{12}} + \frac{1}{n_{21}} + \frac{1}{n_{22}}}$이다.

```python
#오즈비 신뢰구간
import scipy.stats as st
hat_or=(20/6)/(380/594)
se_or=(1/20+1/6+1/380+1/594)**0.5
z=st.norm.ppf(0.975,0,1)
hat_or-z*se_or,hat_or+z*se_or
```
(4.289172810142199, 6.131879821436749)

방사능 노출은 질병 발생과 유의한 양의 연관성이 있으며, 노출군의 질병
오즈는 비노출군에 비해 약 5.2배 유의적으로 높다.

### chapter 2. 교차표 검정 

#### 1. 개념 

두 개의 범주형 변수를 각각 X와 Y로 표시하고 각각 R, C 수준을 갖고 있다고
하자. X를 행으로 Y를 열로 하여 분할표를 만들면 $R \times C$개의 결합
조건이 존재한다. 이를 $R \times C$ 교차표라 한다.

+------------:+:-------------:+:-------------:+:-------:+:-------------:+:-------------:+
| Y           | 범주1         | 범주2         | ...     | 범주C         | 합계          |
|             |               |               |         |               |               |
| X           |               |               |         |               |               |
+-------------+---------------+---------------+---------+---------------+---------------+
| 범주1       | $$\pi_{11}$$  | $$\pi_{12}$$  | ...     | $$\pi_{1C}$$  | $$\pi_{1 +}$$ |
+-------------+---------------+---------------+---------+---------------+---------------+
| 범주2       | $$\pi_{21}$$  | $$\pi_{22}$$  | ...     | $$\pi_{2C}$$  | $$\pi_{2 +}$$ |
+-------------+---------------+---------------+---------+---------------+---------------+
| ...         |               |               | ...     |               |               |
+-------------+---------------+---------------+---------+---------------+---------------+
| 범주R       | $$\pi_{R1}$$  | $$\pi_{R2}$$  | ...     | $$\pi_{RC}$$  | $$\pi_{R +}$$ |
+-------------+---------------+---------------+---------+---------------+---------------+
| 합계        | $$\pi_{+ 1}$$ | $$\pi_{+ 2}$$ | ...     | $$\pi_{+ C}$$ | $$\pi_{+ +}$$ |
+-------------+---------------+---------------+---------+---------------+---------------+

$\pi_{ij}$ : $P(X = i,Y = j)$ X는 범주 $i$, Y는 범주 $j$에 속할 확률변수
$(X,Y)$ 결합확률분포함수

$\pi_{i +}$ : $P(X = i)$ 확률변수 $X$의 주변확률분포함수

$\pi_{+ j}$ : $P(Y = ij)$ 확률변수 $Y$의 주변확률분포함수

$$\pi_{+ +} = 1$$

$O_{ij}$: 셀 $(i,j)$ 관측빈도

$O_{i +}$: 행 $i$ 주변 합 관측빈도, $O_{j +}$: 열 $j$ 주변 합 관측빈도

#### 2. 독립성 검정 

범주형 자료의 관계를 분석할 때, 두 범주형 변수 간의 연관성이
존재하는지를 평가하기 위한 대표적인 방법이 독립성 검정이다. 독립성
검정의 목적은, 두 범주형 변수 간의 분포가 서로 독립적인지를 검토하는 데
있다. 즉, 한 변수의 수준이 다른 변수의 분포에 영향을 주는지를 판단한다.

**통계적 가설**

- 귀무가설: 두 변수는 서로독립이다.
$\pi_{ij} = \pi_{i +}\pi_{+ j}forall(i,j)$

- 대랍가설: 두 변수는 서로 독립이 아니다 (즉, 관련이 있다).

독립이라는 것은, 한 변수의 특정 범주에 속하는 비율이 다른 변수의 범주에
관계없이 일정하다는 의미다. 이를 검정하기 위해, 각 셀의 관측도수와
귀무가설 하에서 기대되는 도수를 비교한다. 기대도수는 귀무가설이 옳다는
가정 하에서 계산되는 셀의 빈도이다.

**검정통계량**

$ts = \sum_{i,j}\frac{(O_{ij} - E_{ij})^{2}}{E_{ij}} \sim \chi^{2}((R - 1) \times (C - 1))$,
여기서 $E_{ij} = \frac{O_{i +}O_{+ j}}{O_{+ +}}$이다.

사례분석

성별(남, 여)에 따른 선호하는 커피 종류(아메리카노, 라떼, 에스프레소)
간의 관계를 분석하고자 한다.

  -------------- -------------- -------------- -------------- --------------
                   아메리카노        라떼        에스프레소        합계

  남성                 30             25             15             70

  여성                 20             30             30             80

  합계                 50             55             45            150
  -------------- -------------- -------------- -------------- --------------

귀무가설: 성별과 커피 선호는 독립이다 (즉, 성별에 따라 커피 선호가
달라지지 않는다)

```python
import pandas as pd
from scipy.stats import chi2_contingency
# 교차표 데이터
data = [[30, 25, 15],   # 남성
        [20, 30, 30]]   # 여성
columns = ['Americano', 'Latte', 'Espresso']
index = ['Male', 'Female']

df = pd.DataFrame(data, index=index, columns=columns)

# 카이제곱 독립성 검정
chi2, p, dof, expected = chi2_contingency(df)

# 결과 출력
print("✅ 카이제곱 통계량:", round(chi2, 3))
print("✅ p-value:", round(p, 4))

# 행 퍼센트 계산
row_percent = df.div(df.sum(axis=1), axis=0) * 100
row_percent_rounded = row_percent.round(2)
print("\n📊 행 퍼센트 (%):")
print(row_percent_rounded)
```
✅ 카이제곱 통계량: 6.818
<br>
✅ p-value: 0.0331
<br>
📊 행 퍼센트 (%):
<br>
Americano  Latte  Espresso
<br>
Male        42.86  35.71     21.43
<br>
Female      25.00  37.50     37.50

유의확률(0.0247)이 0.05보다 작으므로 귀무가설은 기각되어 성별과 커피
선호 간에 통계적으로 유의한 연관성이 존재함을 의미한다. 남성은
아메리카노(42.86%)를 가장 많이 선호하는 반면, 여성은 에스프레소(37.5%)와
라떼(37.5%)에 대한 선호가 상대적으로 높다.

#### 3. 동질성 검정 

동질성 검정은 두 개 이상의 모집단으로부터 각각 표본을 추출하였을 때, 이
모집단들이 하나의 공통된 분포(또는 비율 구조)를 가지고 있는지를 검정하는
절차이다. 즉, 여러 집단이 같은 비율 분포를 공유하고 있는지, 다시 말해
질적 특성의 분포가 동일한지를 평가하는 검정이다.

1900 Karl Pearson에 제안한 방법으로 multinomial(다항) distribution의
확률이 귀무가설에서 설정한 값과 동일한지를 검정한다. 즉 확률변수 $X$의
주변확률분포함수가 모두 동일한지 검정한다.

- 귀무가설 : $\pi_{ij} = \pi_{kj}$, 모든 $j = 1,2,...,C$ 그리고
  $i \neq k$

- 대립가설 : 귀무가설은 사실이 아니다.

**Pearson Chi-square Statistic $\chi ^2$ -검정 통계량**

$$ts = \sum_{i,j}\frac{(O_{ij} - E_{ij})^{2}}{E_{ij}} \sim \chi^{2}((R - 1) \times (C - 1))$$

**사례분석**

한 음료회사가 지역별(서울, 부산) 소비자들을 대상으로, 선호하는 음료
종류(탄산음료, 주스, 생수)에 대한 조사를 실시하였다. 각 지역에서 100명씩
표본을 추출하여 선호도를 조사한 결과는 다음과 같다.

  -------------- -------------- -------------- -------------- --------------
       지역         탄산음료         주스           생수           합계

       서울            40             35             25            100

       부산            30             25             45            100

       합계            70             60             70            200
  -------------- -------------- -------------- -------------- --------------

귀무가설: 두 지역(서울, 부산)의 음료 선호 분포는 동일하다 (즉, 모집단의
분포가 동질적이다)

```python
# 독립성 검정 코드와 동일함
```
✅ 카이제곱 통계량: 8.81
<br>
✅ p-value: 0.0122
<br>
📊 행 퍼센트 (%):
<br>
Soda  Juice  Water
<br>
Seoul  40.0   35.0   25.0
<br>
Busan  30.0   25.0   45.0

유의확률이 0.012이므로, 귀무가설은 기각되어 서울과 부산의 음료 선호
분포는 동일하지 않으며, 지역 간 분포의 차이가 통계적으로 유의미하다고 볼
수 있다. 서울은 탄산음료와 주스 선호도가 높고, 부산은 생수 선호 비율이
상대적으로 높다.

#### 4. Fisher's 정확검정 exact test 

Fisher[']{dir="rtl"}s exact test는 1934년, 피셔가 유전자 분리비 연구 및
실험설계의 정교화를 위해 고안한 검정이다. 이 검정은 당시의 계산 자원
한계에도 불구하고, ["]{dir="rtl"}작은 표본에서의 정확한 결론"을 도출할
수 있는 기법으로 주목받았다. 특히, 정확한 확률을 기반으로 한 논리적 검정
방식을 도입한 점에서 이후의 이항 검정이나 로지스틱 회귀 등의 기반이
되었다. 일반적인 $R \times C$교차표에서도 이론적으로 수행 가능합니다.
하지만 실무에서는 계산량이 급격히 증가하므로 2×2 표 이외에는 거의
사용되지 않습니다

Fisher가 이 검정을 소개하면서 사용한 일화로 유명한 것이 바로
["]{dir="rtl"}홍차 마시는 여인" 실험이다. 한 여성이 ["]{dir="rtl"}우유를
먼저 넣은 차"와 ["]{dir="rtl"}차를 먼저 넣은 우유"를 맛만 보고 구분할 수
있다고 주장하자, Fisher는 8잔 중 4잔씩 두 조건을 섞어 무작위로 제공하고,
이 여성이 구분할 확률을 순열 조합으로 계산하여 검정했다. 이 실험이 바로
Fisher의 정확 검정의 실제 적용 예로 인용된다.

**2X2 교차표**

  ----------------- ----------------- ----------------- -----------------
                          성공              실패              합계

  A 그룹                    a                 b                a+b

  B 그룹                    c                 d                c+d

  합계                     a+c               b+d                n
  ----------------- ----------------- ----------------- -----------------

**검정통계량**

주어진 행과 열의 합이 고정된 상황에서 셀 a에 특정한 값이 나올 확률은
다음과 같이 초기하분포를 따른다. 이러한 확률은 각 가능한 $a$ 값에
대해 계산되며, 관측값과 같거나 더 극단적인 경우의 확률을 모두 합산하여
유의확률을 산출한다.

$$P(a) = \frac{\binom{a + b}{a} \cdot \binom{c + d}{c}}{\binom{n}{a + c}}$$

**피셔 사례분석**

- 귀무가설: 여성의 선택은 무작위이며, 실제 구분 능력이 없다

- 대립가설: 여성은 차/우유 순서를 식별할 수 있다

  ------------------------ --------------- ---------------- --------------
        Fisher 사례             성공             실패            합계

      차를 먼저라 판단            3               1               4

     우유를 먼저라 판단           1               3               4

            합계                  4               4               8
  ------------------------ --------------- ---------------- --------------

- 유의확률,
$P(a \geq 3|a \sim HG(N = 8,K = 4,n = 4))$`<!-- -->`{=html}0.2429이므로 귀무가설을 기각할 수 없으므로 이 결과만으로는 여성이 정확하게 구분한다고
보기는 어렵다.하지만 만약 4잔 모두 정답(4 vs. 0)이었다면, p-value는 약
0.014로, 유의미한 능력이 있다고 결론내릴 수 있습니다.

```python
from scipy.stats import fisher_exact

# 2x2 교차표 (차례대로: 정답, 오답)
table = [[3, 1],  # 여성 선택 = 차 먼저 (맞춤 3, 틀림 1)
         [1, 3]]  # 여성 선택 = 우유 먼저 (틀림 1, 맞춤 3)

# 양측 검정
oddsratio, p_value = fisher_exact(table, alternative='two-sided')

print("오즈비:", round(oddsratio, 2))
print("p-value:", round(p_value, 4)/2)
```
오즈비: 9.0
<br>
p-value: 0.2429

여성은 차와 우유 중 어느 것을 먼저 넣었는지 구별할 능력은
없지만(귀무가설 채택), 오즈비가 9라는 것은 이는 그녀가 실제로 차와
우유의 순서를 일정 부분 구분할 수 있었을 가능성을 시사하는 정량적
지표이다. 여성이 차를 먼저 넣었다고 판단한 잔에서 실제로 차를 먼저
넣었을 오즈가, 우유를 먼저 넣었다고 판단한 잔에서 실제로 우유를 먼저
넣었을 오즈보다 9배 더 높다는 것을 의미한다.
