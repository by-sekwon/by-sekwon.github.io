---
title: "MLDL ë¨¸ì‹ ëŸ¬ë‹ ë¶„ë¥˜ - kNN SVM ì‚¬ë¡€ë¶„ì„"
format: html
---

### Chapter 1. ë¨¸ì‹ ëŸ¬ë‹ ë¶„ë¥˜ (k-NN \| SVM) ì´ì§„í˜• ë°ì´í„° ì‚¬ë¡€ë¶„ì„

#### 1. ì‚¬ë¡€ë¶„ì„ (ì´ì§„ë¶„ë¥˜)
##### \(1) ë°ì´í„°

ë³¸ ì‹¤ìŠµì—ì„œëŠ” ì´ì§„ë¶„ë¥˜ ì˜ˆì œë¡œ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” Breast Cancer Wisconsin (Diagnostic) ë°ì´í„°ë¥¼ ì‚¬ìš©í•œë‹¤. ì´ ë°ì´í„°ëŠ” ìœ ë°© ì¢…ì–‘ì˜ ì„¸í¬í•µ(nucleus) í˜•íƒœ íŠ¹ì„±ìœ¼ë¡œë¶€í„° ì¢…ì–‘ì´ ì•…ì„±(malignant 0) ì¸ì§€ ì–‘ì„±(benign 1) ì¸ì§€ë¥¼ ë¶„ë¥˜í•˜ëŠ” ë¬¸ì œë¥¼ ë‹¤ë£¬ë‹¤. í‘œë³¸ ìˆ˜ëŠ” ğ‘› = 569, ë³€ìˆ˜(íŠ¹ì§•) ìˆ˜ëŠ” p=30ì´ë‹¤.

30ê°œì˜ ì…ë ¥ ë³€ìˆ˜ëŠ” ëª¨ë‘ ì—°ì†í˜• ìˆ˜ì¹˜ ë³€ìˆ˜ë¡œ, ì¢…ì–‘ì˜ í˜•íƒœë¥¼ ìš”ì•½í•œ í†µê³„ì  íŠ¹ì„±ë“¤ì´ë‹¤. ì˜ˆë¥¼ ë“¤ì–´ í‰ê·  ë°˜ì§€ë¦„(mean radius), ë‘˜ë ˆ(mean perimeter), ë©´ì (mean area) ë“± â€œmean / error / worstâ€ ìœ í˜•ì˜ íŒŒìƒ íŠ¹ì§•ë“¤ì´ í¬í•¨ëœë‹¤.

```python
# 1) ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°: Breast Cancer Wisconsin (Diagnostic)
import numpy as np
import pandas as pd
from sklearn.datasets import load_breast_cancer

data = load_breast_cancer()

X = data.data
y = data.target
feature_names = data.feature_names
target_names = data.target_names

print("X shape:", X.shape)
print("y shape:", y.shape)
print("Classes:", dict(enumerate(target_names)))
print("Class counts:", dict(zip(*np.unique(y, return_counts=True))))

# DataFrameìœ¼ë¡œ ë³´ê¸° ì¢‹ê²Œ(ì„ íƒ)
df = pd.DataFrame(X, columns=feature_names)
df["target"] = y
df.info()
```

##### \(2) ì „ì²˜ë¦¬

**ì™œ train/test ë¶„í• ì„ ë¨¼ì € í•˜ëŠ”ê°€?**

ëª¨í˜• ì„±ëŠ¥ í‰ê°€ëŠ” â€œìƒˆë¡œìš´ ë°ì´í„°ì—ì„œ ì–¼ë§ˆë‚˜ ì˜ ë§ì¶”ëŠ”ê°€â€ë¥¼ ë³´ëŠ” ê²ƒì´ë¯€ë¡œ, ì „ì²´ ë°ì´í„°ë¥¼ í•™ìŠµìš©(train) ê³¼ í‰ê°€ìš©(test) ìœ¼ë¡œ ë‚˜ëˆˆë‹¤. ì´ë•Œ í•µì‹¬ ì›ì¹™ì€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” í•™ìŠµ ê³¼ì •ì— ì ˆëŒ€ ì‚¬ìš©ë˜ì§€ ì•Šì•„ì•¼ í•œë‹¤ëŠ” ì ì´ë‹¤. (ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€)

ì½”ë“œì—ì„œëŠ” ë‹¤ìŒì²˜ëŸ¼ 75%ëŠ” í•™ìŠµ, 25%ëŠ” í…ŒìŠ¤íŠ¸ë¡œ ë¶„í• í–ˆë‹¤.

í•™ìŠµ ë°ì´í„°: 426ê°œ / í…ŒìŠ¤íŠ¸ ë°ì´í„°: 143ê°œ

**â€œì¸µí™”(stratify)â€ëŠ” ì™œ í•„ìš”í•œê°€?**

ì´ ë°ì´í„°ëŠ” ì´ì§„ë¶„ë¥˜ì´ë©° í´ë˜ìŠ¤(ì•…ì„±/ì–‘ì„±)ì˜ ë¹„ìœ¨ì´ 212:357ë¡œ ì•½ê°„ ë¶ˆê· í˜•ì´ë‹¤.
ë¬´ì‘ìœ„ ë¶„í• ë§Œ í•˜ë©´ ìš°ì—°íˆ í•œìª½ í´ë˜ìŠ¤ê°€ í…ŒìŠ¤íŠ¸ì— ê³¼ì†Œ/ê³¼ë‹¤ í¬í•¨ë  ìˆ˜ ìˆì–´ í‰ê°€ê°€ í”ë“¤ë¦´ ìˆ˜ ìˆë‹¤.

train_test_split(..., stratify=y)ëŠ”
í›ˆë ¨/í…ŒìŠ¤íŠ¸ ê°ê°ì—ì„œ í´ë˜ìŠ¤ ë¹„ìœ¨ì´ ì› ë°ì´í„°ì™€ ìœ ì‚¬í•˜ê²Œ ìœ ì§€ë˜ë„ë¡ ë¶„í• í•œë‹¤.

ê·¸ë˜ì„œ ì¶œë ¥ì—ì„œ train: (0) 159, (1) 267 / test : (0) 53, (1) 90ì²˜ëŸ¼ ë¹„ìœ¨ì´ í° í­ìœ¼ë¡œ ê¹¨ì§€ì§€ ì•ŠëŠ”ë‹¤.


**StandardScaler(í‘œì¤€í™”)ë¥¼ ì™œ í•˜ëŠ”ê°€?**

SVM(íŠ¹íˆ RBF ì»¤ë„)ê³¼ k-NNì€ ê±°ë¦¬/ë‚´ì  ê¸°ë°˜ì´ë¼ ë³€ìˆ˜ ìŠ¤ì¼€ì¼ì— ë§¤ìš° ë¯¼ê°í•˜ë‹¤.

ì˜ˆë¥¼ ë“¤ì–´, mean area ê°™ì€ ë³€ìˆ˜ëŠ” ê°’ì˜ ìŠ¤ì¼€ì¼ì´ í¬ê³ , mean smoothness ê°™ì€ ë³€ìˆ˜ëŠ” ìŠ¤ì¼€ì¼ì´ ì‘ë‹¤. í‘œì¤€í™” ì—†ì´ ê±°ë¦¬ ê³„ì‚°ì„ í•˜ë©´ ìŠ¤ì¼€ì¼ì´ í° ë³€ìˆ˜ê°€ ê±°ë¦¬ë¥¼ ì§€ë°°í•´, ëª¨ë¸ì´ â€œí° ë‹¨ìœ„ ë³€ìˆ˜â€ë§Œ ë³´ê³  íŒë‹¨í•˜ëŠ” ë¶€ì‘ìš©ì´ ìƒê¸´ë‹¤.

**íŒŒì´í”„ë¼ì¸(Pipeline)ì„ ì“°ëŠ” ì´ìœ : ëˆ„ìˆ˜ ë°©ì§€ + ì¬ì‚¬ìš©ì„±**

í‘œì¤€í™”ëŠ” ë°˜ë“œì‹œ í•™ìŠµ ë°ì´í„°ì—ì„œë§Œ í‰ê· /í‘œì¤€í¸ì°¨ë¥¼ ì¶”ì •(fit)í•´ì•¼ í•œë‹¤. ë§Œì•½ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê¹Œì§€ í¬í•¨í•´ ìŠ¤ì¼€ì¼ì„ ë§ì¶”ë©´, í…ŒìŠ¤íŠ¸ ì •ë³´ê°€ í•™ìŠµ ë‹¨ê³„ì— ì„ì´ëŠ” ë°ì´í„° ëˆ„ìˆ˜ê°€ ë°œìƒí•œë‹¤. ì¦‰, í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” â€œë³€í™˜(transform)â€ë§Œ í•œë‹¤.

```python
# 2ë‹¨ê³„: train/test ë¶„í• (ì¸µí™”) + í‘œì¤€í™”(Standardization) íŒŒì´í”„ë¼ì¸ ì¤€ë¹„

import numpy as np
import pandas as pd
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

# (1) ë°ì´í„° ë¡œë“œ
data = load_breast_cancer()
X = data.data
y = data.target

# (2) train/test ë¶„í•  (ì¸µí™”: stratify=y)
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.25,
    random_state=42,
    stratify=y
)

print("[Split]")
print("X_train:", X_train.shape, "X_test:", X_test.shape)
print("y_train counts:", dict(zip(*np.unique(y_train, return_counts=True))))
print("y_test  counts:", dict(zip(*np.unique(y_test, return_counts=True))))

# (3) í‘œì¤€í™” íŒŒì´í”„ë¼ì¸(í•™ìŠµ ë°ì´í„°ë¡œ fit, í…ŒìŠ¤íŠ¸ì—ëŠ” transformë§Œ ì ìš©)
scaler_pipe = Pipeline([
    ("scaler", StandardScaler())
])

# í‘œì¤€í™” ì ìš©(ì´í›„ k-NN, SVM íŒŒì´í”„ë¼ì¸ì— ê·¸ëŒ€ë¡œ ë¼ì›Œ ë„£ì„ ì˜ˆì •)
X_train_scaled = scaler_pipe.fit_transform(X_train)
X_test_scaled  = scaler_pipe.transform(X_test)
```

[Split]
X_train: (426, 30) X_test: (143, 30)
<br>
y_train counts: {np.int64(0): np.int64(159), np.int64(1): np.int64(267)}
<br>
y_test  counts: {np.int64(0): np.int64(53), np.int64(1): np.int64(90)}

##### \(3) KNN

**kNN ë¶„ì„ ë° ì„±ëŠ¥ ì¶œë ¥**

ì´ ì½”ë“œëŠ” Breast Cancer Wisconsin ë°ì´í„°ì— ëŒ€í•´ k-NN ë¶„ë¥˜ê¸°ë¥¼ í•™ìŠµí•˜ê³ , í…ŒìŠ¤íŠ¸ì…‹ì—ì„œ ê¸°ë³¸ ì„±ëŠ¥(ì •í™•ë„/í˜¼ë™í–‰ë ¬/ë¶„ë¥˜ë¦¬í¬íŠ¸)ì„ í™•ì¸í•˜ëŠ” ì ˆì°¨ë¥¼ êµ¬í˜„í•œë‹¤. íŠ¹íˆ k-NNì€ ê±°ë¦¬ ê¸°ë°˜ ë°©ë²•ì´ë¯€ë¡œ í‘œì¤€í™”(Standardization) ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•˜ë©°, ì´ë¥¼ ëˆ„ìˆ˜ ì—†ì´ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ Pipelineì„ ì‚¬ìš©í•œë‹¤.

ë¨¼ì € Pipeline([("scaler", StandardScaler()), ("knn", KNeighborsClassifier(...))]) í˜•íƒœë¡œ ì „ì²˜ë¦¬ì™€ ëª¨ë¸ì„ í•˜ë‚˜ì˜ íë¦„ìœ¼ë¡œ ë¬¶ëŠ”ë‹¤. ì—¬ê¸°ì„œ StandardScaler()ëŠ” ê° ë³€ìˆ˜ë¥¼ í›ˆë ¨ ë°ì´í„° ê¸°ì¤€ í‰ê· , í‘œì¤€í¸ì°¨ë¡œ ì •ê·œí™” ë³€í™˜í•œë‹¤. 

ì´ ë³€í™˜ì€ ê±°ë¦¬ ê³„ì‚°ì—ì„œ íŠ¹ì • ë³€ìˆ˜(ìŠ¤ì¼€ì¼ì´ í° ë³€ìˆ˜)ê°€ ê³¼ë„í•˜ê²Œ ì˜í–¥ì„ ì£¼ëŠ” ë¬¸ì œë¥¼ ë§‰ê¸° ìœ„í•´ í•„ìˆ˜ì ì´ë‹¤. Pipelineì„ ì“°ë©´ í‘œì¤€í™”ì˜ fitì´ í›ˆë ¨ ë°ì´í„°ì—ì„œë§Œ ìˆ˜í–‰ë˜ê³ , í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ëŠ” ë™ì¼í•œ ë³€í™˜ì´ transformìœ¼ë¡œë§Œ ì ìš©ë˜ì–´ ë°ì´í„° ëˆ„ìˆ˜(leakage) ë¥¼ ë°©ì§€í•œë‹¤.

KNeighborsClassifierì˜ ì£¼ìš” ì„¤ì •ì€ ë‹¤ìŒ ì˜ë¯¸ë¥¼ ê°–ëŠ”ë‹¤.
n_neighbors=15: ì˜ˆì¸¡ ì‹œ ê°€ì¥ ê°€ê¹Œìš´ ì´ì›ƒ k=15ê°œë¥¼ ì‚¬ìš©í•œë‹¤. kê°€ ì‘ìœ¼ë©´ ì¡ìŒì— ë¯¼ê°(ë¶„ì‚°â†‘), ë„ˆë¬´ í¬ë©´ ê²½ê³„ê°€ ê³¼ë„í•˜ê²Œ ë§¤ë„ëŸ¬ì›Œì§(í¸í–¥â†‘)ì´ë¯€ë¡œ ì ì ˆí•œ ê· í˜•ì´ í•„ìš”í•˜ë‹¤.

p=2: ìœ í´ë¦¬ë“œ ê±°ë¦¬(Euclidean)ë¥¼ ê³„ì‚°ëœë‹¤. (p=1ì´ë©´ ë§¨í•´íŠ¼ ê±°ë¦¬)

weights="distance": ë‹¨ìˆœ ë‹¤ìˆ˜ê²°ì´ ì•„ë‹ˆë¼ ê°€ê¹Œìš´ ì´ì›ƒì— ë” í° ê°€ì¤‘ì¹˜ë¥¼ ë‘ì–´ íˆ¬í‘œí•œë‹¤. ê²½ê³„ ê·¼ì²˜ì—ì„œ ë” ì•ˆì •ì ì¸ ì˜ˆì¸¡ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆë‹¤.

í•™ìŠµì€ knn_model.fit(X_train, y_train)ë¡œ ìˆ˜í–‰ëœë‹¤. k-NNì€ ì†ì‹¤í•¨ìˆ˜ ìµœì í™”ë¡œ íŒŒë¼ë¯¸í„°ë¥¼ í•™ìŠµí•˜ê¸°ë³´ë‹¤ëŠ” â€œí›ˆë ¨ ë°ì´í„°ë¥¼ ì €ì¥í•´ë‘ê³ â€, ì˜ˆì¸¡ ì‹œ ë§¤ë²ˆ ì´ì›ƒì„ ê²€ìƒ‰í•˜ëŠ” í˜•íƒœì´ë¯€ë¡œ(ê²Œìœ¼ë¥¸ í•™ìŠµ), ì‹¤ì§ˆì  ê³„ì‚° ë¶€ë‹´ì€ ì˜ˆì¸¡ ë‹¨ê³„ì— ë” í¬ê²Œ ë°œìƒí•œë‹¤.

ì´í›„ predict(X_test)ë¡œ í´ë˜ìŠ¤ ë¼ë²¨ì„ ì˜ˆì¸¡í•˜ê³ , accuracy_score, confusion_matrix, classification_reportë¥¼ í†µí•´ ì„±ëŠ¥ì„ ìš”ì•½í•œë‹¤.

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# k-NN ëª¨ë¸ (í‘œì¤€í™” + kNN)
knn_model = Pipeline([
    ("scaler", StandardScaler()),
    ("knn", KNeighborsClassifier(
        n_neighbors=15,      # k
        weights="distance",  # ê°€ê¹Œìš´ ì´ì›ƒ ê°€ì¤‘â†‘
        p=2                  # p=2: Euclidean, p=1: Manhattan
    ))
])

# í•™ìŠµ
knn_model.fit(X_train, y_train)

# ì˜ˆì¸¡(í´ë˜ìŠ¤)
y_pred_knn = knn_model.predict(X_test)

# í‰ê°€(ê¸°ë³¸)
print("[k-NN] Accuracy:", accuracy_score(y_test, y_pred_knn))
print("[k-NN] Confusion matrix:\n", confusion_matrix(y_test, y_pred_knn))
print("[k-NN] Classification report:\n", classification_report(y_test, y_pred_knn, target_names=data.target_names))
```

[k-NN] Accuracy: 0.965034965034965
<br> 
[k-NN] Confusion matrix:
<br> 
 [[48  5]
<br> 
 [ 0 90]]

[k-NN] Classification report:

```text
               precision    recall  f1-score   support

   malignant       1.00      0.91      0.95        53
      benign       0.95      1.00      0.97        90

    accuracy                           0.97       143
   macro avg       0.97      0.95      0.96       143 
weighted avg       0.97      0.97      0.96       143
```

**k-NN: ROC/PR ê³¡ì„ ê³¼ ì„ê³„ê°’(Threshold) ì„ íƒ**

ì´ ì½”ë“œëŠ” k-NN ë¶„ë¥˜ê¸°ê°€ ì¶œë ¥í•˜ëŠ” í™•ë¥ (score) ì„ ì´ìš©í•´, (1) ROC ê³¡ì„ ê³¼ PR ê³¡ì„ ì„ ê³„ì‚°í•˜ê³  (2) ì„ê³„ê°’ të¥¼ ë°”ê¿€ ë•Œ í˜¼ë™í–‰ë ¬ê³¼ ì„±ëŠ¥ì§€í‘œê°€ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ í™•ì¸í•˜ë©° (3) ìš´ì˜ ëª©ì ì— ë§ëŠ” ì„ê³„ê°’ì„ ì„ íƒí•˜ëŠ” ì ˆì°¨ë¥¼ êµ¬í˜„í•œë‹¤. 

í•µì‹¬ ì•„ì´ë””ì–´ëŠ” â€œí™•ë¥ ì„ 0/1ë¡œ ë°”ê¾¸ëŠ” ê¸°ì¤€ì´ ì„ê³„ê°’ì´ë©°, ì„ê³„ê°’ì„ ì–´ë””ì— ë‘ëŠëƒì— ë”°ë¼ FP/FNì´ ë‹¬ë¼ì§„ë‹¤â€ëŠ” ì ì´ë‹¤.

ROC/PR ë° ì„ê³„ê°’ ì„ íƒì€ í•­ìƒ â€œì–´ë–¤ í´ë˜ìŠ¤ë¥¼ positive(ê´€ì‹¬ ì´ë²¤íŠ¸)ë¡œ ë³¼ ê²ƒì¸ê°€â€ë¥¼ ë¨¼ì € ì •í•´ì•¼ í•œë‹¤. Breast Cancer ë°ì´í„°ëŠ” ë¼ë²¨ì´ 0=malignant(ì•…ì„±), 1=benign(ì–‘ì„±) ì´ë¯€ë¡œ, ì½”ë“œì˜ ê¸°ë³¸ ì„¤ì •(A)ì€ positive=1(benign) ë¡œ ë‘”ë‹¤. ë”°ë¼ì„œ y_pos = y_test ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³ , í™•ë¥ ë„ P(y=1|x)ë¥¼ ì‚¬ìš©í•œë‹¤.

ë‹¤ë§Œ ì˜ë£Œ ì§„ë‹¨ì—ì„œëŠ” ë³´í†µ â€œì•…ì„±(ë†“ì¹˜ë©´ ì¹˜ëª…ì )â€ì„ positiveë¡œ ë‘ëŠ” í•´ì„ì´ ìì—°ìŠ¤ëŸ½ë‹¤. ì´ë¥¼ ìœ„í•´ ì½”ë“œì—ëŠ” ì˜µì…˜(B)ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©°, ì´ ê²½ìš° y_pos = (y_test==0)ì²˜ëŸ¼ ì•…ì„±ì„ 1ë¡œ ì¬ì½”ë”©í•˜ê³ , scoreë„ P(malignant|x)ê°€ ë˜ë„ë¡ 1 - P(benign|x)ë¡œ ë’¤ì§‘ì–´ ì‚¬ìš©í•œë‹¤.
ì¦‰, ê°™ì€ ëª¨ë¸ì´ë¼ë„ positive ì •ì˜ì— ë”°ë¼ ROC/PRì˜ ì˜ë¯¸ê°€ ë‹¬ë¼ì§„ë‹¤.

k-NNì€ predict_probaë¥¼ ì œê³µí•˜ë¯€ë¡œ, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•´ â€œpositive í´ë˜ìŠ¤ì˜ í™•ë¥ â€ì„ ë‹¤ìŒì²˜ëŸ¼ ë§Œë“ ë‹¤. p_pos1 = knn_model.predict_proba(X_test)[:,1] ì´ í™•ë¥  ë²¡í„°ê°€ ì´í›„ ROC/PR ê³¡ì„ ê³¼ ì„ê³„ê°’ ë¶„ì„ì˜ ìœ ì¼í•œ í•µì‹¬ ì…ë ¥(score) ì´ ëœë‹¤.

**ROC ê³¡ì„ ê³¼ AUC ê³„ì‚°**

ROCëŠ” ì„ê³„ê°’ të¥¼ 0ì—ì„œ 1ê¹Œì§€ ì›€ì§ì´ë©°, ê° ì„ê³„ê°’ì—ì„œ ë‹¤ìŒ ë‘ ê°’ì„ ê³„ì‚°í•´ ê·¸ë¦° ê³¡ì„ ì´ë‹¤.

- TPR(ì¬í˜„ìœ¨, ë¯¼ê°ë„) = TP / (TP + FN)
- FPR(ìœ„ì–‘ì„±ë¥ ) = FP / (FP + TN)

ì½”ë“œì˜ roc_curve(y_pos, score)ëŠ” (FPR ë°°ì—´, TPR ë°°ì—´, ê·¸ë¦¬ê³  ê·¸ë•Œì˜ ì„ê³„ê°’ ë°°ì—´)ì„ ë°˜í™˜í•œë‹¤. ì´ì–´ì„œ auc(fpr, tpr)ëŠ” ROC ê³¡ì„  ì•„ë˜ ë©´ì (AUC)ì„ ê³„ì‚°í•œë‹¤.
AUCëŠ” â€œpositive ìƒ˜í”Œì´ negativeë³´ë‹¤ ë” ë†’ì€ ì ìˆ˜(score)ë¥¼ ë°›ë„ë¡ ì •ë ¬ë˜ëŠ” ëŠ¥ë ¥(ìˆœìœ„ ë¶„ë¦¬ ì„±ëŠ¥)â€ì„ ìš”ì•½í•œ ê°’ì´ë‹¤.

**PR ê³¡ì„ ê³¼ AP ê³„ì‚°**

PR ê³¡ì„ ì€ ì„ê³„ê°’ ë³€í™”ì— ë”°ë¼ ë‹¤ìŒ ë‘ ê°’ì˜ trade-offë¥¼ ë³¸ë‹¤.

- Precision(ì •ë°€ë„) = TP / (TP + FP)
- Recall(ì¬í˜„ìœ¨) = TP / (TP + FN)

íŠ¹íˆ ì–‘ì„± í´ë˜ìŠ¤ê°€ í¬ê·€í•œ ìƒí™©ì—ì„œëŠ” ROCë³´ë‹¤ PRì´ ìš´ì˜ í’ˆì§ˆì„ ë” ì§ì ‘ì ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ” ê²½ìš°ê°€ ë§ë‹¤. average_precision_scoreë¡œ ê³„ì‚°í•œ APëŠ” PR ê³¡ì„ ì„ í•˜ë‚˜ì˜ ìˆ˜ì¹˜ë¡œ ìš”ì•½í•œ ê°’ì´ë‹¤.

**â€œì„ê³„ê°’ t í•˜ë‚˜â€ì—ì„œ í˜¼ë™í–‰ë ¬ê³¼ ì§€í‘œë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜**

metrics_at_threshold()ëŠ” íŠ¹ì • ì„ê³„ê°’ të¥¼ ì£¼ë©´ ë‹¤ìŒì„ ìˆ˜í–‰í•œë‹¤.

í™•ë¥ ì„ ì´ì§„ ì˜ˆì¸¡ìœ¼ë¡œ ë³€í™˜: y_hat = (score >= t). ì¦‰, scoreê°€ ì„ê³„ê°’ ì´ìƒì´ë©´ positiveë¡œ íŒì •í•œë‹¤.

í˜¼ë™í–‰ë ¬(TN, FP, FN, TP) ê³„ì‚°í•˜ê³  ê·¸ í˜¼ë™í–‰ë ¬ë¡œë¶€í„° ì§€í‘œ recall(TPR), fpr, precision, accuracyì„ ê³„ì‚°í•œë‹¤. ì´ í•¨ìˆ˜ëŠ” ROC/PR ê°™ì€ â€œê³¡ì„ â€ì„ ì‹¤ì œ ìš´ì˜ ê´€ì ì˜ â€œí•œ ì (ì„ê³„ê°’ í•˜ë‚˜)â€ìœ¼ë¡œ í’€ì–´ì£¼ëŠ” ì—­í• ì„ í•œë‹¤.

ì—¬ëŸ¬ ì„ê³„ê°’(grid)ì„ ì°ì–´ë³´ë©° FP/FN trade-offë¥¼ í™•ì¸: ì½”ë“œëŠ” t=0.1,0.2,â€¦,0.9ì— ëŒ€í•´ metrics_at_threshold ê²°ê³¼ë¥¼ ì¶œë ¥í•œë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ì„ê³„ê°’ì„ ì˜¬ë¦¬ë©´ positive íŒì •ì´ ë³´ìˆ˜ì ìœ¼ë¡œ ë³€í•˜ë©´ì„œ: FPëŠ” ê°ì†Œ(ì •ë°€ë„ëŠ” ì¦ê°€í•˜ëŠ” ê²½í–¥), FNì€ ì¦ê°€(ì¬í˜„ìœ¨ì€ ê°ì†Œí•˜ëŠ” ê²½í–¥). ì¦‰, ì„ê³„ê°’ì€ â€œì˜¤ê²½ë³´(FP)ë¥¼ ì¤„ì´ëŠëƒ, ë†“ì¹¨(FN)ì„ ì¤„ì´ëŠëƒâ€ì˜ ê· í˜•ì„ ì¡°ì ˆí•˜ëŠ” ì†ì¡ì´ë‹¤.

**ì„ê³„ê°’ ì„ íƒ ê·œì¹™ (A): Youdenâ€™s J ìµœëŒ€í™”**

Youdenâ€™s JëŠ” ROC ê´€ì ì—ì„œ ê· í˜•ì ì„ ì¡ëŠ” ë‹¨ìˆœí•œ ê¸°ì¤€ì´ë‹¤.

J(t) = TPR(t) âˆ’ FPR(t)

ì½”ë“œëŠ” ëª¨ë“  ROC ì ì—ì„œ Jë¥¼ ê³„ì‚°í•˜ê³ , Jê°€ ìµœëŒ€ì¸ ì§€ì ì˜ ì„ê³„ê°’ì„ ì„ íƒí•œë‹¤.
ì´ ë°©ì‹ì€ â€œì¬í˜„ìœ¨ì„ ë†’ì´ë˜ ìœ„ì–‘ì„±ë¥ ë„ ë„ˆë¬´ í¬ì§€ ì•Šê²Œâ€ ë§Œë“œëŠ” ê· í˜•í˜• ê¸°ì¤€ìœ¼ë¡œ ì´í•´í•˜ë©´ ëœë‹¤.

**ì„ê³„ê°’ ì„ íƒ ê·œì¹™ (B): FPR ì œì•½ ì¡°ê±´ í•˜ì—ì„œ ìµœì í™”**

ìš´ì˜ì—ì„œ â€œì˜¤ê²½ë³´ëŠ” ìµœëŒ€ Î±ê¹Œì§€ë§Œ í—ˆìš©â€ ê°™ì€ ì •ì±…ì´ ìˆì„ ë•Œ, ë¨¼ì € FPR â‰¤ Î±ë¥¼ ë§Œì¡±í•˜ëŠ” ì„ê³„ê°’ í›„ë³´ë“¤ë§Œ ë‚¨ê¸´ ë’¤, ê·¸ì¤‘ì—ì„œ TPR(ì¬í˜„ìœ¨)ì´ ê°€ì¥ í° ì„ê³„ê°’ì„ ì„ íƒí•œë‹¤.
ì¦‰, ì œì•½ ì¡°ê±´ì„ ë¨¼ì € ë§Œì¡±ì‹œí‚¤ê³  ê·¸ ì•ˆì—ì„œ ì„±ëŠ¥ì„ ìµœëŒ€ë¡œ ë§Œë“œëŠ” ë°©ì‹ì´ë‹¤. ì˜ˆì»¨ëŒ€ Î±=0.02ëŠ” ë§¤ìš° ë³´ìˆ˜ì ì¸ ì˜¤ê²½ë³´ ì œí•œì— í•´ë‹¹í•˜ë¯€ë¡œ ì„ê³„ê°’ì´ ìƒëŒ€ì ìœ¼ë¡œ ë†’ì•„ì§€ê³ , ê·¸ ê²°ê³¼ recallì´ ì¼ë¶€ ê°ì†Œí•  ìˆ˜ ìˆë‹¤.

**ì„ê³„ê°’ ì„ íƒ ê·œì¹™ (C): ë¹„ìš© ê¸°ë°˜ ìµœì†Œí™”**

í˜„ì‹¤ì—ì„œëŠ” FNê³¼ FPì˜ ë¹„ìš©ì´ ë‹¤ë¥´ë¯€ë¡œ, ë¹„ìš©í•¨ìˆ˜ë¥¼ ë‘ê³  ì„ê³„ê°’ì„ ê³ ë¥¼ ìˆ˜ ìˆë‹¤.

Cost(t) = c_fn * FN(t) + c_fp * FP(t)

ì½”ë“œëŠ” ê°€ëŠ¥í•œ ì„ê³„ê°’ í›„ë³´ë“¤ì„ ìˆœíšŒí•˜ë©´ì„œ ë¹„ìš©ì„ ê³„ì‚°í•˜ê³ , ë¹„ìš©ì´ ìµœì†Œì¸ ì„ê³„ê°’ì„ ì„ íƒí•œë‹¤.
ì˜ˆë¥¼ ë“¤ì–´ c_fnì„ í¬ê²Œ ë‘ë©´(ë†“ì¹¨ ë¹„ìš©ì´ í¼), ëª¨ë¸ì€ FNì„ ì¤„ì´ê¸° ìœ„í•´ ì„ê³„ê°’ì„ ë‚®ì¶”ëŠ” ë°©í–¥ìœ¼ë¡œ ì„ íƒë˜ëŠ” ê²½í–¥ì´ ê°•í•´ì§„ë‹¤. ë°˜ëŒ€ë¡œ c_fpê°€ í¬ë©´ ì˜¤ê²½ë³´ë¥¼ ì¤„ì´ê¸° ìœ„í•´ ì„ê³„ê°’ì„ ì˜¬ë¦¬ëŠ” ë°©í–¥ì´ ëœë‹¤.

```python
# k-NN: ROC / PR + ì„ê³„ê°’(Threshold) ì„ íƒ ì½”ë“œ
# (ì „ì œ) knn_modelì´ ì´ë¯¸ fit ë˜ì–´ ìˆê³ , X_test, y_testê°€ ì¤€ë¹„ë˜ì–´ ìˆì–´ì•¼ í•¨.

import numpy as np
from sklearn.metrics import (
    roc_curve, auc,
    precision_recall_curve, average_precision_score,
    confusion_matrix
)

# =========================================================
# 0) Positive(ê´€ì‹¬ í´ë˜ìŠ¤) ì •ì˜
#    - ê¸°ë³¸: positive = 1 (benign)  [ë°ì´í„° ë¼ë²¨ ê·¸ëŒ€ë¡œ]
#    - ì˜ë£Œì§„ë‹¨ ê´€ì : positive = 0 (malignant) ë¡œ ë°”ê¾¸ë ¤ë©´ ì˜µì…˜ B ì‚¬ìš©
# =========================================================

# 1) score(í™•ë¥ ): P(y=1 | x)
p_pos1 = knn_model.predict_proba(X_test)[:, 1]

# A) positive = 1(benign)
y_pos = y_test
score = p_pos1

# B) (ì˜µì…˜) positive = malignant(0)ë¡œ ë³€ê²½ ì‹œ
# y_pos = (y_test == 0).astype(int)
# score = 1.0 - p_pos1   # = P(malignant | x)

# =========================================================
# 1) ROC curve + AUC
# =========================================================
fpr, tpr, thr_roc = roc_curve(y_pos, score)
roc_auc = auc(fpr, tpr)

# =========================================================
# 2) PR curve + AP
# =========================================================
precision, recall, thr_pr = precision_recall_curve(y_pos, score)
ap = average_precision_score(y_pos, score)

print("[k-NN] ROC AUC =", roc_auc)
print("[k-NN] PR  AP  =", ap)
print("ROC thresholds:", thr_roc.shape, "| PR thresholds:", thr_pr.shape)

# =========================================================
# 3) ì„ê³„ê°’ tì—ì„œ í˜¼ë™í–‰ë ¬/ì§€í‘œ ê³„ì‚°
# =========================================================
def metrics_at_threshold(y_true01, score, t):
    """
    y_true01: {0,1} (1ì´ positive)
    score   : positive ì ìˆ˜(í™•ë¥ )
    t       : threshold
    """
    y_hat = (score >= t).astype(int)
    tn, fp, fn, tp = confusion_matrix(y_true01, y_hat).ravel()

    recall_ = tp / (tp + fn) if (tp + fn) > 0 else 0.0  # TPR
    fpr_    = fp / (fp + tn) if (fp + tn) > 0 else 0.0
    prec_   = tp / (tp + fp) if (tp + fp) > 0 else 0.0
    acc_    = (tp + tn) / (tp + tn + fp + fn)

    return {
        "t": float(t),
        "tn": int(tn), "fp": int(fp), "fn": int(fn), "tp": int(tp),
        "recall(tpr)": float(recall_),
        "fpr": float(fpr_),
        "precision": float(prec_),
        "accuracy": float(acc_)
    }

# =========================================================
# 4) ì„ê³„ê°’ gridë¡œ ë³€í™” í™•ì¸(0.1~0.9)
# =========================================================
grid = np.arange(0.1, 1.0, 0.1)
for t in grid:
    print(metrics_at_threshold(y_pos, score, t))

# =========================================================
# 5) ì„ê³„ê°’ ì„ íƒ ê·œì¹™ (A) Youden J = TPR - FPR ìµœëŒ€
# =========================================================
J = tpr - fpr
best_idx = np.argmax(J)
best_t_youden = thr_roc[best_idx]

print("\n[Youden J]")
print("best t =", best_t_youden)
print(metrics_at_threshold(y_pos, score, best_t_youden))

# =========================================================
# 6) ì„ê³„ê°’ ì„ íƒ ê·œì¹™ (B) FPR <= alpha ì¡°ê±´ì—ì„œ TPR ìµœëŒ€
# =========================================================
def best_threshold_fpr_constraint(y_true01, score, alpha=0.02):
    fpr, tpr, thr = roc_curve(y_true01, score)
    candidates = np.where(fpr <= alpha)[0]
    if len(candidates) == 0:
        return None
    i = candidates[np.argmax(tpr[candidates])]
    return thr[i]

alpha = 0.02
best_t_fpr = best_threshold_fpr_constraint(y_pos, score, alpha=alpha)

print("\n[FPR constraint]")
print("alpha =", alpha, "best t =", best_t_fpr)
if best_t_fpr is not None:
    print(metrics_at_threshold(y_pos, score, best_t_fpr))

# =========================================================
# 7) ì„ê³„ê°’ ì„ íƒ ê·œì¹™ (C) ë¹„ìš© ê¸°ë°˜: c_fn*FN + c_fp*FP ìµœì†Œ
# =========================================================
def best_threshold_cost(y_true01, score, c_fn=10.0, c_fp=1.0):
    thresholds = np.unique(np.r_[0.0, score, 1.0])
    best_t, best_m, best_cost = None, None, np.inf

    for t in thresholds:
        m = metrics_at_threshold(y_true01, score, t)
        cost = c_fn * m["fn"] + c_fp * m["fp"]
        if cost < best_cost:
            best_t, best_m, best_cost = float(t), m, float(cost)

    return best_t, best_m, best_cost

best_t_cost, best_m_cost, best_cost_val = best_threshold_cost(y_pos, score, c_fn=10, c_fp=1)

print("\n[Cost-based]")
print("best t =", best_t_cost, "cost =", best_cost_val)
print(best_m_cost)
```

**(A) Youden J ìµœëŒ€:** tâ‰ˆ0.5953 / tn=51, fp=2, fn=2, tp=88 

FPR = 0.0377, TPR(recall)=0.9778

ROC ê´€ì ì—ì„œ TPRì„ ë†’ì´ë©´ì„œ FPRë„ ë‚®ì¶”ëŠ” â€œê· í˜•ì â€ì´ë‹¤. t=0.5ë³´ë‹¤ FP(ì•…ì„± ë†“ì¹¨)ê°€ 5â†’2ë¡œ ê°ì†Œí•˜ì§€ë§Œ, FNì´ 0â†’2ë¡œ ì†Œí­ ì¦ê°€í•œë‹¤.

**(B) FPR ì œì•½:** Î±=0.02 â†’ tâ‰ˆ0.7527

tn=53, fp=0, fn=11, tp=79 

FPR=0 (ì•…ì„±ì„ benignìœ¼ë¡œ ë†“ì¹˜ëŠ” ì¼ì´ 0) ëŒ€ì‹  FN=11 (benignì„ ì•…ì„±ìœ¼ë¡œ ì˜¤ê²½ë³´ ì¦ê°€) â†’ â€œì•…ì„±(malignant)ì„ benignìœ¼ë¡œ ë†“ì¹˜ë©´ ì•ˆ ëœë‹¤â€ ê°™ì€ ì •ì±…ì´ë¼ë©´(ì˜¤ê²½ë³´ ë¹„ìš©ë³´ë‹¤ ë†“ì¹¨ ë¹„ìš©ì´ í° ê²½ìš°) ì´ ë°©ì‹ì´ ìì—°ìŠ¤ëŸ½ë‹¤.

**(C) ë¹„ìš© ê¸°ë°˜:** $C_{FN}=10, C_{FP}=1 $ â†’ tâ‰ˆ0.7527

tn=49, fp=4, fn=0, tp=90, cost=4

FN(benignì„ ì•…ì„±ìœ¼ë¡œ ì˜¤ê²½ë³´)ì„ 10ë°°ë¡œ ë²Œì  ì£¼ì—ˆê¸° ë•Œë¬¸ì—, FN=0ì„ ìœ ì§€í•˜ë ¤ê³  tê°€ ìƒëŒ€ì ìœ¼ë¡œ ë‚®ê²Œ ì„ íƒëœë‹¤. ê·¸ ëŒ€ê°€ë¡œ FP=4ë¥¼ í—ˆìš©í•œë‹¤. â†’ ì´ ê²°ê³¼ëŠ” â€œì–‘ì„±(benign)ì„ ì•…ì„±ìœ¼ë¡œ ì˜¤ê²½ë³´ ë‚´ëŠ” ê²Œ ë§¤ìš° ë¹„ì‹¸ë‹¤â€ëŠ” ìš´ì˜ ê°€ì •ì— ë§ì¶˜ ì„ê³„ê°’ì…ë‹ˆë‹¤.

[k-NN] ROC AUC = 0.9947589098532496
<br>
[k-NN] PR  AP  = 0.9968371869230795
<br>
ROC thresholds: (11,) | PR thresholds: (52,)
{'t': 0.1, 'tn': 43, 'fp': 10, 'fn': 0, 'tp': 90, 'recall(tpr)': 1.0, 'fpr': 0.18867924528301888, 'precision': 0.9, 'accuracy': 0.9300699300699301}
<br>
(ì¤‘ê°„ìƒëµ)
<br>
{'t': 0.9, 'tn': 53, 'fp': 0, 'fn': 18, 'tp': 72, 'recall(tpr)': 0.8, 'fpr': 0.0, 'precision': 1.0, 'accuracy': 0.8741258741258742}

[Youden J]
<br>
best t = 0.5952751094038484
<br>
{'t': 0.5952751094038484, 'tn': 51, 'fp': 2, 'fn': 2, 'tp': 88, 'recall(tpr)': 0.9777777777777777, 'fpr': 0.03773584905660377, 'precision': 0.9777777777777777, 'accuracy': 0.972027972027972}

[FPR constraint]
<br>
alpha = 0.02 best t = 0.7527356507381722
<br>
{'t': 0.7527356507381722, 'tn': 53, 'fp': 0, 'fn': 11, 'tp': 79, 'recall(tpr)': 0.8777777777777778, 'fpr': 0.0, 'precision': 1.0, 'accuracy': 0.9230769230769231}

[Cost-based]
<br>
best t = 0.5563197878398277 cost = 4.0
<br>
{'t': 0.5563197878398277, 'tn': 49, 'fp': 4, 'fn': 0, 'tp': 90, 'recall(tpr)': 1.0, 'fpr': 0.07547169811320754, 'precision': 0.9574468085106383, 'accuracy': 0.972027972027972}

##### \(4) SVM

ì´ ì½”ë“œëŠ” Breast Cancer Wisconsin ë°ì´í„°ì— ëŒ€í•´ SVM(ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹ ) ë¶„ë¥˜ê¸°ë¥¼ í•™ìŠµí•˜ê³ , í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ê¸°ë³¸ ë¶„ë¥˜ ì„±ëŠ¥(ì •í™•ë„Â·í˜¼ë™í–‰ë ¬Â·ë¶„ë¥˜ë¦¬í¬íŠ¸) ì„ í™•ì¸í•˜ëŠ” ì ˆì°¨ë¥¼ êµ¬í˜„í•œë‹¤. 

íŠ¹íˆ SVMì€ ì…ë ¥ ë³€ìˆ˜ì˜ ìŠ¤ì¼€ì¼ì— ë¯¼ê°í•˜ë¯€ë¡œ, í‘œì¤€í™”(Standardization) ì™€ ëª¨ë¸ì„ Pipelineìœ¼ë¡œ ë¬¶ì–´ ì „ì²˜ë¦¬ì™€ í•™ìŠµÂ·ì˜ˆì¸¡ ê³¼ì •ì„ í•œ ë²ˆì— ì²˜ë¦¬í•˜ë„ë¡ êµ¬ì„±í•˜ì˜€ë‹¤.

ë¨¼ì € Pipeline([("scaler", StandardScaler()), ("svm", SVC(...))]) í˜•íƒœë¡œ íŒŒì´í”„ë¼ì¸ì„ ì •ì˜í•œë‹¤. ì—¬ê¸°ì„œ StandardScaler()ëŠ” í›ˆë ¨ ë°ì´í„°ì—ì„œ ê° ë³€ìˆ˜ì˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ ì¶”ì •í•œ ë’¤, ëª¨ë“  ë³€ìˆ˜ë¥¼ ì •ê·œ ë³€í™˜í•˜ì—¬ í‰ê·  0, ë¶„ì‚° 1 ìˆ˜ì¤€ìœ¼ë¡œ ë§ì¶˜ë‹¤. 

SVMì€ ê±°ë¦¬Â·ë‚´ì  ê¸°ë°˜(íŠ¹íˆ RBF ì»¤ë„ì€ ê±°ë¦¬ ê¸°ë°˜)ì˜ ë¶„ë¥˜ê¸°ì´ë¯€ë¡œ ë³€ìˆ˜ ìŠ¤ì¼€ì¼ì´ ë‹¤ë¥´ë©´ íŠ¹ì • ë³€ìˆ˜ì˜ ì˜í–¥ì´ ê³¼ë„í•´ì§ˆ ìˆ˜ ìˆëŠ”ë°, í‘œì¤€í™”ëŠ” ì´ë¥¼ ë°©ì§€í•˜ì—¬ í•™ìŠµì„ ì•ˆì •í™”í•œë‹¤. ë˜í•œ Pipelineì„ ì‚¬ìš©í•˜ë©´ í‘œì¤€í™”ì˜ fitì€ í›ˆë ¨ ë°ì´í„°ì—ë§Œ ì ìš©ë˜ê³  í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ëŠ” ê°™ì€ ë³€í™˜ì´ transformìœ¼ë¡œë§Œ ì ìš©ë˜ì–´, í…ŒìŠ¤íŠ¸ ì •ë³´ê°€ í•™ìŠµì— ì„ì´ëŠ” ë°ì´í„° ëˆ„ìˆ˜(leakage) ë¥¼ ë§‰ëŠ”ë‹¤.

ë‘ ë²ˆì§¸ ë‹¨ê³„ì¸ SVC(...)ëŠ” SVM ë¶„ë¥˜ê¸°ë¥¼ ì˜ë¯¸í•œë‹¤. ì—¬ê¸°ì„œ kernel="rbf"ëŠ” ë¹„ì„ í˜• ë¶„ë¥˜ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ê°€ìš°ì‹œì•ˆ(RBF) ì»¤ë„ì„ ì‚¬ìš©í•œë‹¤ëŠ” ëœ»ì´ë©°, ì…ë ¥ê³µê°„ì—ì„œ ì„ í˜• ë¶„ë¦¬ê°€ ì–´ë µë”ë¼ë„ ê³ ì°¨ì› íŠ¹ì§•ê³µê°„ì—ì„œì˜ ë¶„ë¦¬ ì´ˆí‰ë©´ì„ í†µí•´ ë³µì¡í•œ ê²°ì •ê²½ê³„ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆë‹¤. 

C=1.0ì€ ë§ˆì§„ì„ ë„“ê²Œ ìœ ì§€í•˜ë ¤ëŠ” ì„±í–¥ê³¼ í•™ìŠµ ë°ì´í„° ì˜¤ë¶„ë¥˜ë¥¼ ì¤„ì´ë ¤ëŠ” ì„±í–¥ ì‚¬ì´ì˜ ê· í˜•ì„ ì¡°ì ˆí•˜ëŠ” ê·œì œ(regularization) íŒŒë¼ë¯¸í„°ë¡œ, Cê°€ ì»¤ì§€ë©´ ì˜¤ë¶„ë¥˜ë¥¼ ë” ê°•í•˜ê²Œ ë²Œì  ì£¼ì–´ í›ˆë ¨ ë°ì´í„°ì— ë” ë§ì¶”ë ¤ í•˜ê³ , ì‘ì•„ì§€ë©´ ë§ˆì§„ì„ ë„“ê²Œ ë‘ë©° ì¼ë°˜í™”ë¥¼ ë” ì¤‘ì‹œí•˜ëŠ” ê²½í–¥ì´ ìˆë‹¤. 

gamma="scale"ì€ RBF ì»¤ë„ì˜ í­(ì˜í–¥ ë²”ìœ„)ì„ ìë™ìœ¼ë¡œ ì„¤ì •í•˜ëŠ” ì˜µì…˜ìœ¼ë¡œ, ê°’ì´ ì»¤ì§€ë©´ ê²°ì •ê²½ê³„ê°€ ë” êµ¬ë¶ˆêµ¬ë¶ˆí•´ì ¸ ê³¼ì í•© ìœ„í—˜ì´ ì»¤ì§€ê³ , ì‘ì•„ì§€ë©´ ë” ë§¤ëˆí•œ ê²½ê³„ê°€ ëœë‹¤. probability=TrueëŠ” SVMì´ ê¸°ë³¸ì ìœ¼ë¡œëŠ” â€œí™•ë¥ â€ì´ ì•„ë‹ˆë¼ ê²°ì •í•¨ìˆ˜ ê°’(decision score) ì„ ì¶œë ¥í•˜ëŠ” ëª¨ë¸ì´ê¸° ë•Œë¬¸ì—, ROC/PR ê³¡ì„  ë° ì„ê³„ê°’ ì¡°ì •ì„ ìœ„í•´ í™•ë¥  í˜•íƒœì˜ ì¶œë ¥(predict_proba) ì„ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë‚´ë¶€ì ìœ¼ë¡œ í™•ë¥  ë³´ì •(calibration)ì„ ìˆ˜í–‰í•˜ê² ë‹¤ëŠ” ì„¤ì •ì´ë‹¤. 

random_state=42ëŠ” í™•ë¥  ë³´ì • ê³¼ì • ë“±ì—ì„œ ì¬í˜„ì„±ì„ í™•ë³´í•˜ê¸° ìœ„í•œ ë‚œìˆ˜ ì‹œë“œë¡œ ì´í•´í•˜ë©´ ëœë‹¤.

ëª¨ë¸ í•™ìŠµì€ svm_model.fit(X_train, y_train)ì—ì„œ ì´ë£¨ì–´ì§„ë‹¤. ì´ë•Œ íŒŒì´í”„ë¼ì¸ì´ ë¨¼ì € í›ˆë ¨ ë°ì´í„°ë¥¼ í‘œì¤€í™”í•œ ë’¤, í‘œì¤€í™”ëœ ì…ë ¥ìœ¼ë¡œ SVMì„ í•™ìŠµí•œë‹¤. í•™ìŠµì´ ëë‚˜ë©´ svm_model.predict(X_test)ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ í´ë˜ìŠ¤ ë¼ë²¨(0/1)ì„ ì˜ˆì¸¡í•œë‹¤. 

ë§ˆì§€ë§‰ìœ¼ë¡œ accuracy_scoreëŠ” ì „ì²´ ì •í™•ë„ë¥¼ ê³„ì‚°í•˜ê³ , confusion_matrixëŠ” ì‹¤ì œ ë¼ë²¨ê³¼ ì˜ˆì¸¡ ë¼ë²¨ì„ êµì°¨ ì§‘ê³„í•˜ì—¬ TN, FP, FN, TPì˜ êµ¬ì¡°ë¥¼ ì œê³µí•œë‹¤. classification_reportëŠ” í´ë˜ìŠ¤ë³„ë¡œ precision, recall, F1-scoreë¥¼ ìš”ì•½í•´ì£¼ë¯€ë¡œ, ë‹¨ìˆœ ì •í™•ë„ë¿ ì•„ë‹ˆë¼ â€œì•…ì„±ì„ ì–¼ë§ˆë‚˜ ë†“ì¹˜ëŠ”ì§€(FN)â€ ë˜ëŠ” â€œì–‘ì„±ì„ ì–¼ë§ˆë‚˜ ì•…ì„±ìœ¼ë¡œ ì˜¤ê²½ë³´í•˜ëŠ”ì§€(FP)â€ì™€ ê°™ì€ ì˜¤ë¥˜ ìœ í˜•ì„ ë” ì„¸ë°€í•˜ê²Œ í•´ì„í•  ìˆ˜ ìˆê²Œ í•œë‹¤.

ìš”ì•½í•˜ë©´, ì´ ì½”ë“œëŠ” (í‘œì¤€í™” â†’ RBF SVM í•™ìŠµ â†’ í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ â†’ ê¸°ë³¸ ì„±ëŠ¥ í‰ê°€) ì˜ ì „í˜•ì ì¸ ì´ì§„ë¶„ë¥˜ ì‹¤ìŠµ íë¦„ì„ íŒŒì´í”„ë¼ì¸ í˜•íƒœë¡œ ê¹”ë”í•˜ê²Œ êµ¬í˜„í•œ ì˜ˆì œì´ë©°, ì´í›„ ROC/PR ë¶„ì„ ë° ì„ê³„ê°’ ì„ íƒìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ í™•ì¥í•  ìˆ˜ ìˆëŠ” ê¸°ë³¸ ê³¨ê²©ì„ ì œê³µí•œë‹¤.

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# SVM ëª¨ë¸ (í‘œì¤€í™” + SVM)
svm_model = Pipeline([
    ("scaler", StandardScaler()),
    ("svm", SVC(
        kernel="rbf",        # 'linear', 'rbf' ë“±
        C=1.0,
        gamma="scale",
        probability=True,    # ROC/PRìš© í™•ë¥  í•„ìš”
        random_state=42
    ))
])

# í•™ìŠµ
svm_model.fit(X_train, y_train)

# ì˜ˆì¸¡(í´ë˜ìŠ¤)
y_pred_svm = svm_model.predict(X_test)

# í‰ê°€(ê¸°ë³¸)
print("[SVM] Accuracy:", accuracy_score(y_test, y_pred_svm))
print("[SVM] Confusion matrix:\n", confusion_matrix(y_test, y_pred_svm))
print("[SVM] Classification report:\n", classification_report(y_test, y_pred_svm, target_names=data.target_names))
```
```text
[SVM] Accuracy: 0.9790209790209791
[SVM] Confusion matrix:
 [[52  1]
 [ 2 88]]
[SVM] Classification report:
               precision    recall  f1-score   support

   malignant       0.96      0.98      0.97        53
      benign       0.99      0.98      0.98        90

    accuracy                           0.98       143
   macro avg       0.98      0.98      0.98       143
weighted avg       0.98      0.98      0.98       143
```

```python
# =========================================================
# SVM ì„ê³„ê°’(Threshold) ê²°ì • íŒŒíŠ¸
#   - ì§€í‘œ í•¨ìˆ˜(metrics_at_threshold)
#   - Youden J ìµœì 
#   - FPR <= alpha ì œì•½ ìµœì 
#   - ë¹„ìš© ê¸°ë°˜(c_fn*FN + c_fp*FP) ìµœì 
# (ì „ì œ) svm_model.fit(...) ì™„ë£Œ, X_test, y_test ì¡´ì¬
# =========================================================

import numpy as np
from sklearn.metrics import confusion_matrix, roc_curve

# ---------------------------------------------------------
# 0) Positive(ê´€ì‹¬ í´ë˜ìŠ¤) ì •ì˜
#   - ê¸°ë³¸: positive = 1 (benign)  [ì› ë¼ë²¨ ê·¸ëŒ€ë¡œ]
#   - ì˜ë£Œì§„ë‹¨ ê´€ì : positive = malignant(0)ë¡œ ë°”ê¾¸ë ¤ë©´ ì˜µì…˜ B ì‚¬ìš©
# ---------------------------------------------------------

# SVM í™•ë¥ (score): P(y=1 | x)
p_pos1_svm = svm_model.predict_proba(X_test)[:, 1]

# A) positive = 1(benign)
y_pos = y_test
score = p_pos1_svm

# B) (ì˜µì…˜) positive = malignant(0)ë¡œ ë³€ê²½ ì‹œ (ì•…ì„±ì„ 1ë¡œ ì¬ì½”ë”©)
# y_pos = (y_test == 0).astype(int)
# score = 1.0 - p_pos1_svm   # = P(malignant | x)

# ---------------------------------------------------------
# 1) ì„ê³„ê°’ tì—ì„œ í˜¼ë™í–‰ë ¬/ì§€í‘œ ê³„ì‚°
# ---------------------------------------------------------
def metrics_at_threshold(y_true01, score, t):
    """
    y_true01: {0,1} (1ì´ positive)
    score   : positive ì ìˆ˜(í™•ë¥ )
    t       : threshold
    """
    y_hat = (score >= t).astype(int)
    tn, fp, fn, tp = confusion_matrix(y_true01, y_hat).ravel()

    recall_ = tp / (tp + fn) if (tp + fn) > 0 else 0.0  # TPR
    fpr_    = fp / (fp + tn) if (fp + tn) > 0 else 0.0
    prec_   = tp / (tp + fp) if (tp + fp) > 0 else 0.0
    acc_    = (tp + tn) / (tp + tn + fp + fn)

    return {
        "t": float(t),
        "tn": int(tn), "fp": int(fp), "fn": int(fn), "tp": int(tp),
        "recall(tpr)": float(recall_),
        "fpr": float(fpr_),
        "precision": float(prec_),
        "accuracy": float(acc_)
    }

print("[Default t=0.5]")
print(metrics_at_threshold(y_pos, score, 0.5))

# (ì„ íƒ) ì„ê³„ê°’ ë³€í™” ê° í™•ì¸
print("\n[Grid check]")
for t in np.arange(0.1, 1.0, 0.1):
    print(metrics_at_threshold(y_pos, score, t))

# ---------------------------------------------------------
# 2) (A) Youden's J = TPR - FPR ìµœëŒ€í™”
# ---------------------------------------------------------
fpr, tpr, thr_roc = roc_curve(y_pos, score)
J = tpr - fpr
best_t_youden = float(thr_roc[np.argmax(J)])

print("\n[Youden J]")
print("best t =", best_t_youden)
print(metrics_at_threshold(y_pos, score, best_t_youden))

# ---------------------------------------------------------
# 3) (B) FPR <= alpha ì œì•½ì—ì„œ TPR ìµœëŒ€í™”
# ---------------------------------------------------------
def best_threshold_fpr_constraint(y_true01, score, alpha=0.02):
    fpr, tpr, thr = roc_curve(y_true01, score)
    candidates = np.where(fpr <= alpha)[0]
    if len(candidates) == 0:
        return None
    i = candidates[np.argmax(tpr[candidates])]
    return float(thr[i])

alpha = 0.02
best_t_fpr = best_threshold_fpr_constraint(y_pos, score, alpha=alpha)

print("\n[FPR constraint]")
print("alpha =", alpha, "best t =", best_t_fpr)
if best_t_fpr is not None:
    print(metrics_at_threshold(y_pos, score, best_t_fpr))

# ---------------------------------------------------------
# 4) (C) ë¹„ìš© ê¸°ë°˜: cost = c_fn*FN + c_fp*FP ìµœì†Œí™”
# ---------------------------------------------------------
def best_threshold_cost(y_true01, score, c_fn=10.0, c_fp=1.0):
    thresholds = np.unique(np.r_[0.0, score, 1.0])
    best_t, best_m, best_cost = None, None, np.inf

    for t in thresholds:
        m = metrics_at_threshold(y_true01, score, t)
        cost = c_fn * m["fn"] + c_fp * m["fp"]
        if cost < best_cost:
            best_t, best_m, best_cost = float(t), m, float(cost)

    return best_t, best_m, best_cost

best_t_cost, best_m_cost, best_cost_val = best_threshold_cost(
    y_pos, score, c_fn=10, c_fp=1
)

print("\n[Cost-based]")
print("best t =", best_t_cost, "cost =", best_cost_val)
print(best_m_cost)
```

[Default t=0.5]
{'t': 0.5, 'tn': 52, 'fp': 1, 'fn': 2, 'tp': 88, 'recall(tpr)': 0.9777777777777777, 'fpr': 0.018867924528301886, 'precision': 0.9887640449438202, 'accuracy': 0.9790209790209791}

[Grid check]
{'t': 0.1, 'tn': 44, 'fp': 9, 'fn': 0, 'tp': 90, 'recall(tpr)': 1.0, 'fpr': 0.16981132075471697, 'precision': 0.9090909090909091, 'accuracy': 0.9370629370629371}

(ì´í•˜ ìƒëµ)

[Youden J] best t = 0.4325023552646032

{'t': 0.4325023552646032, 'tn': 52, 'fp': 1, 'fn': 1, 'tp': 89, 'recall(tpr)': 0.9888888888888889, 'fpr': 0.018867924528301886, 'precision': 0.9888888888888889, 'accuracy': 0.986013986013986}

[FPR constraint] alpha = 0.02 best t = 0.4325023552646032

{'t': 0.4325023552646032, 'tn': 52, 'fp': 1, 'fn': 1, 'tp': 89, 'recall(tpr)': 0.9888888888888889, 'fpr': 0.018867924528301886, 'precision': 0.9888888888888889, 'accuracy': 0.986013986013986}

[Cost-based] best t = 0.2980459103264749 cost = 3.0

{'t': 0.2980459103264749, 'tn': 50, 'fp': 3, 'fn': 0, 'tp': 90, 'recall(tpr)': 1.0, 'fpr': 0.05660377358490566, 'precision': 0.967741935483871, 'accuracy': 0.9790209790209791}

##### \(5) knn vs.SVM ë¹„êµ

```python
import numpy as np
import pandas as pd
from sklearn.metrics import roc_curve, confusion_matrix

# =========================================================
# 1) ì•…ì„±=positive(1)ë¡œ ì¬ì½”ë”© + ëª¨ë¸ score(ì•…ì„± í™•ë¥ ) ì¶”ì¶œ
# =========================================================
def get_score_for_class(model, X, class_label):
    """predict_proba ê¸°ë°˜ìœ¼ë¡œ íŠ¹ì • class_labelì˜ í™•ë¥ ì„ ë°˜í™˜ (Pipeline í¬í•¨)."""
    if not hasattr(model, "predict_proba"):
        raise ValueError("This model has no predict_proba. (SVCëŠ” probability=True í•„ìš”)")
    proba = model.predict_proba(X)

    # Pipelineì¸ ê²½ìš° classes_ ì ‘ê·¼ì„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
    classes = getattr(model, "classes_", None)
    if classes is None and hasattr(model, "named_steps"):
        classes = list(model.named_steps.values())[-1].classes_
    classes = np.array(classes)

    idx = np.where(classes == class_label)[0][0]
    return proba[:, idx]

# ì•…ì„±(malignant=0)ì„ positive=1ë¡œ ë‘ê¸°
y_pos = (y_test == 0).astype(int)  # 1ì´ë©´ malignant

# ê° ëª¨ë¸ì˜ "ì•…ì„± í™•ë¥ " score
score_knn = get_score_for_class(knn_model, X_test, class_label=0)  # P(malignant|x)
score_svm = get_score_for_class(svm_model, X_test, class_label=0)  # P(malignant|x)

# =========================================================
# 2) ì„ê³„ê°’ tì—ì„œ ì§€í‘œ ê³„ì‚°
# =========================================================
def metrics_at_threshold(y_true01, score, t):
    y_hat = (score >= t).astype(int)
    tn, fp, fn, tp = confusion_matrix(y_true01, y_hat).ravel()

    recall_ = tp / (tp + fn) if (tp + fn) > 0 else 0.0  # TPR
    fpr_    = fp / (fp + tn) if (fp + tn) > 0 else 0.0
    prec_   = tp / (tp + fp) if (tp + fp) > 0 else 0.0
    acc_    = (tp + tn) / (tp + tn + fp + fn)

    return {
        "t": float(t),
        "tn": int(tn), "fp": int(fp), "fn": int(fn), "tp": int(tp),
        "recall(tpr)": float(recall_),
        "fpr": float(fpr_),
        "precision": float(prec_),
        "accuracy": float(acc_)
    }

# =========================================================
# 3) ì„ê³„ê°’ ì„ íƒ ê·œì¹™ 3ì¢…
# =========================================================
def threshold_youden(y_true01, score):
    fpr, tpr, thr = roc_curve(y_true01, score)
    J = tpr - fpr
    return float(thr[np.argmax(J)])

def threshold_fpr_constraint(y_true01, score, alpha=0.02):
    fpr, tpr, thr = roc_curve(y_true01, score)
    cand = np.where(fpr <= alpha)[0]
    if len(cand) == 0:
        return None
    i = cand[np.argmax(tpr[cand])]
    return float(thr[i])

def threshold_cost(y_true01, score, c_fn=10.0, c_fp=1.0):
    thresholds = np.unique(np.r_[0.0, score, 1.0])
    best_t, best_cost = None, np.inf
    for t in thresholds:
        m = metrics_at_threshold(y_true01, score, t)
        cost = c_fn * m["fn"] + c_fp * m["fp"]
        if cost < best_cost:
            best_cost = cost
            best_t = float(t)
    return best_t, float(best_cost)

# =========================================================
# 4) k-NN vs SVM ë¹„êµí‘œ ìƒì„±
# =========================================================
def build_rows(model_name, y_true01, score, alpha=0.02, c_fn=10.0, c_fp=1.0):
    rows = []

    # Youden
    t_y = threshold_youden(y_true01, score)
    m_y = metrics_at_threshold(y_true01, score, t_y)
    m_y.update({"model": model_name, "rule": "Youden (TPR-FPR)", "cost": c_fn*m_y["fn"] + c_fp*m_y["fp"]})
    rows.append(m_y)

    # FPR constraint
    t_f = threshold_fpr_constraint(y_true01, score, alpha=alpha)
    if t_f is not None:
        m_f = metrics_at_threshold(y_true01, score, t_f)
        m_f.update({"model": model_name, "rule": f"FPR <= {alpha}", "cost": c_fn*m_f["fn"] + c_fp*m_f["fp"]})
    else:
        m_f = {"model": model_name, "rule": f"FPR <= {alpha}", "t": None,
               "tn": None, "fp": None, "fn": None, "tp": None,
               "recall(tpr)": None, "fpr": None, "precision": None, "accuracy": None,
               "cost": None}
    rows.append(m_f)

    # Cost-based
    t_c, best_cost = threshold_cost(y_true01, score, c_fn=c_fn, c_fp=c_fp)
    m_c = metrics_at_threshold(y_true01, score, t_c)
    m_c.update({"model": model_name, "rule": f"Cost (c_fn={c_fn}, c_fp={c_fp})", "cost": best_cost})
    rows.append(m_c)

    return rows

alpha = 0.02
c_fn, c_fp = 10.0, 1.0

rows = []
rows += build_rows("k-NN", y_pos, score_knn, alpha=alpha, c_fn=c_fn, c_fp=c_fp)
rows += build_rows("SVM",  y_pos, score_svm, alpha=alpha, c_fn=c_fn, c_fp=c_fp)

df_cmp = pd.DataFrame(rows)[
    ["model","rule","t","tn","fp","fn","tp","recall(tpr)","fpr","precision","accuracy","cost"]
].sort_values(["rule","model"]).reset_index(drop=True)

print("== ì•…ì„±(malignant=0)ì„ positive(=1)ë¡œ í†µì¼í•œ ì„ê³„ê°’ ë¹„êµí‘œ ==")
display(df_cmp)
```

SVMì€ tâ‰ˆ0.593ì—ì„œ TN=89, FP=1, FN=1, TP=52ë¡œ ë‚˜íƒ€ë‚˜ë©°, ì´ëŠ” ì•…ì„± 53ê±´ ì¤‘ 52ê±´ì„ ì°¾ì•„ ì¬í˜„ìœ¨(Recall)=0.981ì„ ë‹¬ì„±í•˜ë©´ì„œë„, ì–‘ì„± 90ê±´ ì¤‘ ì˜¤ê²½ë³´ëŠ” 1ê±´ë¿ì´ë¼ FPR=0.011ë¡œ ë§¤ìš° ë‚®ë‹¤ëŠ” ëœ»ì´ë‹¤. ì •í™•ë„ë„ 0.986ìœ¼ë¡œ ë†’ë‹¤. 

ì¦‰ SVMì€ ë†“ì¹¨(FN)ê³¼ ì˜¤ê²½ë³´(FP)ë¥¼ ë™ì‹œì— ì‘ê²Œ ìœ ì§€í•˜ëŠ” ê· í˜•í˜• ìš´ì˜ì ì„ ì œê³µí•œë‹¤. ë˜í•œ ì´ ë°ì´í„°ì—ì„œëŠ” Youden ê¸°ì¤€ê³¼ FPRâ‰¤0.02 ì œì•½ ê¸°ì¤€ì´ ê°™ì€ ì„ê³„ê°’(ë™ì¼í•œ ROC êµ¬ê°„ì˜ ìµœì ì )ìœ¼ë¡œ ìˆ˜ë ´í•˜ì—¬, â€œì˜¤ê²½ë³´ë¥¼ 2% ì´ë‚´ë¡œ ì œí•œâ€í•˜ë”ë¼ë„ ì„±ëŠ¥ ì €í•˜ ì—†ì´ ê°™ì€ ìš´ì˜ì ì´ ì„ íƒë˜ì—ˆë‹¤ê³  í•´ì„í•  ìˆ˜ ìˆë‹¤. (í‘œë³¸ì´ ìœ í•œí•˜ë©´ ROCê°€ ê³„ë‹¨í˜•ì´ì–´ì„œ ì—¬ëŸ¬ ê·œì¹™ì´ ê°™ì€ ì ì„ ì„ íƒí•˜ëŠ” ì¼ì´ í”í•˜ë‹¤.)

ë°˜ë©´ k-NNì€ ë¹„ìš©ê¸°ë°˜(c_FN=10, c_FP=1)ì—ì„œ tâ‰ˆ0.254ë¡œ ì„ê³„ê°’ì´ ë‚®ê²Œ ì„ íƒë˜ë©°, ì´ë•Œ FN=0ì´ ë˜ì–´ ì•…ì„± ë†“ì¹¨ì´ ë°œìƒí•˜ì§€ ì•ŠëŠ”ë‹¤(Recall=1.0). í•˜ì§€ë§Œ ê·¸ ëŒ€ê°€ë¡œ FP=11ì´ ë°œìƒí•´ FPRì´ 0.122ë¡œ ì»¤ì§€ê³ , ì •í™•ë„ë„ 0.923ìœ¼ë¡œ ë–¨ì–´ì§„ë‹¤. ì¦‰ k-NNì˜ ë¹„ìš©ê¸°ë°˜ ì„ íƒì€ â€œì•…ì„±ì„ ì ˆëŒ€ ë†“ì¹˜ì§€ ì•ŠëŠ” ê²ƒâ€ì„ ìš°ì„ í•˜ëŠ” ëŒ€ì‹ , ì–‘ì„±ì— ëŒ€í•œ ì˜¤ê²½ë³´ë¥¼ ë§ì´ ê°ìˆ˜í•˜ëŠ” ìš´ì˜ì ì´ë‹¤.

k-NNì—ì„œ FPRâ‰¤0.02 ì œì•½ì„ ê°•í•˜ê²Œ ì ìš©í•˜ë©´ tâ‰ˆ0.423ì—ì„œ FP=1ë¡œ ì˜¤ê²½ë³´ë¥¼ ê±°ì˜ SVM ìˆ˜ì¤€ê¹Œì§€ ì¤„ì¼ ìˆ˜ ìˆì§€ë§Œ, ê·¸ë•Œ FN=3ìœ¼ë¡œ ì•…ì„± ë†“ì¹¨ì´ ì¦ê°€í•˜ì—¬(Recallâ‰ˆ0.943) ë¹„ìš©(ì—¬ê¸°ì„œëŠ” c_FNì´ í¬ë¯€ë¡œ)ì´ ì»¤ì§„ë‹¤. Youden ê¸°ì¤€ì€ tâ‰ˆ0.406ì—ì„œ FP=2, FN=2ë¡œ ê· í˜•ì„ ì¡ì§€ë§Œ, ì—¬ì „íˆ SVMì˜ ìš´ì˜ì (FP=1, FN=1)ë³´ë‹¤ ì „ì²´ì ìœ¼ë¡œ ë¶ˆë¦¬í•˜ë‹¤.

ë”°ë¼ì„œ ì´ í‘œê°€ ì‹œì‚¬í•˜ëŠ” ê²°ë¡ ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. ì¼ë°˜ì ì¸ ê· í˜• ì„±ëŠ¥(ë‚®ì€ FNê³¼ ë‚®ì€ FPë¥¼ ë™ì‹œì—)ê³¼ ë†’ì€ ì •í™•ë„ë¥¼ ì›í•˜ë©´ SVMì´ ìš°ì„¸í•˜ë©°, íŠ¹íˆ í˜„ì¬ ì„¤ì •ì—ì„œëŠ” SVMì˜ Youden(=FPR ì œì•½) ì„ê³„ê°’ì´ ê°€ì¥ ì•ˆì •ì ì¸ ì„ íƒì´ë‹¤. 

ë°˜ëŒ€ë¡œ â€œì•…ì„± ë†“ì¹¨(FN)=0â€ì´ ì •ì±…ì ìœ¼ë¡œ ì ˆëŒ€ì¡°ê±´ì´ë¼ë©´, í˜„ì¬ í‘œì—ì„œëŠ” k-NNì˜ ë¹„ìš©ê¸°ë°˜ ì„ê³„ê°’ì´ ê·¸ ì¡°ê±´ì„ ë§Œì¡±í•˜ì§€ë§Œ, ì˜¤ê²½ë³´(FP)ê°€ í¬ê²Œ ëŠ˜ì–´ë‚˜ëŠ” ì ì„ í•¨ê»˜ ê°ìˆ˜í•´ì•¼ í•œë‹¤. (ì‹¤ë¬´ì ìœ¼ë¡œëŠ” ê°™ì€ ëª©ì ì„ ìœ„í•´ SVMë„ ì„ê³„ê°’ì„ ë” ë‚®ì¶° FN=0ì„ ë§Œì¡±í•˜ëŠ” ì§€ì ì„ ì°¾ëŠ” ë°©ì‹ìœ¼ë¡œ ì¡°ì •í•  ìˆ˜ë„ ìˆë‹¤.)

![](images/classification_ml_tvalue.png){fig-align="center" width="100%"}

##### \(6) íšŒê·€ê¸°ë°˜ ë¶„ë¥˜

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ (í‘œì¤€í™” + Logistic Regression)
logit_model = Pipeline([
    ("scaler", StandardScaler()),
    ("logit", LogisticRegression(
        penalty="l2",
        C=1.0,
        solver="lbfgs",      # ì´ì§„/ë‹¤ì¤‘ ëª¨ë‘ ì•ˆì •ì 
        max_iter=5000,
        random_state=42
    ))
])

# í•™ìŠµ
logit_model.fit(X_train, y_train)

# ì˜ˆì¸¡(í´ë˜ìŠ¤)
y_pred_logit = logit_model.predict(X_test)

# í‰ê°€(ê¸°ë³¸)
print("[Logistic] Accuracy:", accuracy_score(y_test, y_pred_logit))
print("[Logistic] Confusion matrix:\n", confusion_matrix(y_test, y_pred_logit))
print("[Logistic] Classification report:\n",
      classification_report(y_test, y_pred_logit, target_names=data.target_names))
```
```text
[Logistic] Accuracy: 0.986013986013986
[Logistic] Confusion matrix:
 [[52  1]
 [ 1 89]]
[Logistic] Classification report:
               precision    recall  f1-score   support

   malignant       0.98      0.98      0.98        53
      benign       0.99      0.99      0.99        90

    accuracy                           0.99       143
   macro avg       0.99      0.99      0.99       143
weighted avg       0.99      0.99      0.99       143
```

```python
import numpy as np
from sklearn.metrics import (
    roc_curve, auc,
    precision_recall_curve, average_precision_score,
    confusion_matrix
)

# ---------------------------------------------------------
# (A) ì•…ì„±(malignant=0)ì„ positive(=1)ë¡œ í†µì¼
# ---------------------------------------------------------
y_pos = (y_test == 0).astype(int)  # 1ì´ë©´ malignant

# ë¡œì§€ìŠ¤í‹± íšŒê·€ í™•ë¥ : P(y=1|x)ì—ì„œ í´ë˜ìŠ¤ 0(malignant) í™•ë¥ ì„ scoreë¡œ ì‚¬ìš©
proba = logit_model.predict_proba(X_test)  # shape: (n, 2)
classes = logit_model.named_steps["logit"].classes_
idx_malignant = np.where(classes == 0)[0][0]
score = proba[:, idx_malignant]            # score = P(malignant | x)

# ---------------------------------------------------------
# (B) ROC / PR
# ---------------------------------------------------------
fpr, tpr, thr_roc = roc_curve(y_pos, score)
roc_auc = auc(fpr, tpr)

precision, recall, thr_pr = precision_recall_curve(y_pos, score)
ap = average_precision_score(y_pos, score)

print("[Logistic] ROC AUC =", roc_auc)
print("[Logistic] PR  AP  =", ap)

# ---------------------------------------------------------
# (C) ì„ê³„ê°’ tì—ì„œ í˜¼ë™í–‰ë ¬/ì§€í‘œ ê³„ì‚°
# ---------------------------------------------------------
def metrics_at_threshold(y_true01, score, t):
    y_hat = (score >= t).astype(int)
    tn, fp, fn, tp = confusion_matrix(y_true01, y_hat).ravel()

    recall_ = tp / (tp + fn) if (tp + fn) > 0 else 0.0  # TPR
    fpr_    = fp / (fp + tn) if (fp + tn) > 0 else 0.0
    prec_   = tp / (tp + fp) if (tp + fp) > 0 else 0.0
    acc_    = (tp + tn) / (tp + tn + fp + fn)

    return {
        "t": float(t),
        "tn": int(tn), "fp": int(fp), "fn": int(fn), "tp": int(tp),
        "recall(tpr)": float(recall_),
        "fpr": float(fpr_),
        "precision": float(prec_),
        "accuracy": float(acc_)
    }

print("\n[Default t=0.5]")
print(metrics_at_threshold(y_pos, score, 0.5))

print("\n[Grid check]")
for t in np.arange(0.1, 1.0, 0.1):
    print(metrics_at_threshold(y_pos, score, t))

# ---------------------------------------------------------
# (D) ì„ê³„ê°’ ì„ íƒ 1: Youden J = TPR - FPR ìµœëŒ€
# ---------------------------------------------------------
J = tpr - fpr
best_t_youden = float(thr_roc[np.argmax(J)])

print("\n[Youden J]")
print("best t =", best_t_youden)
print(metrics_at_threshold(y_pos, score, best_t_youden))

# ---------------------------------------------------------
# (E) ì„ê³„ê°’ ì„ íƒ 2: FPR <= alpha ì œì•½ì—ì„œ TPR ìµœëŒ€
# ---------------------------------------------------------
def best_threshold_fpr_constraint(y_true01, score, alpha=0.02):
    fpr, tpr, thr = roc_curve(y_true01, score)
    cand = np.where(fpr <= alpha)[0]
    if len(cand) == 0:
        return None
    i = cand[np.argmax(tpr[cand])]
    return float(thr[i])

alpha = 0.02
best_t_fpr = best_threshold_fpr_constraint(y_pos, score, alpha=alpha)

print("\n[FPR constraint]")
print("alpha =", alpha, "best t =", best_t_fpr)
if best_t_fpr is not None:
    print(metrics_at_threshold(y_pos, score, best_t_fpr))

# ---------------------------------------------------------
# (F) ì„ê³„ê°’ ì„ íƒ 3: ë¹„ìš© ê¸°ë°˜ (c_fn*FN + c_fp*FP) ìµœì†Œ
# ---------------------------------------------------------
def best_threshold_cost(y_true01, score, c_fn=10.0, c_fp=1.0):
    thresholds = np.unique(np.r_[0.0, score, 1.0])
    best_t, best_m, best_cost = None, None, np.inf

    for t in thresholds:
        m = metrics_at_threshold(y_true01, score, t)
        cost = c_fn * m["fn"] + c_fp * m["fp"]
        if cost < best_cost:
            best_t, best_m, best_cost = float(t), m, float(cost)

    return best_t, best_m, best_cost

best_t_cost, best_m_cost, best_cost_val = best_threshold_cost(y_pos, score, c_fn=10, c_fp=1)

print("\n[Cost-based]")
print("best t =", best_t_cost, "cost =", best_cost_val)
print(best_m_cost)
```

[Logistic] ROC AUC = 0.9976939203354298
[Logistic] PR  AP  = 0.9967570754716981

[Youden J] best t = 0.636819048492104

{'t': 0.636819048492104, 'tn': 90, 'fp': 0, 'fn': 1, 'tp': 52, 'recall(tpr)': 0.9811320754716981, 'fpr': 0.0, 'precision': 1.0, 'accuracy': 0.993006993006993}

[FPR constraint] alpha = 0.02 best t = 0.636819048492104

{'t': 0.636819048492104, 'tn': 90, 'fp': 0, 'fn': 1, 'tp': 52, 'recall(tpr)': 0.9811320754716981, 'fpr': 0.0, 'precision': 1.0, 'accuracy': 0.993006993006993}

[Cost-based] best t = 0.636819048492104 cost = 10.0

{'t': 0.636819048492104, 'tn': 90, 'fp': 0, 'fn': 1, 'tp': 52, 'recall(tpr)': 0.9811320754716981, 'fpr': 0.0, 'precision': 1.0, 'accuracy': 0.993006993006993}

```python
import numpy as np
import pandas as pd

# (ì „ì œ) logit_model = Pipeline([("scaler", StandardScaler()), ("logit", LogisticRegression(...))])
#       logit_model.fit(X_train, y_train) ê°€ ì´ë¯¸ ìˆ˜í–‰ë˜ì—ˆë‹¤ê³  ê°€ì •

# 1) í•™ìŠµëœ ë¡œì§€ìŠ¤í‹± íšŒê·€ ê³„ìˆ˜ êº¼ë‚´ê¸°
logit = logit_model.named_steps["logit"]
coef = logit.coef_.ravel()          # shape: (p,)
intercept = float(logit.intercept_[0])

# 2) ë³€ìˆ˜ëª… ì¤€ë¹„ (ì•ì—ì„œ feature_namesë¥¼ ë§Œë“¤ì—ˆë‹¤ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
#    feature_names = data.feature_names
feature_names = list(feature_names)

# 3) ì˜¤ì¦ˆë¹„(OR) ê³„ì‚°
odds_ratio = np.exp(coef)

# 4) ê²°ê³¼ í…Œì´ë¸” ìƒì„±
coef_df = pd.DataFrame({
    "feature": feature_names,
    "beta(coef)": coef,
    "odds_ratio(exp(beta))": odds_ratio
}).sort_values("beta(coef)", ascending=False).reset_index(drop=True)

#print("Intercept (beta0) =", intercept)
#display(coef_df.head(10))

# 5) ìƒìœ„ ì–‘(+) / ìŒ(-) ê³„ìˆ˜ ë³€ìˆ˜ ì¶œë ¥
top_k = 10

top_pos = coef_df.head(top_k)                  # benign(=1) í™•ë¥ ì„ ë†’ì´ëŠ” ë°©í–¥
top_neg = coef_df.tail(top_k).iloc[::-1]       # malignant(=0) ìª½ìœ¼ë¡œ ê¸°ì—¬(benign í™•ë¥  ë‚®ì¶¤)

print(f"\n[ìƒìœ„ +ê³„ìˆ˜ {top_k}ê°œ]  (benign=1 ì˜¤ì¦ˆë¥¼ ì¦ê°€ì‹œí‚¤ëŠ” ë³€ìˆ˜)")
display(top_pos)

print(f"\n[ìƒìœ„ -ê³„ìˆ˜ {top_k}ê°œ]  (benign=1 ì˜¤ì¦ˆë¥¼ ê°ì†Œ â†’ malignant ìª½ìœ¼ë¡œ ê¸°ì—¬í•˜ëŠ” ë³€ìˆ˜)")
display(top_neg)
```

ë³¸ ë¡œì§€ìŠ¤í‹± íšŒê·€ëª¨í˜•ì—ì„œ ì¢…ì†ë³€ìˆ˜ëŠ” benign = 1ë¡œ ì •ì˜ë˜ì—ˆìœ¼ë©°, íšŒê·€ê³„ìˆ˜ëŠ” ê° ì„¤ëª…ë³€ìˆ˜ê°€ ì–‘ì„± ì¢…ì–‘ì¼ ì˜¤ì¦ˆ(odds)ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë‚˜íƒ€ë‚¸ë‹¤. ì–‘(+)ì˜ íšŒê·€ê³„ìˆ˜ëŠ” í•´ë‹¹ ë³€ìˆ˜ê°€ ì¦ê°€í• ìˆ˜ë¡ ì–‘ì„±ì¼ ì˜¤ì¦ˆê°€ ì¦ê°€í•¨ì„, ìŒ(â€“)ì˜ íšŒê·€ê³„ìˆ˜ëŠ” ë°˜ëŒ€ë¡œ ì•…ì„±ì¼ ê°€ëŠ¥ì„±ì´ ìƒëŒ€ì ìœ¼ë¡œ ë†’ì•„ì§ì„ ì˜ë¯¸í•œë‹¤.

ë¨¼ì €, ì–‘ì„±(benign) ì˜¤ì¦ˆë¥¼ ì¦ê°€ì‹œí‚¤ëŠ” ë³€ìˆ˜ë¡œëŠ” mean compactnessê°€ ê°€ì¥ í° ì˜í–¥ì„ ë³´ì˜€ë‹¤. ì´ ë³€ìˆ˜ì˜ íšŒê·€ê³„ìˆ˜ëŠ” 0.694ë¡œ, ë‹¤ë¥¸ ì¡°ê±´ì´ ë™ì¼í•  ë•Œ í‰ê·  compactnessê°€ 1ë‹¨ìœ„ ì¦ê°€í•˜ë©´ ì–‘ì„±ì¼ ì˜¤ì¦ˆëŠ” ì•½ 2.00ë°° ì¦ê°€í•˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ë‹¤. ì´ëŠ” ì¢…ì–‘ì˜ í˜•íƒœì  ì••ì¶•ë„ê°€ ë†’ì„ìˆ˜ë¡ ìƒëŒ€ì ìœ¼ë¡œ ì–‘ì„±ìœ¼ë¡œ ë¶„ë¥˜ë  ê°€ëŠ¥ì„±ì´ ì»¤ì§ì„ ì‹œì‚¬í•œë‹¤. 

ì´ì™¸ì—ë„ compactness error, symmetry error, fractal dimension error ë“± í˜•íƒœì˜ ë¶ˆê·œì¹™ì„±ê³¼ ê´€ë ¨ëœ ì˜¤ì°¨ ë³€ìˆ˜ë“¤ì´ ì–‘ì„± ì˜¤ì¦ˆë¥¼ ìœ ì˜í•˜ê²Œ ì¦ê°€ì‹œí‚¤ëŠ” ë°©í–¥ìœ¼ë¡œ ì‘ìš©í•˜ì˜€ë‹¤. ì „ë°˜ì ìœ¼ë¡œ ë³´ë©´, í‰ê·  ìˆ˜ì¤€ì˜ í˜•íƒœ ì§€í‘œë³´ë‹¤ëŠ” ì¸¡ì • ì˜¤ì°¨(error) ê³„ì—´ ë³€ìˆ˜ë“¤ì´ ì–‘ì„± ë¶„ë¥˜ì— ìƒëŒ€ì ìœ¼ë¡œ ê¸ì •ì ì¸ ê¸°ì—¬ë¥¼ í•˜ê³  ìˆë‹¤ëŠ” ì ì´ íŠ¹ì§•ì ì´ë‹¤.

ë°˜ë©´, ì–‘ì„± ì˜¤ì¦ˆë¥¼ ê°ì†Œì‹œí‚¤ëŠ”(ì¦‰, ì•…ì„± ë°©í–¥ìœ¼ë¡œ ê¸°ì—¬í•˜ëŠ”) ë³€ìˆ˜ë“¤ì€ ì£¼ë¡œ worst ì ‘ë‘ì–´ê°€ ë¶™ì€ ë³€ìˆ˜ë“¤ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. íŠ¹íˆ worst textureëŠ” íšŒê·€ê³„ìˆ˜ â€“1.25ë¡œ ê°€ì¥ í° ìŒì˜ íš¨ê³¼ë¥¼ ë³´ì˜€ìœ¼ë©°, ì´ëŠ” í•´ë‹¹ ë³€ìˆ˜ê°€ 1ë‹¨ìœ„ ì¦ê°€í•  ë•Œ ì–‘ì„±ì¼ ì˜¤ì¦ˆê°€ ì•½ 0.29ë°°ë¡œ ê°ì†Œí•¨ì„ ì˜ë¯¸í•œë‹¤. ë‹¤ì‹œ ë§í•´, ì¢…ì–‘ì˜ ìµœì•…(worst) ìƒíƒœì—ì„œ ê´€ì¸¡ëœ ì§ˆê°ì´ë‚˜ í¬ê¸°, ë‘˜ë ˆ, ë©´ì  ê´€ë ¨ ì§€í‘œë“¤ì€ ì•…ì„± ì¢…ì–‘ì„ ê°•í•˜ê²Œ ì‹œì‚¬í•˜ëŠ” íŠ¹ì§•ìœ¼ë¡œ ì‘ìš©í•œë‹¤. 

worst radius, worst area, worst perimeter, mean concave points ë“±ë„ ëª¨ë‘ ì¼ê´€ë˜ê²Œ ìŒì˜ ê³„ìˆ˜ë¥¼ ë³´ì—¬, ì¢…ì–‘ì˜ í¬ê¸° ë° ê²½ê³„ì˜ ì¹¨ìŠµì„±ì´ ì•…ì„± ì—¬ë¶€ íŒë‹¨ì— í•µì‹¬ì ì¸ ì—­í• ì„ í•¨ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

ì¢…í•©í•˜ë©´, ë³¸ ë¶„ì„ ê²°ê³¼ëŠ” ì•…ì„± ì¢…ì–‘ì˜ íŒë³„ì—ëŠ” â€˜worst-caseâ€™ í˜•íƒœ ì§€í‘œë“¤ì´ ê²°ì •ì ì´ë©°, ë°˜ëŒ€ë¡œ ì–‘ì„± ì¢…ì–‘ì˜ ê²½ìš° í‰ê· ì  í˜•íƒœ íŠ¹ì„±ì´ë‚˜ ë³€ë™ì„±(ì˜¤ì°¨) ê´€ë ¨ ì§€í‘œë“¤ì´ ìƒëŒ€ì ìœ¼ë¡œ ì¤‘ìš”í•œ ì—­í• ì„ í•œë‹¤ëŠ” ì ì„ ì‹œì‚¬í•œë‹¤. ì´ëŠ” ì„ìƒì ìœ¼ë¡œë„ ì¢…ì–‘ì˜ ìµœëŒ€ í¬ê¸°ë‚˜ ê°€ì¥ ë¶ˆë¦¬í•œ í˜•íƒœì  íŠ¹ì§•ì´ ì•…ì„± ì—¬ë¶€ íŒë‹¨ì— ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤ëœë‹¤ëŠ” ê¸°ì¡´ ì˜í•™ì  í•´ì„ê³¼ë„ ì •í•©ì ì¸ ê²°ê³¼ì´ë‹¤.

![](images/classification_ml_regresult.png){fig-align="center" width="80%"}


##### \(7) íŠ¸ë¦¬ê¸°ë°˜(ë‹¨ì¼) ë¶„ë¥˜

```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Decision Tree (ë¶„í•  ê¸°ë°˜)
tree_model = DecisionTreeClassifier(
    criterion="gini",        # or "entropy"
    max_depth=4,             # ê³¼ì í•© ë°©ì§€ìš©(ì˜ˆì‹œ). Noneì´ë©´ ëê¹Œì§€ ë¶„í• 
    min_samples_leaf=5,      # ìë…¸ë“œ ìµœì†Œ í‘œë³¸ìˆ˜
    random_state=42
)

# í•™ìŠµ
tree_model.fit(X_train, y_train)

# ì˜ˆì¸¡(í´ë˜ìŠ¤)
y_pred_tree = tree_model.predict(X_test)

# í‰ê°€(ê¸°ë³¸)
print("[Tree] Accuracy:", accuracy_score(y_test, y_pred_tree))
print("[Tree] Confusion matrix:\n", confusion_matrix(y_test, y_pred_tree))
print("[Tree] Classification report:\n",
      classification_report(y_test, y_pred_tree, target_names=data.target_names))
```
```text
[Tree] Accuracy: 0.9300699300699301
[Tree] Confusion matrix:
 [[48  5]
 [ 5 85]]
[Tree] Classification report:
               precision    recall  f1-score   support

   malignant       0.91      0.91      0.91        53
      benign       0.94      0.94      0.94        90

    accuracy                           0.93       143
   macro avg       0.93      0.93      0.93       143
weighted avg       0.93      0.93      0.93       143
```

```python
import numpy as np
from sklearn.metrics import (
    roc_curve, auc,
    precision_recall_curve, average_precision_score,
    confusion_matrix
)

# ---------------------------------------------------------
# 0) ì•…ì„±(malignant=0)ì„ positive(=1)ë¡œ í†µì¼
# ---------------------------------------------------------
y_pos = (y_test == 0).astype(int)  # 1ì´ë©´ malignant

# DecisionTreeì˜ "ì•…ì„± í™•ë¥ " score = P(malignant | x)
proba_tree = tree_model.predict_proba(X_test)
idx_malignant = np.where(tree_model.classes_ == 0)[0][0]
score = proba_tree[:, idx_malignant]

# ---------------------------------------------------------
# 1) ROC / PR
# ---------------------------------------------------------
fpr, tpr, thr_roc = roc_curve(y_pos, score)
roc_auc = auc(fpr, tpr)

prec, rec, thr_pr = precision_recall_curve(y_pos, score)
ap = average_precision_score(y_pos, score)

print("[Tree] ROC AUC =", roc_auc)
print("[Tree] PR  AP  =", ap)

# ---------------------------------------------------------
# 2) ì„ê³„ê°’ tì—ì„œ í˜¼ë™í–‰ë ¬/ì§€í‘œ ê³„ì‚°
# ---------------------------------------------------------
def metrics_at_threshold(y_true01, score, t):
    y_hat = (score >= t).astype(int)
    tn, fp, fn, tp = confusion_matrix(y_true01, y_hat).ravel()

    recall_ = tp / (tp + fn) if (tp + fn) > 0 else 0.0  # TPR
    fpr_    = fp / (fp + tn) if (fp + tn) > 0 else 0.0
    prec_   = tp / (tp + fp) if (tp + fp) > 0 else 0.0
    acc_    = (tp + tn) / (tp + tn + fp + fn)

    return {
        "t": float(t),
        "tn": int(tn), "fp": int(fp), "fn": int(fn), "tp": int(tp),
        "recall(tpr)": float(recall_),
        "fpr": float(fpr_),
        "precision": float(prec_),
        "accuracy": float(acc_)
    }

print("\n[Default t=0.5]")
print(metrics_at_threshold(y_pos, score, 0.5))

# ---------------------------------------------------------
# 3) Youden J = TPR - FPR ìµœëŒ€
# ---------------------------------------------------------
J = tpr - fpr
best_t_youden = float(thr_roc[np.argmax(J)])

print("\n[Youden J]")
print("best t =", best_t_youden)
print(metrics_at_threshold(y_pos, score, best_t_youden))

# ---------------------------------------------------------
# 4) FPR <= alpha ì œì•½ì—ì„œ TPR ìµœëŒ€
# ---------------------------------------------------------
def best_threshold_fpr_constraint(y_true01, score, alpha=0.02):
    fpr, tpr, thr = roc_curve(y_true01, score)
    cand = np.where(fpr <= alpha)[0]
    if len(cand) == 0:
        return None
    i = cand[np.argmax(tpr[cand])]
    return float(thr[i])

alpha = 0.02
best_t_fpr = best_threshold_fpr_constraint(y_pos, score, alpha=alpha)

print("\n[FPR constraint]")
print("alpha =", alpha, "best t =", best_t_fpr)
if best_t_fpr is not None:
    print(metrics_at_threshold(y_pos, score, best_t_fpr))

# ---------------------------------------------------------
# 5) ë¹„ìš© ê¸°ë°˜: c_fn*FN + c_fp*FP ìµœì†Œ
# ---------------------------------------------------------
def best_threshold_cost(y_true01, score, c_fn=10.0, c_fp=1.0):
    thresholds = np.unique(np.r_[0.0, score, 1.0])
    best_t, best_m, best_cost = None, None, np.inf

    for t in thresholds:
        m = metrics_at_threshold(y_true01, score, t)
        cost = c_fn * m["fn"] + c_fp * m["fp"]
        if cost < best_cost:
            best_t, best_m, best_cost = float(t), m, float(cost)
    return best_t, best_m, best_cost

best_t_cost, best_m_cost, best_cost_val = best_threshold_cost(y_pos, score, c_fn=10, c_fp=1)

print("\n[Cost-based]")
print("best t =", best_t_cost, "cost =", best_cost_val)
print(best_m_cost)
```
[Tree] ROC AUC = 0.931446540880503
[Tree] PR  AP  = 0.9139770620510188

[Default t=0.5]

{'t': 0.5, 'tn': 85, 'fp': 5, 'fn': 5, 'tp': 48, 'recall(tpr)': 0.9056603773584906, 'fpr': 0.05555555555555555, 'precision': 0.9056603773584906, 'accuracy': 0.9300699300699301}

[Youden J] best t = 1.0

{'t': 1.0, 'tn': 88, 'fp': 2, 'fn': 5, 'tp': 48, 'recall(tpr)': 0.9056603773584906, 'fpr': 0.022222222222222223, 'precision': 0.96, 'accuracy': 0.951048951048951}

[FPR constraint] alpha = 0.02 best t = inf

{'t': inf, 'tn': 90, 'fp': 0, 'fn': 53, 'tp': 0, 'recall(tpr)': 0.0, 'fpr': 0.0, 'precision': 0.0, 'accuracy': 0.6293706293706294}

[Cost-based] best t = 0.4 cost = 47.0

{'t': 0.4, 'tn': 83, 'fp': 7, 'fn': 4, 'tp': 49, 'recall(tpr)': 0.9245283018867925, 'fpr': 0.07777777777777778, 'precision': 0.875, 'accuracy': 0.9230769230769231}

##### \(8) ì•™ìƒë¸” ê¸°ë²•

**RandomForest í•™ìŠµ** 

```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

rf_model = RandomForestClassifier(
    n_estimators=500,
    max_depth=None,
    min_samples_leaf=2,
    random_state=42,
    n_jobs=-1
)

rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)

print("[RF] Accuracy:", accuracy_score(y_test, y_pred_rf))
print("[RF] Confusion matrix:\n", confusion_matrix(y_test, y_pred_rf))
print("[RF] Classification report:\n",
      classification_report(y_test, y_pred_rf, target_names=data.target_names))
```
```text
[RF] Accuracy: 0.958041958041958
[RF] Confusion matrix:
 [[49  4]
 [ 2 88]]
[RF] Classification report:
               precision    recall  f1-score   support

   malignant       0.96      0.92      0.94        53
      benign       0.96      0.98      0.97        90

    accuracy                           0.96       143
   macro avg       0.96      0.95      0.95       143
weighted avg       0.96      0.96      0.96       143
```

**GradientBoosting í•™ìŠµ**

```python
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

gb_model = GradientBoostingClassifier(
    n_estimators=300,
    learning_rate=0.05,
    max_depth=2,        # ì•½í•œ íŠ¸ë¦¬(ê¹Šì´ ë‚®ê²Œ) ê¶Œì¥
    random_state=42
)

gb_model.fit(X_train, y_train)
y_pred_gb = gb_model.predict(X_test)

print("[GB] Accuracy:", accuracy_score(y_test, y_pred_gb))
print("[GB] Confusion matrix:\n", confusion_matrix(y_test, y_pred_gb))
print("[GB] Classification report:\n",
      classification_report(y_test, y_pred_gb, target_names=data.target_names))
```

```text
[GB] Accuracy: 0.951048951048951
[GB] Confusion matrix:
 [[48  5]
 [ 2 88]]
[GB] Classification report:
               precision    recall  f1-score   support

   malignant       0.96      0.91      0.93        53
      benign       0.95      0.98      0.96        90

    accuracy                           0.95       143
   macro avg       0.95      0.94      0.95       143
weighted avg       0.95      0.95      0.95       143
```

**RF / GB ê³µí†µ: ROC/PR + ì„ê³„ê°’(Youden / FPRì œì•½ / ë¹„ìš©ê¸°ë°˜)**

```python
import numpy as np
import pandas as pd
from sklearn.metrics import (
    roc_curve, auc,
    precision_recall_curve, average_precision_score,
    confusion_matrix
)

# --------------------------------------------
# 0) ì•…ì„±=positive(1)ë¡œ í†µì¼
# --------------------------------------------
y_pos = (y_test == 0).astype(int)  # 1ì´ë©´ malignant

def get_score_for_class(model, X, class_label=0):
    """íŠ¹ì • í´ë˜ìŠ¤(class_label)ì˜ í™•ë¥  score = P(class_label|x)"""
    proba = model.predict_proba(X)
    classes = np.array(model.classes_)
    idx = np.where(classes == class_label)[0][0]
    return proba[:, idx]

def metrics_at_threshold(y_true01, score, t):
    y_hat = (score >= t).astype(int)
    tn, fp, fn, tp = confusion_matrix(y_true01, y_hat).ravel()

    recall_ = tp / (tp + fn) if (tp + fn) > 0 else 0.0
    fpr_    = fp / (fp + tn) if (fp + tn) > 0 else 0.0
    prec_   = tp / (tp + fp) if (tp + fp) > 0 else 0.0
    acc_    = (tp + tn) / (tp + tn + fp + fn)

    return {
        "t": float(t),
        "tn": int(tn), "fp": int(fp), "fn": int(fn), "tp": int(tp),
        "recall(tpr)": float(recall_),
        "fpr": float(fpr_),
        "precision": float(prec_),
        "accuracy": float(acc_)
    }

def threshold_youden(y_true01, score):
    fpr, tpr, thr = roc_curve(y_true01, score)
    J = tpr - fpr
    return float(thr[np.argmax(J)])

def threshold_fpr_constraint(y_true01, score, alpha=0.02):
    fpr, tpr, thr = roc_curve(y_true01, score)
    cand = np.where(fpr <= alpha)[0]
    if len(cand) == 0:
        return None
    i = cand[np.argmax(tpr[cand])]
    return float(thr[i])

def threshold_cost(y_true01, score, c_fn=10.0, c_fp=1.0):
    thresholds = np.unique(np.r_[0.0, score, 1.0])
    best_t, best_cost = None, np.inf
    for t in thresholds:
        m = metrics_at_threshold(y_true01, score, t)
        cost = c_fn*m["fn"] + c_fp*m["fp"]
        if cost < best_cost:
            best_cost = cost
            best_t = float(t)
    return best_t, float(best_cost)

def build_rows(model_name, y_true01, score, alpha=0.02, c_fn=10.0, c_fp=1.0):
    rows = []

    # AUC/AP (ìš”ì•½ìš©)
    fpr, tpr, _ = roc_curve(y_true01, score)
    roc_auc = auc(fpr, tpr)
    ap = average_precision_score(y_true01, score)

    # Youden
    t_y = threshold_youden(y_true01, score)
    m_y = metrics_at_threshold(y_true01, score, t_y)
    m_y.update({"model": model_name, "rule": "Youden (TPR-FPR)", "roc_auc": roc_auc, "ap": ap,
                "cost": c_fn*m_y["fn"] + c_fp*m_y["fp"]})
    rows.append(m_y)

    # FPR constraint
    t_f = threshold_fpr_constraint(y_true01, score, alpha=alpha)
    if t_f is not None:
        m_f = metrics_at_threshold(y_true01, score, t_f)
        m_f.update({"model": model_name, "rule": f"FPR <= {alpha}", "roc_auc": roc_auc, "ap": ap,
                    "cost": c_fn*m_f["fn"] + c_fp*m_f["fp"]})
        rows.append(m_f)
    else:
        rows.append({"model": model_name, "rule": f"FPR <= {alpha}", "t": None,
                     "tn": None, "fp": None, "fn": None, "tp": None,
                     "recall(tpr)": None, "fpr": None, "precision": None, "accuracy": None,
                     "roc_auc": roc_auc, "ap": ap, "cost": None})

    # Cost-based
    t_c, best_cost = threshold_cost(y_true01, score, c_fn=c_fn, c_fp=c_fp)
    m_c = metrics_at_threshold(y_true01, score, t_c)
    m_c.update({"model": model_name, "rule": f"Cost (c_fn={c_fn}, c_fp={c_fp})",
                "roc_auc": roc_auc, "ap": ap, "cost": best_cost})
    rows.append(m_c)

    return rows

# --------------------------------------------
# 1) RF / GB score ì¶”ì¶œ (ì•…ì„± í™•ë¥ )
# --------------------------------------------
score_rf = get_score_for_class(rf_model, X_test, class_label=0)  # P(malignant|x)
score_gb = get_score_for_class(gb_model, X_test, class_label=0)  # P(malignant|x)

# --------------------------------------------
# 2) ë¹„êµí‘œ ìƒì„±
# --------------------------------------------
alpha = 0.02
c_fn, c_fp = 10.0, 1.0

rows = []
rows += build_rows("RandomForest", y_pos, score_rf, alpha=alpha, c_fn=c_fn, c_fp=c_fp)
rows += build_rows("GradientBoosting", y_pos, score_gb, alpha=alpha, c_fn=c_fn, c_fp=c_fp)

df_cmp_ens = pd.DataFrame(rows)[
    ["model","rule","t","tn","fp","fn","tp","recall(tpr)","fpr","precision","accuracy","roc_auc","ap","cost"]
].sort_values(["rule","model"]).reset_index(drop=True)

print("== ì•™ìƒë¸”(RF/GB): ì•…ì„±=positive ê¸°ì¤€ ì„ê³„ê°’ ë¹„êµí‘œ ==")
display(df_cmp_ens)
```

![](images/classification_ml_treeresult.png){fig-align="center" width="100%"}


#### 2. ì‚¬ë¡€ë¶„ì„(ì´ì§„ë¶„ë¥˜, íšŒì†Œì„±ê³µ-ë¶ˆê· í˜•)

ë°ì´í„°ëŠ” í‘œë³¸ì´ ë§¤ìš° ì»¤ì„œ RBF SVM / kNNì€ ê·¸ëŒ€ë¡œ ëŒë¦¬ë©´ ëŠë¦´ ìˆ˜ ìˆì–´ ì‹¤ë¬´ì ìœ¼ë¡œëŠ” (1) Linear SVM + calibration ë˜ëŠ” (2) kNN/SVMì€ í•™ìŠµ ìƒ˜í”Œì„ ì¼ë¶€ë§Œ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤(ì½”ë“œì— ë°˜ì˜).

##### \(1) ë°ì´í„°

**ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°**

Credit Card Fraud(creditcard.csv) ë°ì´í„°ëŠ” ëŒ€í‘œì ì¸ ì´ì§„ ë¶„ë¥˜(surveillance / fraud detection) ë²¤ì¹˜ë§ˆí¬ë¡œ, í•œ ê±´ì˜ ê±°ë˜ê°€ ì‚¬ê¸°(Fraud) ì¸ì§€ ì •ìƒ(Normal) ì¸ì§€ë¥¼ íŒì •í•˜ëŠ” ë¬¸ì œë¥¼ ë‹¤ë£¬ë‹¤. 

ë°˜ì‘ë³€ìˆ˜ëŠ” Class í•˜ë‚˜ì´ë©° ë³´í†µ Class=0ì„ ì •ìƒ(negative), Class=1ì„ ì‚¬ê¸°(positive)ë¡œ ì •ì˜í•œë‹¤. ì¦‰ ëª©í‘œëŠ” ê° ê±°ë˜ $P(Y=1âˆ£X=x)$ ì„ ì¶”ì •í•˜ê³ , ìš´ì˜ ëª©ì (ì˜¤íƒ/ë¯¸íƒ ë¹„ìš©, ê²€í† ëŸ‰ ë“±)ì— ë§ëŠ” ì„ê³„ê°’ të¥¼ ì •í•´ $\hat y =1{p(x)â‰¥t}$ í˜•íƒœë¡œ ì˜ì‚¬ê²°ì •ì„ ë‚´ë¦¬ëŠ” ê²ƒì´ë‹¤.

ë°ì´í„° ê·œëª¨ëŠ” 284,807ê±´ì˜ ê±°ë˜ë¡œ êµ¬ì„±ë˜ë©°, ì´ 31ê°œ ë³€ìˆ˜ë¥¼ ê°€ì§„ë‹¤. ì´ ì¤‘ Classê°€ íƒ€ê¹ƒ(y)ì´ê³  ë‚˜ë¨¸ì§€ 30ê°œê°€ ì…ë ¥ ë³€ìˆ˜(X) ë‹¤. ì…ë ¥ ë³€ìˆ˜ëŠ” Time, V1~V28, Amountë¡œ ì´ë£¨ì–´ì§„ë‹¤. ìë£Œí˜• ê´€ì ì—ì„œ ì…ë ¥ ë³€ìˆ˜ë“¤ì€ ëŒ€ë¶€ë¶„ ì—°ì†í˜•ì´ë©°(ì‹¤ìˆ˜í˜•), Classë§Œ ì •ìˆ˜í˜• ë¼ë²¨ì´ë‹¤. 

íŠ¹íˆ V1~V28ì€ ì›ë˜ ê±°ë˜ ì†ì„±ë“¤ì„ ê·¸ëŒ€ë¡œ ì œê³µí•œ ê²ƒì´ ì•„ë‹ˆë¼, ê°œì¸ì •ë³´ ë³´í˜¸ ë° ë¹„ì‹ë³„í™”ë¥¼ ìœ„í•´ PCA(ì£¼ì„±ë¶„ ë¶„ì„) ë¡œ ë³€í™˜ëœ íŠ¹ì§•ë“¤ì´ë‹¤. ë”°ë¼ì„œ ê° $V_k$ ëŠ” ì›ë³€ìˆ˜ë“¤ì˜ ì„ í˜•ê²°í•©ìœ¼ë¡œ ì–»ì–´ì§„ ì£¼ì„±ë¶„ ì ìˆ˜ì´ë©°, ì›ë˜ ë³€ìˆ˜ì˜ í•´ì„ ê°€ëŠ¥ì„±ì€ ì œí•œëœë‹¤. 

ë°˜ë©´ Timeê³¼ AmountëŠ” ë¹„êµì  ì§ê´€ì ì¸ ì˜ë¯¸ë¥¼ ìœ ì§€í•œë‹¤. Timeì€ ê¸°ì¤€ ì‹œì  ì´í›„ì˜ ê²½ê³¼ ì‹œê°„ìœ¼ë¡œ ì‹œê°„ëŒ€ì— ë”°ë¥¸ íŒ¨í„´ì„ ë°˜ì˜í•  ìˆ˜ ìˆê³ , AmountëŠ” ê±°ë˜ ê¸ˆì•¡ìœ¼ë¡œì„œ ì‚¬ê¸° ì—¬ë¶€ì™€ ì—°ê´€ëœ ì¤‘ìš”í•œ ì‹ í˜¸ê°€ ë  ìˆ˜ ìˆë‹¤.

ì´ ë°ì´í„°ì˜ ê°€ì¥ ê²°ì •ì ì¸ íŠ¹ì„±ì€ ê·¹ì‹¬í•œ í´ë˜ìŠ¤ ë¶ˆê· í˜•(extreme class imbalance) ì´ë‹¤. ì •ìƒ ê±°ë˜(Class=0)ëŠ” 284,315ê±´ìœ¼ë¡œ ì „ì²´ì˜ ì•½ 99.827%ë¥¼ ì°¨ì§€í•˜ëŠ” ë°˜ë©´, ì‚¬ê¸° ê±°ë˜(Class=1)ëŠ” 492ê±´ìœ¼ë¡œ ì•½ 0.173%ì— ë¶ˆê³¼í•˜ë‹¤. 

ì´ëŸ° í™˜ê²½ì—ì„œëŠ” ë‹¨ìˆœ ì •í™•ë„(Accuracy)ê°€ ì‰½ê²Œ ê³¼ëŒ€í‰ê°€ëœë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ëª¨ë“  ê±°ë˜ë¥¼ ì •ìƒìœ¼ë¡œë§Œ ì˜ˆì¸¡í•´ë„ ì •í™•ë„ëŠ” ì•½ 99.8%ì— ë‹¬í•  ìˆ˜ ìˆìœ¼ë‚˜, ì´ëŠ” ì‚¬ê¸° íƒì§€ë¼ëŠ” ëª©ì ì„ ì „í˜€ ë‹¬ì„±í•˜ì§€ ëª»í•œë‹¤. ë”°ë¼ì„œ ì‹¤ë¬´ì ìœ¼ë¡œëŠ” ì–‘ì„±(ì‚¬ê¸°) íƒì§€ ì„±ëŠ¥ì„ ì§ì ‘ ë°˜ì˜í•˜ëŠ” ì§€í‘œ, ì˜ˆì»¨ëŒ€ Precisionâ€“Recall(PR) ê´€ì ì˜ í‰ê°€(AP í¬í•¨)ë‚˜, ì˜¤íƒì„ ì¼ì • ìˆ˜ì¤€ ì´í•˜ë¡œ ì œí•œí•˜ëŠ” FPR ì œì•½ ê¸°ë°˜ ì„ê³„ê°’ ì„ íƒ, í˜¹ì€ ë¯¸íƒ(FN)ê³¼ ì˜¤íƒ(FP)ì˜ ë¹„ìš©ì„ ë°˜ì˜í•œ ë¹„ìš©ê¸°ë°˜ ì„ê³„ê°’ ì„¤ê³„ê°€ í•µì‹¬ì´ ëœë‹¤.

```python
!pip -q install kagglehub

import kagglehub
import pandas as pd
import os

# ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ìºì‹œ ê²½ë¡œ ë°˜í™˜)
path = kagglehub.dataset_download("mlg-ulb/creditcardfraud")
print("downloaded to:", path)
print(os.listdir(path)[:10])

# CSV ë¡œë“œ
df = pd.read_csv(os.path.join(path, "creditcard.csv"))
```

**ë°ì´í„° ë©”íƒ€ì •ë³´ (ë¶ˆê· í˜• í™•ì¸)**

```python
import numpy as np

print("shape:", df.shape)

# íƒ€ê¹ƒ
y = df["Class"].astype(int)        # 1=Fraud(positive), 0=Normal
X = df.drop(columns=["Class"])

# ë¶ˆê· í˜• ì •ë„
cnt = y.value_counts().sort_index()
ratio = cnt / cnt.sum()

print("\nClass counts:")
print(cnt)
print("\nClass ratio:")
print(ratio)

print("\nFraud rate =", ratio.loc[1])
```
```text
shape: (284807, 31)

Class counts:
Class
0    284315
1       492
Name: count, dtype: int64

Class ratio:
Class
0    0.998273
1    0.001727
Name: count, dtype: float64

Fraud rate = 0.001727485630620034
```
**Train/Test ë¶„í• (ì¸µí™”) + í‘œì¤€í™” íŒŒì´í”„ë¼ì¸**

ì´ ì½”ë“œëŠ” (1) ë°ì´í„°ë¥¼ í›ˆë ¨/í…ŒìŠ¤íŠ¸ë¡œ ë‚˜ëˆ„ê³ , (2) ë¶ˆê· í˜• ìƒí™©ì—ì„œë„ ë¼ë²¨ ë¹„ìœ¨ì´ ìœ ì§€ë˜ë„ë¡ ì¸µí™”(stratify) í•˜ë©°, ì´í›„ ëª¨ë¸ë§ì—ì„œ ë°˜ë³µì ìœ¼ë¡œ ì“¸ í‘œì¤€í™”(Standardization) ë„êµ¬ë¥¼ ì¤€ë¹„í•˜ëŠ” ë‹¨ê³„ë‹¤.

ë¨¼ì € train_test_splitì€ ì „ì²´ ë°ì´í„° (X,y)ë¥¼ í›ˆë ¨ìš©(train) ê³¼ í‰ê°€ìš©(test) ìœ¼ë¡œ ë¶„ë¦¬í•œë‹¤. ì—¬ê¸°ì„œ test_size=0.2ëŠ” ì „ì²´ì˜ 20%ë¥¼ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë–¼ì–´ë‘ê² ë‹¤ëŠ” ëœ»ì´ë©°, ê²°ê³¼ì ìœ¼ë¡œ í•™ìŠµì€ 80%, í‰ê°€ëŠ” 20% ë°ì´í„°ë¡œ ìˆ˜í–‰ëœë‹¤. 

random_state=42ëŠ” ë¶„í•  ê³¼ì •ì—ì„œ ë‚œìˆ˜ ì‹œë“œë¥¼ ê³ ì •í•´, ì½”ë“œë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•´ë„ ë™ì¼í•œ ë¶„í•  ê²°ê³¼ê°€ ë‚˜ì˜¤ë„ë¡ í•œë‹¤. ì¦‰ ì¬í˜„ì„±(reproducibility)ì„ í™•ë³´í•œë‹¤.

íŠ¹íˆ ì¤‘ìš”í•œ ì˜µì…˜ì´ stratify=yë‹¤. Credit Card Fraudì²˜ëŸ¼ ì–‘ì„±(ì‚¬ê¸°) ë¹„ìœ¨ì´ ê·¹ë‹¨ì ìœ¼ë¡œ ì‘ì€ ë°ì´í„°ì—ì„œëŠ”, ë¬´ì‘ìœ„ ë¶„í• ë§Œ í•˜ë©´ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ì–‘ì„±ì´ ê±°ì˜ ì—†ê±°ë‚˜(í˜¹ì€ ìš°ì—°íˆ ëª°ë¦¬ê±°ë‚˜) í•˜ëŠ” ì¼ì´ ë°œìƒí•  ìˆ˜ ìˆë‹¤. 

ê·¸ëŸ¬ë©´ í‰ê°€ ì§€í‘œ(ROC/PR ë“±)ê°€ ë¶ˆì•ˆì •í•´ì§€ê³ , ëª¨ë¸ ë¹„êµë„ ì™œê³¡ëœë‹¤. stratify=yëŠ” ë¶„í• í•  ë•Œ í›ˆë ¨/í…ŒìŠ¤íŠ¸ ê°ê°ì—ì„œ í´ë˜ìŠ¤ ë¹„ìœ¨ì´ ì›ìë£Œì™€ ê±°ì˜ ê°™ë„ë¡ ê°•ì œí•œë‹¤. ì¦‰ 
$P(Y=1) in trainâ‰ˆP(Y=1) in testâ‰ˆP(Y=1) in full data$ ê°€ ë˜ê²Œ ë§Œë“œëŠ” ì¥ì¹˜ë‹¤. ë¶ˆê· í˜• íƒì§€ ë¬¸ì œì—ì„œëŠ” ì‚¬ì‹¤ìƒ í•„ìˆ˜ ì˜µì…˜ì— ê°€ê¹ë‹¤.

ë§ˆì§€ë§‰ì˜ scaler = StandardScaler()ëŠ” ì…ë ¥ ë³€ìˆ˜ Xë¥¼ í‘œì¤€í™”í•˜ê¸° ìœ„í•œ ê°ì²´ë¥¼ ë§Œë“ ë‹¤. í‘œì¤€í™”ëŠ” ê° ë³€ìˆ˜ë¥¼ í‰ê·  0, ë¶„ì‚° 1ì´ ë˜ë„ë¡ ë³€í™˜í•˜ëŠ” ê²ƒì´ë‹¤. ì´ëŠ” k-NNì²˜ëŸ¼ ê±°ë¦¬(distance) ì— ë¯¼ê°í•œ ëª¨ë¸ì´ë‚˜ SVMì²˜ëŸ¼ ê²°ì •ê²½ê³„ê°€ ìŠ¤ì¼€ì¼ì— ì˜í–¥ì„ ë°›ëŠ” ëª¨ë¸ì—ì„œ íŠ¹íˆ ì¤‘ìš”í•˜ë‹¤. 

ì—¬ê¸°ì„œëŠ” scalerë§Œ â€œë”°ë¡œâ€ ë§Œë“¤ì–´ ë‘ì—ˆê³ , ì‹¤ì œë¡œëŠ” ì´í›„ Pipeline([("scaler", StandardScaler()), ("model", ...)]) í˜•íƒœë¡œ ëª¨ë¸ê³¼ í•¨ê»˜ ë¬¶ì–´ í›ˆë ¨ ë°ì´í„°ë¡œë§Œ í‘œì¤€í™” íŒŒë¼ë¯¸í„°(í‰ê· /í‘œì¤€í¸ì°¨)ë¥¼ ì¶”ì •í•˜ê³ , ê·¸ ë³€í™˜ì„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ë™ì¼í•˜ê²Œ ì ìš©í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤. ì´ë ‡ê²Œ í•´ì•¼ ë°ì´í„° ëˆ„ìˆ˜(data leakage)ê°€ ìƒê¸°ì§€ ì•ŠëŠ”ë‹¤.


```python
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    stratify=y,          # ê·¹ì‹¬ ë¶ˆê· í˜•ì´ë¯€ë¡œ í•„ìˆ˜
    random_state=42
)

# í‘œì¤€í™” íŒŒì´í”„ë¼ì¸(ëª¨ë¸ë§ˆë‹¤ ë¶™ì—¬ ì“°ê¸° ìœ„í•´ scalerë§Œ ë”°ë¡œ ì •ì˜)
scaler = StandardScaler()
```

##### \(2) ëª¨ë¸ í•™ìŠµ (k-NN / SVM)

**k-NN (ëŒ€ìš©ëŸ‰ì´ë¼ í•™ìŠµ ìƒ˜í”Œ ì¼ë¶€ë§Œ ì‚¬ìš© ê¶Œì¥)**

```python
from sklearn.neighbors import KNeighborsClassifier
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
import numpy as np

# kNNì€ ëŒ€ìš©ëŸ‰ì—ì„œ ëŠë¦¬ë¯€ë¡œ í•™ìŠµ ë°ì´í„° ì¼ë¶€ë§Œ ì‚¬ìš©
n_sub = min(50000, len(X_train))
sub_idx = np.random.RandomState(42).choice(len(X_train), size=n_sub, replace=False)

# âœ… DataFrame/SeriesëŠ” .ilocë¡œ 'í–‰' ì„ íƒ
X_train_knn = X_train.iloc[sub_idx]
y_train_knn = y_train.iloc[sub_idx]

knn_model = Pipeline([
    ("scaler", StandardScaler()),
    ("knn", KNeighborsClassifier(
        n_neighbors=15,
        weights="distance",
        p=2
    ))
])

knn_model.fit(X_train_knn, y_train_knn)
```

![](images/classification_ml_knnfit.png){fig-align="center" width="40%"}


**SVM (ì‹¤ë¬´ ê¶Œì¥: Linear SVM + í™•ë¥  ë³´ì •(calibration))**

```python
from sklearn.svm import LinearSVC
from sklearn.calibration import CalibratedClassifierCV

# Linear SVM (ê²°ì •í•¨ìˆ˜) + í™•ë¥  ë³´ì •(sigmoid)
svm_base = Pipeline([
    ("scaler", StandardScaler()),
    ("svm", LinearSVC(
        C=1.0,
        class_weight="balanced",   # ë¶ˆê· í˜• ëŒ€ì‘(ê¸°ë³¸ ì˜µì…˜)
        random_state=42
    ))
])

# CalibratedClassifierCVëŠ” estimatorê°€ ì´ë¯¸ pipelineì´ì–´ë„ ë™ì‘
svm_model = CalibratedClassifierCV(
    estimator=svm_base,
    method="sigmoid",
    cv=3
)

svm_model.fit(X_train, y_train)
```

![](images/classification_ml_svmfit.png){fig-align="center" width="40%"}


**ROC/PR + ì„ê³„ê°’(Youden / FPRì œì•½ / ë¹„ìš©ê¸°ë°˜) + ë¹„êµí‘œ**

```python
import numpy as np
import pandas as pd
from sklearn.metrics import (
    roc_curve, auc,
    precision_recall_curve, average_precision_score,
    confusion_matrix
)

# (ì•ˆì „) yë¥¼ numpy 1ì°¨ì›ìœ¼ë¡œ í†µì¼
y_train = np.asarray(y_train).ravel()
y_test  = np.asarray(y_test).ravel()
y_pos   = y_test  # 1=Fraud(positive)

def get_pos_score(model, X):
    proba = model.predict_proba(X)
    classes = np.array(model.classes_)
    idx = np.where(classes == 1)[0][0]
    return proba[:, idx]

def metrics_at_threshold(y_true01, score, t):
    y_hat = (score >= t).astype(int)
    tn, fp, fn, tp = confusion_matrix(y_true01, y_hat).ravel()

    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0.0
    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0
    prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0
    acc = (tp + tn) / (tp + tn + fp + fn)

    return {"t": float(t), "tn": int(tn), "fp": int(fp), "fn": int(fn), "tp": int(tp),
            "recall(tpr)": float(tpr), "fpr": float(fpr), "precision": float(prec), "accuracy": float(acc)}

def threshold_youden(y_true01, score):
    fpr, tpr, thr = roc_curve(y_true01, score)
    J = tpr - fpr
    return float(thr[np.argmax(J)])

def threshold_fpr_constraint(y_true01, score, alpha=0.001):
    fpr, tpr, thr = roc_curve(y_true01, score)
    cand = np.where(fpr <= alpha)[0]
    if len(cand) == 0:
        return None
    i = cand[np.argmax(tpr[cand])]
    return float(thr[i])

def threshold_cost(y_true01, score, c_fn=100.0, c_fp=1.0):
    thresholds = np.unique(np.r_[0.0, score, 1.0])
    best_t, best_cost = None, np.inf
    for t in thresholds:
        m = metrics_at_threshold(y_true01, score, t)
        cost = c_fn*m["fn"] + c_fp*m["fp"]
        if cost < best_cost:
            best_cost = cost
            best_t = float(t)
    return best_t, float(best_cost)

def build_rows(model_name, y_true01, score, alpha=0.001, c_fn=100.0, c_fp=1.0):
    rows = []
    fpr, tpr, _ = roc_curve(y_true01, score)
    roc_auc = auc(fpr, tpr)
    ap = average_precision_score(y_true01, score)

    # Youden
    t_y = threshold_youden(y_true01, score)
    m_y = metrics_at_threshold(y_true01, score, t_y)
    m_y.update({"model": model_name, "rule": "Youden (TPR-FPR)", "roc_auc": roc_auc, "ap": ap,
                "cost": c_fn*m_y["fn"] + c_fp*m_y["fp"]})
    rows.append(m_y)

    # FPR constraint
    t_f = threshold_fpr_constraint(y_true01, score, alpha=alpha)
    if t_f is not None:
        m_f = metrics_at_threshold(y_true01, score, t_f)
        m_f.update({"model": model_name, "rule": f"FPR <= {alpha}", "roc_auc": roc_auc, "ap": ap,
                    "cost": c_fn*m_f["fn"] + c_fp*m_f["fp"]})
        rows.append(m_f)
    else:
        rows.append({"model": model_name, "rule": f"FPR <= {alpha}", "t": None,
                     "tn": None, "fp": None, "fn": None, "tp": None,
                     "recall(tpr)": None, "fpr": None, "precision": None, "accuracy": None,
                     "roc_auc": roc_auc, "ap": ap, "cost": None})

    # Cost-based
    t_c, best_cost = threshold_cost(y_true01, score, c_fn=c_fn, c_fp=c_fp)
    m_c = metrics_at_threshold(y_true01, score, t_c)
    m_c.update({"model": model_name, "rule": f"Cost (c_fn={c_fn}, c_fp={c_fp})",
                "roc_auc": roc_auc, "ap": ap, "cost": best_cost})
    rows.append(m_c)

    return rows

# score
score_knn = get_pos_score(knn_model, X_test)
score_svm = get_pos_score(svm_model, X_test)

alpha = 0.001
c_fn, c_fp = 100.0, 1.0

rows = []
rows += build_rows("k-NN", y_pos, score_knn, alpha=alpha, c_fn=c_fn, c_fp=c_fp)
rows += build_rows("SVM(Linear+Calib)", y_pos, score_svm, alpha=alpha, c_fn=c_fn, c_fp=c_fp)

df_cmp = pd.DataFrame(rows)[
    ["model","rule","t","tn","fp","fn","tp","recall(tpr)","fpr","precision","accuracy","roc_auc","ap","cost"]
].sort_values(["rule","model"]).reset_index(drop=True)

display(df_cmp)
```

![](images/classification_ml_knnsvmresult.png){fig-align="center" width="100%"}

##### \(3) ëª¨ë¸ í•™ìŠµ (íšŒê·€ê¸°ë°˜ íŠ¸ë¦¬ê¸°ë°˜ ì•™ìƒë¸”)

**íšŒê·€ê¸°ë°˜**

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report

logit_model = Pipeline([
    ("scaler", StandardScaler()),
    ("logit", LogisticRegression(
        C=1.0,
        solver="lbfgs",
        max_iter=5000,
        class_weight="balanced",   # ê·¹ì‹¬ ë¶ˆê· í˜• ëŒ€ì‘(ê¸°ë³¸ ì˜µì…˜)
        random_state=42
    ))
])

logit_model.fit(X_train, y_train)

y_pred_logit = logit_model.predict(X_test)
print("[Logit] Confusion matrix:\n", confusion_matrix(y_test, y_pred_logit))
print("[Logit] Classification report:\n", classification_report(y_test, y_pred_logit, digits=4))
```
```text
[Logit] Confusion matrix:
 [[55478  1386]
 [    8    90]]
[Logit] Classification report:
               precision    recall  f1-score   support

           0     0.9999    0.9756    0.9876     56864
           1     0.0610    0.9184    0.1144        98

    accuracy                         0.9755     56962
   macro avg     0.5304    0.9470    0.5510     56962
weighted avg     0.9982    0.9755    0.9861     56962
```

```python
import numpy as np
import pandas as pd

# 1) ê³„ìˆ˜ êº¼ë‚´ê¸° (í‘œì¤€í™”ëœ ìŠ¤ì¼€ì¼ ê¸°ì¤€)
logit  = logit_model.named_steps["logit"]
coef   = logit.coef_.ravel()
intercept = float(logit.intercept_[0])

feature_names = X.columns

df_coef = pd.DataFrame({
    "feature": feature_names,
    "coef": coef,
    "odds_ratio": np.exp(coef),        # OR = exp(beta)
    "abs_coef": np.abs(coef),
    "abs_logOR": np.abs(coef)          # log(OR)=coef ì´ë¯€ë¡œ ì ˆëŒ“ê°’ì€ ë™ì¼
}).sort_values("abs_coef", ascending=False)

print("Intercept:", intercept)

# 2) (+) ê³„ìˆ˜ í° ê²ƒ Top10  -> OR > 1
top_pos10 = df_coef[df_coef["coef"] > 0].sort_values("coef", ascending=False).head(10)

# 3) (-) ê³„ìˆ˜ 'í° ê²ƒ' Top10  -> ê°€ì¥ ìŒìˆ˜(ì ˆëŒ“ê°’ í° ìŒìˆ˜), OR < 1
top_neg10 = df_coef[df_coef["coef"] < 0].sort_values("coef", ascending=True).head(10)

print("\n[Top 10 POSITIVE coefs] (Fraud=1 odds â†‘, OR>1)")
display(top_pos10[["feature","coef","odds_ratio"]])

print("\n[Top 10 NEGATIVE coefs] (Fraud=1 odds â†“, OR<1)")
display(top_neg10[["feature","coef","odds_ratio"]])
```

![](images/classification_ml_rareregodds.png){fig-align="center" width="60%"}


**íŠ¸ë¦¬ê¸°ë°˜**

```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix, classification_report

tree_model = DecisionTreeClassifier(
    criterion="gini",
    max_depth=6,
    min_samples_leaf=50,     # fraudì—ì„œëŠ” leafë¥¼ ë„ˆë¬´ ì‘ê²Œ ë‘ë©´ ê³¼ì í•© ì‰¬ì›€
    class_weight="balanced",
    random_state=42
)

tree_model.fit(X_train, y_train)

y_pred_tree = tree_model.predict(X_test)
print("[Tree] Confusion matrix:\n", confusion_matrix(y_test, y_pred_tree))
print("[Tree] Classification report:\n", classification_report(y_test, y_pred_tree, digits=4))
```
```text
[Tree] Confusion matrix:
 [[55491  1373]
 [   13    85]]
[Tree] Classification report:
               precision    recall  f1-score   support

           0     0.9998    0.9759    0.9877     56864
           1     0.0583    0.8673    0.1093        98

    accuracy                         0.9757     56962
   macro avg     0.5290    0.9216    0.5485     56962
weighted avg     0.9981    0.9757    0.9862     56962
```

**ì•™ìƒë¸”**

```python
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.utils.class_weight import compute_sample_weight
from sklearn.metrics import confusion_matrix, classification_report

# (1) RandomForest
rf_model = RandomForestClassifier(
    n_estimators=300,
    max_depth=None,
    min_samples_leaf=2,
    max_features="sqrt",
    class_weight="balanced_subsample",
    n_jobs=-1,
    random_state=42
)
rf_model.fit(X_train, y_train)

y_pred_rf = rf_model.predict(X_test)
print("[RF] Confusion matrix:\n", confusion_matrix(y_test, y_pred_rf))
print("[RF] Classification report:\n", classification_report(y_test, y_pred_rf, digits=4))

# (2) GradientBoosting (+ sample_weight)
GradientBoostingClassifier(
    n_estimators=150,     # 300 â†’ 150
    learning_rate=0.1,    # 0.05 â†’ 0.1
    max_depth=2,
    subsample=0.7,        # ì¶”ê°€
    random_state=42
)
sw = compute_sample_weight(class_weight="balanced", y=y_train)  # ë¶ˆê· í˜• ê°€ì¤‘ì¹˜
gb_model.fit(X_train, y_train, sample_weight=sw)

y_pred_gb = gb_model.predict(X_test)
print("[GB] Confusion matrix:\n", confusion_matrix(y_test, y_pred_gb))
print("[GB] Classification report:\n", classification_report(y_test, y_pred_gb, digits=4))
```
```text
[RF] Confusion matrix:
 [[56860     4]
 [   22    76]]
[RF] Classification report:
               precision    recall  f1-score   support

           0     0.9996    0.9999    0.9998     56864
           1     0.9500    0.7755    0.8539        98

    accuracy                         0.9995     56962
   macro avg     0.9748    0.8877    0.9269     56962
weighted avg     0.9995    0.9995    0.9995     56962

[GB] Confusion matrix:
 [[55591  1273]
 [    9    89]]
[GB] Classification report:
               precision    recall  f1-score   support

           0     0.9998    0.9776    0.9886     56864
           1     0.0653    0.9082    0.1219        98

    accuracy                         0.9775     56962
   macro avg     0.5326    0.9429    0.5553     56962
weighted avg     0.9982    0.9775    0.9871     56962
```

**ëª¨ë¸ ë¹„êµ**

```python
import numpy as np
import pandas as pd
from sklearn.metrics import roc_curve, auc, average_precision_score, confusion_matrix

# yëŠ” 0/1ë¡œ, 1ì´ Fraud(positive)
y_test_np = np.asarray(y_test).ravel()

def get_pos_score(model, X):
    proba = model.predict_proba(X)
    classes = np.array(model.classes_)
    pos_idx = np.where(classes == 1)[0][0]
    return proba[:, pos_idx]

def metrics_at_threshold(y_true01, score, t):
    y_hat = (score >= t).astype(int)
    tn, fp, fn, tp = confusion_matrix(y_true01, y_hat).ravel()
    tpr = tp / (tp + fn) if (tp + fn) else 0.0
    fpr = fp / (fp + tn) if (fp + tn) else 0.0
    prec = tp / (tp + fp) if (tp + fp) else 0.0
    acc = (tp + tn) / (tp + tn + fp + fn)
    return {"t": float(t), "tn": int(tn), "fp": int(fp), "fn": int(fn), "tp": int(tp),
            "recall(tpr)": float(tpr), "fpr": float(fpr), "precision": float(prec), "accuracy": float(acc)}

def threshold_youden(y_true01, score):
    fpr, tpr, thr = roc_curve(y_true01, score)
    # inf(ì•„ë¬´ë„ ì–‘ì„± ì˜ˆì¸¡ ì•ˆ í•¨) ì œì™¸
    mask = np.isfinite(thr)
    J = (tpr - fpr)
    J[~mask] = -np.inf
    return float(thr[np.argmax(J)])

def threshold_fpr_constraint(y_true01, score, alpha=0.001):
    fpr, tpr, thr = roc_curve(y_true01, score)
    # inf ì œì™¸ + (TPR>0) ì¡°ê±´ìœ¼ë¡œ trivial í•´ ë°©ì§€
    mask = np.isfinite(thr) & (tpr > 0)
    cand = np.where(mask & (fpr <= alpha))[0]
    if len(cand) == 0:
        return None
    i = cand[np.argmax(tpr[cand])]
    return float(thr[i])

def threshold_cost(y_true01, score, c_fn=100.0, c_fp=1.0):
    thresholds = np.unique(score)
    thresholds = np.r_[0.0, thresholds, 1.0]  # ë²”ìœ„ í¬í•¨
    best_t, best_cost = None, np.inf
    for t in thresholds:
        m = metrics_at_threshold(y_true01, score, t)
        cost = c_fn*m["fn"] + c_fp*m["fp"]
        if cost < best_cost:
            best_cost, best_t = cost, float(t)
    return best_t, float(best_cost)

def summarize_model(model_name, y_true01, score, alpha=0.001, c_fn=100.0, c_fp=1.0):
    fpr, tpr, _ = roc_curve(y_true01, score)
    roc_auc = auc(fpr, tpr)
    ap = average_precision_score(y_true01, score)

    rows = []

    t_y = threshold_youden(y_true01, score)
    m_y = metrics_at_threshold(y_true01, score, t_y)
    m_y.update({"model": model_name, "rule": "Youden (TPR-FPR)", "roc_auc": roc_auc, "ap": ap,
                "cost": c_fn*m_y["fn"] + c_fp*m_y["fp"]})
    rows.append(m_y)

    t_f = threshold_fpr_constraint(y_true01, score, alpha=alpha)
    if t_f is not None:
        m_f = metrics_at_threshold(y_true01, score, t_f)
        m_f.update({"model": model_name, "rule": f"FPR <= {alpha}", "roc_auc": roc_auc, "ap": ap,
                    "cost": c_fn*m_f["fn"] + c_fp*m_f["fp"]})
        rows.append(m_f)
    else:
        rows.append({"model": model_name, "rule": f"FPR <= {alpha}", "t": None,
                     "tn": None, "fp": None, "fn": None, "tp": None,
                     "recall(tpr)": None, "fpr": None, "precision": None, "accuracy": None,
                     "roc_auc": roc_auc, "ap": ap, "cost": None})

    t_c, best_cost = threshold_cost(y_true01, score, c_fn=c_fn, c_fp=c_fp)
    m_c = metrics_at_threshold(y_true01, score, t_c)
    m_c.update({"model": model_name, "rule": f"Cost (c_fn={c_fn}, c_fp={c_fp})",
                "roc_auc": roc_auc, "ap": ap, "cost": best_cost})
    rows.append(m_c)

    return rows

# ===== ëª¨ë¸ score ëª¨ìœ¼ê¸°(ì´ë¯¸ ì•ì—ì„œ í•™ìŠµëœ ê²ƒìœ¼ë¡œ ê°€ì •) =====
models = {
    "k-NN": knn_model,
    "SVM(Linear+Calib)": svm_model,
    "Logit": logit_model,
    "Tree": tree_model,
    "RandomForest": rf_model,
    "GradientBoosting": gb_model
}

alpha = 0.001          # ì‚¬ê¸°íƒì§€ì—ì„œ í”í•œ FPR ì œì•½(0.1%)
c_fn, c_fp = 100.0, 1.0  # FN(ì‚¬ê¸° ë†“ì¹¨) ë¹„ìš©ì„ í¬ê²Œ

rows = []
for name, m in models.items():
    score = get_pos_score(m, X_test)
    rows += summarize_model(name, y_test_np, score, alpha=alpha, c_fn=c_fn, c_fp=c_fp)

df_all = pd.DataFrame(rows)[
    ["model","rule","t","tn","fp","fn","tp","recall(tpr)","fpr","precision","accuracy","roc_auc","ap","cost"]
].sort_values(["rule","model"]).reset_index(drop=True)
display(df_all)
```

![](images/classification_ml_rareall.png){fig-align="center" width="100%"}
