---
title: "MLDL 딥러닝 분류 - 사례분석"
format: html
---

### 딥러닝 분류 사례분석

#### 1. 희소성공 딥러닝 분류
##### \(1) 데이터

**데이터 불러오기**

Credit Card Fraud(creditcard.csv) 데이터는 대표적인 이진 분류(surveillance / fraud detection) 벤치마크로, 한 건의 거래가 사기(Fraud) 인지 정상(Normal) 인지를 판정하는 문제를 다룬다. 

반응변수는 Class 하나이며 보통 Class=0을 정상(negative), Class=1을 사기(positive)로 정의한다. 즉 목표는 각 거래 $P(Y=1∣X=x)$ 을 추정하고, 운영 목적(오탐/미탐 비용, 검토량 등)에 맞는 임계값 t를 정해 $\hat y =1{p(x)≥t}$ 형태로 의사결정을 내리는 것이다.

데이터 규모는 284,807건의 거래로 구성되며, 총 31개 변수를 가진다. 이 중 Class가 타깃(y)이고 나머지 30개가 입력 변수(X) 다. 입력 변수는 Time, V1~V28, Amount로 이루어진다. 자료형 관점에서 입력 변수들은 대부분 연속형이며(실수형), Class만 정수형 라벨이다. 

특히 V1~V28은 원래 거래 속성들을 그대로 제공한 것이 아니라, 개인정보 보호 및 비식별화를 위해 PCA(주성분 분석) 로 변환된 특징들이다. 따라서 각 $V_k$ 는 원변수들의 선형결합으로 얻어진 주성분 점수이며, 원래 변수의 해석 가능성은 제한된다. 

반면 Time과 Amount는 비교적 직관적인 의미를 유지한다. Time은 기준 시점 이후의 경과 시간으로 시간대에 따른 패턴을 반영할 수 있고, Amount는 거래 금액으로서 사기 여부와 연관된 중요한 신호가 될 수 있다.

이 데이터의 가장 결정적인 특성은 극심한 클래스 불균형(extreme class imbalance) 이다. 정상 거래(Class=0)는 284,315건으로 전체의 약 99.827%를 차지하는 반면, 사기 거래(Class=1)는 492건으로 약 0.173%에 불과하다. 

이런 환경에서는 단순 정확도(Accuracy)가 쉽게 과대평가된다. 예를 들어 모든 거래를 정상으로만 예측해도 정확도는 약 99.8%에 달할 수 있으나, 이는 사기 탐지라는 목적을 전혀 달성하지 못한다. 따라서 실무적으로는 양성(사기) 탐지 성능을 직접 반영하는 지표, 예컨대 Precision–Recall(PR) 관점의 평가(AP 포함)나, 오탐을 일정 수준 이하로 제한하는 FPR 제약 기반 임계값 선택, 혹은 미탐(FN)과 오탐(FP)의 비용을 반영한 비용기반 임계값 설계가 핵심이 된다.

```python
!pip -q install kagglehub

import kagglehub
import pandas as pd
import os

# 데이터 다운로드 (캐시 경로 반환)
path = kagglehub.dataset_download("mlg-ulb/creditcardfraud")
print("downloaded to:", path)
print(os.listdir(path)[:10])

# CSV 로드
df = pd.read_csv(os.path.join(path, "creditcard.csv"))

print("shape:", df.shape)

# 타깃
y = df["Class"].astype(int)        # 1=Fraud(positive), 0=Normal
X = df.drop(columns=["Class"])
```

**전처리**

이 코드는 희귀 이벤트(사기 거래) 이진 분류 문제에서 학습과 평가가 왜곡되지 않도록 데이터 분리와 전처리를 누수 없이 일관되게 수행하기 위한 구성이다.

먼저 train_test_split으로 전체 데이터를 학습용(train)과 테스트용(test)으로 분리하는 단계이다. 이때 stratify=y를 사용하여 사기(Class=1) 비율이 train과 test에 거의 동일하게 유지되도록 하는 방식이다. 사기 데이터는 전체에서 극히 적은 불균형 데이터이므로 stratify를 사용하지 않으면 테스트셋의 양성 비율이 우연에 의해 흔들리고, 그 결과 평가 지표가 불안정해질 가능성이 큰 구조이다. 출력된 Fraud rate가 train과 test에서 거의 같게 나타나는 것은 분리 과정이 의도대로 수행되었음을 보여주는 결과이다.

다음은 ColumnTransformer를 이용한 전처리 정의 단계이다. 이 데이터의 V1~V28은 PCA 기반으로 변환된 수치 특성이므로 대체로 스케일이 유사한 형태로 제공되는 편이다. 반면 Amount와 Time은 원래 스케일을 유지하는 변수이므로 값의 범위가 상대적으로 크고 학습 안정성을 저해할 수 있는 요소이다. 따라서 cols_scale을 ["Amount", "Time"]으로 지정하고, 해당 두 컬럼에만 StandardScaler를 적용하여 평균 0, 표준편차 1로 표준화하는 구성이다. 나머지 컬럼은 remainder="passthrough"로 지정하여 변환 없이 그대로 통과시키는 방식이다. 이는 필요한 컬럼에만 최소 전처리를 적용하는 실무형 선택이다.

전처리에서 가장 중요한 원칙은 데이터 누수 방지 원칙이다. 전처리 객체 preprocess는 학습 데이터에서만 fit을 수행해야 하며, 테스트 데이터에는 transform만 적용되어야 한다. fit_transform(X_train)은 train에서 평균과 표준편차 같은 통계량을 학습하고 동시에 변환하는 과정이다. transform(X_test)은 train에서 학습한 기준을 동일하게 test에 적용하는 과정이다. 만약 테스트 데이터까지 포함하여 스케일러를 fit해버리면 테스트 정보가 전처리 과정에 반영되는 누수 문제가 발생하고, 그 결과 성능이 과대평가되는 위험이 존재하는 구조이다.

set_output(transform="pandas")를 사용할 수 있는 환경에서는 전처리 결과를 pandas DataFrame으로 받아 컬럼명을 보존하는 구성이다. 이때 feature_names는 변환 결과 DataFrame의 columns를 통해 그대로 확보되는 방식이다. 이후 딥러닝 모델 입력을 위해 to_numpy()로 넘파이 배열로 변환하여 X_train_scaled와 X_test_scaled를 생성하는 흐름이다. 만약 set_output이 지원되지 않는 환경이면 예외 처리로 넘어가며, 이 경우 ColumnTransformer의 출력은 보통 배열 형태이므로 feature_names는 직접 구성하게 된다. 이때 ColumnTransformer 특성상 변환된 컬럼(Amount, Time)이 앞쪽에 배치되고, remainder로 통과된 나머지 컬럼이 뒤에 이어지는 순서가 된다. 실제 출력에서 feature_names의 앞부분이 ['Amount', 'Time', 'V1', 'V2', 'V3'] 형태로 나타나는 것은 이러한 출력 순서를 반영한 결과이다.

종합하면, 이 코드는 불균형 데이터에서 분포를 안정적으로 유지한 train/test 분리를 수행하고, Amount와 Time에만 표준화를 적용하며, 전처리의 fit을 train에만 고정함으로써 누수를 방지하고, 딥러닝 학습을 위한 배열과 특성 이름까지 일관되게 준비하는 전처리 파이프라인 구성이다.

```python
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler

# =========================
# 0) Train/Test 분리 (불균형 유지)
# =========================
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

print("Train shape:", X_train.shape, "Test shape:", X_test.shape)
print("Fraud rate (train):", y_train.mean(), "Fraud rate (test):", y_test.mean())

# =========================
# 1) 전처리 파이프라인(누수 방지)
#   - Time, Amount만 표준화
#   - 나머지 컬럼(V1~V28)은 그대로 통과
# =========================
cols_scale = ["Amount", "Time"]

preprocess = ColumnTransformer(
    transformers=[
        ("scale_time_amount", StandardScaler(), cols_scale),
    ],
    remainder="passthrough",              # 나머지 컬럼은 그대로
    verbose_feature_names_out=False
)

# (선택) 가능하면 pandas로 출력되게 해서 feature_names를 안전하게 확보
try:
    preprocess.set_output(transform="pandas")
    X_train_scaled_df = preprocess.fit_transform(X_train)   # train에만 fit
    X_test_scaled_df  = preprocess.transform(X_test)        # test는 transform만

    # Keras용 numpy 배열
    X_train_scaled = X_train_scaled_df.to_numpy()
    X_test_scaled  = X_test_scaled_df.to_numpy()

    # 컬럼명 유지
    feature_names = X_train_scaled_df.columns.tolist()

except Exception:
    # 구버전 sklearn 등으로 set_output이 없을 때 fallback
    X_train_scaled = preprocess.fit_transform(X_train)      # train에만 fit
    X_test_scaled  = preprocess.transform(X_test)           # test는 transform만

    # ColumnTransformer는 스케일된 cols_scale이 앞쪽으로 오고, 나머지가 뒤로 붙습니다.
    feature_names = cols_scale + [c for c in X_train.columns if c not in cols_scale]

print("Scaled shapes:", X_train_scaled.shape, X_test_scaled.shape)
print("First 5 feature names:", feature_names[:5])
```

Train shape: (227845, 30) Test shape: (56962, 30)
<br>
Fraud rate (train): 0.001729245759178389 Fraud rate (test): 0.0017204452090867595
<br>
Scaled shapes: (227845, 30) (56962, 30)
<br>
First 5 feature names: ['Amount', 'Time', 'V1', 'V2', 'V3']