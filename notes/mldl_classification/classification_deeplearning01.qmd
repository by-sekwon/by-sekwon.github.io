---
title: "MLDL 딥러닝 분류 - 파트1"
format: html
---

### Chapter 1. 딥러닝 분류 (파트1)

딥러닝 분류는 입력 $x \in \mathbb{R}^{d}$가 주어졌을 때, 출력 y가 어떤
클래스에 속하는지 예측하는 문제이다. 전통적 분류(로지스틱 회귀, LDA
등)가 비교적 명시적 확률모형 혹은 선형 결정규칙을 강조했다면, 딥러닝
분류는 표현학습을 통해 복잡한 비선형 결정경계를 자동으로 학습한다는 점이
핵심이다.

딥러닝 분류를 이해할 때는 ["]{dir="rtl"}모형이 무엇을 내놓고(출력층), 그
출력을 어떻게 확률로 바꾸며, 어떤 손실을 최소화하는가"를 한 덩어리로
보는 것이 중요하다. 특히 분류에서 실무적 의사결정은 다음의 3단계를
분리해서 생각하면 정리된다.

아직 확률이 아니라, 클래스별로 얼마나 그럴듯한지를 나타내는 원시적인
척도이며 보통 $logitz = (z_{1},\ldots,z_{K})$ 형태로 출력된다.

다음으로 이 점수 벡터를 확률로 해석할 수 있도록 변환한다. 다중분류라면
점수들 사이의 상대적 크기를 반영해 합이 1이 되도록 만드는 softmax를
적용하고, 이진분류나 멀티라벨이라면 각 클래스의 ["]{dir="rtl"}존재
확률"을 독립적으로 해석하기 위해 sigmoid를 적용해 p를 얻는다.

마지막으로 이렇게 얻어진 확률 p를 실제 의사결정으로 연결한다.
다중분류에서는 가장 큰 확률을 가진 클래스를 선택하여
$\widehat{y} = \arg\max_{k}p_{k}$로 예측하고, 이진/멀티라벨에서는 특정
임계값 t를 기준으로 $p \geq t$이면 양성, 그렇지 않으면 음성으로
판정한다. 즉 딥러닝 분류는 ["]{dir="rtl"}점수를 계산하고 → 확률로 바꾸고
→ 운영 규칙에 따라 결정한다"는 흐름으로 정리할 수 있다.

#### 1\. 개요: 딥러닝 분류는 무엇을 학습하나?

딥러닝 분류는 입력 X로부터 클래스에 대한 ["]{dir="rtl"}점수(score)"를
만들고, 그 점수를 확률로 바꾼 뒤, 운영 목적에 맞게 결정을 내리도록
학습하는 과정이다. 핵심은 ["]{dir="rtl"}정답 라벨을 맞추는 것"만이
아니라, 얼마나 확신하는지(확률의 품질)까지 포함해 모델을
설계·학습·평가하는 데 있다.

##### \(1) 분류 문제와 목표: 점수--확률--결정

**점수(score): 신경망이 직접 출력하는 값**

신경망 분류기는 보통 마지막 층에서 클래스별 로짓(logit) 혹은 점수를
출력한다.

- 이진 분류(positive vs negative): $z = f_{\theta}(x) \in \mathbb{R}$
- 다중 분류(K개 클래스):
$\mathbf{z} = f_{\theta}(x) = (z_{1},\ldots,z_{K}) \in \mathbb{R}^{K}$

여기서 $\theta$는 신경망 파라미터(가중치/편향)이며, $f_{\theta}$는 여러
층의 합성함수로 표현된다.
$f_{\theta}(x) = W_{L}\phi(W_{L - 1}\phi(\cdots\phi(W_{1}x + b_{1})\cdots) + b_{L - 1}) + b_{L}$($\phi$:
ReLU 등 비선형 활성함수)

점수 z 자체는 확률이 아니다. 임의의 실수이며, ["]{dir="rtl"}양성일수록
크게" 혹은 ["]{dir="rtl"}해당 클래스일수록 크게" 만들도록 학습된다.

**확률(probability): 점수를 확률로 변환**

점수를 확률로 바꾸는 대표 변환은 다음과 같다.

- 이진 분류: 시그모이드(sigmoid)
$p(x) = P(Y = 1 \mid X = x) = \sigma(z) = \frac{1}{1 + e^{- z}}$
- 다중 분류: 소프트맥스(softmax)
$p_{k}(x) = P(Y = k \mid X = x) = \frac{e^{z_{k}}}{\sum_{j = 1}^{K}e^{z_{j}}},k = 1,\ldots,K$.
softmax는 $\sum_{k}p_{k}(x) = 1$을 만족하는 ["]{dir="rtl"}단일
정답(one-of-K)" 확률 모델이다.

**결정: 확률을 임계값/규칙으로 행동으로 바꾸기**

운영에서는 확률을 바로 쓰지 않고, 어떤 의사결정 규칙을 적용한다.

- 이진 분류(임계값 t): $\widehat{y} = \{\begin{matrix}
1 & \text{if}p(x) \geq t \\
0 & \text{otherwise}
\end{matrix}$
- 다중 분류: $\widehat{y} = \arg\max_{k}p_{k}(x) = \arg\max_{k}z_{k}$

중요한 점은 학습 목적(손실 최소화)과 운영 목적(오경보/미탐 비용, 정책
제약)이 반드시 동일하지 않다는 것이다. 예를 들어, 사기탐지에서는 t를
낮추면 재현율(Recall)은 올라가지만 오경보(FP)도 늘어난다. 즉 분류는
["]{dir="rtl"}모델 출력 \\rightarrow 확률 \\rightarrow 임계값/정책"까지
포함한 전체 파이프라인 문제다.

##### \(2) 데이터/라벨 구조(이진, 다중, 멀티라벨)

분류에서 가장 먼저 확인해야 할 것은 라벨 Y의 구조이다. 라벨 구조에 따라
출력층/손실함수/평가가 달라진다.

**이진 분류(Binary): $Y \in \{ 0,1\}$**

- 출력: $z \in \mathbb{R},p = \sigma(z)$
- 대표 손실(이진 교차엔트로피, BCE):
$\mathcal{L}_{\text{BCE}}(y,p) = - (y\log p + (1 - y)\log(1 - p))$

**다중 분류(Multiclass, 단일 정답) $Y \in \{ 1,2,\ldots,K\}$**

- 출력:
$\mathbf{z} \in \mathbb{R}^{K},\mathbf{p} = \text{softmax}(\mathbf{z})$
- 손실(범주형 교차엔트로피, CE):
$\mathcal{L}_{\text{CE}}(y,\mathbf{p}) = - \log p_{y}$

원-핫(one-hot) 벡터 $\mathbf{y}$로 쓰면
$\mathcal{L}_{\text{CE}}(\mathbf{y},\mathbf{p}) = - \overset{K}{\sum_{k = 1}}y_{k}\log p_{k}$

**멀티라벨 분류(Multilabel, 여러 라벨 동시)**

한 관측치가 여러 클래스를 동시에 가질 수 있다.
$\mathbf{Y} \in \{ 0,1\}^{K},Y_{k} = 1$ 이면 k번째 라벨이 존재한다.

- 출력: 각 라벨별 독립 로짓 $z_{k}$, 확률 $p_{k} = \sigma(z_{k})$
- 손실(라벨별 BCE의 합):
$\mathcal{L}_{\text{ML}}(\mathbf{y},\mathbf{p}) = - \overset{K}{\sum_{k = 1}}(y_{k}\log p_{k} + (1 - y_{k})\log(1 - p_{k}))$

멀티라벨에서는 softmax(합이 1인 확률)보다 sigmoid를 쓰는 것이
자연스럽다(각 라벨이 ["]{dir="rtl"}독립적으로 참/거짓"이기 때문).

##### \(3) 학습과 일반화 개요(과적합, 정규화, 데이터 규모)

딥러닝 분류의 성능은 단순히 ["]{dir="rtl"}학습 정확도"가 아니라 일반화
성능(새 데이터에서의 성능)으로 평가된다. 신경망은 표현력이 매우 커서
훈련데이터를 거의 외워버릴 수 있으므로, 과적합을 통제하는 것이 핵심이다.

**경험위험 최소화와 일반화**

훈련 데이터 $\{(x_{i},y_{i})\}_{i = 1}^{n}$에 대해
$\widehat{\theta} = \arg\min_{\theta}\frac{1}{n}\overset{n}{\sum_{i = 1}}\mathcal{L}(y_{i},f_{\theta}(x_{i}))$을
최소화하면 훈련 손실은 내려가지만, 테스트 손실이 함께 내려간다는 보장은
없다. 일반화 관점에서는
$\text{Test risk}\mathbb{E}_{(X,Y)}\lbrack\mathcal{L}(Y,f_{\theta}(X))\rbrack$를
낮추는 것이 목표다.

**과적합의 전형적 징후**

- 훈련 손실은 계속 감소하지만, 검증 손실이 어느 시점부터 증가한다.
- 훈련 정확도는 매우 높지만, 테스트 정확도는 정체/하락 한다.
- 예측 확률이 과도하게 0 또는 1로 쏠리는(과신) 현상이다.

**정규화(Regularization)의 큰 축**

딥러닝 분류에서는 다음이 ["]{dir="rtl"}일반화"를 좌우하는 실무적 레버다.

- 가중치 규제(Weight decay, $L_{2}$):
$\min_{\theta}\frac{1}{n}\overset{n}{\sum_{i = 1}}\mathcal{L}_{i}(\theta) + \lambda \parallel \theta \parallel_{2}^{2}$
- 드롭아웃(Dropout): 학습 중 일부 뉴런을 확률적으로 제거하여
공적응(co-adaptation)을 억제
- 조기종료(Early stopping): 검증 손실이 나빠지기 시작하면 학습 중단
- 데이터 증강(Data augmentation): 입력 변형으로 유효 샘플 수를 늘려 과적합 완화
- 배치정규화(BatchNorm) 등 학습 안정화: 최적화가 안정되면 일반화도
개선되는 경우가 많음

##### \(4) 데이터 규모와 모델 규모의 균형

일반적으로 데이터가 작을수록: 모델을 단순화(파라미터 수↓), 정규화
강하게(드롭아웃/weight decay↑), 사전학습 모델 활용(transfer learning)
비중↑

반대로 데이터가 충분히 크면: 모델 규모를 키워 표현력을 확보, 데이터
증강/정규화는 ["]{dir="rtl"}안정성 확보" 용도로 조절

#### 2\. 출력층과 확률모형

딥러닝 분류에서 출력층(output layer)은 ["]{dir="rtl"}신경망이 만든
점수를 확률로 해석 가능한 형태로 바꾸는 구간"이다. 즉, 출력층은 단순한
마지막 층이 아니라 확률모형의 형태를 결정한다. 라벨
구조(이진/다중/멀티라벨)에 맞는 출력층을 선택하지 않으면,
손실함수·평가·의사결정 규칙이 서로 충돌하여 학습이 불안정해진다.

##### \(1) 이진분류: logit, sigmoid, P(Y=1\\mid X)

이진분류에서는 라벨이 $Y \in \{ 0,1\}$이며, 신경망은 마지막에서 단일
실수 점수(logit)를 출력한다.

**logit의 정의**

$z = f_{\theta}(x) \in \mathbb{R}$, 여기서 z는 ["]{dir="rtl"}양성일
가능성이 높을수록 크게" 학습되는 점수다. 확률이 아니라는 점이 중요하다.

**sigmoid로 확률화**

이 점수를 확률로 바꾸기 위해 sigmoid를 사용한다.
$p(x) = P(Y = 1 \mid X = x) = \sigma(z) = \frac{1}{1 + e^{- z}}$. 그럼
$P(Y = 0 \mid x) = 1 - p(x)$가 된다.

**logit과 odds 해석(확률모형 관점)**

sigmoid는 다음 관계를 만족한다.
$\frac{p(x)}{1 - p(x)} = e^{z} \Rightarrow \log\frac{p(x)}{1 - p(x)} = z$.
즉 $logitz$는 조건부 확률의 로그 오즈(log-odds)에 해당한다. 딥러닝
이진분류는 ["]{dir="rtl"}입력 x로부터 $P(Y = 1 \mid x)$"를 직접
학습한다기보다, 우선 log-odds를 예측하고 이를 확률로 변환하는 구조라고
이해하면 정리된다.

##### \(2) 다중분류 확률모형: Softmax

다중분류(멀티클래스, 단일 정답)에서는 $Y \in \{ 1,\ldots,K\}$이고
관측치마다 정답 클래스가 정확히 하나 존재한다. 신경망은 클래스별 점수
벡터를 출력한다.

**클래스별 logit**

$$\mathbf{z} = f_{\theta}(x) = (z_{1},\ldots,z_{K}) \in \mathbb{R}^{K}$$

**softmax로 확률 벡터 생성**

$$p_{k}(x) = P(Y = k \mid X = x) = \frac{e^{z_{k}}}{\sum_{j = 1}^{K}e^{z_{j}}},k = 1,\ldots,K$$

softmax의 핵심 성질은
$p_{k}(x) \in (0,1),\overset{K}{\sum_{k = 1}}p_{k}(x) = 1$. 즉
["]{dir="rtl"}확률 질량이 K개 클래스에 분배"되는 구조이며, 클래스들이
서로 경쟁한다.

**softmax의 불변성(중요한 성질)**

모든 로짓에 같은 상수 c를 더해도 확률은 변하지 않는다.
$\frac{e^{z_{k} + c}}{\sum_{j}^{}e^{z_{j} + c}} = \frac{e^{z_{k}}}{\sum_{j}^{}e^{z_{j}}}$.
이 성질 때문에 실제 구현에서는 수치안정성을 위해
$p_{k} = \frac{e^{z_{k} - \max_{j}z_{j}}}{\sum_{j}^{}e^{z_{j} - \max_{j}z_{j}}}$처럼
계산한다(overflow 방지).

##### \(3) 다중분류의 결정규칙: $\\argmax_k~ p_k$ 

확률모형이 정해지면, 의사결정 규칙을 통해 최종 예측 클래스가 결정된다.

**MAP 결정규칙**

다중분류에서 가장 기본 규칙은 최대확률(MAP)이다.
$\widehat{y}(x) = \arg\max_{k \in \{ 1,\ldots,K\}}p_{k}(x)$. softmax는
단조 변환이므로 다음도 동일하다. $\widehat{y}(x) = \arg\max_{k}z_{k}$.
즉 ["]{dir="rtl"}확률이 가장 큰 클래스"는 ["]{dir="rtl"}로짓이 가장 큰
클래스"와 같다.

**비용민감(cost-sensitive) 상황의 일반화**

현실에서는 오분류 비용이 클래스별로 다를 수 있다. 비용행렬 C(a,y)가 있을
때 최적 규칙은
$\widehat{a}(x) = \arg\min_{a}\overset{K}{\sum_{k = 1}}C(a,k)p_{k}(x)$이며,
$\arg\max$는 ["]{dir="rtl"}모든 오분류 비용이 동일"한 특수한 경우로 볼
수 있다. (이 점 때문에 운영단에서는 단순 정확도보다 임계값/정책 설계가
중요해진다.)

##### \(4) 멀티클래스 vs 멀티라벨 출력 구조 비교(softmax vs sigmoid)

둘은 이름이 비슷하지만 라벨의 의미 자체가 다르다. 따라서 출력층과 확률
해석도 완전히 달라진다.

**멀티클래스(Multiclass, 단일 정답)**

- 라벨: $Y \in \{ 1,\ldots,K\}$
- 의미: 정답은 하나, 클래스들은 상호배타적(mutually exclusive)
- 출력: $\mathbf{z} \in \mathbb{R}^{K}$
- 확률화: softmax
$p_{k} = \frac{e^{z_{k}}}{\sum_{j}^{}e^{z_{j}}},\sum_{k}p_{k} = 1$
- 결정: $\widehat{y} = \arg\max_{k}p_{k}$
- 해석: ["]{dir="rtl"}이 샘플은 K개 중 정확히 하나다"라는 확률모형.

**멀티라벨(Multilabel, 여러 라벨 동시)**

- 라벨: $\mathbf{Y} \in \{ 0,1\}^{K}$
- 의미: 여러 라벨이 동시에 참일 수 있음(비배타)
- 출력: $\mathbf{z} \in \mathbb{R}^{K}$ (라벨별 로짓)
- 확률화: 라벨별 sigmoid $p_{k} = \sigma(z_{k}),k = 1,\ldots,K$. 여기서 $p_{k} = P(Y_{k} = 1 \mid x)$로 해석된다.
- 결정: 라벨별 임계값 ${\widehat{y}}_{k} = 1\{ p_{k} \geq t_{k}\}$ (라벨마다 임계값 $t_{k}$를 다르게 두는 것이 흔하다)
- 해석: ["]{dir="rtl"}각 라벨이 존재할 확률을 따로 추정한다." (클래스 간
경쟁 구조가 없다)

**softmax를 멀티라벨에 쓰면 왜 문제가 되나?**

softmax는 $\sum_{k}p_{k} = 1$을 강제하므로, ["]{dir="rtl"}여러 라벨이
동시에 1"이어야 하는 데이터에서 확률 질량을 나눠 가지게 되어 구조적으로
충돌한다. 예를 들어 이미지에 ["]{dir="rtl"}사람"과
["]{dir="rtl"}자전거"가 함께 있으면 둘 다 높은 확률이어야 하는데,
softmax는 둘이 동시에 0.9가 되는 것을 허용하지 않는다.

#### 3\. 손실함수: Cross-Entropy의 원리

딥러닝 분류에서 손실함수는 ["]{dir="rtl"}정답을 맞추게 하라"는 막연한
지시가 아니라, 확률모형 $P_{\theta}(Y \mid X)$을 데이터에 맞게
추정하도록 만드는 통계적 기준이다. 분류에서 가장 표준인 손실이
Cross-Entropy이며, 이는 곧 음의 로그우도(NLL) 최소화와 동치다. (즉,
딥러닝 분류는 [']{dir="rtl"}확률모형의 최대우도추정[']{dir="rtl"}을
SGD로 수행한다고 볼 수 있다.)

##### \(1) 최대우도--음의 로그우도(NLL)--Cross-Entropy 연결

데이터 $\{(x_{i},y_{i})\}_{i = 1}^{n}$가 i.i.d.라고 할 때, 모델이
조건부확률 $P_{\theta}(Y \mid X)$를 준다고 하자. 최대우도추정(MLE)은
$\widehat{\theta} = \arg\max_{\theta}\overset{n}{\prod_{i = 1}}P_{\theta}(y_{i} \mid x_{i})$.

로그를 취하면 곱이 합으로 바뀌어 최적화가
쉬워진다.$\widehat{\theta} = \arg\max_{\theta}\overset{n}{\sum_{i = 1}}\log P_{\theta}(y_{i} \mid x_{i})$

최대화를 최소화 문제로 바꾸기 위해 마이너스를 붙이면 음의 로그우도는
$\widehat{\theta} = \arg\min_{\theta}\overset{n}{\sum_{i = 1}}( - \log P_{\theta}(y_{i} \mid x_{i}))$,
여기서 분류에서 $y_{i}$를 원-핫 벡터 $\mathbf{y}_{i}$로 쓰고, 모델
확률을 $\mathbf{p}_{i}$로 쓰면
$- \log P_{\theta}(y_{i} \mid x_{i}) = - \overset{K}{\sum_{k = 1}}y_{ik}\log p_{ik}$.
이 식이 바로 Cross-Entropy(교차엔트로피)다. 즉 $MLE \leftrightarrow NLL$
최소화 $\leftrightarrow Cross - Entropy$ 최소화가 한 줄로 연결된다.

정답 클래스에 부여한 확률 $p_{i,y_{i}}$가 작을수록
$- \log p_{i,y_{i}}$는 크게 벌점을 준다. 특히 $p \rightarrow 0$이면
손실이 $\rightarrow \infty$로 발산하므로 ["]{dir="rtl"}정답인데 거의
0이라고 확신하는 예측"을 강하게 교정한다.

##### \(2) 다중분류 손실: Softmax + Cross-Entropy

다중분류(단일 정답)에서 신경망은 로짓 $\mathbf{z} \in \mathbb{R}^{K}$를
출력하고, softmax로 확률 $\mathbf{p}$를 만든다.
$p_{k} = \frac{e^{z_{k}}}{\sum_{j = 1}^{K}e^{z_{j}}}$. 정답이
$y \in \{ 1,\ldots,K\}$일 때 Cross-Entropy는
$\mathcal{L}_{\text{CE}}(y,\mathbf{p}) = - \log p_{y}$이다.

원-핫 벡터 $\mathbf{y}$로 쓰면 더 일반적으로
$\mathcal{L}_{\text{CE}}(\mathbf{y},\mathbf{p}) = - \overset{K}{\sum_{k = 1}}y_{k}\log p_{k}$이다.
따라서 다중분류 표준 학습은
$\min_{\theta}\frac{1}{n}\overset{n}{\sum_{i = 1}}( - \log p_{i,y_{i}})\text{where}\mathbf{p}_{i} = \text{softmax}(f_{\theta}(x_{i}))$으로
정리된다.

##### \(3) gradient 직관: $(p - y)$ 형태와 학습 안정성

Cross-Entropy가 실무에서 압도적으로 쓰이는 이유 중 하나는, softmax와
결합했을 때 기울기가 매우 깔끔해져 학습이 안정적이기 때문이다.

한 샘플에 대해, 로짓 \\mathbf{z}에 대한 손실의 미분은
$\frac{\partial\mathcal{L}}{\partial z_{k}} = p_{k} - y_{k}$이다. 즉
["]{dir="rtl"}예측확률 p에서 정답 y를 뺀 오차"가 그대로 역전파된다.

- 정답 클래스($y_{k} = 1$)에서는
$\frac{\partial\mathcal{L}}{\partial z_{k}} = p_{k} - 1$ → 정답 확률 $p_{k}$ 가 1보다 작으면 음수이므로 $z_{k}$를 키우는 방향으로 업데이트
된다.
- 오답 클래스($y_{k} = 0$)에서는
$\frac{\partial\mathcal{L}}{\partial z_{k}} = p_{k}$ → 오답 확률이 클수록 z_k를 줄이는 방향으로 업데이트 된다.

이 형태는 ["]{dir="rtl"}출력층에서의 오차 신호"가 직관적이고 크기 조절도
잘 되어, 단순한 제곱오차(MSE)를 분류에 억지로 쓰는 것보다 훨씬 학습이 잘
된다.

특히 softmax의 미분(야코비안)과 $- \log( \cdot )$ 미분이 결합되며 복잡한
항이 상쇄되어 $(p - y)$로 단순화된다. 이 단순화가 수치적으로도 유리하고,
최적화 관점에서 안정적인 신호를 제공한다.

##### \(4) 실무 옵션: class weight / label smoothing

현장 데이터는 ["]{dir="rtl"}클래스 불균형"과 ["]{dir="rtl"}라벨
노이즈(오표기)"가 흔하다. Cross-Entropy는 기본형으로도 강력하지만, 아래
옵션을 붙이면 성능/안정성이 좋아지는 경우가 많다.

**Class weight (불균형 대응)**

소수 클래스의 손실을 더 크게 벌점 주어 모델이 놓치지 않게 만드는
방식이다.

다중분류 가중 CE:
$\mathcal{L} = - \overset{K}{\sum_{k = 1}}w_{k}y_{k}\log p_{k}$

정답 클래스가 y라면 $\mathcal{L} = - w_{y}\log p_{y}$로 단순화된다.

이진분류 가중 BCE(양성 가중 $w_{1}$, 음성 가중 $w_{0}$):
$\mathcal{L} = - (w_{1}y\log p + w_{0}(1 - y)\log(1 - p))$

실무 포인트는 ["]{dir="rtl"}가중치를 올리면 Recall은 좋아질 수 있지만
FP도 같이 늘 수 있다"는 점이다. 결국 운영 목적(놓침 비용 vs 오경보
비용)에 맞춰 임계값과 함께 튜닝한다.

**Label smoothing (과신 완화, 일반화 개선)**

원-핫 정답 $\mathbf{y}$는 ["]{dir="rtl"}정답 클래스 확률 1"을 강제해
모델이 과도하게 확신하게 만들 수 있다. 이를 완화하기 위해 정답 분포를
약간 부드럽게 만든다.

${\overset{˜}{y}}_{k} = (1 - \varepsilon)y_{k} + \frac{\varepsilon}{K}$.
그리고 $\overset{˜}{\mathbf{y}}$로 Cross-Entropy를 계산한다.
$\mathcal{L} = - \overset{K}{\sum_{k = 1}}{\overset{˜}{y}}_{k}\log p_{k}$

효과: 과신 감소(확률 보정에 유리), 라벨 노이즈에 덜 민감, 일부
데이터셋에서 일반화 성능 개선. 단, $\varepsilon$를 너무 크게
잡으면(정답을 너무 희석하면) 성능이 떨어질 수 있어 보통 작은 값(예:
0.05\~0.1)을 후보로 둔다.

#### 4\. 결정규칙과 임계값(운영 관점)

딥러닝 분류 모델은 보통 확률 $p(x) = P(Y = 1 \mid x)$ 또는
$\{ p_{k}(x)\}$를 출력한다. 하지만 운영(실제 의사결정)은
["]{dir="rtl"}확률을 어떻게 행동으로 바꿀지"가 핵심이며, 그 연결고리가
임계값이다. 같은 모델이라도 임계값을 어떻게 두느냐에 따라
미탐/오경보/검토량/비용이 크게 달라진다.

##### \(1) 왜 임계값이 필요한가: 확률 예측과 의사결정의 분리

이진분류에서 모델은 확률 p(x)를 준다. 그러나 실제 행동은 보통
$\widehat{y} = 1\{ p(x) \geq t\}$처럼 임계값 t로 결정된다.

- 학습(모형 추정): 교차엔트로피(NLL) 최소화로 p(x)를 ["]{dir="rtl"}잘"
예측
- 운영(정책 결정): 비용/제약/리소스에 맞춰 t를 선택

즉, 모델링과 정책을 분리해야 한다. 학습은 ["]{dir="rtl"}확률을 잘 맞추는
것"이고, 운영은 ["]{dir="rtl"}그 확률을 이용해 최적 행동을 선택"하는
문제다.

##### \(2) Confusion Matrix 기반 운영지표(Precision/Recall/FPR/FNR)

이진분류에서 혼동행렬(Confusion Matrix)은 다음 네 개로 요약된다.

- TP: 실제 1(양성)을 1(양성)로 예측
- FP: 실제 0(음성)을 1(양성)로 예측 (오경보)
- FN: 실제 1(양성)을 0(음성)로 예측 (미탐)
- TN: 실제 0(음성)을 0(음성)로 예측

운영에서 자주 쓰는 지표는 다음이다.

- Precision (정밀도) $Precision = \frac{TP}{TP + FP}$
["]{dir="rtl"}양성이라고 예측했을 때, 진짜 양성 비율"
- Recall (재현율, 민감도, TPR) $Recall = TPR = \frac{TP}{TP + FN}$ ["]{dir="rtl"}진짜 양성 중 얼마나 양성이라고 예측했나"
- Spevification(특이도) $Specification = \frac{TN}{YN + FP}$
["]{dir="rtl"}음성이라고 예측했을 때, 진짜 음성 비율"
- FPR (False Positive Rate 거짓 양성률) $FPR = \frac{FP}{FP + TN}$ ["]{dir="rtl"}진짜 음성 중 얼마나 오경보를 냈나"
$FPR = 1 - Specification$
- FNR (False Negative Rate 거짓 음성률)
$FNR = \frac{FN}{TP + FN} = 1 - Recall$ ["]{dir="rtl"}진짜 양성 중 얼마나 음성으로 예측하였나"

임계값 t를 올리면 보통 FP가 줄어 Precision은 오르기 쉽지만 Recall은
떨어진다. t를 내리면 그 반대가 된다. 이 trade-off가 운영의 핵심이다.

##### \(3) ROC, AUC와 임계값 선택

ROC는 임계값 t를 바꿔가며 x축은 $FPR(t) = 1 - Spec(t)$, y축은
$TPR(t) = Recall(t)$를 그린 곡선이다.

AUC(Area Under ROC Curve)는 ["]{dir="rtl"}무작위 양성 샘플이 무작위 음성
샘플보다 더 높은 점수를 받을 확률"로도 해석된다. 즉, 순위 분리력을 보는
지표다.

ROC/AUC는 불균형에서 상대적으로 덜 흔들리지만, 운영에서 중요한
["]{dir="rtl"}양성 경보의 품질(Precision)"을 직접 보여주진 않는다.

["]{dir="rtl"}어떤 t가 좋은가?"는 ROC 자체가 답을 주기보다, FPR 제한이나
비용 기준 같은 운영 조건을 함께 줘야 결정된다.

##### \(4) Precision-Recall, AP(불균형에서의 핵심 평가)

불균형(양성이 희귀)인 경우, ROC는 꽤 좋아 보여도 실제로는 FP가 대량
발생할 수 있다. 이때 더 직접적인 지표가 Precision--Recall(PR) 곡선이다.

PR 곡선은 임계값 t를 바꾸며 x축에는 Recall(재현율), y축은
Precision(정밀도)을 그린다. AP (Average Precision)는 PR 곡선 아래 면적(정확히는 Precision의 Recall-가중 평균)으로, 불균형에서 모델 비교에 자주 쓴다.

희귀 양성 탐지(사기, 결함, 이상탐지)는 ["]{dir="rtl"}Recall을 조금
올리려다 FP가 폭증"하기 쉬우므로, PR/AP가 의사결정에 더 실용적이다.

##### \(5) Cost-based threshold: 비용행렬 기반 최적 $t^{*}$

이진분류에서 ["]{dir="rtl"}양성으로 띄울 때의 오경보 비용"을 $c_{FP}$,
["]{dir="rtl"}음성으로 넘길 때의 미탐 비용"을 $c_{FN}$이라 하자. (정답
비용은 0이라고 두는 단순화)

확률 $p = P(Y = 1 \mid x)$에 대해, $\widehat{y} = 1$로 결정 시
기대비용은
$\mathbb{E}\lbrack C \mid \widehat{y} = 1\rbrack = c_{FP} \cdot P(Y = 0 \mid x) = c_{FP}(1 - p)$이다.

$\widehat{y} = 0$로 결정 시 기대비용은
$\mathbb{E}\lbrack C \mid \widehat{y} = 0\rbrack = c_{FN} \cdot P(Y = 1 \mid x) = c_{FN}p$

따라서 $\widehat{y} = 1$이 유리한 조건은
$c_{FP}(1 - p) \leq c_{FN}p \Longleftrightarrow p \geq \frac{c_{FP}}{c_{FP} + c_{FN}}$.

즉, $t^{*} = \frac{c_{FP}}{c_{FP} + c_{FN}}$

- 미탐지 비용 $c_{FN}$이 크면 $t^{*}$가 내려가서(더 쉽게 양성) Recall을 우선한다.
- 오경보 비용 $c_{FP}$이 크면 $t^{*}$가 올라가서(더 보수적으로 양성) FP를 줄인다.

일반 비용행렬, 클래스 사전확률/운영 분포 변화, 검토 비용 포함 등으로
확장 가능하지만, 위 식이 가장 자주 쓰는 핵심 형태다.

##### \(6) 제약 기반 임계값 선택($FPR \leq \alpha$, 검토량≤K 등)

현장에서는 ["]{dir="rtl"}비용 숫자를 정확히 못 박기 어렵다"거나
["]{dir="rtl"}정책/규제/리소스 제약이 먼저"인 경우가 많다. 이때는 제약을
만족하는 t를 검증셋에서 찾는다.

**FPR 제약: $FPR(t) \leq \alpha$**

예를 들면 ["]{dir="rtl"}오경보율은 1% 이하"가 필수인 알림 시스템이다.
절차(검증셋 기준는 (1) 여러 t에 대해 $FPR(t)$ 계산하고 (2)
$FPR(t) \leq \alpha$를 만족하는 후보 중 Recall 최대 또는 비용 최소
선택한다.

**검토량(알람 수) 제약: ["]{dir="rtl"}하루 최대 K건만 검토 가능"**

예를 들면, 사기 의심 거래 상위 K건만 조사이다. 이 경우 임계값 대신 Top-K
정책이 자연스럽다. 점수 s(x) 또는 확률 p(x)를 내림차순 정렬 후 상위
K개만 양성(검토 대상) 처리 또는 ["]{dir="rtl"}양성 예측 비율 \\le r"
제약을 두고 t를 선택한다.

**복합 제약: \\mathrm{FPR}\\le \\alpha AND 검토량 \\le K**

실무에서는 다중 제약이 흔하다. 이때는 검증셋에서 임계값 후보를
스윕하면서 제약을 모두 만족하는 구간에서 목표(Recall 최대, 비용 최소,
Precision 최대 등)를 최적화 하는 방식으로 결정한다.

#### 5\. 멀티라벨 분류 (Multi-label Classification)

멀티라벨 분류는 한 관측치 x에 대해 라벨이 하나로 끝나지 않고, 여러
라벨이 동시에 참(True)일 수 있는 문제를 다룬다. 따라서
["]{dir="rtl"}클래스들 간 경쟁"을 가정하는 softmax 다중분류와 달리,
멀티라벨에서는 각 라벨에 대해 독립적인 존재 여부를 추정하는 확률모형이
자연스럽다.

##### \(1) 문제 정의: 여러 라벨 동시 예측

라벨 집합이 K개일 때, 멀티라벨의 정답은 하나의 값이 아니라 벡터다.
$\mathbf{Y} = (Y_{1},\ldots,Y_{K}) \in \{ 0,1\}^{K}$, 여기서
$Y_{k} = 1$이면 ["]{dir="rtl"}k번째 라벨이 존재", $Y_{k} = 0$이면
["]{dir="rtl"}없음"을 의미한다.

- 이미지 태깅:{사람, 자동차, 자전거}가 동시에 1 가능
- 문서 분류:{정치, 경제} 동시 분류 가능
- 의학 진단: 다수 질환 공존 가능

목표는 각 라벨에 대해 조건부확률을 추정하는 것이다.
$p_{k}(x) = P(Y_{k} = 1 \mid X = x),k = 1,\ldots,K$

##### \(2) 출력층: 라벨별 sigmoid, 독립 BCE

멀티라벨 신경망은 마지막에 K개의 로짓을 출력한다.
$\mathbf{z} = f_{\theta}(x) = (z_{1},\ldots,z_{K}) \in \mathbb{R}^{K}$.
각 로짓을 sigmoid로 변환해 라벨별 확률을 얻는다.
$p_{k} = \sigma(z_{k}) = \frac{1}{1 + e^{- z_{k}}}$

가장 표준 손실은 라벨별 이진 교차엔트로피(BCE)를 합산한 형태다.

$$\mathcal{L}_{\text{ML}}(\mathbf{y},\mathbf{p}) = - \overset{K}{\sum_{k = 1}}(y_{k}\log p_{k} + (1 - y_{k})\log(1 - p_{k}))$$

이 구성은 ["]{dir="rtl"}각 라벨이 독립적인 베르누이 타깃"이라는 모델링
관점과 대응된다. (현실에서는 라벨 간 상관이 존재해도, 예측 자체는 독립
확률로 두고 표현력은 신경망의 공유 표현이 흡수하는 방식이 실무적으로
많이 쓰인다.)

##### \(3) 임계값 전략: global t vs 라벨별 t_k

멀티라벨의 최종 예측은 라벨별 임계값을 적용해 이진화한다.
${\widehat{y}}_{k} = 1\{ p_{k} \geq t_{k}\}$. 임계값 선택이 성능을 좌우하며, 대표 전략은 두 가지다.

**Global threshold t (전 라벨 공통 임계값) $t_{k} = t\forall k$**

- 장점: 단순, 운영/설명이 쉬움, 튜닝 비용 낮음
- 단점: 라벨별 빈도(희귀도)·오류비용이 다르면 비효율적 (희귀 라벨은 보통
t를 낮춰야 잡히는데, 공통 t는 놓치기 쉬움)

**라벨별 threshold t_k $t_{1},\ldots,t_{K}$ 을 각각 튜닝**

- 장점: 라벨별 불균형/비용/난이도를 반영 가능 → 실무 성능 향상 흔함
- 단점: 관리 복잡도 증가(라벨 수가 많을수록), 데이터가 적으면 과적합 위험

라벨별 $t_{k}$는 보통 검증셋에서 라벨별로 다음 같은 기준으로 고른다.

- F1 최대화: $t_{k} = \arg\max_{t}F1_{k}(t)$
- 제약 기반: ${FPR}_{k}(t) \leq \alpha_{k}$만족하는 최소 t
- 운영량 기반: 라벨 k에 대해 하루 알람 수 상한을 만족하는 t

##### \(4) 평가: micro/macro F1, PR 관점 정리

멀티라벨에서는 ["]{dir="rtl"}정확도"가 의미가 약해지는 경우가 많아, 보통
Precision/Recall/F1을 micro/macro로 요약한다.

먼저 라벨 k별 혼동행렬을 ${TP}_{k},{FP}_{k},{FN}_{k},{TN}_{k}$을
정의하면

라벨 k의 정밀도/재현율/F1은 다음과 같다.
${Precision}_{k} = \frac{{TP}_{k}}{{TP}_{k} + {FP}_{k}},{Recall}_{k} = \frac{{TP}_{k}}{{TP}_{k} + {FN}_{k}}F1_{k} = \frac{2{Precision}_{k}{Recall}_{k}}{{Precision}_{k} + {Recall}_{k}}$

**Micro 평균 (전체 사건을 한데 모아 계산)**

$$\begin{matrix}
{TP}_{\text{micro}} & = \sum_{k}{TP}_{k},{FP}_{\text{micro}} = \sum_{k}{FP}_{k},{FN}_{\text{micro}} = \sum_{k}{FN}_{k} \\
{Precision}_{\text{micro}} & = \frac{\sum_{k}^{}{TP}_{k}}{\sum_{k}({TP}_{k} + {FP}_{k})} \\
{Recall}_{\text{micro}} & = \frac{\sum_{k}^{}{TP}_{k}}{\sum_{k}({TP}_{k} + {FN}_{k})} \\
F1_{\text{micro}} & = \frac{2{Precision}_{\text{micro}}{Recall}_{\text{micro}}}{{Precision}_{\text{micro}} + {Recall}_{\text{micro}}}
\end{matrix}$$

- 특징: 빈도가 큰 라벨(자주 등장)이 지표를 강하게 좌우
- 해석: 시스템 전체에서 ["]{dir="rtl"}맞춘 양성 사건 비율"을 강조

**Macro 평균 (라벨별 점수를 평균)**

$$\begin{array}{r}
{Precision}_{\text{macro}} = \frac{1}{K}\overset{K}{\sum_{k = 1}}{Precision}_{k}, \\
{Recall}_{\text{macro}} = \frac{1}{K}\overset{K}{\sum_{k = 1}}{Recall}_{k},F1_{\text{macro}} = \frac{1}{K}\overset{K}{\sum_{k = 1}}F1_{k}
\end{array}$$

- 특징: 희귀 라벨도 동일 가중치로 반영
- 해석: ["]{dir="rtl"}모든 라벨을 고르게 잘하나?"를 평가

**PR 관점: 불균형에서 핵심**

멀티라벨은 라벨별로 양성 비율이 크게 다르므로, ROC보다
PR(Precision--Recall) 곡선이 더 직접적이다. 라벨별 PR 곡선/라벨별 AP를
산출한 뒤 macro 평균을 내기도 한다. 운영에서는 ["]{dir="rtl"}Recall을
조금 올리려다 FP가 폭증"하는 구간이 흔하므로, PR 곡선으로 임계값
민감도를 확인하는 것이 중요하다

#### 6\. 불균형 데이터와 어려운 샘플 학습

현실의 분류 문제에서는 양성이 희귀한 경우가 많고, 그 희귀한 양성
중에서도 모델이 특히 헷갈리는 샘플(경계 사례, 노이즈 포함)이 존재한다.

이때 성능을 좌우하는 것은 단순히 모델 구조가 아니라, (i) 학습에서 어떤
샘플에 더 큰 학습 신호를 줄 것인가와 (ii) 운영에서 어떤 기준으로 양성을
선언할 것인가(임계값 정책)이다.

불균형 문제는 학습과 운영을 함께 보지 않으면 ["]{dir="rtl"}훈련 성능은
좋아 보이는데 실제 운영 성능은 나쁜" 상황이 쉽게 발생한다.

##### \(1) 클래스 불균형과 오류비용은 다른 문제다

클래스 불균형은 데이터에서 양성 비율이 작은 현상으로,
$\pi = P(Y = 1) \ll 1$처럼 표현된다. 양성이 희귀하면 학습 과정에서
모델이 양성 패턴을 충분히 보지 못해, 양성에 대한 민감도가 떨어지기 쉽다.

반면 오류비용은 데이터 비율과 무관하게 ["]{dir="rtl"}틀렸을 때의 손해"가
비대칭인 상황이다. 예컨대 미탐 비용 $c_{FN}$이 크면 양성을 놓치는 것이
치명적이고, 오경보 비용 $c_{FP}$이 크면 괜히 양성으로 띄우는 것이 더
위험하다.

이 비용 비대칭은 운영 의사결정에서 임계값을 바꾸는 이유가 된다. 비용
기준으로는 $t^{*} = \frac{c_{FP}}{c_{FP} + c_{FN}}$가 자연스러운 선택이
된다. 즉 불균형은 ["]{dir="rtl"}학습 신호의 희소화" 문제이고, 비용
비대칭은 ["]{dir="rtl"}결정 정책" 문제다.

##### \(2) 학습단에서의 대응: 손실을 가중하거나, 데이터를 재구성한다

불균형 대응의 가장 기본은 손실에서 양성의 기여를 키우는 것이다.
이진분류에서 확률 $p = P(Y = 1 \mid x)$에 대한 BCE는
$\mathcal{L}_{BCE} = - (y\log p + (1 - y)\log(1 - p))$인데, 여기에
가중치를 주면
$\mathcal{L} = - (w_{1}y\log p + w_{0}(1 - y)\log(1 - p))$가 된다.

이 방식은 구현이 단순하고 효과가 빠르게 나타나지만, 가중치가 과하면 FP가
늘어나거나 예측 확률이 ["]{dir="rtl"}양성 쪽으로 치우친" 형태가 될 수
있어, 운영 임계값을 다시 맞추는 작업이 거의 항상 필요하다.

다른 축은 샘플링이다. 오버샘플링은 소수 클래스를 더 자주 뽑아 학습
배치에서 양성을 자주 보게 하고, 언더샘플링은 다수 클래스를 줄여 균형을
맞춘다. 오버샘플링은 Recall 개선에 도움이 되지만 반복으로 인한 과적합
위험이 있고, 언더샘플링은 음성의 다양성을 잃어 FP가 늘 수 있다.

특히 샘플링으로 클래스 비율을 바꾸면 학습된 확률이 운영 분포의 확률과
어긋날 수 있으므로, ["]{dir="rtl"}점수의 순위"는 좋아져도
["]{dir="rtl"}확률의 정확도(calibration)"는 나빠질 수 있다는 점을 염두에
둔다.

##### \(3) 어려운 샘플 대응: focal loss와 hard example mining

불균형에서 모델을 힘들게 하는 것은 ["]{dir="rtl"}양성이 적다"는 사실뿐
아니라 ["]{dir="rtl"}학습이 쉬운 음성"이 너무 많아 업데이트가 그쪽으로
쏠리는 현상이다. 이때는 ["]{dir="rtl"}쉬운 샘플의 영향은 줄이고 어려운
샘플에 집중"시키는 설계가 유효하다.

**focal loss**는 정답 확률 $p_{t}$에 대해
$\mathcal{L}_{focal} = - \alpha(1 - p_{t})^{\gamma}\log(p_{t})$로
정의된다. $p_{t} \approx 1$인 쉬운 샘플은 $(1 - p_{t})^{\gamma}$가 매우
작아져 학습 기여가 거의 사라지고, $p_{t}$가 작은 어려운 샘플은
상대적으로 큰 기여를 갖는다. 결과적으로 결정경계 근처의 샘플이 학습을
주도하게 된다.

**hard example mining**은 손실이 큰 샘플을 더 자주 학습에 포함시키거나,
미니배치에서 손실 상위 일부만으로 역전파하는 방식으로 ["]{dir="rtl"}학습
신호를 어려운 사례에 집중"한다. 다만 라벨 노이즈가 있으면, 모델이
["]{dir="rtl"}사실 틀린 라벨"을 어려운 샘플로 착각해 과도하게 끌려갈 수
있어, 정규화나 label smoothing 같은 안정화가 함께 필요해질 수 있다.

##### \(3) 학습단에서의 대응: 임계값 이동과 PR 최적화가 핵심이다

학습단에서 가중치, 샘플링, focal loss를 적용하면 모델의 점수/확률 분포가
바뀌므로, 운영에서 임계값 t를 다시 설계해야 한다.

이진분류의 결정은 $\widehat{y} = 1\{ p(x) \geq t\}$로 표현되며, t를
내리면 Recall은 올라가지만 FP도 늘고, t를 올리면 FP는 줄지만 Recall이
떨어진다. 따라서 ["]{dir="rtl"}기본값 t=0.5"는 불균형 문제에서 거의
최적이 아니다.

불균형에서는 ROC보다 PR 관점이 운영 품질을 더 직접적으로 보여준다. 즉
임계값은 검증셋에서 PR 곡선을 확인하면서, 운영 목적에 맞게 다음 중
하나로 선택하는 것이 일반적이다.

예를 들어 F1(t)를 최대화하는 t를 고르거나,
["]{dir="rtl"}$Recall \geq r$" 같은 제약 하에 Precision을 최대화하거나,
["]{dir="rtl"}검토량 $\leq K$" 같은 리소스 제약을 만족하도록 t를
조정한다. 결국 불균형 대응은 학습 기법만으로 끝나지 않고, 임계값
정책까지 포함한 최적화 문제로 완성된다.
