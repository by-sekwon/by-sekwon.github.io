---
title: "MLDL ë¨¸ì‹ ëŸ¬ë‹ ë¶„ë¥˜ - kNN SVM ì‚¬ë¡€ë¶„ì„ (3ê°œ ì´ìƒ ë²”ì£¼í˜•)"
format: html
---

### ë¨¸ì‹ ëŸ¬ë‹ ë¶„ë¥˜ (k-NN \| SVM) 3ê°œ ì´ìƒ ë²”ì£¼í˜• ë¶„ë¥˜ ì‚¬ë¡€ë¶„ì„

#### 1. ë°ì´í„°

seabornì˜ `penguins` ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì˜¨ ê²°ê³¼, ì „ì²´ ë°ì´í„°ëŠ” 344ê°œ í–‰ê³¼ 7ê°œ ì—´ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ì´ ì¤‘ íƒ€ê¹ƒ(y)ì€ species 1ê°œ ì—´, ì„¤ëª…ë³€ìˆ˜(X)ëŠ” speciesë¥¼ ì œì™¸í•œ 6ê°œ ì—´ë¡œ ë¶„ë¦¬ëœë‹¤. ì¢…(species)ì€ Adelie, Chinstrap, Gentooì˜ 3ê°œ ë²”ì£¼ë¡œ ì´ë£¨ì–´ì§„ ë‹¤ì¤‘ë¶„ë¥˜ ë¬¸ì œì— í•´ë‹¹í•œë‹¤.

ë°ì´í„°ì˜ ë³€ìˆ˜ êµ¬ì„±ì€ ì¢…(species)ê³¼ ì„¬(island), ê·¸ë¦¬ê³  ë¶€ë¦¬ ê¸¸ì´/ê¹Šì´(bill_length_mm, bill_depth_mm), ë‚ ê°œ ê¸¸ì´(flipper_length_mm), ì²´ì¤‘(body_mass_g) ê°™ì€ ì—°ì†í˜• ìˆ˜ì¹˜ ë³€ìˆ˜ì™€ ì„±ë³„(sex) ê°™ì€ ë²”ì£¼í˜• ë³€ìˆ˜ë¡œ ë˜ì–´ ìˆë‹¤. ìë£Œí˜•ì„ ë³´ë©´ ìˆ˜ì¹˜í˜•(float64) ë³€ìˆ˜ê°€ 4ê°œ, ë¬¸ìì—´(object) ë³€ìˆ˜ê°€ 3ê°œë¡œ í˜¼í•©ë˜ì–´ ìˆë‹¤.

ê²°ì¸¡ì¹˜ë„ ì¼ë¶€ ì¡´ì¬í•œë‹¤. ë¶€ë¦¬ ê¸¸ì´, ë¶€ë¦¬ ê¹Šì´, ë‚ ê°œ ê¸¸ì´, ì²´ì¤‘ì€ ê°ê° 342ê°œë§Œ ê´€ì¸¡ë˜ì–´ ìˆì–´ ê° ë³€ìˆ˜ë§ˆë‹¤ 2ê°œì”© ê²°ì¸¡ì¹˜ê°€ ìˆê³ , ì„±ë³„(sex)ì€ 333ê°œë§Œ ê´€ì¸¡ë˜ì–´ 11ê°œì˜ ê²°ì¸¡ì¹˜ê°€ í™•ì¸ëœë‹¤. ë°˜ë©´ ì¢…(species)ê³¼ ì„¬(island)ì€ ëª¨ë“  344ê°œê°€ ê²°ì¸¡ ì—†ì´ ì±„ì›Œì ¸ ìˆë‹¤. ë”°ë¼ì„œ ì´í›„ ëª¨ë¸ë§ì„ ìœ„í•´ì„œëŠ” ê²°ì¸¡ì¹˜ ì²˜ë¦¬(ëŒ€ì¹˜)ì™€ ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©(ì˜ˆ: ì›-í•« ì¸ì½”ë”©), ê·¸ë¦¬ê³  k-NN/SVMì²˜ëŸ¼ ìŠ¤ì¼€ì¼ì— ë¯¼ê°í•œ ëª¨ë¸ì„ ìœ„í•œ í‘œì¤€í™”ê°€ í•„ìš”í•˜ë‹¤.

#### 2. ì „ì²˜ë¦¬

í•´ë‹¹ ì „ì²˜ë¦¬ ê³¼ì •ì€ k-NNê³¼ SVM ëª¨ë¸ì—ì„œ ì„±ëŠ¥ì— í° ì˜í–¥ì„ ì£¼ëŠ” ìŠ¤ì¼€ì¼ë§(í‘œì¤€í™”)ì„ íŒŒì´í”„ë¼ì¸ ì•ˆì— ìë™ìœ¼ë¡œ í¬í•¨í•˜ë„ë¡ êµ¬ì„±ë˜ì–´ ìˆë‹¤. ë˜í•œ ë°ì´í„°ì— ê²°ì¸¡ì¹˜ê°€ ì¡´ì¬í•˜ë”ë¼ë„ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ëŠ” ì ì ˆí•œ ë°©ì‹ìœ¼ë¡œ ëŒ€ì¹˜í•œ ë’¤ í‘œì¤€í™”ë¥¼ ìˆ˜í–‰í•˜ê³ , ë²”ì£¼í˜• ë³€ìˆ˜ëŠ” ì›-í•« ì¸ì½”ë”©ìœ¼ë¡œ ë³€í™˜í•´ ëª¨ë¸ì´ ë°”ë¡œ í•™ìŠµí•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ì²˜ë¦¬í•œë‹¤. 

ì¦‰, ë°ì´í„°ì˜ ëˆ„ë½ê°’ê³¼ ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ ë³„ë„ë¡œ ìˆ˜ì‘ì—… ì²˜ë¦¬í•˜ì§€ ì•Šì•„ë„ ì¼ê´€ëœ ë°©ì‹ìœ¼ë¡œ ì „ì²˜ë¦¬ê°€ ì§„í–‰ë˜ë©°, k-NN/SVMì— í•„ìš”í•œ ì…ë ¥ í˜•íƒœë¥¼ ì•ˆì •ì ìœ¼ë¡œ ë³´ì¥í•œë‹¤.

ì´ ì½”ë“œëŠ” ì „ì²´ ë°ì´í„°ì—ì„œ ì…ë ¥ ë³€ìˆ˜(X)ì™€ ì •ë‹µ ë¼ë²¨(y)ë¥¼ í•™ìŠµìš©ê³¼ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ìœ„í•´ `train_test_split()`ì„ ì‚¬ìš©í•œ ê²ƒì…ë‹ˆë‹¤. ì—¬ê¸°ì„œ `test_size=0.2`ëŠ” ì „ì²´ ë°ì´í„°ì˜ 20%ë¥¼ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë–¼ì–´ ë‚´ê³ , ë‚˜ë¨¸ì§€ 80%ë¥¼ í•™ìŠµ ì„¸íŠ¸ë¡œ ì“°ê² ë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. ì´ë ‡ê²Œ ë¶„ë¦¬í•˜ë©´ ëª¨ë¸ì„ í•™ìŠµí•  ë•ŒëŠ” `X_train, y_train`ë§Œ ì‚¬ìš©í•˜ê³ , í•™ìŠµì— ì“°ì§€ ì•Šì€ ë°ì´í„°ì¸ `X_test, y_test`ë¡œ ì„±ëŠ¥ì„ í‰ê°€í•  ìˆ˜ ìˆì–´ â€œìƒˆ ë°ì´í„°ì—ì„œë„ ì˜ ë§íˆëŠ”ì§€(ì¼ë°˜í™” ì„±ëŠ¥)â€ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

íŠ¹íˆ `stratify=y`ëŠ” ë¶„ë¥˜ ë¬¸ì œì—ì„œ ë§¤ìš° ì¤‘ìš”í•œ ì˜µì…˜ì¸ë°, í•™ìŠµ/í…ŒìŠ¤íŠ¸ë¡œ ë‚˜ëˆŒ ë•Œ ê° í´ë˜ìŠ¤ì˜ ë¹„ìœ¨ì´ ì›ë³¸ ë°ì´í„°ì™€ ìµœëŒ€í•œ ë¹„ìŠ·í•˜ê²Œ ìœ ì§€ë˜ë„ë¡(ì¸µí™” ì¶”ì¶œ) í•´ì¤ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ë°ì´í„°ê°€ ë¶ˆê· í˜•(í•œ í´ë˜ìŠ¤ê°€ í›¨ì”¬ ë§ìŒ)í•œ ê²½ìš°, ì¸µí™” ì—†ì´ ë¬´ì‘ì • ë‚˜ëˆ„ë©´ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— íŠ¹ì • í´ë˜ìŠ¤ê°€ ê±°ì˜ ì—†ê±°ë‚˜ ì•„ì˜ˆ ë¹ ì§€ëŠ” ì¼ì´ ìƒê¸¸ ìˆ˜ ìˆê³ , ê·¸ëŸ¬ë©´ í‰ê°€ ê²°ê³¼ê°€ ì™œê³¡ë˜ê±°ë‚˜ ROC/PR ê°™ì€ ì§€í‘œ ê³„ì‚° ìì²´ê°€ ì–´ë ¤ì›Œì§ˆ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. `stratify=y`ë¥¼ ì£¼ë©´ ì´ëŸ° ìœ„í—˜ì„ í¬ê²Œ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer

# -------------------------------------------------------
# (0) X, y ì¤€ë¹„ (ì˜ˆ: dfì—ì„œ íƒ€ê¹ƒ ë¶„ë¦¬)
# -------------------------------------------------------
# y = df["Class"]  # ë˜ëŠ” df["species"] ë“±
# X = df.drop(columns=["Class"])

# -------------------------------------------------------
# (1) Train/Test split (ë¶„ë¥˜ë©´ stratify ê¶Œì¥)
# -------------------------------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    stratify=y,          # ë¶ˆê· í˜•/ë¶„ë¥˜ì—ì„œ ë§¤ìš° ì¤‘ìš”
    random_state=42
)

# -------------------------------------------------------
# (2) ì»¬ëŸ¼ íƒ€ì… ë¶„ë¦¬
# -------------------------------------------------------
num_cols = X_train.select_dtypes(include=["number"]).columns.tolist()
cat_cols = X_train.select_dtypes(exclude=["number"]).columns.tolist()

# -------------------------------------------------------
# (3) ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
#   - ìˆ˜ì¹˜í˜•: ê²°ì¸¡ì¹˜ ì¤‘ì•™ê°’ ëŒ€ì¹˜ + í‘œì¤€í™”
#   - ë²”ì£¼í˜•: ìµœë¹ˆê°’ ëŒ€ì¹˜ + ì›í•«ì¸ì½”ë”©
# -------------------------------------------------------
numeric_pipe = Pipeline([
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())
])

# sklearn ë²„ì „ì— ë”°ë¼ sparse ì˜µì…˜ëª…ì´ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ try ì²˜ë¦¬
try:
    ohe = OneHotEncoder(handle_unknown="ignore", sparse_output=False)
except TypeError:
    ohe = OneHotEncoder(handle_unknown="ignore", sparse=False)

categorical_pipe = Pipeline([
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("onehot", ohe)
])

preprocess = ColumnTransformer(
    transformers=[
        ("num", numeric_pipe, num_cols),
        ("cat", categorical_pipe, cat_cols),
    ],
    remainder="drop"   # ì•ˆ ì“°ëŠ” ì»¬ëŸ¼ ë²„ë¦´ì§€/ì‚´ë¦´ì§€ ì„ íƒ
)
```

#### 3. ë¨¸ì‹ ëŸ¬ë‹ ë¶„ë¥˜
##### \(1) kNN

**ì‹¤í–‰ì½”ë“œ**

```python
from sklearn.neighbors import KNeighborsClassifier

knn_model = Pipeline([
    ("preprocess", preprocess),
    ("knn", KNeighborsClassifier(
        n_neighbors=15,
        weights="distance",
        p=2
    ))
])

knn_model.fit(X_train, y_train)         # (ì „ì²´í•™ìŠµ ì‹œ)
```

![](images/classification_ml_category_knn.png){fig-align="center" width="40%"}

confusion matrix

```python
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report
import matplotlib.pyplot as plt
import numpy as np

# ì˜ˆì¸¡
y_pred = knn_model.predict(X_test)

# (ë©€í‹°í´ë˜ìŠ¤/ë¬¸ìì—´ ë¼ë²¨ í¬í•¨) ë¼ë²¨ ìˆœì„œ ê³ ì •
labels = knn_model.named_steps["knn"].classes_  # Pipelineì´ë©´ ë§ˆì§€ë§‰ ëª¨ë¸ì˜ classes_

# confusion matrix
cm = confusion_matrix(y_test, y_pred, labels=labels)
print("Confusion matrix:\n", cm)

# (ì„ íƒ) classification report
print("\nClassification report:\n",
      classification_report(y_test, y_pred, labels=labels, target_names=labels.tolist()))

# (ì„ íƒ) ì‹œê°í™”
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)
disp.plot(values_format="d")
plt.show()
```
```text
Confusion matrix:
 [[30  0  0]
 [ 0 14  0]
 [ 0  0 25]]

Classification report:
               precision    recall  f1-score   support

      Adelie       1.00      1.00      1.00        30
   Chinstrap       1.00      1.00      1.00        14
      Gentoo       1.00      1.00      1.00        25

    accuracy                           1.00        69
   macro avg       1.00      1.00      1.00        69
weighted avg       1.00      1.00      1.00        69
```

![](images/classification_ml_category_knnconfusion.png){fig-align="center" width="40%"}

**ì‚¬í›„í™•ë¥  ì¶œë ¥**

```python
#ì‚¬í›„ í™•ë¥  ê³„ì‚°
# (n_samples, n_classes)
proba_knn = knn_model.predict_proba(X_test)

# Pipelineì´ë©´ classes_ëŠ” ë§ˆì§€ë§‰ ëª¨ë¸ì—ì„œ ê°€ì ¸ì˜¤ê¸°
classes_knn = knn_model.named_steps["knn"].classes_

proba_knn_df = pd.DataFrame(proba_knn, columns=classes_knn)
display(proba_knn_df.head())
```
```text
Adelie	Chinstrap	Gentoo
0	1.000000	0.000000	0.0
1	1.000000	0.000000	0.0
2	0.000000	0.000000	1.0
3	0.000000	0.000000	1.0
4	0.053935	0.946065	0.0
```

**ë¶„ë¥˜ ì˜í–¥ë³€ì¸ ì¶œë ¥**

ë‹¤ìŒ ì½”ë“œëŠ” í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ íŠ¹ì • 1ê°œ ìƒ˜í”Œì„ ê³¨ë¼, ê·¸ ìƒ˜í”Œì´ preprocess(ì „ì²˜ë¦¬ê¸°: ê²°ì¸¡ì¹˜ ì²˜ë¦¬/ìŠ¤ì¼€ì¼ë§/ì›í•«ì¸ì½”ë”© ë“±)ë¥¼ ê±°ì¹œ ë’¤ ì–´ë–¤ â€œì „ì²˜ë¦¬ëœ í”¼ì²˜ë“¤â€ë¡œ ë³€í™˜ë˜ëŠ”ì§€ë¥¼ í™•ì¸í•´ì„œ, ê·¸ì¤‘ ì˜í–¥(ê°’ì˜ ì ˆëŒ“ê°’)ì´ í° í”¼ì²˜ Top-kë§Œ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥í•˜ëŠ” ì½”ë“œì´ë‹¤.

```python
# íŠ¹ì • ìƒ˜í”Œì´ ì „ì²˜ë¦¬ í›„ ì–´ë–¤ í”¼ì²˜ë¡œ ë°”ë€ŒëŠ”ì§€ ì¶œë ¥
import pandas as pd
import numpy as np

def show_transformed_features(preprocess, X_row, topk=20):
    Xt = preprocess.transform(X_row)
    feat = preprocess.get_feature_names_out()
    s = pd.Series(Xt.ravel(), index=feat)
    # ê°’ì´ í° ìˆœìœ¼ë¡œ(ì›í•«ì€ 0/1ì´ë¼ topkë¡œ ë³´ë©´ í¸í•¨)
    return s.reindex(s.abs().sort_values(ascending=False).head(topk).index)

i = 0
x0 = X_test.iloc[[i]]
display(show_transformed_features(preprocess, x0, topk=30))
```

ì¶œë ¥ì€ ì „ì²˜ë¦¬(preprocess)ë¥¼ ê±°ì¹œ ë’¤, í…ŒìŠ¤íŠ¸ ë°ì´í„° 0ë²ˆ ìƒ˜í”Œì´ â€œëª¨ë¸ ì…ë ¥ í”¼ì²˜ ë²¡í„°â€ë¡œ ë°”ë€ ê°’ì„ ë³´ì—¬ì¤€ë‹¤. (ì½”ë“œì—ì„œ get_feature_names_out() + preprocess.transform() ê²°ê³¼ë¥¼ Seriesë¡œ ë§Œë“  ê²ƒ)

cat__... (ë²”ì£¼í˜• ì›-í•« ì¸ì½”ë”©) í•´ì„

ì›-í•« ì¸ì½”ë”©ì€ í•´ë‹¹ ë²”ì£¼ë©´ 1, ì•„ë‹ˆë©´ 0ì…ë‹ˆë‹¤.

cat__sex_Male = 1.0 â†’ ì´ ìƒ˜í”Œì˜ ì„±ë³„ì€ Male
<br>
cat__sex_Female = 0.0 â†’ Femaleì´ ì•„ë‹˜
<br>
cat__island_Dream = 1.0 â†’ ì„¬ì€ Dream
<br>
cat__island_Biscoe = 0.0, cat__island_Torgersen = 0.0 â†’ ë‹¤ë¥¸ ì„¬ì´ ì•„ë‹˜
<br>
ì¦‰, â€œDream ì„¬ì˜ ìˆ˜ì»·â€ì´ë¼ëŠ” ëœ»ì´ë‹¤.

num__... (ìˆ˜ì¹˜í˜• í‘œì¤€í™” z-score) í•´ì„

ìˆ˜ì¹˜í˜•ì€ StandardScaler()ê°€ ì ìš©ë˜ì–´ (ê°’ âˆ’ í‰ê· ) / í‘œì¤€í¸ì°¨ í˜•íƒœì˜ í‘œì¤€í™” ì ìˆ˜(z-score) ë¡œ ë³€í™˜ëœë‹¤.
ê·¸ë˜ì„œ ë‹¨ìœ„(mm, g)ê°€ ì‚¬ë¼ì§€ê³ , â€œí›ˆë ¨ ë°ì´í„° í‰ê·  ëŒ€ë¹„ ëª‡ í‘œì¤€í¸ì°¨ ìœ„/ì•„ë˜ì¸ê°€â€ë¡œ í•´ì„ëœë‹¤.

num__bill_depth_mm = 0.663 â†’ ë¶€ë¦¬ ê¹Šì´ê°€ í‰ê· ë³´ë‹¤ 0.66 í‘œì¤€í¸ì°¨ ì •ë„ í¼ (ì¡°ê¸ˆ í° í¸)
<br>
num__bill_length_mm = -0.471 â†’ ë¶€ë¦¬ ê¸¸ì´ê°€ í‰ê· ë³´ë‹¤ 0.47 í‘œì¤€í¸ì°¨ ì •ë„ ì‘ìŒ (ì¡°ê¸ˆ ì‘ì€ í¸)
<br>
num__body_mass_g = -0.262 â†’ ëª¸ë¬´ê²Œê°€ í‰ê· ë³´ë‹¤ 0.26 í‘œì¤€í¸ì°¨ ì •ë„ ì‘ìŒ (ì•½ê°„ ê°€ë²¼ìš´ í¸)
<br>
num__flipper_length_mm = 0.013 â†’ ì§€ëŠëŸ¬ë¯¸ ê¸¸ì´ê°€ ê±°ì˜ í‰ê·  ìˆ˜ì¤€ (í‰ê· ê³¼ ë§¤ìš° ë¹„ìŠ·)

ì´ ê°’ë“¤ì´ ëª¨ë¸ì—ì„œ ì˜ë¯¸í•˜ëŠ” ê²ƒ

k-NN: ì´ ë²¡í„°ë“¤ë¡œ ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ë‹ˆ, ì ˆëŒ“ê°’ì´ í° í•­ëª©(ì˜ˆ: bill_depth 0.66, bill_length -0.47)ì´ ê±°ë¦¬/ì´ì›ƒ ì„ íƒì— ë” ì˜í–¥ì„ ì£¼ê¸° ì‰¬ì›€

```text
cat__sex_Male	1.000000
cat__island_Dream	1.000000
num__bill_depth_mm	0.663008
num__bill_length_mm	-0.470502
num__body_mass_g	-0.262136
num__flipper_length_mm	0.013088
cat__island_Biscoe	0.000000
cat__island_Torgersen	0.000000
cat__sex_Female	0.000000
```
ì´ì›ƒ ê°œì²´ ê±°ë¦¬ ì •ë³´

ë‹¤ìŒ ì½”ë“œëŠ” k-NN ëª¨ë¸ì´ íŠ¹ì • ìƒ˜í”Œ 1ê°œ(`X_row`)ë¥¼ ì–´ë–¤ ê·¼ê±°ë¡œ ë¶„ë¥˜í–ˆëŠ”ì§€ë¥¼ â€œì´ì›ƒ ê¸°ë°˜â€ìœ¼ë¡œ ì„¤ëª…í•˜ê¸° ìœ„í•œ í•¨ìˆ˜ì´ë‹¤. ì…ë ¥ìœ¼ë¡œëŠ” ì „ì²˜ë¦¬+ëª¨ë¸ì´ ë¬¶ì¸ `Pipeline`(`pipeline`), í•™ìŠµ ë°ì´í„° `X_train`, í•™ìŠµ ë¼ë²¨ `y_train`, ì„¤ëª… ëŒ€ìƒ 1í–‰ ë°ì´í„°í”„ë ˆì„ `X_row`, ê·¸ë¦¬ê³  ì´ì›ƒ ìˆ˜ `k`ë¥¼ ë°›ëŠ”ë‹¤.

```python
#kNN ë¶„ë¥˜ ê³¼ì • ì¶œë ¥: â€œì–´ë–¤ ì´ì›ƒë“¤ì´ ê²°ì •í–ˆëŠ”ì§€â€
import numpy as np
import pandas as pd

def explain_knn(pipeline, X_train, y_train, X_row, k=15):
    pre = pipeline.named_steps["preprocess"]
    knn = pipeline.named_steps["knn"]

    Xt_row = pre.transform(X_row)
    dist, ind = knn.kneighbors(Xt_row, n_neighbors=k, return_distance=True)
    dist, ind = dist[0], ind[0]

    neigh = X_train.iloc[ind].copy()
    neigh["y"] = y_train.iloc[ind].to_numpy()
    neigh["distance"] = dist

    # weights="distance"ì¸ ê²½ìš° ê°€ì¤‘ì¹˜(ê±°ë¦¬ì˜ ì—­ìˆ˜)ë¡œ íˆ¬í‘œê°€ ì´ë£¨ì–´ì§
    if getattr(knn, "weights", None) == "distance":
        w = 1.0 / (dist + 1e-12)
    else:
        w = np.ones_like(dist)

    vote = pd.Series(w).groupby(neigh["y"]).sum().sort_values(ascending=False)
    pred = pipeline.predict(X_row)[0]
    proba = pipeline.predict_proba(X_row)[0]
    classes = knn.classes_

    print("pred =", pred)
    print("proba =", dict(zip(classes, proba)))
    print("\n[weighted vote by class]")
    display(vote)

    return neigh.sort_values("distance")

i = 0
x0 = X_test.iloc[[i]]
display(explain_knn(knn_model, X_train, y_train, x0, k=3))
```

ì¶œë ¥ì€ â€œk-NNì´ ì™œ Adelieë¼ê³  ì˜ˆì¸¡í–ˆëŠ”ì§€â€ë¥¼ ì•„ì£¼ ì§ê´€ì ìœ¼ë¡œ ë³´ì—¬ì¤€ë‹¤.

pred = Adelie: k-NNì˜ ìµœì¢… ì˜ˆì¸¡ í´ë˜ìŠ¤ê°€ Adelieë¼ëŠ” ëœ»ì´ë‹¤. kê°œì˜ ì´ì›ƒ(ì˜ˆ: k=15)ì´ ì–´ëŠ í´ë˜ìŠ¤ì— ë” â€œê°€ê¹ê²Œ/ë§ì´â€ ëª°ë ¤ìˆëŠëƒë¡œ ê²°ì •ëœë‹¤.

proba = {'Adelie': 1.0, 'Chinstrap': 0.0, 'Gentoo': 0.0}: predict_probaëŠ” ì´ì›ƒë“¤ì˜ íˆ¬í‘œ ê²°ê³¼ë¥¼ í™•ë¥ ì²˜ëŸ¼ ì •ê·œí™”í•´ì„œ ë³´ì—¬ì¤€ë‹¤.

ì§€ê¸ˆì€ Adelieê°€ 1.0(=100%)ì¸ ê±¸ ë³´ë©´, (ê±°ì˜ í™•ì‹¤í•˜ê²Œ) ì„ íƒëœ kê°œ ì´ì›ƒì´ ì „ë¶€ Adelieì´ê±°ë‚˜ ê±°ë¦¬ ê°€ì¤‘ì¹˜ í•©ì´ Adelie ìª½ì—ë§Œ ëª°ë ¤ ìˆë‹¤ëŠ” ëœ»ì´ë‹¤. ê·¸ë˜ì„œ ëª¨ë¸ì´ â€œì´ ìƒ˜í”Œì€ Adelieì¼ ê°€ëŠ¥ì„±ì´ ë§¤ìš° ë†’ë‹¤â€ê³  íŒë‹¨í•œ ê²ë‹ˆë‹¤.

[weighted vote by class]: weights="distance"ë¥¼ ì“°ë©´, ê° ì´ì›ƒì˜ í‘œ(íˆ¬í‘œ)ê°€ ê°€ê¹Œìš¸ìˆ˜ë¡ ë” í¬ê²Œ ë°˜ì˜ëœë‹¤. ë³´í†µ ê°€ì¤‘ì¹˜ê°€ 1 / distance í˜•íƒœë¡œ ë“¤ì–´ê°„ë‹¤. ê·¸ë˜ì„œ [weighted vote by class]ëŠ” í´ë˜ìŠ¤ë³„ë¡œ ê°€ì¤‘ì¹˜ í•©(=íˆ¬í‘œ ì ìˆ˜ í•©) ì„ ë³´ì—¬ì¤€ë‹¤. ì§€ê¸ˆ ê²°ê³¼ê°€ ì‚¬ì‹¤ìƒ Adelieë¡œë§Œ ì°íŒ ê±´ â€œê°€ê¹Œìš´ ì´ì›ƒë“¤ì´ Adelieë¡œë§Œ êµ¬ì„±â€ë˜ì—ˆìŒì„ ì˜ë¯¸í•œë‹¤.

ì´ í‘œëŠ” ê°€ì¥ ê°€ê¹Œìš´ ì´ì›ƒë“¤ ì¼ë¶€ë¥¼ ë³´ì—¬ì¤€ ê±°ê³ , distanceëŠ” â€œì „ì²˜ë¦¬(í‘œì¤€í™” + ì›í•«)â€ ì´í›„ ê³µê°„ì—ì„œì˜ ê±°ë¦¬ë¼ì„œ ì›ë˜ ë‹¨ìœ„(mm, g) ê·¸ëŒ€ë¡œì˜ ê±°ë¦¬ëŠ” ì•„ë‹ˆë‹¤. ê°€ê¹Œìš´ ì´ì›ƒë“¤ì´ ì „ë¶€ Adelie â†’ ê·¸ë˜ì„œ ì˜ˆì¸¡ë„ Adelieë¡œ ê°•í•˜ê²Œ ì ë¦¼.

```python
pred = Adelie
proba = {'Adelie': np.float64(1.0), 'Chinstrap': np.float64(0.0), 'Gentoo': np.float64(0.0)}

island	bill_length_mm	bill_depth_mm	flipper_length_mm	body_mass_g	sex	y	distance
97	Dream	40.3	18.5	196.0	4350.0	Male	Adelie	0.606939
95	Dream	40.8	18.9	208.0	4300.0	Male	Adelie	0.671009
139	Dream	39.7	17.9	193.0	4250.0	Male	Adelie	0.791762
137	Dream	40.2	20.1	200.0	3975.0	Male	Adelie	0.836881
135	Dream	41.1	17.5	190.0	3900.0	Male	Adelie	0.947113
133	Dream	37.5	18.5	199.0	4475.0	Male	Adelie	0.952186
149	Dream	37.8	18.1	193.0	3750.0	Male	Adelie	0.962429
43	Dream	44.1	19.7	196.0	4400.0	Male	Adelie	0.981460
143	Dream	40.7	17.0	190.0	3725.0	Male	Adelie	1.151793
45	Dream	39.6	18.8	190.0	4600.0	Male	Adelie	1.153475
85	Dream	41.3	20.3	194.0	3550.0	Male	Adelie	1.173729
36	Dream	38.8	20.0	190.0	3950.0	Male	Adelie	1.197918
33	Dream	40.9	18.9	184.0	3900.0	Male	Adelie	1.250992
93	Dream	39.6	18.1	186.0	4450.0	Male	Adelie	1.281267
145	Dream	39.0	18.7	185.0	3650.0	Male	Adelie	1.317596
```

##### \(2) SVM

**ì‹¤í–‰ ì½”ë“œ**

```python
from sklearn.neighbors import KNeighborsClassifier

knn_model = Pipeline([
    ("preprocess", preprocess),
    ("knn", KNeighborsClassifier(
        n_neighbors=15,
        weights="distance",
        p=2
    ))
])

knn_model.fit(X_train, y_train)         # (ì „ì²´í•™ìŠµ ì‹œ)
```

![](images/classification_ml_category_svm.png){fig-align="center" width="40%"}

```python
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# ì˜ˆì¸¡
y_pred_svm = svm_model.predict(X_test)

# âœ… ë¼ë²¨(í´ë˜ìŠ¤ ì´ë¦„) ê°€ì ¸ì˜¤ê¸°: data.target_names ëŒ€ì‹  ì‚¬ìš©
labels = svm_model.named_steps["svm"].classes_   # ì˜ˆ: ['Adelie','Chinstrap','Gentoo']

# í‰ê°€
print("[k-NN] Accuracy:", accuracy_score(y_test, y_pred_svm))

cm = confusion_matrix(y_test, y_pred_svm, labels=labels)
print("[k-NN] Confusion matrix:\n", cm)

print("[k-NN] Classification report:\n",
      classification_report(y_test, y_pred_svm,
                            labels=labels,
                            target_names=labels.tolist()))

# (ì„ íƒ) ë³´ê¸° ì¢‹ê²Œ ê·¸ë¦¼ìœ¼ë¡œ ì¶œë ¥
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)
disp.plot(values_format="d")
plt.show()
```
```text
[k-NN] Accuracy: 0.9855072463768116
[k-NN] Confusion matrix:
 [[29  1  0]
 [ 0 14  0]
 [ 0  0 25]]
[k-NN] Classification report:
               precision    recall  f1-score   support

      Adelie       1.00      0.97      0.98        30
   Chinstrap       0.93      1.00      0.97        14
      Gentoo       1.00      1.00      1.00        25

    accuracy                           0.99        69
   macro avg       0.98      0.99      0.98        69
weighted avg       0.99      0.99      0.99        69
```

![](images/classification_ml_category_svmconfusion.png){fig-align="center" width="40%"}

**ì‚¬í›„í™•ë¥  ì¶œë ¥**

```python
#ì‚¬í›„í™•ë¥  
from sklearn.calibration import CalibratedClassifierCV

# svm_model ìì²´ê°€ Pipelineì´ì–´ë„ ê·¸ëŒ€ë¡œ ê°ìŒ€ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
svm_cal = CalibratedClassifierCV(svm_model, method="sigmoid", cv=5)
svm_cal.fit(X_train, y_train)

proba_svm = svm_cal.predict_proba(X_test)
classes_svm = svm_cal.classes_

proba_svm_df = pd.DataFrame(proba_svm, columns=classes_svm)
display(proba_svm_df.head())
```
```text

Adelie	Chinstrap	Gentoo
0	0.895637	0.077118	0.027245
1	0.944391	0.029562	0.026046
2	0.017208	0.026771	0.956021
3	0.036579	0.002759	0.960662
4	0.122979	0.866984	0.010037
```
**ì„ê³„ê°’ ì¶œë ¥**

POS_LABEL = "Gentoo": ì–‘ì„±, ë‹¤ë¥¸ ë‘ ì¢…ì€ "Adelie" / "Chinstrap" ìŒì„±ìœ¼ë¡œ ë¶„ë¥˜í•˜ëŠ” ROC/PR(AUC/AP) ê³„ì‚°, ì„ê³„ê°’ 3ì¢…(Youden / FPR ì œì•½ / ë¹„ìš©ê¸°ë°˜) ì„ íƒ, ëª¨ë¸ë³„ ë¹„êµí‘œ(DataFrame) ìƒì„±í•œë‹¤.

```python
import numpy as np
import pandas as pd
from sklearn.metrics import roc_curve, auc, average_precision_score, confusion_matrix

# âœ… ë©€í‹°í´ë˜ìŠ¤ì—ì„œ "ì–‘ì„± í´ë˜ìŠ¤" í•˜ë‚˜ë¥¼ ì§€ì • (ì›í•˜ëŠ” ê±¸ë¡œ ë°”ê¾¸ì„¸ìš”)
POS_LABEL = "Gentoo"   # "Adelie" / "Chinstrap" ë„ ê°€ëŠ¥

def _get_classes(model):
    # Pipelineì´ë©´ ë§ˆì§€ë§‰ estimatorì˜ classes_ë¥¼ ê°€ì ¸ì˜¤ë„ë¡ ë³´ê°•
    classes = getattr(model, "classes_", None)
    if classes is None and hasattr(model, "named_steps"):
        last = list(model.named_steps.values())[-1]
        classes = getattr(last, "classes_", None)
    return None if classes is None else np.array(classes)

def get_pos_score(model, X, pos_label):
    classes = _get_classes(model)

    # 1) predict_proba ìš°ì„ 
    if hasattr(model, "predict_proba"):
        proba = model.predict_proba(X)
        proba = np.asarray(proba)
        if proba.ndim == 1:
            return proba
        if classes is None:
            raise ValueError("classes_ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (Pipeline/Estimator í™•ì¸ í•„ìš”)")
        idx = np.where(classes == pos_label)[0]
        if len(idx) == 0:
            raise ValueError(f"pos_label={pos_label} ê°€ classes_ì— ì—†ìŠµë‹ˆë‹¤: {classes}")
        return proba[:, idx[0]]

    # 2) ì—†ìœ¼ë©´ decision_function ì‚¬ìš© (LinearSVCëŠ” ì—¬ê¸°ë¡œ ì˜´)
    if hasattr(model, "decision_function"):
        s = np.asarray(model.decision_function(X))
        if s.ndim == 1:
            return s
        if s.ndim == 2:
            if classes is None:
                raise ValueError("decision_functionì´ 2Dì¸ë° classes_ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            idx = np.where(classes == pos_label)[0]
            if len(idx) == 0:
                raise ValueError(f"pos_label={pos_label} ê°€ classes_ì— ì—†ìŠµë‹ˆë‹¤: {classes}")
            return s[:, idx[0]]

    raise ValueError(f"{type(model)}: predict_proba/decision_function ë‘˜ ë‹¤ ì—†ìŠµë‹ˆë‹¤.")

def metrics_at_threshold(y_true01, score, t):
    y_hat = (score >= t).astype(int)
    cm = confusion_matrix(y_true01, y_hat, labels=[0, 1])
    tn, fp, fn, tp = cm.ravel()

    tpr = tp / (tp + fn) if (tp + fn) else 0.0
    fpr = fp / (fp + tn) if (fp + tn) else 0.0
    prec = tp / (tp + fp) if (tp + fp) else 0.0
    acc = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) else 0.0

    return {
        "t": float(t),
        "tn": int(tn), "fp": int(fp), "fn": int(fn), "tp": int(tp),
        "recall(tpr)": float(tpr),
        "fpr": float(fpr),
        "precision": float(prec),
        "accuracy": float(acc),
    }

def best_thresholds(y_true01, score, alpha=0.001, c_fn=100.0, c_fp=1.0):
    fpr, tpr, thr = roc_curve(y_true01, score)  # y_true01ì€ 0/1ì´ì–´ì•¼ í•¨
    roc_auc = auc(fpr, tpr)
    ap = average_precision_score(y_true01, score)

    finite = np.isfinite(thr)
    thr_fin, fpr_fin, tpr_fin = thr[finite], fpr[finite], tpr[finite]

    # (A) Youden
    J = tpr_fin - fpr_fin
    t_y = float(thr_fin[np.argmax(J)])

    # (B) FPR<=alpha ì¤‘ TPR ìµœëŒ€
    cand = np.where((fpr_fin <= alpha) & (tpr_fin > 0))[0]
    t_f = float(thr_fin[cand[np.argmax(tpr_fin[cand])]]) if len(cand) > 0 else None

    # (C) ë¹„ìš© ê¸°ë°˜
    cand_thr = np.r_[-np.inf, thr_fin, np.inf]
    best_t, best_cost = None, np.inf
    for t in cand_thr:
        m = metrics_at_threshold(y_true01, score, t)
        cost = c_fn * m["fn"] + c_fp * m["fp"]
        if cost < best_cost:
            best_cost, best_t = cost, float(t)

    return {"roc_auc": float(roc_auc), "ap": float(ap),
            "t_youden": t_y, "t_fpr": t_f,
            "t_cost": best_t, "best_cost": float(best_cost)}

def summarize_model(model_name, y_true01, score, alpha=0.001, c_fn=100.0, c_fp=1.0):
    info = best_thresholds(y_true01, score, alpha=alpha, c_fn=c_fn, c_fp=c_fp)
    rows = []

    # Youden
    m = metrics_at_threshold(y_true01, score, info["t_youden"])
    m.update({"model": model_name, "rule": "Youden (TPR-FPR)",
              "roc_auc": info["roc_auc"], "ap": info["ap"],
              "cost": c_fn*m["fn"] + c_fp*m["fp"]})
    rows.append(m)

    # FPR constraint
    if info["t_fpr"] is not None:
        m = metrics_at_threshold(y_true01, score, info["t_fpr"])
        m.update({"model": model_name, "rule": f"FPR <= {alpha}",
                  "roc_auc": info["roc_auc"], "ap": info["ap"],
                  "cost": c_fn*m["fn"] + c_fp*m["fp"]})
        rows.append(m)
    else:
        rows.append({"model": model_name, "rule": f"FPR <= {alpha}", "t": None,
                     "tn": None, "fp": None, "fn": None, "tp": None,
                     "recall(tpr)": None, "fpr": None, "precision": None, "accuracy": None,
                     "roc_auc": info["roc_auc"], "ap": info["ap"], "cost": None})

    # Cost-based
    m = metrics_at_threshold(y_true01, score, info["t_cost"])
    m.update({"model": model_name, "rule": f"Cost (c_fn={c_fn}, c_fp={c_fp})",
              "roc_auc": info["roc_auc"], "ap": info["ap"],
              "cost": info["best_cost"]})
    rows.append(m)

    return rows

# -----------------------------
# âœ… ì‹¤í–‰ë¶€ (ë©€í‹°í´ë˜ìŠ¤ â†’ one-vs-restë¡œ 0/1 ë§Œë“¤ê¸°)
# -----------------------------
y_test_arr = np.asarray(y_test)
y_pos = (y_test_arr == POS_LABEL).astype(int)

# ì–‘ì„±/ìŒì„±ì´ ë‘˜ ë‹¤ ìˆì–´ì•¼ ROC ê³„ì‚° ê°€ëŠ¥
if y_pos.sum() == 0 or y_pos.sum() == len(y_pos):
    raise ValueError(f"y_testì— '{POS_LABEL}' ì–‘ì„±/ìŒì„±ì´ í•œìª½ë§Œ ìˆìŠµë‹ˆë‹¤. POS_LABELì´ë‚˜ splitì„ í™•ì¸í•˜ì„¸ìš”.")

models = {
    "k-NN": knn_model,
    "SVM(LinearSVC)": svm_model,
}

alpha = 0.001
c_fn, c_fp = 100.0, 1.0

rows = []
for name, model in models.items():
    score = get_pos_score(model, X_test, pos_label=POS_LABEL)  # âœ… POS_LABEL ì»¬ëŸ¼ ì ìˆ˜
    rows += summarize_model(name, y_pos, score, alpha=alpha, c_fn=c_fn, c_fp=c_fp)

df_cmp = pd.DataFrame(rows)[
    ["model","rule","t","tn","fp","fn","tp","recall(tpr)","fpr","precision","accuracy","roc_auc","ap","cost"]
].sort_values(["rule","model"]).reset_index(drop=True)

display(df_cmp)
```
**ì™œ k-NN ì ìˆ˜ê°€ 1.0ì´ ìì£¼ ë‚˜ì˜¤ë‚˜?**

ê²°ê³¼ë¥¼ ë³´ë©´ ( tn=44, tp=25, fp=0, fn=0 )ë¥¼ ë³´ë©´, k-NNì˜ POS_LABEL(Gentoo) ì ìˆ˜ê°€ â€œ1.0ì¸ ìƒ˜í”Œ = ì „ë¶€ Gentooâ€, â€œ1.0 ë¯¸ë§Œ = ì „ë¶€ ë¹„-Gentooâ€ë¡œ ì™„ë²½ ë¶„ë¦¬ê°€ ëœ ìƒíƒœì´ë‹¤. ê·¸ë˜ì„œ Youden / FPRâ‰¤0.001 / Cost ê°™ì€ ì„ê³„ê°’ ì„ íƒ ê·œì¹™ì´ ì „ë¶€ â€œê°€ì¥ ë†’ì€ ì„ê³„ê°’â€ ìª½(=1.0)ì„ ê³¨ë¼ë„ ì„±ëŠ¥ì´ ì•ˆ ë–¨ì–´ì ¸ì„œ tê°€ í•­ìƒ 1.0ìœ¼ë¡œ ê³ ì •ë©ë‹ˆë‹¤.

k-NNì˜ predict_probaëŠ” ì´ì›ƒë“¤ì˜ â€œíˆ¬í‘œ ë¹„ìœ¨â€ì´ë¼ì„œ ì´ë¡ ì ìœ¼ë¡œ 0~1 ì‚¬ì´ì˜ ì´ì‚°ê°’ë§Œ ë‚˜ì˜¨ë‹¤. íŠ¹íˆ weights="distance"ì¼ ë•ŒëŠ” ì•„ë˜ ìƒí™©ì—ì„œ í™•ë¥ ì´ ì •í™•íˆ 1.0ì´ ì‰½ê²Œ ë‚˜ì˜¨ë‹¤. ê±°ë¦¬ 0ì¸ ì´ì›ƒ(ì™„ì „íˆ ë™ì¼í•œ ì „ì²˜ë¦¬ ê²°ê³¼) ì´ ì¡´ì¬
â†’ scikit-learnì€ ê±°ë¦¬ 0ì´ë©´ ê·¸ ì´ì›ƒ(ë“¤)ì—ê²Œ ì‚¬ì‹¤ìƒ ëª¨ë“  ê°€ì¤‘ì¹˜ê°€ ëª°ë ¤ì„œ í•œ í´ë˜ìŠ¤ í™•ë¥ ì´ 1.0ì´ ë  ìˆ˜ ìˆë‹¤.

ë˜ëŠ” kê°œ ì´ì›ƒì´ ì „ë¶€ ê°™ì€ í´ë˜ìŠ¤ â†’ ê·¸ í´ë˜ìŠ¤ í™•ë¥ ì´ 1.0. í­ê·„ ë°ì´í„°ì²˜ëŸ¼ í´ë˜ìŠ¤ê°€ ì˜ ë¶„ë¦¬ë˜ê±°ë‚˜, ê²°ì¸¡ì¹˜ ëŒ€ì¹˜/ì›í•«/ìŠ¤ì¼€ì¼ë§ í›„ì— ë™ì¼í•œ íŒ¨í„´ì´ ìƒê¸°ë©´ ì´ëŸ° ì¼ì´ ë” ì˜ ìƒê¹ë‹ˆë‹¤.

```text
	model	rule	t	tn	fp	fn	tp	recall(tpr)	fpr	precision	accuracy	roc_auc	ap	cost
0	SVM(LinearSVC)	Cost (c_fn=100.0, c_fp=1.0)	0.656852	44	0	0	25	1.0	0.0	1.0	1.0	1.0	1.0	0.0
1	k-NN	Cost (c_fn=100.0, c_fp=1.0)	1.000000	44	0	0	25	1.0	0.0	1.0	1.0	1.0	1.0	0.0
2	SVM(LinearSVC)	FPR <= 0.001	0.656852	44	0	0	25	1.0	0.0	1.0	1.0	1.0	1.0	0.0
3	k-NN	FPR <= 0.001	1.000000	44	0	0	25	1.0	0.0	1.0	1.0	1.0	1.0	0.0
4	SVM(LinearSVC)	Youden (TPR-FPR)	0.656852	44	0	0	25	1.0	0.0	1.0	1.0	1.0	1.0	0.0
5	k-NN	Youden (TPR-FPR)	1.000000	44	0	0	25	1.0	0.0	1.0	1.0	1.0	1.0	0.0
```

```python
score_knn = get_pos_score(knn_model, X_test, pos_label=POS_LABEL)
y_pos = (np.asarray(y_test) == POS_LABEL).astype(int)

pos_scores = score_knn[y_pos == 1]
neg_scores = score_knn[y_pos == 0]

print("unique scores (top 20):", np.unique(score_knn)[:20])
print("count(score==1):", np.sum(score_knn == 1.0))
print("pos min:", pos_scores.min(), "neg max:", neg_scores.max())
```
ì§€ê¸ˆ ì¶œë ¥ì€ k-NNì´ Gentoo(POS_LABEL)ë¥¼ ê±°ì˜ ì™„ë²½í•˜ê²Œ ë¶„ë¦¬í•˜ê³  ìˆë‹¤ëŠ” ì‹ í˜¸ì˜ˆìš”.

ì´ ê²°ê³¼ê°€ ì˜ë¯¸í•˜ëŠ” ê²ƒ

unique scores = [0, 0.03668, 0.05069, 1]
â†’ Gentoo í™•ë¥ (p(Gentoo))ì´ ë”± 4ê°€ì§€ ê°’ë§Œ ë‚˜ì˜µë‹ˆë‹¤.

count(score==1): 25
â†’ í…ŒìŠ¤íŠ¸ì—ì„œ p(Gentoo)=1ì¸ ìƒ˜í”Œì´ 25ê°œ.

pos min: 1.0
â†’ ì‹¤ì œ Gentooì¸ ìƒ˜í”Œì€ ì „ë¶€ p(Gentoo)=1 (ìµœì†Œê°€ 1ì´ë‹ˆê¹Œ ì „ë¶€ 1).

neg max: 0.050686...
â†’ Gentooê°€ ì•„ë‹Œ ìƒ˜í”Œ ì¤‘ ê°€ì¥ í° p(Gentoo)ë„ 0.05 ì •ë„.

ì¦‰, í…ŒìŠ¤íŠ¸ì…‹ì—ì„œ

ì–‘ì„±(Gentoo): ì ìˆ˜ = ì „ë¶€ 1

ìŒì„±(ë¹„ Gentoo): ì ìˆ˜ = ìµœëŒ€ 0.0507

ì´ë¼ì„œ **0.0507ê³¼ 1 ì‚¬ì´ì— í° â€œê°„ê²©(gap)â€**ì´ ìƒê¹ë‹ˆë‹¤.
ê·¸ë˜ì„œ ì„ê³„ê°’ì„ të¡œ ì¡ì„ ë•Œ 0.0507 < t â‰¤ 1 ì•„ë¬´ê±°ë‚˜ ì„ íƒí•´ë„ TPR=1, FPR=0 (ì™„ë²½ ë¶„ë¥˜)ê°€ ë©ë‹ˆë‹¤.
ì´ëŸ° ê²½ìš° ROC/AUC, ì„ê³„ê°’ íƒìƒ‰ì´ â€œì´ìƒí•˜ê²Œ ì‰¬ì›Œ ë³´ì´ê±°ë‚˜â€ ê°’ì´ ë­‰ì³ ë³´ì´ëŠ” ê²Œ ì •ìƒì´ì—ìš”.

ì™œ ì ìˆ˜ê°€ ì´ë ‡ê²Œ â€œì´ì‚°ì (ëª‡ ê°œ ê°’ë§Œ)â€ì¼ê¹Œ?

k-NNì˜ í™•ë¥ ì€ ë³¸ì§ˆì ìœ¼ë¡œ **ì´ì›ƒë“¤ì˜ íˆ¬í‘œ(ê°€ì¤‘ì¹˜ í•© / ì „ì²´ ê°€ì¤‘ì¹˜ í•©)**ë¼ì„œ,

ë°ì´í„°ê°€ ì˜ ë¶„ë¦¬ë˜ì–´ ìˆìœ¼ë©´ ë§ì€ ì ë“¤ì´ ì´ì›ƒì´ ì „ë¶€ Gentoo â†’ í™•ë¥  1,

í˜¹ì€ Gentoo ì´ì›ƒì´ ì•„ì˜ˆ ì—†ìŒ â†’ í™•ë¥  0,

ê²½ê³„ ê·¼ì²˜ ì¼ë¶€ë§Œ â€œì¡°ê¸ˆ ì„ì—¬â€ì„œ 0.03~0.05 ê°™ì€ ê°’ì´ ë‚˜ì˜µë‹ˆë‹¤.

(íŠ¹íˆ í­ê·„ ë°ì´í„°ëŠ” Gentooê°€ ëª‡ ê°œ ìˆ˜ì¹˜ íŠ¹ì„±ì—ì„œ ê½¤ ê¹”ë”í•˜ê²Œ êµ¬ë¶„ë˜ëŠ” í¸ì´ë¼ ì´ëŸ° íŒ¨í„´ì´ ìì£¼ ë‚˜ì˜µë‹ˆë‹¤.)

```text
unique scores (top 20): [0.         0.03668167 0.05068641 1.        ]
count(score==1): 25
pos min: 1.0 neg max: 0.0506864093164956
```

#### 4. íŠ¸ë¦¬ê¸°ë°˜ ë¶„ë¥˜

##### \(1) logit/tree/rf/gb ëª¨ë¸ í•™ìŠµ

```python
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier

# Logit
logit_model = Pipeline([
    ("preprocess", preprocess),
    ("logit", LogisticRegression(max_iter=2000))
])
logit_model.fit(X_train, y_train)

# Tree
tree_model = Pipeline([
    ("preprocess", preprocess),
    ("tree", DecisionTreeClassifier(random_state=42))
])
tree_model.fit(X_train, y_train)

# RandomForest
rf_model = Pipeline([
    ("preprocess", preprocess),
    ("rf", RandomForestClassifier(
        n_estimators=300, random_state=42
    ))
])
rf_model.fit(X_train, y_train)

# GradientBoosting
gb_model = Pipeline([
    ("preprocess", preprocess),
    ("gb", GradientBoostingClassifier(random_state=42))
])
gb_model.fit(X_train, y_train)
```

![](images/classification_ml_category_treebase.png){fig-align="center" width="40%"}

**ëª¨ë¸í‰ê°€ ë° ì„ê³„ê°’ t ê²°ì •**

```python
import numpy as np
import pandas as pd
from sklearn.metrics import roc_curve, auc, average_precision_score, confusion_matrix

def _get_classes(model):
    # 1) ì¼ë°˜ estimator
    if hasattr(model, "classes_"):
        return np.array(model.classes_)
    # 2) Pipelineì´ë©´ ë§ˆì§€ë§‰ stepì—ì„œ classes_
    if hasattr(model, "named_steps"):
        last = list(model.named_steps.values())[-1]
        if hasattr(last, "classes_"):
            return np.array(last.classes_)
    return None

def get_pos_score(model, X, pos_label=1):
    # 1) predict_proba ìš°ì„ 
    if hasattr(model, "predict_proba"):
        proba = np.asarray(model.predict_proba(X))
        if proba.ndim == 1:
            return proba
        classes = _get_classes(model)
        if classes is None:
            raise ValueError("classes_ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (Pipeline/Estimator í™•ì¸ í•„ìš”)")
        idx = np.where(classes == pos_label)[0]
        if len(idx) == 0:
            raise ValueError(f"pos_label={pos_label} ê°€ classes_ì— ì—†ìŠµë‹ˆë‹¤: {classes}")
        return proba[:, idx[0]]

    # 2) ì—†ìœ¼ë©´ decision_function (LinearSVC ë“±)
    if hasattr(model, "decision_function"):
        s = np.asarray(model.decision_function(X))
        if s.ndim == 1:
            return s.ravel()
        classes = _get_classes(model)
        if classes is None:
            raise ValueError("decision_functionì´ 2Dì¸ë° classes_ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        idx = np.where(classes == pos_label)[0]
        if len(idx) == 0:
            raise ValueError(f"pos_label={pos_label} ê°€ classes_ì— ì—†ìŠµë‹ˆë‹¤: {classes}")
        return s[:, idx[0]]

    raise ValueError(f"{type(model)}: predict_proba/decision_function ë‘˜ ë‹¤ ì—†ìŒ")

def metrics_at_threshold(y_true01, score, t):
    y_hat = (score >= t).astype(int)
    cm = confusion_matrix(y_true01, y_hat, labels=[0, 1])  # âœ… í•­ìƒ 2x2 ë³´ì¥
    tn, fp, fn, tp = cm.ravel()

    tpr = tp / (tp + fn) if (tp + fn) else 0.0
    fpr = fp / (fp + tn) if (fp + tn) else 0.0
    prec = tp / (tp + fp) if (tp + fp) else 0.0
    acc = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) else 0.0
    return {"t": float(t), "tn": int(tn), "fp": int(fp), "fn": int(fn), "tp": int(tp),
            "recall(tpr)": float(tpr), "fpr": float(fpr), "precision": float(prec), "accuracy": float(acc)}

def best_thresholds(y_true01, score, alpha=0.001, c_fn=100.0, c_fp=1.0):
    # âœ… ROC ê³„ì‚° ê°€ëŠ¥ ì—¬ë¶€ ì²´í¬ (í•œ í´ë˜ìŠ¤ë§Œ ìˆìœ¼ë©´ roc_curveê°€ ì—ëŸ¬)
    y_true01 = np.asarray(y_true01).astype(int)
    if y_true01.sum() == 0 or y_true01.sum() == len(y_true01):
        raise ValueError("y_true01ì— 0/1ì´ ë‘˜ ë‹¤ ìˆì–´ì•¼ ROC ê³„ì‚°ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. split/ë°ì´í„° í™•ì¸!")

    fpr, tpr, thr = roc_curve(y_true01, score)
    roc_auc = auc(fpr, tpr)
    ap = average_precision_score(y_true01, score)

    finite = np.isfinite(thr)
    thr_fin, fpr_fin, tpr_fin = thr[finite], fpr[finite], tpr[finite]

    # (A) Youden
    J = tpr_fin - fpr_fin
    t_y = float(thr_fin[np.argmax(J)])

    # (B) FPR<=alpha ì¤‘ TPR ìµœëŒ€
    cand = np.where((fpr_fin <= alpha) & (tpr_fin > 0))[0]
    t_f = float(thr_fin[cand[np.argmax(tpr_fin[cand])]]) if len(cand) > 0 else None

    # (C) ë¹„ìš© ê¸°ë°˜
    cand_thr = np.r_[-np.inf, thr_fin, np.inf]
    best_t, best_cost = None, np.inf
    for t in cand_thr:
        m = metrics_at_threshold(y_true01, score, t)
        cost = c_fn * m["fn"] + c_fp * m["fp"]
        if cost < best_cost:
            best_cost, best_t = cost, float(t)

    return {"roc_auc": float(roc_auc), "ap": float(ap),
            "t_youden": t_y, "t_fpr": t_f, "t_cost": best_t,
            "best_cost": float(best_cost)}

def summarize_model(model_name, y_true01, score, alpha=0.001, c_fn=100.0, c_fp=1.0):
    info = best_thresholds(y_true01, score, alpha=alpha, c_fn=c_fn, c_fp=c_fp)
    rows = []

    m = metrics_at_threshold(y_true01, score, info["t_youden"])
    m.update({"model": model_name, "rule": "Youden (TPR-FPR)",
              "roc_auc": info["roc_auc"], "ap": info["ap"],
              "cost": c_fn*m["fn"] + c_fp*m["fp"]})
    rows.append(m)

    if info["t_fpr"] is not None:
        m = metrics_at_threshold(y_true01, score, info["t_fpr"])
        m.update({"model": model_name, "rule": f"FPR <= {alpha}",
                  "roc_auc": info["roc_auc"], "ap": info["ap"],
                  "cost": c_fn*m["fn"] + c_fp*m["fp"]})
        rows.append(m)
    else:
        rows.append({"model": model_name, "rule": f"FPR <= {alpha}", "t": None,
                     "tn": None, "fp": None, "fn": None, "tp": None,
                     "recall(tpr)": None, "fpr": None, "precision": None, "accuracy": None,
                     "roc_auc": info["roc_auc"], "ap": info["ap"], "cost": None})

    m = metrics_at_threshold(y_true01, score, info["t_cost"])
    m.update({"model": model_name, "rule": f"Cost (c_fn={c_fn}, c_fp={c_fp})",
              "roc_auc": info["roc_auc"], "ap": info["ap"], "cost": info["best_cost"]})
    rows.append(m)

    return rows
```

```python
# âœ… ì–‘ì„±ìœ¼ë¡œ ë³¼ í´ë˜ìŠ¤ ì§€ì • (ì›í•˜ëŠ” ê±¸ë¡œ ë°”ê¾¸ì„¸ìš”)
POS_LABEL = "Gentoo"   # "Adelie" / "Chinstrap" ë„ ê°€ëŠ¥

# âœ… y_test(ë¬¸ìì—´) -> 0/1ë¡œ ë³€í™˜
y_pos = (np.asarray(y_test) == POS_LABEL).astype(int)

models = {
    "k-NN": knn_model,
    "SVM(Linear+Calib)": svm_cal,   # í™•ë¥  ì“°ë ¤ë©´ calibration ë²„ì „
    "Logit": logit_model,
    "Tree": tree_model,
    "RandomForest": rf_model,
    "GradientBoosting": gb_model
}

alpha = 0.001
c_fn, c_fp = 100.0, 1.0

rows = []
for name, model in models.items():
    # âœ… pos_labelì„ 1ì´ ì•„ë‹ˆë¼ POS_LABEL(ë¬¸ìì—´)ë¡œ!
    score = get_pos_score(model, X_test, pos_label=POS_LABEL)
    rows += summarize_model(name, y_pos, score, alpha=alpha, c_fn=c_fn, c_fp=c_fp)

df_cmp = pd.DataFrame(rows)[
    ["model","rule","t","tn","fp","fn","tp","recall(tpr)","fpr","precision","accuracy","roc_auc","ap","cost"]
].sort_values(["rule","model"]).reset_index(drop=True)

display(df_cmp)

df_t = df_cmp.pivot(index="model", columns="rule", values="t")
```
```text

model	rule	t	tn	fp	fn	tp	recall(tpr)	fpr	precision	accuracy	roc_auc	ap	cost
0	GradientBoosting	Cost (c_fn=100.0, c_fp=1.0)	0.999803	44	0	0	25	1.0	0.0	1.0	1.0	1.0	1.0	0.0
1	Logit	Cost (c_fn=100.0, c_fp=1.0)	0.930046	44	0	0	25	1.0	0.0	1.0	1.0	1.0	1.0	0.0
2	RandomForest	Cost (c_fn=100.0, c_fp=1.0)	0.746667	44	0	0	25	1.0	0.0	1.0	1.0	1.0	1.0	0.0
3	SVM(Linear+Calib)	Cost (c_fn=100.0, c_fp=1.0)	0.635238	44	0	0	25	1.0	0.0	1.0	1.0	1.0	1.0	0.0
4	Tree	Cost (c_fn=100.0, c_fp=1.0)	1.000000	44	0	0	25	1.0	0.0	1.0	1.0	1.0	1.0	0.0
5	k-NN	Cost (c_fn=100.0, c_fp=1.0)	1.000000	44	0	0	25	1.0	0.0	1.0	1.0	1.0	1.0	0.0
6	GradientBoosting	FPR <= 0.001	0.999803	44	0	0	25	1.0	0.0	1.0	1.0	1.0	1.0	0.0
7	Logit	FPR <= 0.001	0.930046	44	0	0	25	1.0	0.0	1.0	1.0	1.0	1.0	0.0
8	RandomForest	FPR <= 0.001	0.746667	44	0	0	25	1.0	0.0	1.0	1.0	1.0	1.0	0.0
9	SVM(Linear+Calib)	FPR <= 0.001	0.635238	44	0	0	25	1.0	0.0	1.0	1.0	1.0	1.0	0.0
10	Tree	FPR <= 0.001	1.000000	44	0	0	25	1.0	0.0	1.0	1.0	1.0	1.0	0.0
11	k-NN	FPR <= 0.001	1.000000	44	0	0	25	1.0	0.0	1.0	1.0	1.0	1.0	0.0
12	GradientBoosting	Youden (TPR-FPR)	0.999803	44	0	0	25	1.0	0.0	1.0	1.0	1.0	1.0	0.0
13	Logit	Youden (TPR-FPR)	0.930046	44	0	0	25	1.0	0.0	1.0	1.0	1.0	1.0	0.0
14	RandomForest	Youden (TPR-FPR)	0.746667	44	0	0	25	1.0	0.0	1.0	1.0	1.0	1.0	0.0
15	SVM(Linear+Calib)	Youden (TPR-FPR)	0.635238	44	0	0	25	1.0	0.0	1.0	1.0	1.0	1.0	0.0
16	Tree	Youden (TPR-FPR)	1.000000	44	0	0	25	1.0	0.0	1.0	1.0	1.0	1.0	0.0
17	k-NN	Youden (TPR-FPR)	1.000000	44	0	0	25	1.0	0.0	1.0	1.0	1.0	1.0	0.0
```

##### \(2) ë‹¤í•­ë¡œì§“

**í˜¼ë™í–‰ë ¬ ì¶œë ¥**

```python
#í˜¼ë™í–‰ë ¬ ì¶œë ¥
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# ì˜ˆì¸¡
y_pred_logit = logit_model.predict(X_test)

# âœ… ë¼ë²¨(í´ë˜ìŠ¤ ì´ë¦„) ê°€ì ¸ì˜¤ê¸°: data.target_names ëŒ€ì‹  ì‚¬ìš©
labels = logit_model.named_steps["logit"].classes_   # ì˜ˆ: ['Adelie','Chinstrap','Gentoo']

# í‰ê°€
print("[logit]] Accuracy:", accuracy_score(y_test, y_pred_logit))

cm = confusion_matrix(y_test, y_pred_logit, labels=labels)
print("[logit] Confusion matrix:\n", cm)

print("[logi] Classification report:\n",
      classification_report(y_test, y_pred_logit,
                            labels=labels,
                            target_names=labels.tolist()))
```
```text
[logit]] Accuracy: 1.0
[logit] Confusion matrix:
 [[30  0  0]
 [ 0 14  0]
 [ 0  0 25]]
[logi] Classification report:
               precision    recall  f1-score   support

      Adelie       1.00      1.00      1.00        30
   Chinstrap       1.00      1.00      1.00        14
      Gentoo       1.00      1.00      1.00        25

    accuracy                           1.00        69
   macro avg       1.00      1.00      1.00        69
weighted avg       1.00      1.00      1.00        69
```

**ì‚¬í›„í™•ë¥  ë° íšŒê·€ê³„ìˆ˜ ì¶œë ¥**

```python
#ì‚¬í›„í™•ë¥  ì¶œë ¥ ë° íšŒê·€ê³„ìˆ˜

import numpy as np
import pandas as pd

# ===== 1) ì‚¬í›„í™•ë¥ (Posterior probabilities) =====
proba = logit_model.predict_proba(X_test)  # (n_samples, n_classes)
classes = logit_model.named_steps["logit"].classes_
proba_df = pd.DataFrame(proba, columns=classes)
display(proba_df.head())

# íŠ¹ì • í´ë˜ìŠ¤(ì˜ˆ: POS_LABEL) í™•ë¥ ë§Œ ë³´ê³  ì‹¶ìœ¼ë©´:
POS_LABEL = "Gentoo"
pos_proba = proba_df[POS_LABEL]
display(pos_proba.head())

# ===== 2) íšŒê·€ê³„ìˆ˜(coef) + ì ˆí¸(intercept) =====
logit = logit_model.named_steps["logit"]
pre  = logit_model.named_steps["preprocess"]

# ì „ì²˜ë¦¬ í›„ feature ì´ë¦„ ë½‘ê¸° (sklearn ìµœì‹  ë²„ì „ ê¸°ì¤€)
feat_names = pre.get_feature_names_out()

coef = logit.coef_               # (n_classes, n_features) ë˜ëŠ” (1, n_features)
intercept = logit.intercept_     # (n_classes,) ë˜ëŠ” (1,)

coef_df = pd.DataFrame(coef, columns=feat_names, index=classes)
intercept_s = pd.Series(intercept, index=classes, name="intercept")

display(intercept_s)
display(coef_df.iloc[:, :10].head())  # ì¼ë¶€ë§Œ ë¯¸ë¦¬ë³´ê¸°

# ê° í´ë˜ìŠ¤ë³„ë¡œ |ê³„ìˆ˜| í° ìƒìœ„ 15ê°œ ë³´ê¸°
topk = 15
for c in classes:
    s = coef_df.loc[c].sort_values(key=lambda x: np.abs(x), ascending=False).head(topk)
    print(f"\n=== Top {topk} coefficients for class: {c} ===")
    display(s)
```

í‘œì— ë‚˜ì˜¨ ê°’(ì˜ˆ: 0ë²ˆ ê°œì²´: Adelie 0.918, Chinstrap 0.069, Gentoo 0.012)ì€ ê·¸ ê°œì²´ê°€ ê° ì¢…ì¼ â€˜í™•ë¥ â€™(ëª¨ë¸ì˜ ì¶”ì • í™•ë¥ )ì´ë‹¤. ì¦‰ 0ë²ˆì€ Adelieì¼ ê°€ëŠ¥ì„±ì´ ì•½ 91.8%ë¡œ ê°€ì¥ í¬ë¯€ë¡œ ìµœì¢… ë¶„ë¥˜ëŠ” Adelieë¡œ ë¶„ë¥˜ëœë‹¤.

ì´ëŸ° ì‹ìœ¼ë¡œ ì‚¬í›„í™•ë¥ ì€ â€œë§í˜”ë‹¤/í‹€ë ¸ë‹¤â€ë¥¼ ë„˜ì–´ì„œ, ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ í™•ì‹ í•˜ëŠ”ì§€(ë¶ˆí™•ì‹¤ì„±)ê¹Œì§€ ë³´ì—¬ì£¼ê³ , í™•ë¥ ì´ í•œ í´ë˜ìŠ¤ì— ì ë¦¬ë©´(0.95 ì´ìƒ ë“±) íŒì •ì´ ë§¤ìš° ê²¬ê³ í•˜ê³ , ì„¸ ê°’ì´ ë¹„ìŠ·í•˜ë©´ ê²½ê³„ ì‚¬ë¡€(ì• ë§¤í•œ ê°œì²´)ì´ë‹¤.

```text
Adelie	Chinstrap	Gentoo
0	0.918290	0.069404	0.012307
1	0.988199	0.008662	0.003139
2	0.001760	0.008249	0.989991
3	0.000773	0.000746	0.998481
4	0.036945	0.962263	0.000792

Gentoo
0	0.012307
1	0.003139
2	0.989991
3	0.998481
4	0.000792
```
ë‹¤í•­ ë¡œì§“ì€ ê° í´ë˜ìŠ¤ $Î·_kâ€‹(x)=Î±kâ€‹+xâŠ¤Î²_kâ€‹$ ë¥¼ ë§Œë“  ë’¤, softmaxë¡œ í™•ë¥ , $P(Y=kâˆ£x)=\frac{exp(Î·kâ€‹)-max_j n_j}{âˆ‘_jâ€‹ exp(Î·jâ€‹ - max_j n_j)}$â€‹ ê³„ì‚°í•œë‹¤.

ë”°ë¼ì„œ ê³„ìˆ˜ $\beta_k$ ëŠ” ë³€ìˆ˜ xê°€ ì»¤ì§ˆ ë•Œ í´ë˜ìŠ¤ kì˜ ì ìˆ˜(ë¡œê·¸ì˜¤ì¦ˆ)ê°€ ì–¼ë§ˆë‚˜ ì¦ê°€/ê°ì†Œí•˜ëŠ”ì§€ë¥¼ ëœ»í•œë‹¤. ê³„ìˆ˜ ì–‘(+): ê·¸ ë³€ìˆ˜ê°€ ì¦ê°€í• ìˆ˜ë¡ ê·¸ í´ë˜ìŠ¤ì¼ ê°€ëŠ¥ì„±ì´ ì»¤ì§€ëŠ” ë°©í–¥ìœ¼ë¡œ ê³„ìˆ˜ ìŒ(-): ê·¸ ë³€ìˆ˜ê°€ ì¦ê°€í• ìˆ˜ë¡ ê·¸ í´ë˜ìŠ¤ì¼ ê°€ëŠ¥ì„±ì´ ì‘ì•„ì§€ëŠ” ë°©í–¥ì´ë‹¤. í¬ê¸°(ì ˆëŒ€ê°’)ê°€ í´ìˆ˜ë¡ ì˜í–¥ì´ í¬ë‹¤.

ì§€ê¸ˆ ì¶œë ¥ëœ ë³€ìˆ˜ë“¤ì€ num__...ëŠ” í‘œì¤€í™”(í‰ê· 0, í‘œì¤€í¸ì°¨1) ëœ ê°’ì´ë¼, â€œ1 ì¦ê°€â€ëŠ” ì› ë‹¨ìœ„ 1mmê°€ ì•„ë‹ˆë¼ 1í‘œì¤€í¸ì°¨ ì¦ê°€ì´ë‹¤. ê·¸ë¦¬ê³  ë²”ì£¼í˜•(ì„¬/ì„±ë³„)ì€ ì›í•«ì´ë¯€ë¡œ ê³„ìˆ˜ëŠ” â€œê·¸ ë²”ì£¼ì¼ ë•Œ(1ì¼ ë•Œ) vs ì•„ë‹ ë•Œ(0ì¼ ë•Œ)â€ì˜ íš¨ê³¼ì´ë‹¤.

**Adelie í´ë˜ìŠ¤**

bill_length_mm ê³„ìˆ˜ -2.344 (í° ìŒìˆ˜): ë¶€ë¦¬ ê¸¸ì´ê°€(í‘œì¤€í™” ê¸°ì¤€ìœ¼ë¡œ) ê¸¸ì–´ì§ˆìˆ˜ë¡ Adelieì¼ ê°€ëŠ¥ì„±ì€ ëšœë ·í•˜ê²Œ ê°ì†Œí•œë‹¤. ì¦‰, ì§§ì€ ë¶€ë¦¬ê°€ Adelie ìª½ìœ¼ë¡œ ê°•í•˜ê²Œ ì‘ìš©í•œë‹¤.

bill_depth_mm ê³„ìˆ˜ +0.991 (ì–‘ìˆ˜): ë¶€ë¦¬ ê¹Šì´ê°€ ê¹Šì–´ì§ˆìˆ˜ë¡ Adelieì¼ í™•ë¥ ì´ ì¦ê°€í•œë‹¤. (ê¹Šì€ ë¶€ë¦¬ â†’ Adelie ìª½)

island_Torgersen ê³„ìˆ˜ +0.649 (ì–‘ìˆ˜): ì„œì‹ì§€ê°€ Torgersenì´ë©´ Adelieì¼ ê°€ëŠ¥ì„±ì´ ìƒëŒ€ì ìœ¼ë¡œ ë†’ì•„ì§„ë‹¤.

flipper_length_mm ê³„ìˆ˜ -0.572 (ìŒìˆ˜): ë‚ ê°œ(í”Œë¦¬í¼) ê¸¸ì´ê°€ ê¸¸ìˆ˜ë¡ Adelieì¼ ê°€ëŠ¥ì„±ì€ ê°ì†Œí•œë‹¤. ì¦‰, í”Œë¦¬í¼ê°€ ìƒëŒ€ì ìœ¼ë¡œ ì§§ì€ ê°œì²´ê°€ Adelie ì¼ ê°€ëŠ¥ì„± ë†’ë‹¤.

island_Dream ê³„ìˆ˜ -0.548 (ìŒìˆ˜): Dream ì„¬ì´ë©´ Adelie í™•ë¥ ì€ ë‚®ì•„ì§€ëŠ” ë°©í–¥ì´ë‹¤.

sex_Male +0.468 / sex_Female -0.462
ë‚¨ì„±(ìˆ˜ì»·) í‘œì‹œëŠ” Adelie ìª½ìœ¼ë¡œ ì•½ê°„ ë°€ê³ , ì•”ì»·ì€ ë°˜ëŒ€ ë°©í–¥ì´ì§€ë§Œ, ì´ ì„±ë³„ íš¨ê³¼ëŠ” ë¶€ë¦¬/í”Œë¦¬í¼ ë³€ìˆ˜ë“¤ì— ë¹„í•´ â€œê²°ì •íƒ€â€ë¼ê¸°ë³´ë‹¤ëŠ” ë³´ì¡°ì ì…ë‹ˆë‹¤.

ğŸ‘‰ ìš”ì•½í•˜ë©´, ì´ ëª¨ë¸ì—ì„œ AdelieëŠ” â€œì§§ì€ ë¶€ë¦¬ ê¸¸ì´ + ê¹Šì€ ë¶€ë¦¬ + ì§§ì€ í”Œë¦¬í¼ + (Torgersen)â€ì˜ ì¡°í•©ìœ¼ë¡œ ì„¤ëª…ëœë‹¤.

**ë‹¤ë¥¸ 2ì¢…ì— ëŒ€í•´ì„œë„ ë™ì¼í•œ í•´ì„ì´ ê°€ëŠ¥í•˜ë‹¤.** ì´ ë‹¤í•­ ë¡œì§“ ëª¨ë¸ì€ í­ê·„ ì¢…ì„ êµ¬ë¶„í•  ë•Œ, ë¶€ë¦¬ ê¸¸ì´/ê¹Šì´ì™€ í”Œë¦¬í¼ ê¸¸ì´, ì²´ì¤‘, ê·¸ë¦¬ê³  ì„¬(island) ì •ë³´ê°€ í•µì‹¬ ê²°ì •ìš”ì¸ìœ¼ë¡œ ì‘ë™í•œë‹¤. 

AdelieëŠ” ìƒëŒ€ì ìœ¼ë¡œ ì§§ì€ ë¶€ë¦¬ ê¸¸ì´ì™€ ê¹Šì€ ë¶€ë¦¬, ì§§ì€ í”Œë¦¬í¼(íŠ¹íˆ Torgersen) íŠ¹ì§•ì„ ë³´ì´ë©°, Chinstrapì€ ê¸´ ë¶€ë¦¬ì™€ Dream ì„¬, ë¹„êµì  ê°€ë²¼ìš´ ì²´ì¤‘ì´ íŠ¹ì§•ì ì´ë‹¤. GentooëŠ” Biscoe ì„¬ì— ìˆì„ ë•Œ í™•ë¥ ì´ í¬ê²Œ ì¦ê°€í•˜ê³ , ê¸´ í”Œë¦¬í¼ì™€ í° ì²´ì¤‘ì´ Gentoo ìª½ìœ¼ë¡œ ê°•í•˜ê²Œ ì‘ë™í•˜ëŠ” ë°˜ë©´, ë¶€ë¦¬ ê¹Šì´ëŠ” Gentooì— ë¶ˆë¦¬í•˜ê²Œ(ì–•ì„ìˆ˜ë¡ Gentoo ìœ ë¦¬) ì‘ë™í•œë‹¤. 

```text
dtype: float64
intercept
Adelie	0.626198
Chinstrap	-0.487019
Gentoo	-0.139179

num__bill_length_mm	num__bill_depth_mm	num__flipper_length_mm	num__body_mass_g	cat__island_Biscoe	cat__island_Dream	cat__island_Torgersen	cat__sex_Female	cat__sex_Male
Adelie	-2.344400	0.990900	-0.571682	0.00089	-0.094988	-0.548209	0.649429	-0.461786	0.468019
Chinstrap	1.882937	0.344919	-0.287865	-0.74111	-0.770085	1.189199	-0.421828	0.516992	-0.519705
Gentoo	0.461463	-1.335819	0.859546	0.74022	0.865073	-0.640990	-0.227602	-0.055206	0.051687

=== Top 15 coefficients for class: Adelie ===
Adelie
num__bill_length_mm	-2.344400
num__bill_depth_mm	0.990900
cat__island_Torgersen	0.649429
num__flipper_length_mm	-0.571682
cat__island_Dream	-0.548209
cat__sex_Male	0.468019
cat__sex_Female	-0.461786
cat__island_Biscoe	-0.094988
num__body_mass_g	0.000890

=== Top 15 coefficients for class: Chinstrap ===
Chinstrap
num__bill_length_mm	1.882937
cat__island_Dream	1.189199
cat__island_Biscoe	-0.770085
num__body_mass_g	-0.741110
cat__sex_Male	-0.519705
cat__sex_Female	0.516992
cat__island_Torgersen	-0.421828
num__bill_depth_mm	0.344919
num__flipper_length_mm	-0.287865

=== Top 15 coefficients for class: Gentoo ===
Gentoo
num__bill_depth_mm	-1.335819
cat__island_Biscoe	0.865073
num__flipper_length_mm	0.859546
num__body_mass_g	0.740220
cat__island_Dream	-0.640990
num__bill_length_mm	0.461463
cat__island_Torgersen	-0.227602
cat__sex_Female	-0.055206
cat__sex_Male	0.051687
```

##### \(3) tree ê¸°ë°˜

**í˜¼ë™í–‰ë ¬ ì¶œë ¥**
```python
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# ì˜ˆì¸¡
y_pred_tree = tree_model.predict(X_test)

# âœ… ë¼ë²¨(í´ë˜ìŠ¤ ì´ë¦„) ê°€ì ¸ì˜¤ê¸°: data.target_names ëŒ€ì‹  ì‚¬ìš©
labels = tree_model.named_steps["tree"].classes_   # ì˜ˆ: ['Adelie','Chinstrap','Gentoo']

# í‰ê°€
print("[tree] Accuracy:", accuracy_score(y_test, y_pred_tree))

cm = confusion_matrix(y_test, y_pred_tree, labels=labels)
print("[tree] Confusion matrix:\n", cm)

print("[tree] Classification report:\n",
      classification_report(y_test, y_pred_tree,
                            labels=labels,
                            target_names=labels.tolist()))
```
```text
[tree] Accuracy: 1.0
[tree] Confusion matrix:
 [[30  0  0]
 [ 0 14  0]
 [ 0  0 25]]
[tree] Classification report:
               precision    recall  f1-score   support

      Adelie       1.00      1.00      1.00        30
   Chinstrap       1.00      1.00      1.00        14
      Gentoo       1.00      1.00      1.00        25

    accuracy                           1.00        69
   macro avg       1.00      1.00      1.00        69
weighted avg       1.00      1.00      1.00        69
```

**ì‚¬í›„í™•ë¥  ì¶œë ¥**
```python
#ì‚¬í›„ í™•ë¥  ì¶œë ¥
import pandas as pd

# (n_samples, n_classes)
proba_tree = tree_model.predict_proba(X_test)

tree_clf = tree_model.named_steps["tree"]
classes_tree = tree_clf.classes_

proba_tree_df = pd.DataFrame(proba_tree, columns=classes_tree)
display(proba_tree_df.head())
```
```text
Adelie	Chinstrap	Gentoo
0	1.0	0.0	0.0
1	1.0	0.0	0.0
2	0.0	0.0	1.0
3	0.0	0.0	1.0
4	0.0	1.0	0.0
```
**ì˜ì‚¬ê²°ì • ì¶œë ¥**
```python
import numpy as np
import pandas as pd

def explain_tree_path(pipeline, X_row, feature_names=None):
    """
    pipeline: tree_model (preprocess + tree)
    X_row: DataFrame 1í–‰ (ì˜ˆ: X_test.iloc[[i]])
    """
    pre = pipeline.named_steps["preprocess"]
    clf = pipeline.named_steps["tree"]

    # ì „ì²˜ë¦¬ëœ 2D í–‰ë ¬
    Xt = pre.transform(X_row)

    # feature name
    if feature_names is None:
        feature_names = pre.get_feature_names_out()

    # decision path
    node_indicator = clf.decision_path(Xt)
    leaf_id = clf.apply(Xt)[0]

    tree_ = clf.tree_
    node_index = node_indicator.indices[
        node_indicator.indptr[0] : node_indicator.indptr[1]
    ]

    rows = []
    for node_id in node_index:
        if node_id == leaf_id:
            # leafì—ì„œì˜ class count / posterior
            counts = tree_.value[node_id][0]  # (n_classes,)
            probs = counts / counts.sum() if counts.sum() > 0 else counts
            rows.append({
                "node": int(node_id),
                "type": "LEAF",
                "class_counts": counts.tolist(),
                "posterior": {str(c): float(p) for c, p in zip(clf.classes_, probs)}
            })
        else:
            f = tree_.feature[node_id]
            thr = tree_.threshold[node_id]
            feat_name = feature_names[f]
            val = Xt[0, f]
            direction = "LEFT (<=)" if val <= thr else "RIGHT (>)"
            rows.append({
                "node": int(node_id),
                "type": "SPLIT",
                "feature": feat_name,
                "value_in_node": float(val),
                "threshold": float(thr),
                "go": direction
            })

    return pd.DataFrame(rows), int(leaf_id)

# ì‚¬ìš© ì˜ˆì‹œ: ië²ˆì§¸ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ê²½ë¡œ ë³´ê¸°
i = 0
path_df, leaf = explain_tree_path(tree_model, X_test.iloc[[i]])
display(path_df)

# ì˜ˆì¸¡/í™•ë¥ ë„ ê°™ì´ í™•ì¸
print("pred =", tree_model.predict(X_test.iloc[[i]])[0])
print("proba =", dict(zip(tree_model.named_steps["tree"].classes_,
                         tree_model.predict_proba(X_test.iloc[[i]])[0])))
print("leaf =", leaf)
```

**ëª¨ë¸: ê²°ì •íŠ¸ë¦¬(ì „ì²˜ë¦¬ í¬í•¨)**

ëŒ€ìƒ: í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤‘ íŠ¹ì • ê°œì²´ 1ê°œ
<br>
ê²°ê³¼: ì˜ˆì¸¡ í´ë˜ìŠ¤: Adelie
<br>
ì‚¬í›„í™•ë¥ : P(Adelie)=1.0,P(Chinstrap)=0,P(Gentoo)=0
<br>
ìµœì¢… ë„ì°© ë¦¬í”„: leaf = 7

**ë‹¨ê³„ë³„ ë¶„ê¸° í•´ì„ (ì˜ì‚¬ê²°ì • ê³¼ì •)**

ì²« ë²ˆì§¸ ë¶„ê¸°: ì¡°ê±´ flipper_length_mmâ‰¤0.409, ì´ ê°’ì€ í‘œì¤€í™”ëœ ê°’(z-score)ì´ë‹¤. â†’ í”Œë¦¬í¼ ê¸¸ì´ê°€ í‰ê· ë³´ë‹¤ ê¸¸ì§€ ì•Šë‹¤. GentooëŠ” í”Œë¦¬í¼ê°€ ë§¤ìš° ê¸´ ì¢…ì´ë¯€ë¡œ ì´ ì¡°ê±´ì„ ë§Œì¡±í•˜ë©´ Gentoo ê°€ëŠ¥ì„±ì´ í¬ê²Œ ê°ì†Œí•œë‹¤. ë”°ë¼ì„œ íŠ¸ë¦¬ëŠ” Gentooë¥¼ 1ì°¨ì ìœ¼ë¡œ ë°°ì œí•˜ê³  ì™¼ìª½ìœ¼ë¡œ ì´ë™í•œë‹¤.

ë‘ ë²ˆì§¸ ë¶„ê¸°: ì¡°ê±´ bill_length_mmâ‰¤0.178 â†’ ë¶€ë¦¬ ê¸¸ì´ê°€ í‰ê· ë³´ë‹¤ ì•½ê°„ ì§§ê±°ë‚˜ ë¹„ìŠ·í•œ ìˆ˜ì¤€ì´ë‹¤. Chinstrapì€ ë¶€ë¦¬ ê¸¸ì´ê°€ ê¸´ í¸ì´ë¯€ë¡œ ì´ ì¡°ê±´ì€ Chinstrap ê°€ëŠ¥ì„±ì„ ë‚®ì¶”ëŠ” ë°©í–¥ì´ë‹¤. íŠ¸ë¦¬ëŠ” Adelie/Chinstrap ì¤‘ì—ì„œë„ Adelie ìª½ìœ¼ë¡œ ê¸°ìš¸ê¸° ì‹œì‘í•œë‹¤.

ì„¸ ë²ˆì§¸ ë¶„ê¸°: ì¡°ê±´ bill_length_mmâ‰¤âˆ’0.315 â†’ ë¶€ë¦¬ ê¸¸ì´ê°€ í‰ê· ë³´ë‹¤ ìƒë‹¹íˆ ì§§ìŒ. ì§§ì€ ë¶€ë¦¬ëŠ” Adelieì˜ í•µì‹¬ íŠ¹ì§•ì„ ê°€ì§€ë¯€ë¡œ Chinstrap ê°€ëŠ¥ì„±ì€ ì—¬ê¸°ì„œ ê±°ì˜ ì œê±°ëœë‹¤.

ë„¤ ë²ˆì§¸ ë¶„ê¸°: ì¡°ê±´ bill_depth_mm>âˆ’0.260 â†’ ë¶€ë¦¬ ê¹Šì´ê°€ ë„ˆë¬´ ì–•ì§€ ì•ŠìŒ(ì¦‰, ìƒëŒ€ì ìœ¼ë¡œ ë‘êº¼ìš´ ë¶€ë¦¬). AdelieëŠ” ì§§ê³  ê¹Šì€ ë¶€ë¦¬ë¥¼ ê°€ì§€ë¯€ë¡œ ì´ ì¡°ê±´ì€ Adelieì˜ ì „í˜•ì  í˜•ì§ˆê³¼ ì •í™•íˆ ì¼ì¹˜í•œë‹¤.

ë¦¬í”„ ë…¸ë“œ ë„ì°©: ë¦¬í”„ ì •ë³´ class_counts = [1, 0, 0] posterior = {Adelie: 1.0} â†’ ì´ ê²½ë¡œë¡œ ë„ë‹¬í•œ í•™ìŠµ ë°ì´í„°ê°€ ëª¨ë‘ Adelie. ëª¨ë¸ì€ í™•ë¥  1.0ìœ¼ë¡œ Adelie íŒì •

ë³¸ ê°œì²´ëŠ” í”Œë¦¬í¼ ê¸¸ì´ê°€ í‰ê· ë³´ë‹¤ ê¸¸ì§€ ì•Šì•„ Gentooì¼ ê°€ëŠ¥ì„±ì´ ì´ˆê¸° ë‹¨ê³„ì—ì„œ ë°°ì œë˜ì—ˆìœ¼ë©°, ë¶€ë¦¬ ê¸¸ì´ê°€ í‰ê· ë³´ë‹¤ ìƒë‹¹íˆ ì§§ì•„ Chinstrap ê°€ëŠ¥ì„± ë˜í•œ ë‹¨ê³„ì ìœ¼ë¡œ ê°ì†Œí•˜ì˜€ë‹¤. 

ì´í›„ ë¶€ë¦¬ ê¹Šì´ê°€ ìƒëŒ€ì ìœ¼ë¡œ ê¹Šì€ íŠ¹ì„±ì„ ë³´ì„ì— ë”°ë¼, í•´ë‹¹ ê°œì²´ëŠ” Adelieì˜ ì „í˜•ì ì¸ í˜•íƒœì  íŠ¹ì„±ì„ ì¶©ì¡±í•˜ëŠ” ê²ƒìœ¼ë¡œ íŒë‹¨ë˜ì—ˆê³ , ì´ì— ë”°ë¼ ë³¸ ê²°ì •íŠ¸ë¦¬ëŠ” í•´ë‹¹ ê°œì²´ë¥¼ Adelieë¡œ í™•ë¥  1.0ìœ¼ë¡œ ë¶„ë¥˜í•˜ì˜€ë‹¤.

```text
node	type	feature	value_in_node	threshold	go	class_counts	posterior
0	0	SPLIT	num__flipper_length_mm	0.013088	0.409002	LEFT (<=)	NaN	NaN
1	1	SPLIT	num__bill_length_mm	-0.470502	0.178449	LEFT (<=)	NaN	NaN
2	2	SPLIT	num__bill_length_mm	-0.470502	-0.315119	LEFT (<=)	NaN	NaN
3	3	SPLIT	num__bill_depth_mm	0.663008	-0.260357	RIGHT (>)	NaN	NaN
4	7	LEAF	NaN	NaN	NaN	NaN	[1.0, 0.0, 0.0]	{'Adelie': 1.0, 'Chinstrap': 0.0, 'Gentoo': 0.0}
pred = Adelie
proba = {'Adelie': np.float64(1.0), 'Chinstrap': np.float64(0.0), 'Gentoo': np.float64(0.0)}
leaf = 7
```
```python
from sklearn.tree import export_text

pre = tree_model.named_steps["preprocess"]
clf = tree_model.named_steps["tree"]
feat_names = pre.get_feature_names_out()

print(export_text(clf, feature_names=list(feat_names), max_depth=4))
```

ì œì‹œëœ ì¶œë ¥ì€ í­ê·„ ë°ì´í„°ì…‹ì„ ì „ì²˜ë¦¬(ìˆ˜ì¹˜í˜• í‘œì¤€í™”, ë²”ì£¼í˜• ì›í•«ì¸ì½”ë”©)í•œ ë’¤, ì˜ì‚¬ê²°ì •ë‚˜ë¬´(DecisionTreeClassifier)ê°€ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ëŠ” ê·œì¹™ì„ í…ìŠ¤íŠ¸ë¡œ í¼ì³ ë†“ì€ ê²°ê³¼ì´ë‹¤. ë§¨ ì•ì˜ |---ëŠ” ë¶„ê¸° ì¡°ê±´ì„ ëœ»í•˜ë©°, ìœ„ì—ì„œ ì•„ë˜ë¡œ ë‚´ë ¤ê°€ë©´ì„œ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê²½ë¡œë¥¼ ë”°ë¼ê°€ë©´ ìµœì¢… ì˜ˆì¸¡ í´ë˜ìŠ¤ê°€ ê²°ì •ë˜ëŠ” êµ¬ì¡°ì´ë‹¤. 

num__ë¡œ ì‹œì‘í•˜ëŠ” ë³€ìˆ˜ëŠ” í‘œì¤€í™”ëœ ìˆ˜ì¹˜í˜• íŠ¹ì„±(í‰ê·  0, í‘œì¤€í¸ì°¨ 1 ê¸°ì¤€ì˜ ê°’)ì´ê³ , cat__ë¡œ ì‹œì‘í•˜ëŠ” ë³€ìˆ˜ëŠ” ì›í•«ì¸ì½”ë”©ëœ ë²”ì£¼í˜• ë”ë¯¸ ë³€ìˆ˜ì´ë‹¤. ë”°ë¼ì„œ cat__sex_Male <= 0.500ì€ â€œMale ë”ë¯¸ê°€ 0ì¸ ê²½ìš°â€, ì¦‰ ë‚¨ì„±ì´ ì•„ë‹Œ ê²½ìš°(ëŒ€ê°œ Female ë˜ëŠ” ê²°ì¸¡ì´ ë‹¤ë¥¸ ê°’ìœ¼ë¡œ ì²˜ë¦¬ëœ ê²½ìš°)ë¼ëŠ” ëœ»ì´ë‹¤.

ê°€ì¥ ë¨¼ì € ëª¨ë¸ì€ num__flipper_length_mmë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì „ì²´ë¥¼ ë‘ ê°ˆë˜ë¡œ ë‚˜ëˆ„ëŠ” êµ¬ì¡°ì´ë‹¤. num__flipper_length_mm <= 0.409ì´ë©´ ìƒëŒ€ì ìœ¼ë¡œ ì§€ëŠëŸ¬ë¯¸ ê¸¸ì´ê°€ ì§§ì€ ìª½ ì§‘ë‹¨ìœ¼ë¡œ ë“¤ì–´ê°€ê³ , num__flipper_length_mm > 0.409ì´ë©´ ìƒëŒ€ì ìœ¼ë¡œ ì§€ëŠëŸ¬ë¯¸ ê¸¸ì´ê°€ ê¸´ ìª½ ì§‘ë‹¨ìœ¼ë¡œ ë“¤ì–´ê°€ëŠ” ë°©ì‹ì´ë‹¤. ì´ ë¶„ê¸° ìì²´ê°€ â€œì§€ëŠëŸ¬ë¯¸ ê¸¸ì´ê°€ ê¸¸ë©´ Gentooì¼ ê°€ëŠ¥ì„±ì´ í¬ë‹¤â€ëŠ” í° íŒ¨í„´ì„ ë°˜ì˜í•œ ê·œì¹™ì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤.

ì§€ëŠëŸ¬ë¯¸ ê¸¸ì´ê°€ ì§§ì€ ì§‘ë‹¨(<= 0.409) ì•ˆì—ì„œëŠ” num__bill_length_mm(ë¶€ë¦¬ ê¸¸ì´)ë¡œ ë‹¤ì‹œ ê°ˆë¼ì§€ëŠ” êµ¬ì¡°ì´ë‹¤. num__bill_length_mm <= 0.178ì´ë©´ ë¶€ë¦¬ ê¸¸ì´ê°€ ìƒëŒ€ì ìœ¼ë¡œ ì§§ê±°ë‚˜ ë³´í†µì¸ ìª½ì´ë©°, ì—¬ê¸°ì„œ num__bill_length_mm <= -0.315ì²˜ëŸ¼ ë” ì§§ì€ êµ¬ê°„ìœ¼ë¡œ ë“¤ì–´ê°€ë©´ num__bill_depth_mm(ë¶€ë¦¬ ê¹Šì´) ì¡°ê±´ì´ ì¶”ê°€ë¡œ ë¶™ëŠ”ë‹¤. 

íŠ¹íˆ num__bill_depth_mm > -0.260ì¸ ê²½ìš°ì—ëŠ” ìë…¸ë“œì—ì„œ weights: [103.000, 0.000, 0.000] class: Adelieë¡œ ëë‚˜ëŠ”ë°, ì´ëŠ” ê·¸ ì§€ì ê¹Œì§€ ë„ë‹¬í•œ í•™ìŠµ í‘œë³¸ì˜ í´ë˜ìŠ¤ ë¶„í¬ê°€ Adelie 103, Chinstrap 0, Gentoo 0ì´ë©° ìµœì¢… ì˜ˆì¸¡ì´ Adelieë¼ëŠ” ëœ»ì´ë‹¤. ë°˜ëŒ€ë¡œ num__bill_depth_mm <= -0.260ì²˜ëŸ¼ ë” ì–•ì€ ê²½ìš°ì—ëŠ” ë¶€ë¦¬ ê¸¸ì´ë¥¼ í•œ ë²ˆ ë” ìª¼ê°œì–´ Adelie 7ê°œê°€ ëª¨ì¸ ììœ¼ë¡œ ê°€ê±°ë‚˜, ë§¤ìš° ë“œë¬¼ê²Œ Chinstrap 1ê°œê°€ ëª¨ì¸ ììœ¼ë¡œ ê°€ëŠ” êµ¬ì¡°ë„ ë‚˜íƒ€ë‚œë‹¤.

ê°™ì€ â€œì§€ëŠëŸ¬ë¯¸ ì§§ìŒâ€ ê°€ì§€ì—ì„œ num__bill_length_mm > -0.315ë¡œ ë„˜ì–´ê°€ë©´ cat__sex_Maleì´ ë“±ì¥í•œë‹¤. cat__sex_Male <= 0.500ì´ë©´ weights: [0.000, 4.000, 0.000] class: Chinstrapìœ¼ë¡œ ëë‚˜ì„œ Chinstrapìœ¼ë¡œ ì˜ˆì¸¡ë˜ëŠ” êµ¬ê°„ì´ ìƒê¸´ë‹¤. 

cat__sex_Male > 0.500ì´ë©´ ë‹¤ì‹œ num__bill_depth_mmë¡œ ê°ˆë¼ì§€ëŠ”ë°, ì¼ë¶€ëŠ” truncated branch of depth 2ë¡œ í‘œì‹œë˜ì–´ ì¶œë ¥ì—ì„œ ë” ê¹Šì€ ë¶„ê¸°ê°€ ìƒëµëœ ë¶€ë¶„ì´ë‹¤. ì¶œë ¥ì— ë³´ì´ëŠ” ë²”ìœ„ì—ì„œëŠ” num__bill_depth_mm > 0.139ì¸ ê²½ìš° weights: [7.000, 0.000, 0.000] class: Adelieë¡œ ê·€ê²°ë˜ëŠ” êµ¬ê°„ì´ ì¡´ì¬í•œë‹¤.

í•œí¸ num__bill_length_mm > 0.178ì¸ ìª½(ë¶€ë¦¬ ê¸¸ì´ê°€ ìƒëŒ€ì ìœ¼ë¡œ ê¸´ ìª½)ì—ì„œëŠ” cat__island_Dreamì´ í•µì‹¬ ë¶„ê¸°ì´ë‹¤. cat__island_Dream > 0.500ì´ë©´ weights: [0.000, 44.000, 0.000] class: Chinstrapìœ¼ë¡œ ë°”ë¡œ ëë‚˜ë©°, Dream ì„¬ìœ¼ë¡œ ì¸ì½”ë”©ëœ ê²½ìš° Chinstrapì´ ë§¤ìš° ê°•í•˜ê²Œ ì˜ˆì¸¡ë˜ëŠ” ê·œì¹™ì„ì„ ë³´ì—¬ì¤€ë‹¤. 

cat__island_Dream <= 0.500ì¸ ê²½ìš°ì—ëŠ” ë‹¤ì‹œ cat__sex_Maleë¡œ ê°ˆë¼ì§€ë©´ì„œ, ë‚¨ì„±ì´ ì•„ë‹ˆë©´ Gentoo 1ê°œê°€ ëª¨ì¸ ììœ¼ë¡œ, ë‚¨ì„±ì´ë©´ Adelie 3ê°œê°€ ëª¨ì¸ ììœ¼ë¡œ ê°€ëŠ” ì‘ì€ ë³´ì¡° ê·œì¹™ì´ ë¶™ì–´ ìˆë‹¤.

ì§€ëŠëŸ¬ë¯¸ ê¸¸ì´ê°€ ê¸´ ì§‘ë‹¨(> 0.409)ì—ì„œëŠ” ëª¨ë¸ì´ ë¨¼ì € num__bill_depth_mmë¡œ ë¶„ê¸°í•œë‹¤. num__bill_depth_mm <= 0.413ì´ë©´ weights: [0.000, 0.000, 97.000] class: Gentooë¡œ ëë‚˜ë©°, ì´ êµ¬ê°„ì€ ê±°ì˜ ìˆœìˆ˜í•˜ê²Œ Gentooë¡œ êµ¬ì„±ëœ ë§¤ìš° ê°•í•œ ê·œì¹™ì´ë‹¤. 

ë°˜ëŒ€ë¡œ num__bill_depth_mm > 0.413ì´ë©´ num__bill_length_mmë¡œ í•œ ë²ˆ ë” ê°ˆë¼ì ¸ì„œ, <= 0.151ì¸ ê²½ìš° Adelie 1ê°œê°€ ëª¨ì¸ ììœ¼ë¡œ, > 0.151ì¸ ê²½ìš° Chinstrap 5ê°œê°€ ëª¨ì¸ ììœ¼ë¡œ ê°€ëŠ” ì˜ˆì™¸ ê·œì¹™ì´ ì¡´ì¬í•œë‹¤.

ì •ë¦¬í•˜ë©´, ì´ ì˜ì‚¬ê²°ì •ë‚˜ë¬´ëŠ” ì§€ëŠëŸ¬ë¯¸ ê¸¸ì´ë¡œ í° í‹€ì„ ë¨¼ì € ë‚˜ëˆ„ê³ , ê·¸ ë‹¤ìŒì— ë¶€ë¦¬ ê¸¸ì´/ë¶€ë¦¬ ê¹Šì´ ë° ì„¬(Dream)ê³¼ ì„±ë³„(Male ë”ë¯¸) ê°™ì€ ì •ë³´ë¡œ ì„¸ ì¢…(Adelie, Chinstrap, Gentoo)ì„ íŒë³„í•˜ëŠ” êµ¬ì¡°ì´ë‹¤. 

ê° ìë…¸ë“œì˜ weights: [a, b, c]ëŠ” í•´ë‹¹ ê·œì¹™ê¹Œì§€ ë„ë‹¬í•œ í•™ìŠµ ë°ì´í„°ì˜ í´ë˜ìŠ¤ ë¶„í¬ì´ë©°, ê·¸ ë¶„í¬ì—ì„œ ê°€ì¥ ë§ì€ í´ë˜ìŠ¤ë¥¼ class:ë¡œ ì˜ˆì¸¡í•˜ëŠ” ë°©ì‹ì¸ ê²ƒì´ë‹¤. ë˜í•œ ìˆ˜ì¹˜í˜• ê¸°ì¤€ê°’ë“¤ì´ í‘œì¤€í™” ì¢Œí‘œì´ë¯€ë¡œ, ì„ê³„ê°’ì˜ í¬ê¸° ìì²´ëŠ” â€œì›ë˜ ë‹¨ìœ„(mm)â€ê°€ ì•„ë‹ˆë¼ â€œí‰ê·  ëŒ€ë¹„ ëª‡ í‘œì¤€í¸ì°¨ì¸ê°€â€ë¥¼ ì˜ë¯¸í•˜ëŠ” ê°’ì´ë¼ëŠ” ì ì´ í•µì‹¬ ì „ì œì´ë‹¤.

```text
|--- num__flipper_length_mm <= 0.409
|   |--- num__bill_length_mm <= 0.178
|   |   |--- num__bill_length_mm <= -0.315
|   |   |   |--- num__bill_depth_mm <= -0.260
|   |   |   |   |--- num__bill_length_mm <= -0.836
|   |   |   |   |   |--- weights: [7.000, 0.000, 0.000] class: Adelie
|   |   |   |   |--- num__bill_length_mm >  -0.836
|   |   |   |   |   |--- weights: [0.000, 1.000, 0.000] class: Chinstrap
|   |   |   |--- num__bill_depth_mm >  -0.260
|   |   |   |   |--- weights: [103.000, 0.000, 0.000] class: Adelie
|   |   |--- num__bill_length_mm >  -0.315
|   |   |   |--- cat__sex_Male <= 0.500
|   |   |   |   |--- weights: [0.000, 4.000, 0.000] class: Chinstrap
|   |   |   |--- cat__sex_Male >  0.500
|   |   |   |   |--- num__bill_depth_mm <= 0.139
|   |   |   |   |   |--- truncated branch of depth 2
|   |   |   |   |--- num__bill_depth_mm >  0.139
|   |   |   |   |   |--- weights: [7.000, 0.000, 0.000] class: Adelie
|   |--- num__bill_length_mm >  0.178
|   |   |--- cat__island_Dream <= 0.500
|   |   |   |--- cat__sex_Male <= 0.500
|   |   |   |   |--- weights: [0.000, 0.000, 1.000] class: Gentoo
|   |   |   |--- cat__sex_Male >  0.500
|   |   |   |   |--- weights: [3.000, 0.000, 0.000] class: Adelie
|   |   |--- cat__island_Dream >  0.500
|   |   |   |--- weights: [0.000, 44.000, 0.000] class: Chinstrap
|--- num__flipper_length_mm >  0.409
|   |--- num__bill_depth_mm <= 0.413
|   |   |--- weights: [0.000, 0.000, 97.000] class: Gentoo
|   |--- num__bill_depth_mm >  0.413
|   |   |--- num__bill_length_mm <= 0.151
|   |   |   |--- weights: [1.000, 0.000, 0.000] class: Adelie
|   |   |--- num__bill_length_mm >  0.151
|   |   |   |--- weights: [0.000, 5.000, 0.000] class: Chinstrap
```

```python
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

pre = tree_model.named_steps["preprocess"]
clf = tree_model.named_steps["tree"]
feat_names = pre.get_feature_names_out()

plt.figure(figsize=(18, 8))
plot_tree(clf, feature_names=feat_names, class_names=clf.classes_, filled=True, max_depth=3)
plt.show()
```
![](images/classification_ml_category_treeprocess.png){fig-align="center" width="100%"}

##### \(4) random forest

**í˜¼ë™í–‰ë ¬ ì¶œë ¥**

```python
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# ì˜ˆì¸¡
y_pred_tree = rf_model.predict(X_test)

# âœ… ë¼ë²¨(í´ë˜ìŠ¤ ì´ë¦„) ê°€ì ¸ì˜¤ê¸°: data.target_names ëŒ€ì‹  ì‚¬ìš©
labels = tree_model.named_steps["tree"].classes_   # ì˜ˆ: ['Adelie','Chinstrap','Gentoo']

# í‰ê°€
print("[Random Forest] Accuracy:", accuracy_score(y_test, y_pred_tree))

cm = confusion_matrix(y_test, y_pred_tree, labels=labels)
print("[Random Forest] Confusion matrix:\n", cm)

print("[Random Forest] Classification report:\n",
      classification_report(y_test, y_pred_tree,
                            labels=labels,
                            target_names=labels.tolist()))
```
```text
[Random Forest] Accuracy: 1.0
[Random Forest] Confusion matrix:
 [[30  0  0]
 [ 0 14  0]
 [ 0  0 25]]
[Random Forest] Classification report:
               precision    recall  f1-score   support

      Adelie       1.00      1.00      1.00        30
   Chinstrap       1.00      1.00      1.00        14
      Gentoo       1.00      1.00      1.00        25

    accuracy                           1.00        69
   macro avg       1.00      1.00      1.00        69
weighted avg       1.00      1.00      1.00        69
```
**ì‚¬í›„í™•ë¥  ì¶œë ¥**
```python
import pandas as pd

# (n_samples, n_classes)
proba_rf = rf_model.predict_proba(X_test)

rf_clf = rf_model.named_steps["rf"]
classes_rf = rf_clf.classes_

proba_rf_df = pd.DataFrame(proba_rf, columns=classes_rf)
display(proba_rf_df.head())
```
```text
Adelie	Chinstrap	Gentoo
0	0.853333	0.146667	0.0
1	0.986667	0.013333	0.0
2	0.000000	0.000000	1.0
3	0.000000	0.000000	1.0
4	0.060000	0.940000	0.0
```

**ì˜ì‚¬ê²°ì • ê³¼ì •**

```python
from sklearn.tree import export_text

def explain_one_tree(rf_pipeline, tree_idx=0, max_depth=4):
    pre = rf_pipeline.named_steps["preprocess"]
    rf  = rf_pipeline.named_steps["rf"]
    feat_names = list(pre.get_feature_names_out())

    tree = rf.estimators_[tree_idx]
    print(export_text(tree, feature_names=feat_names, max_depth=max_depth))

explain_one_tree(rf_model, tree_idx=0, max_depth=4)
```

ì´ ê·œì¹™ì€ ì „ì²˜ë¦¬ëœ ë³€ìˆ˜(ìˆ˜ì¹˜í˜•ì€ í‘œì¤€í™”ëœ ê°’, ë²”ì£¼í˜•ì€ ì›-í•« ì¸ì½”ë”©ëœ 0/1 ê°’)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìµœì¢… í´ë˜ìŠ¤ë¥¼ ê²°ì •í•˜ëŠ” ë¶„ê¸° ê·œì¹™ì´ë‹¤. ì—¬ê¸°ì„œ cat__island_Torgersen, cat__island_Dreamì€ ì›-í•« ë³€ìˆ˜ì´ë¯€ë¡œ ê°’ì´ 0.50 ì´í•˜ì´ë©´ í•´ë‹¹ ì„¬ì´ ì•„ë‹Œ ê²½ìš°ì´ê³ , 0.50 ì´ˆê³¼ì´ë©´ í•´ë‹¹ ì„¬ì¸ ê²½ìš°ë¡œ í•´ì„í•˜ëŠ” ê²ƒì´ ìì—°ìŠ¤ëŸ¬ìš´ ê·œì¹™ì´ë‹¤.

ë˜í•œ num__bill_length_mm, num__bill_depth_mm, num__body_mass_gëŠ” í‘œì¤€í™”ëœ ìˆ˜ì¹˜ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìœ¼ë¯€ë¡œ ì„ê³„ê°’ -0.32, -0.24, -1.35, 0.41 ë“±ì€ ì› ë‹¨ìœ„(mm, g)ê°€ ì•„ë‹ˆë¼ í‘œì¤€í™” ìŠ¤ì¼€ì¼ ê¸°ì¤€ì˜ ê²½ê³„ê°’ì¸ í•´ì„ì´ë‹¤.

ì²« ë²ˆì§¸ í° ë¶„ê¸°ëŠ” num__bill_length_mmì´ -0.32 ì´í•˜ì¸ì§€ ì—¬ë¶€ë¡œ ë‚˜ë‰˜ëŠ” ê·œì¹™ì´ë‹¤. 

- num__bill_length_mmì´ -0.32 ì´í•˜ì´ë©´, ë‹¤ìŒìœ¼ë¡œ num__bill_depth_mmì´ -0.24 ì´í•˜ì¸ì§€ í™•ì¸í•˜ëŠ” ê·œì¹™ì´ë‹¤.
- num__bill_depth_mmì´ -0.24 ì´í•˜ì´ë©´, num__body_mass_gì´ -1.35 ì´í•˜ì¸ì§€ í™•ì¸í•˜ëŠ” ê·œì¹™ì´ë‹¤.
- num__body_mass_gì´ -1.35 ì´í•˜ì´ë©´ ìµœì¢… í´ë˜ìŠ¤ëŠ” 0.0ì¸ ê·œì¹™ì´ë‹¤.
- num__body_mass_gì´ -1.35 ì´ˆê³¼ì´ë©´ cat__island_Torgersenì´ 0.50 ì´í•˜ì¸ì§€ í™•ì¸í•˜ëŠ” ê·œì¹™ì´ë‹¤.
- cat__island_Torgersenì´ 0.50 ì´í•˜ì´ë©´ ìµœì¢… í´ë˜ìŠ¤ëŠ” 1.0ì¸ ê·œì¹™ì´ë‹¤.
- cat__island_Torgersenì´ 0.50 ì´ˆê³¼ì´ë©´ ìµœì¢… í´ë˜ìŠ¤ëŠ” 0.0ì¸ ê·œì¹™ì´ë‹¤.
- num__bill_length_mmì´ -0.32 ì´í•˜ì´ë©´ì„œ num__bill_depth_mmì´ -0.24 ì´ˆê³¼ì´ë©´ ìµœì¢… í´ë˜ìŠ¤ëŠ” 0.0ì¸ ê·œì¹™ì´ë‹¤.

ë‘ ë²ˆì§¸ í° ë¶„ê¸°ëŠ” num__bill_length_mmì´ -0.32 ì´ˆê³¼ì¸ ê²½ìš°ì˜ ê·œì¹™ì´ë‹¤.

- num__bill_length_mmì´ -0.32 ì´ˆê³¼ì´ë©´, cat__island_Dreamì´ 0.50 ì´í•˜ì¸ì§€ í™•ì¸í•˜ëŠ” ê·œì¹™ì´ë‹¤.
- cat__island_Dreamì´ 0.50 ì´í•˜ì´ë©´, cat__island_Torgersenì´ 0.50 ì´í•˜ì¸ì§€ í™•ì¸í•˜ëŠ” ê·œì¹™ì´ë‹¤.
- cat__island_Torgersenì´ 0.50 ì´í•˜ì´ë©´, num__bill_depth_mmì´ 0.41 ì´í•˜ì¸ì§€ í™•ì¸í•˜ëŠ” ê·œì¹™ì´ë‹¤.
- num__bill_depth_mmì´ 0.41 ì´í•˜ì´ë©´ ìµœì¢… í´ë˜ìŠ¤ëŠ” 2.0ì¸ ê·œì¹™ì´ë‹¤.
- num__bill_depth_mmì´ 0.41 ì´ˆê³¼ì´ë©´ ìµœì¢… í´ë˜ìŠ¤ëŠ” 0.0ì¸ ê·œì¹™ì´ë‹¤.
- cat__island_Torgersenì´ 0.50 ì´ˆê³¼ì´ë©´ ìµœì¢… í´ë˜ìŠ¤ëŠ” 0.0ì¸ ê·œì¹™ì´ë‹¤.
- num__bill_length_mmì´ -0.32 ì´ˆê³¼ì´ë©´ì„œ cat__island_Dreamì´ 0.50 ì´ˆê³¼ì´ë©´ ìµœì¢… í´ë˜ìŠ¤ëŠ” 1.0ì¸ ê·œì¹™ì´ë‹¤.

ì •ë¦¬í•˜ë©´, ì´ íŠ¸ë¦¬ëŠ” (1) í‘œì¤€í™”ëœ ë¶€ë¦¬ ê¸¸ì´ì™€ ë¶€ë¦¬ ê¹Šì´, ì²´ì¤‘ ê°™ì€ ìˆ˜ì¹˜í˜• ê²½ê³„ê°’ê³¼ (2) íŠ¹ì • ì„¬ ì—¬ë¶€(ì›-í•«)ë¥¼ ì¡°í•©í•˜ì—¬ ìµœì¢… í´ë˜ìŠ¤ë¥¼ 0.0, 1.0, 2.0ìœ¼ë¡œ ê²°ì •í•˜ëŠ” ê·œì¹™ ì§‘í•©ì¸ í•´ì„ì´ë‹¤.

```text
|--- num__bill_length_mm <= -0.32
|   |--- num__bill_depth_mm <= -0.24
|   |   |--- num__body_mass_g <= -1.35
|   |   |   |--- class: 0.0
|   |   |--- num__body_mass_g >  -1.35
|   |   |   |--- cat__island_Torgersen <= 0.50
|   |   |   |   |--- class: 1.0
|   |   |   |--- cat__island_Torgersen >  0.50
|   |   |   |   |--- class: 0.0
|   |--- num__bill_depth_mm >  -0.24
|   |   |--- class: 0.0
|--- num__bill_length_mm >  -0.32
|   |--- cat__island_Dream <= 0.50
|   |   |--- cat__island_Torgersen <= 0.50
|   |   |   |--- num__bill_depth_mm <= 0.41
|   |   |   |   |--- class: 2.0
|   |   |   |--- num__bill_depth_mm >  0.41
|   |   |   |   |--- class: 0.0
|   |   |--- cat__island_Torgersen >  0.50
|   |   |   |--- class: 0.0
|   |--- cat__island_Dream >  0.50
|   |   |--- class: 1.0
```

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

# =========================================================
# 0) ì…ë ¥: rf_model(Pipeline), X_test(DataFrame) ê°€ ì´ë¯¸ ìˆë‹¤ê³  ê°€ì •
# =========================================================

# ---------------------------------------------------------
# 1) íŠ¹ì • ìƒ˜í”Œ 1ê°œì— ëŒ€í•´: íŠ¸ë¦¬ë³„ íˆ¬í‘œ(í™•ë¥ ) + í‰ê· /í‘œì¤€í¸ì°¨
# ---------------------------------------------------------
def rf_vote_summary(rf_pipeline, X_row):
    pre = rf_pipeline.named_steps["preprocess"]
    rf  = rf_pipeline.named_steps["rf"]

    Xt = pre.transform(X_row)
    classes = rf.classes_

    # ê° íŠ¸ë¦¬ì˜ predict_proba
    probs = np.array([est.predict_proba(Xt)[0] for est in rf.estimators_])  # (n_trees, n_classes)
    df = pd.DataFrame(probs, columns=classes)

    mean_proba = df.mean().sort_values(ascending=False)
    std_proba  = df.std().sort_values(ascending=False)

    pred = mean_proba.index[0]
    return pred, mean_proba, std_proba, df


# ---------------------------------------------------------
# 2) "ëŒ€í‘œ íŠ¸ë¦¬" ì„ íƒ: (A) í‰ê· ì˜ˆì¸¡ê³¼ ê°™ì€ í´ë˜ìŠ¤ë¥¼ ë‚´ëŠ” íŠ¸ë¦¬ ì¤‘
#    (B) í•´ë‹¹ ìƒ˜í”Œì—ì„œ ì˜ˆì¸¡í™•ë¥ ì´ ê°€ì¥ ë†’ì€ íŠ¸ë¦¬ 1ê°œë¥¼ ê³ ë¦„
# ---------------------------------------------------------
def pick_representative_tree(rf_pipeline, X_row, target_class=None):
    pre = rf_pipeline.named_steps["preprocess"]
    rf  = rf_pipeline.named_steps["rf"]
    Xt = pre.transform(X_row)
    classes = list(rf.classes_)

    # target_classë¥¼ ì•ˆ ì£¼ë©´ RF í‰ê·  ì˜ˆì¸¡ í´ë˜ìŠ¤ë¡œ
    if target_class is None:
        mean_proba = np.mean([est.predict_proba(Xt)[0] for est in rf.estimators_], axis=0)
        target_class = classes[int(np.argmax(mean_proba))]

    c_idx = classes.index(target_class)

    best_idx, best_p = None, -1
    for i, est in enumerate(rf.estimators_):
        proba = est.predict_proba(Xt)[0]
        pred  = classes[int(np.argmax(proba))]
        if pred == target_class and proba[c_idx] > best_p:
            best_p = float(proba[c_idx])
            best_idx = i

    # í˜¹ì‹œ ì¼ì¹˜ íŠ¸ë¦¬ê°€ ì—†ë‹¤ë©´(ê±°ì˜ ì—†ì§€ë§Œ) ê·¸ëƒ¥ í™•ë¥  ìµœëŒ€ íŠ¸ë¦¬
    if best_idx is None:
        best_idx = int(np.argmax([est.predict_proba(Xt)[0][c_idx] for est in rf.estimators_]))
        best_p   = float(rf.estimators_[best_idx].predict_proba(Xt)[0][c_idx])

    return best_idx, target_class, best_p


# ---------------------------------------------------------
# 3) íŠ¹ì • íŠ¸ë¦¬ì—ì„œ "í•œ ìƒ˜í”Œ"ì˜ ê²°ì • ê²½ë¡œ(path) í‘œë¡œ ì¶œë ¥
#    (split feature, threshold, ì‹¤ì œ ê°’, LEFT/RIGHT, ë§ˆì§€ë§‰ leafì˜ posterior)
# ---------------------------------------------------------
def tree_decision_path_for_one(estimator_tree, Xt_row_2d, feature_names, class_names):
    clf = estimator_tree
    tree_ = clf.tree_

    node_indicator = clf.decision_path(Xt_row_2d)
    leaf_id = clf.apply(Xt_row_2d)[0]

    node_index = node_indicator.indices[
        node_indicator.indptr[0]: node_indicator.indptr[1]
    ]

    rows = []
    for node_id in node_index:
        if node_id == leaf_id:
            counts = tree_.value[node_id][0]
            probs = counts / counts.sum() if counts.sum() > 0 else counts
            rows.append({
                "node": int(node_id),
                "type": "LEAF",
                "class_counts": counts.tolist(),
                "posterior": {str(c): float(p) for c, p in zip(class_names, probs)}
            })
        else:
            f = tree_.feature[node_id]
            thr = tree_.threshold[node_id]
            feat_name = feature_names[f]
            val = float(Xt_row_2d[0, f])
            go = "LEFT(<=)" if val <= thr else "RIGHT(>)"
            rows.append({
                "node": int(node_id),
                "type": "SPLIT",
                "feature": feat_name,
                "value_in_node": val,
                "threshold": float(thr),
                "go": go
            })

    return pd.DataFrame(rows), int(leaf_id)


# ---------------------------------------------------------
# 4) í•œ ë²ˆì— ì‹¤í–‰: íˆ¬í‘œìš”ì•½ + ëŒ€í‘œíŠ¸ë¦¬ ì‹œê°í™” + path ì¶œë ¥
# ---------------------------------------------------------
def explain_random_forest_sample(rf_pipeline, X_row, plot_max_depth=3, figsize=(22, 10), topn_trees=10):
    pre = rf_pipeline.named_steps["preprocess"]
    rf  = rf_pipeline.named_steps["rf"]

    # (A) RF íˆ¬í‘œ ìš”ì•½
    pred, mean_proba, std_proba, all_tree_df = rf_vote_summary(rf_pipeline, X_row)
    print("=== RandomForest final prediction (mean proba) ===")
    print("pred =", pred)
    print("\n[mean proba]")
    print(mean_proba)
    print("\n[std proba]  (íŠ¸ë¦¬ë“¤ ì˜ê²¬ ë¶ˆì¼ì¹˜ ì •ë„)")
    print(std_proba)

    # íŠ¸ë¦¬ë³„ë¡œ 'ì˜ˆì¸¡ëœ í´ë˜ìŠ¤' ì§‘ê³„(ë‹¤ìˆ˜ê²° ëŠë‚Œ)
    tree_preds = all_tree_df.idxmax(axis=1)
    print("\n[top class vote count]")
    print(tree_preds.value_counts())

    # (B) ëŒ€í‘œ íŠ¸ë¦¬ ì„ íƒ
    rep_idx, target_class, rep_p = pick_representative_tree(rf_pipeline, X_row, target_class=pred)
    print(f"\n=== Representative tree ===\nindex={rep_idx}, target_class={target_class}, tree_proba={rep_p:.4f}")

    # (C) ëŒ€í‘œ íŠ¸ë¦¬ ì‹œê°í™”
    feat_names = pre.get_feature_names_out()
    rep_tree = rf.estimators_[rep_idx]

    plt.figure(figsize=figsize)
    plot_tree(
        rep_tree,
        feature_names=feat_names,
        class_names=[str(c) for c in rf.classes_],
        filled=True,
        max_depth=plot_max_depth
    )
    plt.title(f"Representative Tree #{rep_idx} (max_depth={plot_max_depth})")
    plt.show()

    # (D) ëŒ€í‘œ íŠ¸ë¦¬ì—ì„œ í•´ë‹¹ ìƒ˜í”Œì˜ ê²°ì • ê²½ë¡œ
    Xt = pre.transform(X_row)
    path_df, leaf_id = tree_decision_path_for_one(rep_tree, Xt, feat_names, rf.classes_)
    print("\n=== Decision path in representative tree ===")
    display(path_df)
    print("leaf_id =", leaf_id)

    # (E) ì°¸ê³ : target_classì— ë†’ì€ í™•ë¥ ì„ ì¤€ íŠ¸ë¦¬ TOP-N
    c_idx = list(rf.classes_).index(target_class)
    tree_scores = all_tree_df[target_class].sort_values(ascending=False).head(topn_trees)
    print(f"\n=== Top-{topn_trees} trees by P({target_class}) ===")
    display(tree_scores)

    return {
        "pred": pred,
        "mean_proba": mean_proba,
        "std_proba": std_proba,
        "tree_proba_table": all_tree_df,
        "rep_tree_idx": rep_idx,
        "path_df": path_df
    }


# =========================
# ì‚¬ìš© ì˜ˆì‹œ
# =========================
i = 0
x0 = X_test.iloc[[i]]          # DataFrame 1í–‰ ìœ ì§€ê°€ í¬ì¸íŠ¸!
out = explain_random_forest_sample(rf_model, x0, plot_max_depth=3)
```

ëœë¤í¬ë ˆìŠ¤íŠ¸(RandomForest)ëŠ” ì—¬ëŸ¬ ê°œì˜ ê²°ì •íŠ¸ë¦¬ì˜ ì˜ˆì¸¡ì„ í‰ê· ë‚´ì–´ ìµœì¢… í´ë˜ìŠ¤ë¥¼ ê²°ì •í•˜ëŠ” ì•™ìƒë¸” ëª¨ë¸ì´ë‹¤. ë³¸ ìƒ˜í”Œì— ëŒ€í•´ íŠ¸ë¦¬ë“¤ì˜ ì˜ˆì¸¡í™•ë¥ ì„ í‰ê· ë‚¸ ê²°ê³¼, ìµœì¢… ì˜ˆì¸¡ í´ë˜ìŠ¤ëŠ” Adelieì´ë‹¤. í‰ê·  ì‚¬í›„í™•ë¥ (mean proba)ì€ Adelie 0.853333, Chinstrap 0.146667, Gentoo 0.000000ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ Adelieì¼ ê°€ëŠ¥ì„±ì´ ê°€ì¥ ë†’ë‹¤ê³  íŒë‹¨ëœë‹¤.

íŠ¸ë¦¬ë³„ ì˜ˆì¸¡í™•ë¥ ì˜ í‘œì¤€í¸ì°¨(std proba)ëŠ” Adelie 0.354364, Chinstrap 0.354364, Gentoo 0.000000ì´ë‹¤. ì´ëŠ” Adelieì™€ Chinstrapì— ëŒ€í•´ íŠ¸ë¦¬ë“¤ ì‚¬ì´ì˜ ì˜ê²¬ ë¶ˆì¼ì¹˜ê°€ ì¡´ì¬í•¨ì„ ì˜ë¯¸í•œë‹¤. íŠ¹íˆ í™•ë¥ ì´ 0 ë˜ëŠ” 1ì²˜ëŸ¼ ê·¹ë‹¨ì ìœ¼ë¡œ ê°ˆë¦¬ëŠ” íŠ¸ë¦¬ê°€ ì„ì—¬ ìˆì„ ë•Œ í‘œì¤€í¸ì°¨ê°€ í¬ê²Œ ë‚˜íƒ€ë‚˜ëŠ” ê²½í–¥ì´ ìˆë‹¤. ë°˜ë©´ GentooëŠ” í‰ê· ë„ 0ì´ê³  í‘œì¤€í¸ì°¨ë„ 0ì´ë¯€ë¡œ, ê±°ì˜ ëª¨ë“  íŠ¸ë¦¬ê°€ Gentoo ê°€ëŠ¥ì„±ì„ ì‚¬ì‹¤ìƒ ë°°ì œí•œ ìƒíƒœì´ë‹¤.

ë‹¤ìˆ˜ê²° ê´€ì ì˜ ì§‘ê³„(top class vote count)ì—ì„œ ì „ì²´ 300ê°œ íŠ¸ë¦¬ ì¤‘ 256ê°œ íŠ¸ë¦¬ê°€ Adelie, 44ê°œ íŠ¸ë¦¬ê°€ Chinstrapì„ ìµœì¢… í´ë˜ìŠ¤ë¡œ ì„ íƒí•˜ì˜€ë‹¤. Gentooë¥¼ ìµœì¢… í´ë˜ìŠ¤ë¡œ ì„ íƒí•œ íŠ¸ë¦¬ëŠ” ì—†ì—ˆë‹¤. ë”°ë¼ì„œ â€˜ëŒ€ë¶€ë¶„ì˜ íŠ¸ë¦¬ëŠ” Adelieë¡œ ë¶„ë¥˜í•˜ë˜, ì¼ë¶€ íŠ¸ë¦¬ëŠ” Chinstrapìœ¼ë¡œ ë¶„ë¥˜í•˜ëŠ”â€™ êµ¬ì¡°ë¼ê³  í•´ì„ëœë‹¤.

ëŒ€í‘œ íŠ¸ë¦¬(representative tree)ëŠ” ì „ì²´ í‰ê·  ì˜ˆì¸¡ê³¼ ë™ì¼í•œ ëª©í‘œ í´ë˜ìŠ¤(Adelie)ë¥¼ ë‚´ëŠ” íŠ¸ë¦¬ë“¤ ì¤‘ì—ì„œ, í•´ë‹¹ ìƒ˜í”Œì— ëŒ€í•´ Adelie í™•ë¥ ì„ ê°€ì¥ ë†’ê²Œ ì‚°ì¶œí•œ íŠ¸ë¦¬ë¡œ ì„ íƒëœ ê²ƒì´ë‹¤. ì„ íƒëœ ëŒ€í‘œ íŠ¸ë¦¬ëŠ” index=0ì´ë©°, ì´ íŠ¸ë¦¬ì—ì„œì˜ Adelie ì˜ˆì¸¡í™•ë¥ (tree_proba)ì€ 1.0000ìœ¼ë¡œ ì™„ì „ í™•ì‹ ì— í•´ë‹¹í•œë‹¤.

ëŒ€í‘œ íŠ¸ë¦¬ì—ì„œì˜ ê²°ì • ê²½ë¡œ(decision path)ëŠ” ì „ì²˜ë¦¬(í‘œì¤€í™” ë° ì›í•«ì¸ì½”ë”©) ì´í›„ì˜ íŠ¹ì§• ê³µê°„ì—ì„œ ì´ë£¨ì–´ì§„ ë¶„ê¸° ê·œì¹™ì˜ ì—°ì‡„ì´ë‹¤. ì²« ë¶„ê¸°ì—ì„œ num__bill_length_mmì˜ í‘œì¤€í™” ê°’ì´ -0.470502ì´ê³  ì„ê³„ê°’ -0.315119 ì´í•˜ì´ë¯€ë¡œ ì™¼ìª½(LEFT)ìœ¼ë¡œ ì´ë™í•œë‹¤. 

ë‹¤ìŒ ë¶„ê¸°ì—ì„œ num__bill_depth_mmì˜ í‘œì¤€í™” ê°’ì´ 0.663008ì´ê³  ì„ê³„ê°’ -0.235401ë³´ë‹¤ í¬ë¯€ë¡œ ì˜¤ë¥¸ìª½(RIGHT)ìœ¼ë¡œ ì´ë™í•œë‹¤. ê·¸ ê²°ê³¼ leaf_id=7ì— ë„ë‹¬í•˜ë©°, ì´ ë¦¬í”„ì˜ í´ë˜ìŠ¤ ë¶„í¬(class_counts)ëŠ” [1.0, 0.0, 0.0]ì´ê³  ì‚¬í›„í™•ë¥ (posterior)ì€ {Adelie: 1.0, Chinstrap: 0.0, Gentoo: 0.0}ì´ë‹¤. ì¦‰ ëŒ€í‘œ íŠ¸ë¦¬ ê¸°ì¤€ìœ¼ë¡œëŠ” í•´ë‹¹ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ë¦¬í”„ì— Adelieë§Œ ì¡´ì¬í•˜ì—¬ Adelieë¡œ ë‹¨ì •í•˜ëŠ” êµ¬ì¡°ì´ë‹¤.

ì¶”ê°€ë¡œ, Adelieì— ëŒ€í•œ í™•ë¥ ì´ 1.0ì¸ íŠ¸ë¦¬ê°€ ìƒìœ„ 10ê°œ(ì˜ˆ: 298, 0, 1, 2, 3, 297, 5, 6, 7, 8 ë“±)ë¡œ í™•ì¸ëœë‹¤. ì´ëŠ” ì¼ë¶€ íŠ¸ë¦¬ë“¤ì´ í•´ë‹¹ ìƒ˜í”Œì„ Adelieë¡œ ë§¤ìš° ê°•í•˜ê²Œ(í™•ë¥  1.0) ë¶„ë¥˜í•˜ê³  ìˆìŒì„ ë³´ì—¬ì£¼ëŠ” ê·¼ê±°ì´ë‹¤. ë‹¤ë§Œ ì „ì²´ì ìœ¼ë¡œëŠ” Chinstrapìœ¼ë¡œ ë¶„ë¥˜í•˜ëŠ” íŠ¸ë¦¬ë„ ì¼ì • ë¹„ìœ¨ ì¡´ì¬í•˜ë¯€ë¡œ, ëª¨ë¸ ë‚´ë¶€ì—ì„œëŠ” Adelieì™€ Chinstrapì˜ ê²½ê³„ ê·¼ì²˜ì— ìœ„ì¹˜í•œ ìƒ˜í”Œì¼ ê°€ëŠ¥ì„±ì´ ìˆìŒì„ ì‹œì‚¬í•œë‹¤.

```text
=== RandomForest final prediction (mean proba) ===
pred = Adelie

[mean proba]
Adelie       0.853333
Chinstrap    0.146667
Gentoo       0.000000
dtype: float64

[std proba]  (íŠ¸ë¦¬ë“¤ ì˜ê²¬ ë¶ˆì¼ì¹˜ ì •ë„)
Adelie       0.354364
Chinstrap    0.354364
Gentoo       0.000000
dtype: float64

[top class vote count]
Adelie       256
Chinstrap     44
Name: count, dtype: int64

=== Representative tree ===
index=0, target_class=Adelie, tree_proba=1.0000
```
![](images/classification_ml_category_rfprocess.png){fig-align="center" width="100%"}


node 0ì—ì„œ num__bill_length_mm = -0.4705 ì´ê³  ê¸°ì¤€ì´ -0.3151ì´ë‹ˆê¹Œ -0.4705 <= -0.3151 â†’ LEFTë¡œ ê°

node 1ì—ì„œ num__bill_depth_mm = 0.6630 ê¸°ì¤€ -0.2354ë³´ë‹¤ í¬ë‹ˆê¹Œ â†’ RIGHTë¡œ ê°

node 7 (LEAF) ë„ì°©
class_counts = [1.0, 0.0, 0.0] â†’ ì´ ì ë…¸ë“œì— ë„ë‹¬í•œ (í•™ìŠµ ë°ì´í„° ê¸°ì¤€) í´ë˜ìŠ¤ ë¶„í¬ê°€ Adelieë§Œ ìˆì—ˆë‹¤ëŠ” ëœ»ì´ë‹¤.  ê·¸ë˜ì„œ posterior = {'Adelie': 1.0, ...}ë¡œ Adelie í™•ë¥  100%ê°€ ëœë‹¤.

class_counts/posteriorëŠ” â€œí…ŒìŠ¤íŠ¸ ìƒ˜í”Œì˜ ì§„ì§œ ì •ë‹µâ€ì´ ì•„ë‹ˆë¼, ê·¸ leafì— ëª¨ì¸ í•™ìŠµ ìƒ˜í”Œ(ë˜ëŠ” ê°€ì¤‘ì¹˜)ì˜ ë¶„í¬ë¼ì„œ íŠ¸ë¦¬ê°€ ê·¸ë ‡ê²Œ â€œë¯¿ëŠ”ë‹¤â€ëŠ” ê·¼ê±°ì˜ˆìš”.

leaf_id = 7: ì´ ìƒ˜í”Œì´ ëŒ€í‘œ íŠ¸ë¦¬ì—ì„œ ìµœì¢…ì ìœ¼ë¡œ ë„ì°©í•œ ì ë…¸ë“œì˜ IDê°€ 7ì´ë¼ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.

=== Top-10 trees by P(Adelie) ===: ëœë¤í¬ë ˆìŠ¤íŠ¸ì—ëŠ” íŠ¸ë¦¬ê°€ ì—„ì²­ ë§ë‹¤(ì˜ˆ: 300ê°œ). ê·¸ì¤‘ì—ì„œ ì´ ìƒ˜í”Œì— ëŒ€í•´ Adelie í™•ë¥ ì„ ê°€ì¥ ë†’ê²Œ ì¤€ íŠ¸ë¦¬ 10ê°œë¥¼ ë³´ì—¬ì¤€ ê±°ì˜ˆìš”.

ì˜ˆë¥¼ ë“¤ì–´: íŠ¸ë¦¬ 298ë²ˆì€ ì´ ìƒ˜í”Œì„ Adelie í™•ë¥  1.0ìœ¼ë¡œ ë´¤ë‹¤ íŠ¸ë¦¬ 0,1,2,...ë„ 1.0ìœ¼ë¡œ ë´¤ë‹¤. ì¦‰, ì—¬ëŸ¬ íŠ¸ë¦¬ê°€ ì•„ì£¼ ê°•í•˜ê²Œ Adelieë¡œ ë™ì˜í•˜ê³  ìˆëŠ” ìƒí™©ì´ë¼ ëœë¤í¬ë ˆìŠ¤íŠ¸ ìµœì¢… ì˜ˆì¸¡ë„ í”ë“¤ë¦¼ì´ ì ìŠµë‹ˆë‹¤.

```text
=== Decision path in representative tree ===
node	type	feature	value_in_node	threshold	go	class_counts	posterior
0	0	SPLIT	num__bill_length_mm	-0.470502	-0.315119	LEFT(<=)	NaN	NaN
1	1	SPLIT	num__bill_depth_mm	0.663008	-0.235401	RIGHT(>)	NaN	NaN
2	7	LEAF	NaN	NaN	NaN	NaN	[1.0, 0.0, 0.0]	{'Adelie': 1.0, 'Chinstrap': 0.0, 'Gentoo': 0.0}

leaf_id = 7

=== Top-10 trees by P(Adelie) ===
Adelie
298	1.0
0	1.0
1	1.0
2	1.0
3	1.0
297	1.0
5	1.0
6	1.0
7	1.0
8	1.0
```