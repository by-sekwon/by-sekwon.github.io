---
title: "머신러닝·딥러닝 개념"
---

##### [머신·딥러닝 개념] 섹션 메인(머신러닝·딥러닝)

이 섹션에서는 머신러닝과 딥러닝의 핵심 개념과 방법론을 다룬다.
<br>
통계학적 모형과의 연결, 예측과 분류, 평가와 일반화, 그리고 딥러닝의 기본 구조를 체계적으로 정리한다.

⸻

[머신·딥러닝 개념] 개요

머신러닝은 데이터를 이용해 규칙을 “학습”하여 예측·분류를 수행하는 방법의 집합이다.
<br>
문제 설정(입력 X, 출력 Y), 학습 데이터와 테스트 데이터, 학습 목표(손실 최소화)의 틀을 소개한다.
<br>
또한 통계적 추론과의 차이(설명 vs 예측) 및 공통점(모형화·불확실성)을 함께 정리한다.

⸻

[머신·딥러닝 개념] MLDL 개념 1

학습은 보통 “모형 + 손실함수 + 최적화”로 구성된다.
<br>
손실함수(회귀의 MSE, 분류의 교차엔트로피 등)가 목표를 정의하고, 최적화가 파라미터를 갱신한다.
<br>
편향–분산 트레이드오프와 과적합/과소적합 개념을 통해 일반화의 핵심을 이해한다.

⸻

[머신·딥러닝 개념] MLDL 개념 2

일반화 성능은 데이터 분할(훈련/검증/테스트)과 교차검증으로 평가한다.
<br>
특성공학(스케일링, 인코딩), 규제(릿지/라쏘), 조기종료 등은 과적합을 줄이는 대표 전략이다.
<br>
또한 데이터 누수(leakage)와 재현성(고정 시드, 파이프라인)의 중요성을 강조한다.

⸻

[머신·딥러닝 개념] 지도학습

지도학습은 정답 라벨 Y가 주어진 데이터로부터 f(X)를 학습하는 방법이다.
<br>
회귀(연속형 Y)와 분류(범주형 Y) 문제로 나뉘며, 예측 성능과 해석 가능성이 모두 중요하다.
<br>
대표 모형(선형모형, 트리, SVM, 신경망 등)의 역할과 적용 상황을 개괄한다.

⸻

[머신·딥러닝 개념] 비지도학습

비지도학습은 라벨 없이 데이터의 구조를 찾아 요약·군집화·표현학습을 수행한다.
<br>
차원축소(PCA 등), 군집(K-means 등), 밀도기반 방법을 통해 패턴과 이상치를 탐색한다.
<br>
“정답이 없는 문제”이므로 목적에 맞는 평가 기준과 해석이 특히 중요하다.

⸻

[머신·딥러닝 개념] 평가

모형 평가는 “훈련 성능”이 아니라 “새 데이터 성능(일반화)”을 기준으로 한다.
<br>
회귀는 RMSE/MAE/R^2, 분류는 정확도·정밀도·재현율·F1·ROC-AUC 등을 사용한다.
<br>
불균형 데이터에서의 지표 선택, 임계값 설정, 비용 민감도까지 함께 다룬다.

⸻

[머신·딥러닝 개념] 불확실성

같은 예측값이라도 그 예측이 얼마나 믿을 만한지(불확실성)는 별도의 문제다.
<br>
데이터 잡음(aleatoric)과 모형 불확실성(epistemic)을 구분하고,
<br>
예측구간/신뢰구간, 부트스트랩, 앙상블, 분위수 회귀 등 대표 접근을 소개한다.

⸻

[머신·딥러닝 예측방법] MLDL 방법론 소개

AI·ML 방법론은 “데이터 → 모형 → 평가 → 개선”의 반복 과정으로 성능을 높인다.
<br>
문제 정의(목표/지표), 데이터 분할, 파이프라인 구성, 하이퍼파라미터 튜닝의 전체 흐름을 개관한다.
<br>
또한 예측 중심 접근이 통계적 추론과 어떻게 연결되는지 큰 그림을 제시한다.

⸻

[머신·딥러닝 개념] 딥러닝이란?

딥러닝은 다층 신경망을 사용해 복잡한 비선형 패턴을 학습하는 방법이다.
<br>
층(layer), 활성화함수, 손실함수, 역전파와 경사하강법을 통해 학습이 이루어진다.
<br>
정규화(드롭아웃, 배치정규화), 초기화, 학습률 스케줄링 등 실무적 안정화 기법도 함께 다룬다.

⸻

[머신·딥러닝 개념] 딥러닝방법론 기초

딥러닝은 다층 신경망을 사용해 입력 X로부터 출력 Y를 예측하는 함수 $f_\theta(X)$ 를 학습하는 방법이다.
<br>
층(layer)을 쌓아 특징을 단계적으로 변환하고, 활성화함수로 비선형성을 도입해 복잡한 패턴을 표현한다.
<br>
학습은 손실함수(회귀: MSE, 분류: cross-entropy)를 최소화하도록 역전파(backpropagation)로 기울기를 계산하고, 
<br>
경사하강법/확률적 경사하강법(SGD)으로 파라미터를 갱신하는 과정으로 이루어진다.
<br>
실무에서는 과적합과 학습 불안정을 줄이기 위해 정규화(드롭아웃, 가중치 감쇠), 정규화·안정화 기법(배치정규화), 
<br>
초기화, 학습률 스케줄링, 조기 종료 등의 설정을 함께 조정한다.