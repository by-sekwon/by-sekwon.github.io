![myself.png](media/image1.png){width="4.076208442694663in"
height="2.9841404199475066in"}Chapter 1. 서론

vol 3. 설문조사

section 5. 데이터 처리

wolfpack se kwon

<https://sites.google.com/view/wolfpack61>

권세혁교수 통계노트시리즈

설문조사 데이터 처리 단계는 다음과 같다.

데이터 수집: 설문 응답을 수집하는 과정

텍스트 데이터 코딩: 비정형 응답을 수치화하는 과정

데이터 입력: 설문 데이터를 전산 시스템에 입력

편집 및 오류 확인: 데이터의 논리적 오류 및 누락값 검토

결측값 대체: 누락된 데이터를 보완하는 과정

가중치 생성: 표본 편향을 조정하기 위한 가중치 적용

분산 추정: 추정 통계 품질 측정값

1코딩 coding

코딩은 설문 조사에서 데이터를 체계적으로 정리하고 분석하는 데 필수적인
과정이다. 단순한 범주형 데이터는 명확한 숫자로 변환될 수 있지만, 자유
응답형 데이터나 산업 분류와 같은 정보는 복잡한 코딩이 필요하다. 또한,
코딩 오류는 조사 결과에 중대한 영향을 미칠 수 있으므로, 코딩의 정확성과
일관성을 유지하는 것이 중요하다.

예를 들어, 설문지에서 응답자가 자신의 상태를 체크할 수 있는 폐쇄형
질문과 같이 명확한 범주가 있는 경우 각 응답 숫자로 부호화 하는 것이
비교적 간단한 코딩 방식이다.

개방형 질문은 응답자가 자유롭게 답변할 수 있는 형태로, 다양한 방식으로
서술될 수 있어 코딩이 어렵다. 다음은 개방형 질문의 코딩 방법에 대한
설명이다.

예비 분석: 수집된 응답을 검토하여 공통 패턴을 파악한다. 응답 내용을
기반으로 주요 범주를 설정한다.

코드북 개발: 응답을 분류할 코드 체계를 설계한다. 각 코드에 대한 명확한
정의를 포함한다. 예를 들어, 산림 활용 관련 개방형 질문이 있다면, 1 =
목재 생산, 2 = 레크리에이션(산림욕, 캠핑 등), 3 = 환경 보호, 4 = 연구 및
교육, 5 = 기타

응답 매핑: 개별 응답을 코드북에 따라 적절한 코드로 변환한다. 응답이 여러
개의 범주에 해당할 경우, 우선순위 규칙을 적용하거나 다중 코드를 허용할
수 있다.

신뢰성 검토: 여러 명의 분석자가 같은 응답을 동일한 코드로 부여하는지
확인한다. 코딩 일관성 검증을 위해 상호 신뢰도 테스트를 수행한다.

1)  코딩의 본질

코딩은 단순한 변환 행위가 아니라 요약의 과정이다. 코딩은 개별 응답을
특정 코드로 묶어 데이터 분석이 가능하도록 정리하는 역할을 한다.

효과적인 코딩 시스템의 필수 요소

고유한 숫자 부여: 코드는 통계 분석을 위해 고유한 숫자로 관리되어야 한다.

텍스트 라벨 추가: 코드에는 모든 응답을 설명할 수 있는 텍스트 라벨이
필요하다.

완전한 포괄성: 모든 응답이 최소한 하나의 코드로 할당될 수 있어야 한다.

상호 배타성: 동일한 응답이 두 개 이상의 코드에 속하지 않아야 한다.

실용적인 코드 범주 설정: 분석 목적에 맞는 적절한 코드 개수를 유지해야
한다.

이러한 원칙은 산림 통계 조사와 같은 연구에서도 적용 가능하다. 예를 들어,
응답자가 산림을 이용하는 목적을 서술하면 이를 명확한 코드(예: 1=목재
생산, 2=산림 복지, 3=환경 보호)로 변환해야 한다.

코드 구조의 지속적인 검토와 개선

사전 정의된 코딩 구조를 사용하더라도 일부 응답은 쉽게 코드로 변환되지
않는다. 이러한 문제를 해결하기 위해 초기 응답 샘플을 바탕으로 테스트하여
코딩 구조를 보완하는 것이 일반적이다. 하지만, 새로운 응답이 기존
카테고리에 맞지 않는 경우, 기존 코드 구조를 재검토해야 한다. 예를 들어,
기존의 코드 체계가 새로운 산림 이용 유형(예: 탄소중립을 위한 산림
보전)과 잘 맞지 않는다면 새로운 코드가 추가될 필요가 있다.

모든 응답을 포괄하는 코딩 체계 설계

코딩 구조는 모든 유형의 응답을 수용할 수 있도록 설계되어야 한다. 이를
위해 다음과 같은 전략을 사용한다:

응답이 없는 경우를 위한 코드 설정: 질문에 대한 응답이 없는 경우,
["]{dir="rtl"}미확인["]{dir="rtl"}을 의미하는 코드(예: 9)를 할당.

특정 질문이 해당 응답자에게 적용되지 않는 경우, ["]{dir="rtl"}적용 불가"
코드(예: 0)를 부여.

기타 특수 응답 처리: 질문을 거부한 응답자(예: ["]{dir="rtl"}답하고 싶지
않음")나 ["]{dir="rtl"}잘 모르겠다"는 응답도 별도로 코딩하여 데이터
분석에서 구분할 수 있도록 해야 한다. 예를 들어, 단일 숫자 코드에서는
["]{dir="rtl"}9"를 미확인 값으로, ["]{dir="rtl"}0"을 적용 불가 값으로
사용하고, 두 자리 숫자 코드에서는 각각 ["]{dir="rtl"}99"와
["]{dir="rtl"}00"을 사용할 수 있다.

결론 및 시사점

코딩은 단순한 변환이 아니라 연구 목적에 맞는 요약의 과정이며, 코드의
개수와 분류 체계를 신중하게 설계해야 한다.

상호 배타성과 포괄성을 유지하여 데이터 분석이 용이하도록 해야 한다.

연구 목적과 가설에 맞는 코드 구조를 설계하여 통계적으로 의미 있는 결과를
도출할 수 있어야 한다.

기존 코드 구조가 새로운 데이터에 적절히 대응하는지 지속적으로 검토하고
필요 시 수정해야 한다.

모든 응답을 고려하는 코드(응답 없음, 미확인, 적용 불가 등)를 설정하여
데이터 누락을 최소화해야 한다.

1)  필드 코딩

필드 코딩의 개념

필드 코딩은 개방형 질문의 자유로움과 폐쇄형 질문의 구조화된 응답을
결합한 방식이다.즉, 응답자는 자유롭게 서술형 답변을 제시하지만, 조사원은
해당 응답을 미리 정해진 코드 범주 중 하나로 즉시 변환한다. 이러한 방식은
응답자의 답변을 실시간으로 수집하면서 코딩까지 동시에 수행할 수 있는
장점이 있다.

필드 코딩의 절차

1)  응답자에게 개방형 질문을 제시 → 자유롭게 서술형 응답을 하도록
    유도한다.

2)  조사원이 즉시 응답을 해석 → 해당 응답이 포함될 수 있는 코드 범주를
    검토한다.

3)  사전 정의된 코드 리스트와 비교하여 적절한 코드 선택 → 가장 적합한
    카테고리에 배정한다.

4)  코딩을 완료하고 데이터 저장 → 이후 데이터 분석에서 활용 가능하도록
    정리한다.

필드 코딩 장단점

+:-------:+:--------------------:+:-----------------------------------:+
| 구분    | 항목                 | 설명                                |
+---------+----------------------+-------------------------------------+
| 장점    | 즉각적인 코딩 가능   | 응답을 수집하면서 동시에 코딩을     |
|         |                      | 수행하여 사후 코딩 과정이 불필요    |
|         +----------------------+-------------------------------------+
|         | 질문에 대한 깊이     | 인터뷰어가 응답 내용을 추가로       |
|         | 있는 탐색 가능       | 탐색하여 보다 정확한 분류 가능      |
|         +----------------------+-------------------------------------+
|         | 응답자의 자유도 보장 | 완전한 폐쇄형 질문과 달리, 응답자의 |
|         |                      | 입장에서 보다 자연스러운 답변 제공  |
|         |                      | 가능                                |
+---------+----------------------+-------------------------------------+
| 단점    | 인터뷰어의 해석에    | 같은 응답이라도 조서자마다 코드     |
|         | 따른 오류 발생 가능  | 부여 방식이 다를 수 있음            |
|         +----------------------+-------------------------------------+
|         | 실시간 처리의 부담   | 조사원이 실시간으로 응답을 분석하고 |
|         |                      | 코드화해야 하므로 부담이 클 수 있음 |
|         +----------------------+-------------------------------------+
|         | 복잡한 코드 체계의   | 코드의 수가 많거나 복잡하면         |
|         | 경우 어려움          | 인터뷰어가 즉시 적절한 범주를       |
|         |                      | 선택하기 어려울 수 있음             |
+---------+----------------------+-------------------------------------+

필드 코딩과 사후 코딩 비교

  ------------ -------------------------- -------------------------------
      구분             필드 코딩                    오피스 코딩

   코딩 시점    실시간 코딩 (인터뷰 진행     조사 후 코딩 (설문 응답을
                          중)                       저장한 후)

     책임자       조사원이 직접 코드화      전문 코더가 응답을 해석하여
                                                      코드화

      장점     즉각적인 데이터 정리 가능,   보다 체계적이고 일관성 있는
                     추가 탐색 가능                  코딩 가능

      단점     인터뷰어의 주관 개입 가능,  시간이 많이 소요됨, 사후 코드
                    실시간 처리 부담                 검토 필요
  ------------ -------------------------- -------------------------------

3)  코딩 품질 지표

코딩 과정에서 개념적 오류나 실행의 비일관성이 발생할 수 있으며, 이는
조사 데이터의 품질 저하로 이어질 수 있다.

코딩 구조의 취약점

코딩 체계가 잘못 설계되면 비동등한 응답이 동일한 코드 범주에 포함될 수
있다. 이로 인해 체계적인 오류가 발생할 수 있다.

예제: 학력(고졸자, 대졸자)과 소득분석에서의 오류, 3년 전 과정을 이수한
고졸과 검정고시 고졸 학력을 분리하여 코딩해야 한다. 따라서 코딩 구조를
보다 정교하게 설계하여 이러한 오류를 방지하는 것이 중요하다.

코더 변량 coder variance

코딩 품질에 대한 연구는 주로 코더 간 코딩 결정의 차이로 인해 발생하는
조사 추정치의 변동성에 초점을 맞춘다. 코더 변량은 조사 데이터의 전체
변동성 중 코딩 구조 사용 패턴의 차이로 인해 발생하는 요소이다. 이는
조사원 변량과 유사한 개념이며, 서베이 결과의 신뢰도에 영향을 미칠 수
있다.

코더마다 같은 코딩 구조를 다르게 사용할 가능성이 있음

특정 코드 범주를 더 자주 사용하는 경향

특정 응답을 해석하는 방식의 차이

["]{dir="rtl"}기타)", ["]{dir="rtl"}명확히 지정되지 않음["]{dir="rtl"}와
같은 잔여 코드를 사용할 가능성

코더별 코딩 편차를 측정하는 방법

내집단 interclass 상관계수를 활용하여 코더 간 일관성을 분석

영국에서 수행된 연구 결과에 따르면 평균 ρ 값이 0.001임

이는 조사원 효과보다는 작은 수준이지만, 여전히 조사 통계의 변동성에
영향을 줄 수 있음

코더 변량이 조사 통계에 미치는 영향

코딩 과정에서의 작은 차이도 조사 결과의 통계적 변동성을 증가시킬 수 있음

코더 변량이 조사 통계의 분산에 미치는 영향을 나타내는 공식:

$Deff = 1 + \rho_{c}(m - 1)(1 - r)$, 여기서 $\rho_{c}$은 코더의 내집단
상관계수, $m$은 개별 코더가 코딩한 평균 사례 수, $r$은 특정 코드의
신뢰도이다.

코더 변량이 조사 결과에 미치는 영향

동일한 코드 구조를 적용하더라도 코더마다 코딩 방식이 다를 수 있으며,
이는 조사 추정치의 불안정성을 증가시킬 수 있다.

훈련된 코더는 일반적으로 조사원보다 더 작은 변동성을 보이지만, 코더의
업무량이 조사원보다 훨씬 많기 때문에 표준오차의 증가가 발생할 가능성도
있다.

2수치 데이터를 파일에 입력하기

데이터 입력의 개념

데이터 캡처는 숫자 데이터를 전자 파일에 입력하는 과정을 의미한다. 데이터
입력 방식은 데이터 수집 방법에 따라 달라진다.

컴퓨터 지원 조사(CAPI)에서는 조사원 또는 응답자가 직접 데이터를 입력하는
경우가 많다.

터치톤 데이터 입력 및 음성 인식 조사에서는 응답자가 직접 전자 파일에
데이터를 입력한다.

종이 설문지 기반 조사에서는 데이터 입력 담당자가 수작업으로 숫자를
입력하거나 마크 문자 인식, 광학 문자 인식(OCR) 기술을 활용하여 데이터를
변환할 수 있다.

인간 데이터 입력 방식의 한계

사람이 직접 데이터를 입력하는 방식은 비용이 많이 드는 설계 요소이다.

이에 따라, 최근에는 컴퓨터 지원 방식을 활용하여 노동 비용을 절감하려는
경향이 증가하고 있다.

사람이 데이터를 입력할 때 일반적으로 100% 재입력 및 검증을 수행하지만
그럼에도 불구하고 오류발생 가능성이 존재한다.

입력 과정이 정확하게 수행될 가능성이 높더라도, 비용 문제로 인해
연구자들은 컴퓨터 지원 데이터 수집 방식을 선호하는 경향이 있다.

3데이터 편집 editing

데이터 편집의 개념

편집은 통계 분석 전에 수집된 데이터를 검사하고 수정하는 과정을 의미한다.
이는 설문 응답의 정확성과 일관성을 보장하기 위한 필수적인 절차이다. 편집
과정은 인터뷰어, 감독자, 데이터 입력 담당자, 전문가 또는 컴퓨터
소프트웨어를 통해 수행될 수 있다. 편집의 궁극적인 목표는 데이터가 원래
설계된 측정 방식과 일치하도록 검증하는 것이다.

편집의 주요 내용

1\) 조사원 또는 응답자가 기록한 데이터를 보정하여 품질을 향상한다. 2)
코딩 및 결측치 대체도 편집의 일부로 포함될 수 있다. 3) 데이터가
논리적으로 정합성을 유지하도록 정리하는 것이 핵심이다.

데이터 편집 주요 유형

  ----------------- ------------------------- ----------------------------
      편집 유형               설명                        예시

      범위 편집      데이터 값이 허용된 범위  연령 값이 1개월 이상, 120년
                        내에 있는지 확인             이하인지 검사

      비율 편집         특정 값 간 비율이      농장에서 생산된 우유 갤런
                     논리적으로 맞는지 확인      수와 젖소의 수 비율이
                                                     적절한지 확인

  이력 데이터 비교     이전 조사 데이터와       1차 조사와 2차 조사에서
                     비교하여 일관성을 점검    가구원 수가 유사한지 확인

      균형 편집     여러 변수의 합이 일정해야 집, 직장, 기타 장소에서 보낸
                         하는 경우 확인        시간의 합이 100%인지 검사

  최대·최소 값 확인  비정상적으로 큰 값이나        극단적인 소득 값이
                    작은 값이 존재하는지 검사       존재하는지 확인

     일관성 편집    논리적 관계가 성립하는지    12세 미만 응답자의 혼인
                              점검              상태는 \'미혼\'이어야 함
  ----------------- ------------------------- ----------------------------

CAPI와 편집

최근에는 컴퓨터 기술이 발전하면서 편집 과정을 실시간으로 수행하는 경우가
많아졌다. 응답자가 설문을 완료하기 전에 데이터 오류를 수정하도록 유도할
수 있다. 하지만, 응답자가 특정 패턴의 답변을 계속 고집하면 인터뷰어의
논리가 실제 응답자의 상황을 반영하지 못할 수도 있다.

강제 체크: 반드시 수정해야 하는 오류

소프트 체크: 이상하지만 허용될 수 있는 응답을 경고만 제공

데이터 편집 발전

편집 시스템은 점점 규칙 기반 및 컴퓨터 지원 방식으로 전환되고 있다.

자동화된 편집 시스템은 비용 절감과 데이터 품질 향상을 동시에 가능하게
한다.

데이터 수집 단계에서 편집을 통합하여 사후 편집이 감소할 가능성이 크다.

편집 시스템은 점점 더 전문가 지식(AI)을 반영하는 방향으로 발전하고 있다.

Chapter 2. 가중치 산정

조사 표본에서 가중치는 다양한 상황에서 활용된다. 표본 설계가 단순하지
않고 복잡한 층화, 클러스터링, 불균형한 응답률 등의 문제를 포함할 때,
가중치는 이를 보정하는 중요한 역할을 한다. 여기서는 복잡한 조사에서 흔히
사용되는 가중치 조정 방식을 설명하고 있지만, 여기서 다룬 내용 외에도
다양한 가중치 부여 방법이 존재할 수 있다. 보다 심층적인 논의와 구체적인
방법론에 대해서는 Kalton(1981)과 Bethlehem(2002)의 연구를 참고하기
바란다.

11단계 비율 조정 가중치

복잡한 다단계 표본 설계에서는 기본 표본 단위(PSU, Primary Selection
Unit)를 크기 척도에 비례하는 확률로 선택한다. 이러한 표본 설계에서는
모집단의 규모를 나타내는 대체 지표가 표본 프레임에서 제공되며 이를
이용해 표본을 추출한다.

1단계 비율 조정 가중치 개념

균등 확률 표본(EPSM, Equal Probability Sample)을 사용하는 경우 각 층에서
최종적으로 선택된 단위의 수는 해당 층 내 모집단 크기에 비례해야 한다.
예를 들어, 특정 층이 전체 가구 모집단의 0.5%를 차지한다고 가정하면, 이
층 내에서 1차 표본 단위(PSU, 일반적으로 시군구)를 선택하고, 해당 층의
모집단 크기를 추정할 수 있다.

$$\text{Estimated Stratum Population Total} = \frac{\text{Population Total in Selected PSU}}{\text{Probability of Selecting PSU}}$$

즉, 층 전체의 모집단 규모를 반영하여 선택된 PSU의 모집단 총계를 기반으로
가중치를 조정한다. 이 조정의 핵심 목표는 층 내 다른 PSU가 선택되었을
경우에도 일관된 추정치를 유지할 수 있도록 하는 것이다.

실질적인 가중치 적용

선택된 PSU에 포함된 모든 응답자에 대해 새로운 가중치 변수가 생성된다. 이
값은 1단계 비율 조정 가중치, $W_{i1}$와 동일하게 설정된다. 여기서
["]{dir="rtl"}1"이라는 첨자는 이 가중치가 여러 가중치 중 첫 번째
단계임을 나타내며 대문자 $W$는 이 가중치가 표본 데이터가 아닌 프레임
모집단 기반임을 나타낸다.

2차등 선택 확률 가중치

조사에서 특정 모집단을 과소 또는 과대표본으로 포함할 경우 표본이 전체
모집단을 정확히 반영하지 못할 수 있다. 이를 보정하기 위해 차등 선택 확률
가중치를 사용한다.

성폭력 피해 경험을 조사에서 전체 인구는 1,000명이며 남성은 600명, 여성은
400명이라 하자. 이제, 표본 크기를 200명으로 설정한다고 가정하자.

비례 배분(EPSEM, Equal Probability Selection Method)

모집단의 성비가 남성 60%, 여성 40%인 상황에서 표본을 추출할 때, 이를
그대로 반영하면 남성 120명, 여성 80명으로 표본이 구성된다. 이는 모집단의
성비를 유지하는 비례 배분 방식으로, 표본이 모집단을 대표하도록
설계되었기 때문에 별도의 가중치를 적용할 필요가 없다. 남녀 가중치는 모두
$5 = 1/(1/5)$이다.

차등 배분(Disproportionate Allocation)

그러나 성폭력 피해율이 일반적으로 여성에서 더 높게 나타나는 경향이
있으므로, 보다 정밀한 분석을 위해 여성의 표본 수를 증가시킬 필요가 있다.
여성 표본의 크기를 인위적으로 늘리면 보다 많은 사례를 확보할 수 있어
통계적 신뢰도를 높일 수 있지만, 이로 인해 여성 집단이 과대표본이 되는
문제가 발생할 수 있다. 따라서, 조사 결과를 모집단 전체로 일반화하기
위해서는 가중치를 적용하여 남성과 여성의 비율을 원래 모집단과 일치시키는
조정이 필요하다.

성폭력 피해율을 보다 정확히 분석하기 위해 여성 표본의 비율을
증가시키기로 결정한다. 남성과 여성의 표본을 동일한 수 100명 씩으로
배분한다고 가정하자. 남성 표본 비율은 1/6이고 여성 표본 비율 1/4이므로
남성 가중치는 6, 여성 가중치는 4이다.

가중 평균 적용

조사 결과 성폭력 피해 경험이 있는 비율이 다음과 같다고 가정한다. 남성
피해율은 10% (조사된 남성 100명 중 10명 피해 경험), 여성 피해율은 30%
(조사된 여성 100명 중 30명 피해 경험)이다.

${\overline{Y}}_{w} = \frac{\sum w_{i}Y_{i}}{\sum w_{i}}$, $w_{i}$ 성별
총 가중치, 남성 (100x6), 여성 (100x4)

$$\text{추정 피해율} = \frac{(10\% \times 600) + (30\% \times 400)}{600 + 400} = 18\%$$

가중치 조정이 필요한 이유

여성 표본이 인위적으로 증가하면서 과대표본이 되었기 때문에 조사 결과를
모집단으로 일반화하려면 가중치를 적용해야 한다.

가중치를 적용하지 않으면 여성의 피해율이 실제보다 더 크게 반영될 수
있다.

가중 평균을 통해 모집단의 성비를 고려한 성폭력 피해율을 보다 정확하게
추정할 수 있다.

성폭력 피해 조사에서 차등 선택 확률 가중치의 필요성

여성의 성폭력 피해율이 남성보다 높은 경향이 있음 → 따라서, 여성 표본을
늘려서 보다 정밀한 분석이 필요하다.

여성 표본을 증가시키면 과대표본 문제가 발생 → 이를 해결하기 위해
가중치를 적용하여 모집단을 정확히 반영해야 한다.

가중치를 적용하면 전체 인구에서의 피해율을 정확하게 추정 가능 → 남성과
여성의 비율을 고려하여 성폭력 피해율을 조정할 수 있다.

3단위 무응답 조정을 위한 가중치

1)  무응답의 문제와 표본 구성

성폭력 피해조사에서는 무응답이 발생할 가능성이 높다. 특히 성폭력 피해
조사와 같은 민감한 주제에서는 일부 응답자가 조사 참여를 거부할 확률이
크다. 성폭력 피해 조사를 위해 모집단 1,000명 중 200명을 표본으로
선정한다고 가정하자.

- 모집단의 성비: 남성 600명 (60%), 여성 400명 (40%)

- 비례 배분 방식 표본: 남성 표본 120명, 여성 표본 80명

조사 참여율은 성별에 따라 다를 수 있다. 예를 들어, 남성 응답률이 90%,
여성 응답률이 75%라고 가정하면, 실제 응답자는 다음과 같이 변한다.

- 응답한 남성: 120 $\times$ 0.9 = 108 명

- 응답한 여성: 80 $\times$ 0.75 = 60 명

이 경우, 여성이 모집단에서 과소 표본되는 문제가 발생한다. 이를 보정하기
위해 무응답 조정 가중치를 적용해야 한다.

2)  무응답 조정 가중치 계산

각 집단의 응답률의 역수를 사용하여 가중치를 설정한다.

$$W_{male} = \frac{1}{\text{응답률}_{male}} = \frac{1}{0.9} = 1.11$$

$$W_{female} = \frac{1}{\text{응답률}_{female}} = \frac{1}{0.75} = 1.33$$

3)  가중 평균 적용

성폭력 피해 경험이 있는 비율이 다음과 같다고 가정한다.

남성 피해율: 10% (응답한 남성 108명 중 10.8명 피해 경험)

여성 피해율: 30% (응답한 여성 60명 중 18명 피해 경험)

이제 무응답 가중치를 반영한 전체 모집단의 피해율을 추정한다.

$$\text{추정 피해율} = \frac{(10\% \times 119.88) + (30\% \times 79.8)}{119.88 + 79.8}$$

남성 가중치 총합: 108 $\times$ 1.11 = 119.88

여성 가중치 총합: 60 $\times$ 1.33 = 79.8

전체 가중치 총합: 119.88 + 79.8 = 199.68

무응답 조정 가중치의 필요성

성폭력 피해 조사에서는 응답률이 성별에 따라 다를 수 있다. → 예를 들어,
피해 경험이 있는 사람이 조사 참여를 꺼릴 가능성이 있다.

여성의 응답률이 낮을 경우 여성의 피해율이 실제보다 과소추정될 위험이
있다.

무응답 가중치를 적용하면, 원래 모집단의 성비를 반영한 피해율을 보다
정확하게 추정 가능하다.

4사후 가중치

1)  사후 층화 가중치 개념

사후 층화는 표본 조정의 마지막 단계에서 사용되는 가중치 조정 방법이다.
이는 표본이 모집단의 특정 분포(예: 성별, 연령, 지역 등)와 일치하도록
보정하는 역할을 한다. 성폭력 피해조사를 예로 들어보자.

이전 단계에서 비례 배분, 차등 선택 확률 가중치, 무응답 가중치를 적용하여
조사 표본을 조정했다.

하지만, 외부 자료(예: 국가 통계 데이터)에서 모집단의 성비가 실제로는
여성 52%, 남성 48%임을 알고 있다고 가정하자.

반면, 가중치 적용 후의 조사 표본에서 남성과 여성의 가중치 합이 각각
50%씩 동일하게 나타났다면?

이는 모집단과 불일치한 부분이므로, 이를 보정하기 위해 사후 층화 가중치를
적용해야 한다.

4)  사후 층화 가중치 적용 방법

1\. 현재 조사 데이터의 성별 가중치 비율을 확인한다.

조사 데이터에서 남성과 여성의 총 가중치 합이 50%씩 동일한 상태라 하자.

2\. 모집단의 성비를 반영하여 가중치 조정

실제 모집단 성비: 남성 48%, 여성 52%

조사 표본 가중치 성비: 남성 50%, 여성 50%

따라서, 남성의 가중치는 낮추고 여성의 가중치는 높여야 한다.

3\. 가중치 조정 비율 계산

남성 가중치 감소: $\frac{0.48}{0.50} = 0.96$

여성 가중치 증가: $\frac{0.52}{0.50} = 1.04$

가중 평균 적용

남성 총 가중치 조정 후 합: $0.96 \times 600 = 576.0$

여성 총 가중치 조정 후 합: $1.04 \times 400 = 416.0$

최종 성폭력 피해율:

$$\text{추정 피해율} = \frac{(10\% \times 576.0) + (30\% \times 416.0)}{576.0 + 416.0} = 18.39\%$$

Chapter 3. 결측치 대체

조사에서 응답자가 특정 질문에 답하지 않는 경우, 해당 변수의 값이
누락되는 항목 무응답이 발생할 수 있다. 이는 조사 응답자가 민감한
질문(예: 소득, 건강 상태, 범죄 피해 경험 등)에 답변을 꺼리거나, 실수로
질문을 놓쳤을 때 나타난다.

예를 들어, 성폭력 피해 조사에서 응답자가 범죄 피해 경험에 대해서는
답했지만 가해자와의 관계나 소득 수준 등의 질문에 응답하지 않은 경우가
이에 해당한다. 이러한 항목 무응답이 많아지면 분석의 신뢰도가 떨어지고,
모집단을 대표하는 결과를 얻기 어려워진다. 따라서, 조사 데이터를 보다
정확하게 활용하기 위해 결측값을 보정하는 기법 Imputation이 필요하다.

1결측값을 처리하는 방법

결측값을 무시하는 방법

이 방법에서는 결측값이 포함된 응답을 데이터에서 제외(삭제)하고 분석을
수행한다. 이를 완전 사례 분석 complete case analysis, casewise
deletion이라고 한다. 예를 들어, 성폭력 피해율을 분석하는 조사에서
응답자의 나이, 성별, 소득 수준 등을 포함한 통계분석을 수행한다고
가정하자. 이때, 응답자가 소득 수준을 밝히지 않았다면 해당 응답을
분석에서 제외하는 방식이다.

장점: 단순하고 직관적인 방법이며, 별도의 가정 없이 기존 데이터만을
이용하여 분석이 가능하다.

단점: 일부 응답을 삭제하면 표본 크기가 줄어들어 분석의 정확도가
떨어지고, 특정 집단(예: 고소득층, 피해 경험이 심한 응답자 등)이
과소표집될 가능성이 있다.

결측값을 보완하는 방법

보다 정확한 분석을 위해서는 누락된 값을 합리적으로 예측하여 보완하는
방법(결측값 대체)을 사용할 수 있다. 이 방법은 분석의 신뢰성을 높이고,
모집단을 보다 정확하게 반영할 수 있도록 돕는다.

5)  결측값 대체 방법

  ------------------ ------------------------ ----------------------------
      대체 방법                장점                       단점

    완전 사례 분석     단순하고 직관적이며,      데이터 손실 발생 가능,
                     추가적인 가정 없이 분석  모집단 대표성이 감소할 위험
                               가능           

      평균 대체      계산이 간단하고 빠르며,    분산 감소로 인해 데이터
                         데이터 손실 없음     변동성이 왜곡될 가능성 있음

     확률적 대체     변동성을 유지하여 데이터   무작위성이 도입되어 결과
                           왜곡을 방지          변동성이 증가할 수 있음

      회귀 대체        다른 변수와의 관계를   모델이 잘못 설정되면 왜곡된
                       고려하여 현실적인 값      값이 대체될 위험 있음
                            대체 가능         

      핫덱 대체       실제 응답자의 데이터를  적절한 유사 기준을 설정하는
                     활용하여 자연스러운 대체 것이 중요, 표본 크기 작으면
                               가능             부적절한 대체 발생 가능

      다중 대체      불확실성을 반영하여 보다 계산량이 많고 통계적 해석이
                      신뢰성 높은 결과 제공       다소 복잡할 수 있음
  ------------------ ------------------------ ----------------------------

2대체 방법

1)  평균 대체 mean imputation

가장 간단한 방법은 결측값을 해당 변수의 평균값으로 대체하는 방법이다.
예를 들어, 가족 소득 정보를 응답하지 않은 경우, 조사된 응답자의 평균
소득 값으로 해당 값을 채우는 방식이다.

장점: 계산이 간단하고, 모든 표본을 유지할 수 있다.

단점: 모든 결측값이 동일한 값으로 채워지기 때문에 데이터의 변동성이
왜곡될 위험이 있다.

6)  확률적 대체 stochastic imputation

평균 대체의 단점을 보완하기 위해, 확률적 요소를 추가하여 변동성을
반영하는 방법도 있다. 이 방법에서는 평균값을 기본값으로 사용하되,
정규분포에서 무작위로 선택된 값을 더하여 변동성을 유지한다.

장점: 평균 대체의 단점을 보완하며, 실제 데이터와 유사한 변동성을 유지할
수 있다.

단점: 무작위 요소가 포함되므로 분석 결과가 달라질 수 있으며, 적용이 다소
복잡할 수 있다.

평균 대체와 확률적 대체 사례

예를 들어, 100명의 응답자가 소득을 보고했으며, 평균 월소득이 5백만원,
표준편차가 백만원이라 가정하자. 또한, 5명의 응답자는 소득을 밝히지
않았다(결측값 발생).

평균 대체: 5명의 소득을 5백만원으로 채우게 된다.

확률적 대체: 정규분포 N(500, $100^{2}$) 에서 무작위로 5개 값을 추출하여
대체한다.

7)  회귀 대체 regression imputation

결측값을 다른 변수들과의 관계를 고려하여 예측하는 방식도 있다.예를 들어,
응답자의 나이, 교육 수준, 직업 정보를 이용하여 소득 수준을 회귀 모델로
예측하고 결측값을 채운다면, 보다 정교한 대체가 가능하다. 소득을 예측하기
위해 나이(Age), 교육 수준(Education Level), 직업(Job Type) 등의 변수를
사용한 회귀모델을 사용하자. 항목 응답자 데이터만을 사용하여 회귀계수를
추정하여 무응답 항목 ${\widehat{y}}_{i(r)}$을 추정한다.

$$y_{i(r)} = \alpha + \beta_{1}\text{Age}_{i(r)} + + \beta_{2}\text{Edu}_{i(r)} + \beta_{3}\text{Job}_{i(r)} + e_{i(r)}$$

장점: 단순한 평균 대체보다 더 현실적인 값을 채울 수 있다.

단점: 회귀 모델이 잘못 설정되면 왜곡된 결과가 나올 수 있으며, 대체된
값이 원래 데이터보다 과도하게 일관된 패턴을 보일 수 있다.

8)  핫덱 대체 Hot-Deck imputation

핫덱 대체는 결측값을 비슷한 특성을 가진 응답자의 실제 데이터로 대체하는
방법이다. 이는 결측값이 있는 항목과 유사한 특성을 가진 다른 응답자의
값을 찾아 채워 넣는 방식으로 조사 데이터에서 유사한 패턴을 유지하면서도
데이터의 신뢰도를 높일 수 있는 장점이 있다.

예를 들어, 성폭력 피해 조사에서 피해자의 나이, 성별, 지역 등이 유사한
다른 응답자의 데이터를 참조하여 결측값을 채운다면 보다 현실적인 대체가
가능하며, 데이터의 변동성을 유지하면서도 모집단을 반영할 수 있다. 핫덱
대체는 통계적 방법 뿐만 아니라, 설문 조사 및 행정 데이터 분석에서도 널리
사용되는 결측값 처리 기법이다.

장점: 평균 대체나 회귀 대체보다 현실적인 값이 채워질 가능성이 크다.

단점: 적절한 유사 기준을 설정하는 것이 중요하며, 표본 크기가 작을 경우
적절한 대체값을 찾기 어려울 수 있다.

핫덱 Hot-Deck

같은 데이터셋 내에서 유사한 응답자의 값을 가져와 대체하는 방식으로 조사
대상자가 많고 동일한 조건을 가진 응답자가 많을 때 효과적이다.

콜드덱 Cold-Deck

과거의 다른 데이터셋이나 외부 자료에서 값을 가져와 대체하는 방식으로
데이터가 부족할 경우 활용되지만, 시간이 지난 데이터가 반영될 가능성이
있음.

핫덱 대체 과정

\(1\) 데이터 정렬 및 유사 집단 형성

연령, 성별, 교육 수준, 지역 등의 변수에 따라 데이터를 그룹화한다.

예를 들어, 나이(20\~29세), 성별(여성), 지역(서울)으로 그룹을 나누는
방식이 있다.

\(2\) 결측값이 있는 응답자 식별

특정 변수에서 결측값이 발생한 응답자를 찾는다.

\(3\) 적절한 응답 값 선택

같은 그룹 내에서 유사한 응답자를 찾아 데이터 값 대체

일반적으로 가장 가까운 응답자 값을 결측값 대체한다.

\(4\) 결측값 대체 수행

응답자의 값을 결측값이 있는 응답자의 변수에 적용한다.

다수의 유사한 응답자가 있을 경우, 랜덤하게 선택하여 대체할 수도 있다.

9)  다중 대체 multiple imputation

하나의 대체값만 사용하는 것이 아니라, 여러 개의 대체값을 생성하여 각각의
분석을 수행한 후 결과를 종합하는 방식이다. 예를 들어, 동일한 결측값에
대해 평균 대체, 회귀 대체, 핫덱 대체 등 다양한 방법을 활용하여 여러 개의
데이터 세트를 만들고, 그 평균을 최종 분석에 반영하는 방식이다.

장점: 단일 대체보다 더 정확한 추정이 가능하며, 불확실성을 반영할 수
있다.

단점: 계산량이 많고, 통계적 해석이 다소 복잡할 수 있다.

Chapter 4. 복합표본 분산 추정

조사 데이터는 단순한 확률 표본이 아니라 층화, 다단계 표본 추출, 가중치,
결측값 대체 등의 복잡한 구조를 가지는 경우가 많다. 이러한 요소들은
단순한 표본 추출과 달리 표본 간의 상관관계를 증가시키며 표본의 실제
분산을 과소 또는 과대 추정할 가능성이 있다. 따라서, 일반적인 분산 추정
방법이 아닌, 복합 표본 설계를 반영한 분산 추정 방법을 적용해야 한다.

1테일러 급수 근사법(Taylor Series Approximation)

테일러 급수 근사법은 비율(비율, 오즈비 등)과 같은 비선형 통계량의 분산을
추정하는 대표적인 기법이다. 비율 기반 통계량은 단순한 합(sum) 연산으로
분산을 추정할 수 없으므로, 테일러 급수를 활용하여 비율을 근사값으로
변환한 후 분산을 계산한다.

\(1\) 개념

테일러 급수 근사법은 복잡한 분산 계산을 단순한 합산(Summation) 형태로
변환하여 수행한다. 즉, 비율 같은 복잡한 통계량을 단순화하여 쉽게 분산을
추정할 수 있도록 변환하는 방법이다.

\(2\) 테일러 급수 근사를 이용한 가중 평균의 분산

조사 데이터에서 가중 평균(${\overline{Y}}_{w})$을 사용하여 분산을
추정하는 방법은 다음과 같다.

$$\overline{Y}w = \frac{\sum{i = 1}^{n}w_{i}y_{i}}{\sum_{i = 1}^{n}w_{i}}$$

테일러 급수 근사법을 사용하면, 해당 가중 평균의 분산은 다음과 같이
표현된다.

$$\frac{1}{(\sum w_{i})^{2}}\left\lbrack Var(\sum w_{i}y_{i}) + {\overline{Y}}_{w}^{2}Var(\sum w_{i}) - 2{\overline{Y}}_{w}Cov(\sum w_{i}y_{i},\sum w_{i}) \right\rbrack$$

이는 단순한 분산 계산보다 복잡하지만, 복합 표본 설계에서의 정확한 분산
추정을 위해 필수적인 접근법이다.

\(3\) 특징

현재 가장 널리 사용되는 방법으로, SAS, Stata, SUDAAN 등의 통계
소프트웨어에서 기본적인 복합 표본 분산 추정 방식으로 채택하고 있다.

비율, 평균, 회귀 계수 등의 다양한 통계량에 적용 가능하다.

가중치를 고려한 복합 표본의 구조를 반영하여 보다 정확한 분산 추정을
수행할 수 있다.

2균형 반복 복제법(Balanced Repeated Replication, BRR)

균형 반복 복제법(BRR)은 표본을 여러 개의 하위 표본(Replicates)으로
분할한 후, 각 표본에 대해 통계량을 계산하여 분산을 추정하는 방식이다.

\(1\) 개념

전체 표본을 반으로 나누어 여러 번 반복하여 표본을 추출한다.

각 표본에서 평균(${\overline{Y}}_{r}$)을 계산하고, 그 평균의 변동성을
기반으로 전체 표본의 분산을 추정한다.

$$\overline{Y} = \frac{1}{c}\overset{c}{\sum_{r = 1}}{\overline{Y}}_{r}$$

분산은 다음과 같이 계산된다.

$$Var(\overline{Y}) = \frac{1}{c(c - 1)}\overset{c}{\sum_{r = 1}}({\overline{Y}}_{r} - \overline{Y})^{2}$$

\(2\) 특징

층화된 복합 표본설계에 유용하며 분산 추정의 정확도가 높다.

2단계 이상의 복합 표본 조사에서 적절하게 사용 가능하다.

단점은 복잡한 표본 설계에서는 적절한 균형을 맞추기 어렵다는 점이 있다.

3잭나이프 반복 복제법(Jackknife Repeated Replication, JRR)

잭나이프 반복 복제법은 데이터에서 하나의 표본 또는 하나의
군집(Cluster)을 제외한 후 통계량을 계산하여 분산을 추정하는 방식이다.

\(1\) 개념

원래 표본에서 한 개의 케이스(또는 클러스터)를 제거한 표본을 만든다.

해당 표본에서 평균(${\overline{Y}}_{r}$)을 계산한다.

이 과정을 여러 번 반복한 후, 평균의 변동성을 기반으로 전체 분산을
추정한다.

\(2\) 특징

데이터에서 하나씩 제거하는 방식으로 수행되므로, 계산 과정이 단순하다.

비선형 통계량에서도 안정적인 분산 추정이 가능하다.

단점은 표본 크기가 작을 경우, 반복 횟수가 부족하여 분산 추정의 신뢰도가
낮아질 수 있다.

4비교

테일러 급수 근사법은 가장 널리 사용되며, 대부분의 소프트웨어에서
기본적으로 적용된다.

균형 반복 복제법은 층화 표본에서 높은 정확도를 보이지만, 표본 크기에
따라 조정이 필요하다.

잭나이프 반복 복제법은 단순한 구조에서 유용하지만, 복잡한 표본
설계에서는 한계가 있다.

Chapter 5. 조사 데이터 문서화 및 메타데이터

조사 데이터는 단 한 번의 분석만을 위해 수집되지 않는다. 데이터 수집 후
단순히 한 명의 연구자가 분석하고 끝나는 것이 아니라 수년 동안 다양한
연구자가 재분석하고 새로운 연구에 활용된다.

이처럼 조사 데이터는 장기간 동안 여러 연구자가 활용할 수 있도록 체계적인
문서화가 필요하며, 연구자가 데이터를 분석하기 전에 데이터의 기본 속성을
이해할 수 있도록 제공하는 정보가 필수적이다. 이러한 데이터를 설명하는
정보를 메타데이터 Metadata라고 한다.

메타데이터란 조사 데이터에 대한 정보(["]{dir="rtl"}데이터에 대한
데이터")를 의미하며 연구자가 데이터를 이해하고 활용할 수 있도록 제공하는
모든 정보를 포함한다.

메타데이터의 주요 목적은 조사 데이터의 속성을 명확하게 설명하여 연구자가
데이터를 효과적으로 활용할 수 있도록 하는 것이다.

특정 연구자가 아닌, 전 세계 누구나 데이터의 의미를 쉽게 이해할 수 있도록
표준화된 문서화를 제공하는 것이 핵심이다.

메타데이터의 주요 유형

  ----------------------- -----------------------------------------------
      메타데이터 유형                          설명

     정의적 메타데이터     조사 대상 모집단, 표본 설계, 질문 문구, 코딩
                                          용어 등을 설명

     절차적 메타데이터     조사원 교육 절차, 표본 선정 방법, 데이터 수집
                                   과정 등 조사 프로토콜을 설명

     운영적 메타데이터    결측 데이터 비율, 데이터 수정 실패율, 평균 조사
                           시간, 조사원이 완료한 케이스 수 등 조사 품질
                                          평가 정보 포함

     시스템 메타데이터      데이터 파일 형식, 파일 위치, 데이터 검색 및
                                  호출 방법, 변수 정의 등을 설명
  ----------------------- -----------------------------------------------

메타데이터 예시

  ------------------- ---------------------------------------------------
         항목                                설명

        변수명                       AR21 (피해 보고 항목)

       질문 문구      당신의 재산이 손상되었거나 파괴된 적이 있습니까?\'

      데이터 위치                      컬럼 140, 너비 1

      결측값 처리                   -9 (무응답), -0 (모름)

      데이터 수준                가구 데이터 또는 개인 데이터

    추가 메타데이터     표시(X)하여 해당하는 모든 항목을 선택하세요.\'
  ------------------- ---------------------------------------------------

메타데이터 설계의 중요성

메타데이터의 발전은 조사 방법론 연구자에게 새로운 기회와 도전 과제를
동시에 제공한다.

조사 품질 평가 및 사용자 확장: 조사 품질을 측정하는 재조사 연구, 응답
분산 추정 등의 정보가 쉽게 제공될 수 있다. 이를 통해, 조사 데이터의
신뢰성을 높이고, 다양한 연구자들이 데이터를 활용할 수 있도록 지원한다.

설문지 개발 과정에서의 연계: 특정 문항에 대해 과거 연구에서의 활용 방식,
문항 재설계 사례, 응답자 행동 데이터(Behavior Coding) 등과 연계하여 문항
개발이 가능하다.

연구자의 데이터 활용 지원: 연구자가 분석을 수행하기 전, 특정 변수가 과거
연구에서 어떻게 활용되었는지를 쉽게 확인할 수 있도록 설계할 수 있다.
이를 통해 조사 데이터의 신뢰성을 유지하면서도, 보다 효율적인 데이터
분석을 지원할 수 있다.

메타데이터는 단순한 부가 정보가 아니라, 조사 데이터를 보다 효과적으로
활용할 수 있도록 지원하는 핵심 요소이다. 특히, 대규모 조사 데이터에서는
메타데이터의 체계적인 관리와 전자 문서화가 필수적이다.

메타데이터는 조사 데이터의 활용도를 높이고, 연구자가 데이터를 쉽게
이해할 수 있도록 돕는 중요한 역할을 한다.

전통적인 코드북에서 벗어나, 전자 문서화와 웹 기반 시스템이 발전하면서
보다 효율적인 데이터 관리가 가능해지고 있다.

조사 설계 단계에서부터 메타데이터의 체계적인 구성을 고려하는 것이
중요하며, 이를 통해 조사 품질을 높이고 연구자들이 보다 쉽게 데이터를
활용할 수 있도록 해야 한다.

결국, 좋은 조사 데이터는 메타데이터가 잘 정리되어 있어야 한다. 조사
데이터를 체계적으로 문서화하고, 연구자들이 손쉽게 접근할 수 있도록
메타데이터를 설계하는 것이 향후 조사 연구의 핵심 과제가 될 것이다.

저자 정보

1982\. 성균관대학교 통계학 학사

1985\. 성균관대학교 통계학 석사

1992\. 미국 North Carolina State University 통계학 박사

1993-1995. 전자통신연구원 선임연구원

1995-2026. 한남대학교 통계학과 교수
